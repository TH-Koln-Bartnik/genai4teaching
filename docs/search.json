[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "KI als Hilfe zum Lehren und Lernen",
    "section": "",
    "text": "Übersicht\nDieses Buch untersucht, wie generative künstliche Intelligenz (GenAI) Lehre, Lernen und Forschung verändern kann. Es richtet sich an Lehrende, Forschende und Studierende, die verstehen möchten, wie KI als Werkzeug der Hochschuldidaktik eingesetzt werden kann.\nDas Buch besteht aus fünf Kapiteln:\n\nÜberblick: KI als Hilfe zum Lehren und Lernen\n\nGrundbegriffe und technische Grundlagen\n\nDidaktische Prinzipien und Cognitive Science\n\nPraxisbeispiele: KI als Hiwi, Copilot, Tutor, Simulator\n\nEmpfehlungen zur Umsetzung\n\n\nIm ersten Teil fassen wir die aktuelle Forschungslage zusammen.",
    "crumbs": [
      "Übersicht"
    ]
  },
  {
    "objectID": "kapitel01.html",
    "href": "kapitel01.html",
    "title": "1  Einleitung",
    "section": "",
    "text": "1.1 KI als Hilfe für die Lehre\nWie kann uns generative künstliche Intelligenz (KI) in der Lehre helfen? Hoffnung besteht hier für zwei typische Probleme: Erstens haben Studierende individuelle Bedürfnisse, aber wir haben nur begrenzte Zeit, auf diese einzugehen. Wie können wir Einzelne möglichst intensiv fördern, ohne vor Arbeit unterzugehen? Zweitens ist der Aufwand gerade für effektive Lehrmethoden oft sehr hoch, so etwa für häufige niedrigschwellige Tests, oder individuelles Feedback zu Studienarbeiten (Brown, Roediger, et al., 2014; s. etwa Hattie, 2023, Kap.13). Wer lehrt, fühlt sich aus Zeit- und Stoffdruck oft gezwungen, Abstriche von idealen Lehrsetups zu machen (Henderson & Dancy, 2007; Schmidt & Tippelt, 2005, S.104–105). Gerade Lehrmethoden, die didaktisch sinnvoll, aber mit hohem Aufwand verbunden sind, drohen dabei auf der Strecke zu bleiben (Brown, Roediger III, et al., 2014).\nFür die Lehre erschließen sich durch die großen KI-Sprachmodelle (LLM = Large Language Models) neue Möglichkeiten. Sie sind, wie es eine Analyse des MIT Professors Andrew McAfee auf den Punkt bringt „generally faster” (McAfee, 2024). Lehrende können mit KI-Unterstützung etwa deutlich schneller ein Set von Übungsaufgaben erstellen, mehrere Anwendungsbeispiele pro Konzept hinzufügen, Quizfragen zur schnellen Lernüberprüfung generieren, oder mit den Studierenden Rollenspiele durchführen (Meincke et al., 2024; E. Mollick & Mollick, 2023). Der Berg ist noch da, aber mit dem E-Bike kommt man weiter.\nImmer mehr Aspekte von typischen Forschungstätigkeiten – ein zentraler Ausbildungsinhalt der Hochschulen – können von der KI übernommen werden und zwar auf hohem Niveau. Vorbei sind die Zeiten, in denen wir die banalen Schreibprodukte der KI nur belächeln konnten. Ein Überblicksartikel des Forschers Anton Korinek im renommierten Journal of Economic Literature vom Dezember 2024 fasst das deutlich höhere Niveau zusammen: „die derzeitige Generation von LLMs ist in hohem Maße in der Lage, die wichtigsten Erkenntnisse von Forschungsarbeiten zu verarbeiten” (Korinek, 2024-12 (update), S.3, Übersetzung RB mit DeepL). Die professionelle Nutzung ist hier noch weiter: So demonstrierte etwa Google 2025 ein mehrstufiges Modell für die Pharma-Forschung („AI co-scientist”), das den Forschenden zeitintensive Zwischenschritte abnimmt (Gottweis et al., 2025). Auch im Peer-Review werden zunehmend Sprachmodelle eingesetzt – mit allen Vor- und Nachteilen, die das mit sich bringt (Naddaf, 2025a). Wie wir in den späteren Kapiteln sehen, experimentieren Hochschulen weltweit intensiv mit den neuen Möglichkeiten für Lehre und Forschung.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Einleitung</span>"
    ]
  },
  {
    "objectID": "kapitel01.html#aktuelle-weiterentwicklungen-der-sprachmodelle",
    "href": "kapitel01.html#aktuelle-weiterentwicklungen-der-sprachmodelle",
    "title": "1  Einleitung",
    "section": "1.2 Aktuelle Weiterentwicklungen der Sprachmodelle",
    "text": "1.2 Aktuelle Weiterentwicklungen der Sprachmodelle\nDrei zentrale Weiterentwicklungen zwischen 2024 und 2025 sind laut Korinek für den deutlichen Sprung in forschungsrelevanten Fähigkeiten der Sprachmodelle verantwortlich (Korinek, 2024-12 (update), S.2–3): Erstens neue Interaktionsmöglichkeiten – während die typische Nutzung früher auf Texteingabe im Eingabefenster beschränkt war, bieten die großen Sprachmodelle mittlerweile die Möglichkeit an, in einem Workspace gemeinsam an Text oder Code zu arbeiten (z.B. ChatGPT Canvas, Claude Artifacts). Zweitens eine deutliche Verbesserung der Problemlösefähigkeit (reasoning) der Modelle. Den stärksten Modellen (Chat GPT-5, Gemini 2.5, Claude Opus 4.1) kann man mittlerweile dabei zusehen, wie sie mehrstufiges Problemlösen und logisches Schlussfolgern etwa bei Rechercheaufgaben durchführen. Die Bedeutung von präzisen Prompt-„Zaubersprüchen” nimmt ab, da die neueren (Reasoning) Modelle ohnehin selbst Schritt für Schritt vorgehen und nachfragen (Meincke et al., 2025). Insgesamt steigt seit 2023 die Qualität der Aufgaben, die Sprachmodelle erledigen können, rasant. Empirische Untersuchungen zeigen, dass die Sprachmodelle immer längere Aufgaben auf hohem Niveau erledigen können (Kwa et al., 2025).\nWas ändert sich durch GTP-5? Aus User-Sicht ist GPT-5 im Vergleich zu Vormodellen selbstständiger geworden, User müssen nicht mehr selbst zwischen vielen unterschiedlichen Modellen auswählen. Je nachdem, wie einfach die Frage ist, wird Schnelligkeit bevorzugt (durch Nutzung eines kleineren Modells wie GPT-5 nano) oder es wird ein schwereres Werkzeug angelegt (mehrstufiges Suchen und Reflektieren mit einem größeren Modell). Diese „schlaueren” Reasoning Modelle werden somit jetzt gerade für komplexere Fragen häufiger zur Anwendung kommen – nach Herstellerangaben stieg die Nutzung dieser stärkeren Modelle unter den zahlenden Usern von 7% auf 24%, was insgesamt die Qualität der Ergebnisse steigern sollte. Die neuen Modelle sind wiederum deutlich effizienter geworden, mit stark sinkenden Kosten pro Prompt. Eine Millionen Token kosteten mit GPT-4 noch 50 Dollar, jetzt nur noch 14 Cent (InvertedStone, 2025; Ethan Mollick, 2025). Das Modell halluziniert (weiterhin, also Vorsicht, aber) deutlich seltener als seine Vorgänger: OpenAI gibt hier ca. 1% Halluzinationen der Antworten statt ca. 5% bei Vorgängermodellen (o3, 4o) an, je nach Komplexität der Frage und erlaubter „Bedenkzeit” (OpenAI, 2025).\nDrittens hat sich die Internetsuche mit LLMs deutlich verbessert. Während man früher noch oft über sinnlose oder erfundene Ergebnisse lachte, stellt die Suche von ChatGPT, Google/Gemini, oder speziellen Suchanbietern wie Perplexity mittlerweile eine große Zeitersparnis dar: „a useful tool to provide up-to-date answers to questions that are grounded in facts found on the internet, together with the requisite citations—a crucial capability for researchers” (Korinek, 2024-12 (update), S.3). Das gilt zunehmend für die stärksten allgemeinen Modelle und erst recht für Anbieter, die auf Forschungsrecherche (und Studierende) spezialisiert sind, wie Elicit oder Paperpal. Auch breite Internet-Recherchen und Textproduktionen sind zunehmend komplett delegierbar („deep research”), mit deutlichen Auswirkungen auf den Arbeitsprozess in der Wissensarbeit Liang et al. (2025).",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Einleitung</span>"
    ]
  },
  {
    "objectID": "kapitel01.html#wie-nutzen-studierende-und-lehrende-genai",
    "href": "kapitel01.html#wie-nutzen-studierende-und-lehrende-genai",
    "title": "1  Einleitung",
    "section": "1.3 Wie nutzen Studierende und Lehrende GenAI?",
    "text": "1.3 Wie nutzen Studierende und Lehrende GenAI?\nAuch Studierende nutzen bereits umfangreich Sprachmodelle für einen breiten Strauß an Zielen (s. Abbildung 1.1). Eine Auswertung der KI-Forscher des KI-Unternehmens Anthropic von 1 Millionen anonymisierten Chats zwischen Usern mit Universitätskonto und dem KI Bot zeigt typische Muster der Nutzung (Handa et al., 2025): Studierende setzen das Sprachmodell vor allem für anspruchsvolle Tätigkeiten ein, wie das Erstellen neuer Inhalte und das Analysieren komplexer Themen, was höheren Ebenen der Bloomschen Taxonomie entspricht. Daraus ergibt sich die Herausforderung sicherzustellen, dass Studierende wesentliche kognitive Aufgaben nicht vollständig an KI delegieren: Aufgaben müssen angepasst und der verantwortungsvolle Umgang mit der Technik muss eingeübt werden.\n\n\n\n\n\n\nAbbildung 1.1: Wofür Studierende LLMs nutzen Quelle: Handa et al. (2025)\n\n\n\n\n\n\n\n\n\nAbbildung 1.2: Schwerpunkte der Nutzung von LLMs (Claude) durch Studierende nach der Bloom’schen Taxonomie. Quelle: Handa et al. (2025)\n\n\n\nAuch außerhalb der Hochschule steigt die Nutzung. Eine Reihe von Studien zeigen erhöhte Produktivität von Büroarbeitenden mit LLM-Unterstützung: der Kundensupport arbeitet 15% schneller, wenn das Sprachmodell Antwortoptionen vorschlägt und Verweise auf interne technische Dokumentation anbietet (Brynjolfsson et al., 2025), Programmierer programmieren schneller (Peng et al., 2023), Consultants sind produktiver bei komplexen Beratungsprojekten (Dell’Acqua et al., 2023) und Sprachmodelle wie ChatGPT können eine Vielzahl kleiner Aufgaben beschleunigen (Handa et al., 2025) und werden insofern gerade zur Texterstellung schon millionenfach als Hilfsmittel im Beruf genutzt: Von Kundenbewertungen über Pressemitteilungen und Stellenanzeigen (Liang et al., 2025).\nDie zunehmende Verwendung von KI in der Lehre hat gute Gründe. Wie oft eine neue Technologie genutzt wird, hängt nach dem Technology Acceptance Model (TAM) von der wahrgenommenen Benutzerfreundlichkeit (perceived ease of use) und der wahrgenommenen Nützlichkeit (perceived usefulness) ab (Marangunić & Granić, 2015). Generative KI wie ChatGPT decken sichtlich beide Aspekte ab: Sie sind einfach zu nutzen (Kestin et al., 2025; Lee et al., 2025; Monib et al., 2025; Naddaf, 2025b) und erzeugen einen deutlichen Mehrwert, wie Studierende und Lehrende in einer Vielzahl von Umfragen der letzten zwei Jahren berichten (Heidt, 2025; Morgan, 2024; Ou et al., 2024). Lehrende ziehen nach: Meta-Untersuchungen zeigen ein extremes Wachstum an Publikationen zur Nutzung von LLM im Hochschulalltag (Ma, 2025; Ogunleye et al., 2024).",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Einleitung</span>"
    ]
  },
  {
    "objectID": "kapitel01.html#risiken-und-nebenwirkungen",
    "href": "kapitel01.html#risiken-und-nebenwirkungen",
    "title": "1  Einleitung",
    "section": "1.4 Risiken und Nebenwirkungen",
    "text": "1.4 Risiken und Nebenwirkungen\nDie Metapher mit dem E-Bike trägt allerdings auch, was die Risiken und Nebenwirkungen angeht: Ab wann lässt die maschinelle Unterstützung wichtige Muskeln verkümmern? Solche Gefahren bestehen – wie empirische Studien zeigen, erfordern die neuen Workflows der Wissensarbeit durch KI-Unterstützung auch neue Formen der kritischen Auseinandersetzung mit den Inhalten. Die Analyse von 1 Millionen anonymisierten Studierenden-Chats durch Anthropic (Handa et al., 2025) zeigt einerseits, dass Studierende das LLM vor allem für kognitiv anspruchsvollere Aufgaben einsetzen, vor allem in den Kategorien „Creating” und „Analyzing” (s. Abbildung 1.2). Dies steht im deutlichen Gegensatz zur Nutzung von einfachen Internetsuchen, die einen Schwerpunkt auf dem Finden einzelner Fakten haben.\nWie kann man verhindern, dass die Studierenden kritische kognitive Aufgaben allein den KI-Systemen übergeben? Eine Studie von 319 Wissensarbeitern zeigt, dass sich das Gewicht zwischen den Einzelaufgaben der Wissensarbeit mit LLMs verschiebt: Der Aufwand für die Recherchen selbst sinkt, es steigt anderseits der Aufwand für Management-ähnliche Aufgaben: Koordination der Einzelaufgaben für Mensch und Maschine, kritische Prüfung der berichteten Ergebnisse und die Integration von Ergebnissen in den Gesamtprozess (etwa zur Erstellung eines Gesamtberichtes, einer Test-Spezifikation oder eines Protokolls) (Lee et al., 2025). Werden solche neuen Vorgehensweisen nicht geübt, droht ein Rückgang des kritischen Denkens. Lehre heißt in diesem Kontext auch, empfohlene Arbeitsweisen mit der neuen Technik zu üben.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Einleitung</span>"
    ]
  },
  {
    "objectID": "kapitel01.html#kapitelübersicht",
    "href": "kapitel01.html#kapitelübersicht",
    "title": "1  Einleitung",
    "section": "1.5 Kapitelübersicht",
    "text": "1.5 Kapitelübersicht\nIm Folgenden werden wir zunächst einige Grundbegriffe klären: Was sind große Sprachmodelle und was ist mit Begriffen wie Token, Prompt und RAG gemeint? Welche Modelle können Lehrende aktuell nutzen und welche Empfehlungen für Prompts sind belastbar (Abschnitt 2.5)? Dann fragen wir nach Zielen: Welche Art von Wissen und Methoden unterscheidet und empfiehlt die Lernforschung? Welche didaktischen Wirkmechanismen können durch KI genutzt werden, um typische Probleme der Hochschullehre anzugehen (Abschnitt 3)? Im Abschnitt 4 schauen wir auf Praxisbeispiele für vier Anwendungsfelder von Sprachmodellen an Hochschulen: KI als Hiwi (direkte Arbeitserleichterung), KI als Copilot (Unterstützung beim Schreiben und Coden) und KI als Tutor (Feedback und Lernunterstützung) sowie KI als Simulator (Role Play und Goal Play). Abschließend zeigen wir verschiedene Anwendungen von KI in verschiedenen Kurstypen und gehen auf neue Herausforderungen für Prüfungen ein (Abschnitt 5). Im Appendix werden Risiken von KI, rechtliche Rahmenbedingungen und konkrete Prompts und Aufgabenbeispiele aufgeführt.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Einleitung</span>"
    ]
  },
  {
    "objectID": "kapitel02.html",
    "href": "kapitel02.html",
    "title": "LLM vs RAG vs Agent",
    "section": "",
    "text": "2.1 Definition einiger Grundbegriffe\nHier führen wir kurz ein, was es mit Begriffen wie Transformer, Token, Kontextfenstern und Prompts auf sich hat. Technische Details klammern wir dabei aus, es geht nur um eine kurze Begriffsbestimmung.\nAls visuelle Begleitung empfehle ich das sehr schöne Einführungsvideo des Mathematik-Didaktikers Grant Sanderson (7 Minuten). Tiefer in die mathematischen Details geht die grafische und interaktive Einführung als Animation von Brendan Bycroft. Wer tiefer in die Hintergründe einsteigen will, kann das Lehrbuch-Standardwerk von Jurafsky & Martin (2025) nutzen, das online frei verfügbar ist.\nEin Large Language Model (LLM) ist ein fortschrittliches maschinelles Lernmodell, das speziell darauf trainiert ist, menschliche Sprache zu verstehen und Texte zu erzeugen, die natürlich erscheinen. Die Modelle können erstaunliche Mengen von Textdaten verarbeiten, um vielseitige Sprachanwendungen zu ermöglichen.\nDie generative Künstliche Intelligenz (GenAI) bezieht sich auf Systeme, die fähig sind, neue Inhalte zu erzeugen, wie etwa Texte, die noch nicht existierten. LLMs sind ein zentraler Teil dieser generativen KI und können eigenständig Texte zu einem breiten Spektrum von Themen generieren.\nDas Sprachmodell (s. Abbildung 3) zerlegt dazu grob gesagt Inputs wie Texte in kleine Bausteine (Tokens), verwandelt diese in Zahlen (Embeddings), erkennt mithilfe komplexer Muster (Transformer und Attention) deren Zusammenhänge, und erzeugt auf diese Weise selbstständig basierend auf kontextbezogen berechneten Wahrscheinlichkeiten neue Texte (generative Sprachproduktion).\nHier kann man das selbst einfach ausprobieren: Das interaktive Widget simuliert eine GPT-2-ähnliche Tokenisierung.\nQuelle: Erstellt basierend auf Miguel Grinberg, https://blog.miguelgrinberg.com/post/how-llms-work-explained-without-math\nSiehe dazu auch die animierte Darstellung von Grant Sanderson:\nSprachmodelle wie ChatGPT funktionieren insofern wie ein sehr gut trainierter Autovervollständiger für Texte. Wenn man ihm den Anfang eines Satzes gibt, sagt es mit hoher Wahrscheinlichkeit voraus, wie der Satz weitergeht – basierend auf Milliarden von Textbeispielen, die es zuvor „gelesen“ hat. Damit GPT Sprache verstehen und erzeugen kann, zerlegt es jeden Text in sogenannte Tokens – kleine Bausteine wie Wörter, Wortteile oder Satzzeichen. Jedes dieser Tokens wird in einen Vektor umgewandelt – eine Zahlenreihe, die das Wort mathematisch beschreibt. Dieser Vorgang nennt sich Embedding. Dabei wird darauf geachtet, dass ähnliche Wörter ähnliche Vektoren erhalten, beispielsweise „Hund“ und „Katze“.\nDas Herzstück von GPT, dem Generative Pre-trained Transformer, ist der sogenannte Transformer – ein Rechenmodell, das durch ein spezielles Aufmerksamkeitsverfahren (Attention) erkennt, welche Wörter im Zusammenhang wichtig sind. Dadurch kann GPT die Bedeutung von Wörtern im Kontext richtig einschätzen. GPT „achtet“ besonders auf bestimmte Tokens (Wörter oder Satzteile), die für die jeweilige Aussage wichtig sind (s. @fig-transformer). Damit bestimmt das Modell, welche Begriffe stärker zur Bedeutung beitragen und in welchem Verhältnis sie zueinander stehen.\nBeispielsweise erkennt GPT dank Attention in einem Satz wie „Die Bank steht unter einem Baum“ anhand des Kontextes, ob „Bank“ ein Möbelstück oder eine Institution meint. Attention ist ein zentraler Bestandteil des Transformer-Modells und sorgt dafür, dass GPT Texte nicht nur wortweise, sondern im Gesamtkontext verstehen und sinnvoll vervollständigen kann.\nGPT wurde mit riesigen Textmengen vortrainiert (Pretraining), ohne konkrete Aufgaben lösen zu müssen – dieser Vorgang erfolgt unüberwacht (unsupervised learning).\nSprachmodelle nutzen häufig die Methode „Reinforcement Learning with Human Feedback“ (RLHF), um noch bessere Texte zu generieren. Dabei erzeugt das LLM zunächst verschiedene Textversionen, die von menschlichen Bewertern nach Qualität beurteilt werden. Diese Bewertungen dienen dazu, das Modell zusätzlich zu trainieren und zu steuern, indem Texte belohnt werden, die von Menschen als besonders gut, klar oder hilfreich eingeschätzt wurden. Durch diesen Prozess „lernt“ das LLM, Texte zu bevorzugen, die nicht nur sprachlich richtig, sondern für Menschen besonders verständlich und nützlich sind.\nDas macht es möglich, dass GPT später aus wenigen Stichworten neue Texte generieren kann – also kreativ Sprache produziert, ohne bloß zu kopieren (generativ). Der Begriff „generativ“ bedeutet in diesem Zusammenhang, dass GPT eigenständig neue, sinnvolle Texte erzeugen kann, indem es gelernte Muster neu kombiniert, anstatt fertige Texte zu übernehmen.\nToken sind die Bausteine der Sprachverarbeitung in LLMs und repräsentieren oft Wörter oder Satzzeichen. Die Zerlegung von Text in Token ermöglicht es dem Modell, mit Sprache auf einer granularen Ebene zu arbeiten. Auf Webseiten wie Tiktokenizer können wir selbst Text eingeben und diese Zerlegung ausprobieren.\nWas behält das Sprachmodell von unserer Unterhaltung? Wie viel Text kann ich – auch als PDF – hochladen? Neuere LLMs können schon ganze Bücher schnell aufsaugen und dann zusammenfassen (z.B. Claude, GPT-4o oder Gemini). Das Kontext-Fenster eines LLM beschreibt die Menge an vorherigem Text, die das Modell bei der Verarbeitung neuer Informationen berücksichtigt, um den Kontext und die Zusammenhänge zu verstehen.\nEin Prompt ist eine Eingabeaufforderung, die an ein LLM gesendet wird, um eine spezifische Antwort zu erhalten. Die Gestaltung dieser Prompts ist entscheidend für die Qualität der generierten Antworten und wird als Prompt Engineering bezeichnet.\nAgenten im Kontext von KI sind fortgeschrittene Prompts, die spezifische Aufgaben in natürlicher Sprache umsetzen. GPT-basierte Agenten können Text analysieren, generieren und verschiedene Aufgaben automatisieren, indem sie vorab definierte Muster und Regeln befolgen. Durch die Erstellung solcher Agenten können Lehrende interaktive und personalisierte Lerninhalte einfacher gestalten.\nWie unterscheiden sich Agenten von Sprachmodellen und RAG? Hier wird das anhand von Beispielen erläutert:\nimport { game } from \"./llm-rag-agent-game.ojs\"\ngame\nSprachmodelle haben mittlerweile mehrere Nutzungs-Muster - verschiedene Ansätze also, eine Anfrage zu beantworten. Hier stellt das Prof. Tom Yeh schön anschaulich an der Frage “Was ist der Sinn des Lebens?” dar:\nRAG (Retrieval-Augmented Generation) beschreibt die Möglichkeit, zusätzliche Daten wie Fachtexte, Statistiken oder Gesetzesbücher in Kombination mit einem KI Modell zu nutzen. Die KI ist das Gehirn, die zusätzliche Wissensdatenbank quasi das Bücherregal, das zu Rate gezogen werden kann. Je nach Kontextfenster stehen dort mehr oder weniger Bücher. Insofern umschreibt RAG ein KI-Modell, das die Fähigkeiten von Textgenerierungsmodellen (wie GPT) mit einer Wissensdatenbank kombiniert. So wird etwa der Prompt-Agent (s.u.) mit einer Reihe von Fachtexten „gefüttert“, in denen Best Practices des Prompting erklärt werden.\nDas Modell sucht nach relevanten Daten und integriert diese in die generierte Antwort. In der Lehre kann RAG verwendet werden, um den Studierenden Fachtexte oder besonders aktuelle Informationen zur Verfügung zu stellen. Beispielsweise könnten Studierende in einem Geschichtsseminar eine KI befragen, die externe Quellen durchforstet, um aktuelle Erkenntnisse zu historischen Ereignissen zu präsentieren. Unternehmen nutzen diese Technik, um etwa 1000-seitige Gebrauchsanweisungen mit KI durchsuchbar zu machen, oder Chatbots zu trainieren, die typische, repetitive Kundenanfragen beantworten. Insofern ermöglicht RAG eine dynamische und zeitgemäße Wissensvermittlung, die nicht auf das festgelegte Wissen des KI-Modells beschränkt ist.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>LLM vs RAG vs Agent</span>"
    ]
  },
  {
    "objectID": "kapitel02.html#definition-einiger-grundbegriffe",
    "href": "kapitel02.html#definition-einiger-grundbegriffe",
    "title": "LLM vs RAG vs Agent",
    "section": "2.2 LLM-Lernspiel",
    "text": "Lernspiel: Begriffe prüfen\n\n\n\nWollen Sie gleich prüfen, welche der Begriffe Sie schon kennen?\nHier ist ein kleines Lernspiel (als Artifact mit dem Sprachmodell Claude erstellt), in dem Sie die Begriffe den richtigen Definitionen zuordnen müssen:\n\n2.2 LLM-Lernspiel\n\n\n(am besten auf dem Computer spielen). Hier auch Online abrufbar (so etwas nennt sich “Artifact” beim Sprachmodell “Claude”) https://claude.site/artifacts/d8e3cee4-ea47-48e3-a84c-a774d408aac8\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAbbildung 2.1: Visualisierung von Transformator-Sprachmodellen. Quelle: Grant Sanderson, https://youtu.be/LPZh9BOjkQs\n\n\n\n\n\n\n\n\n\n\n\n\n\nBeispiel für die Umwandlung von Text in Token",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>LLM vs RAG vs Agent</span>"
    ]
  },
  {
    "objectID": "kapitel02.html#llm-lernspiel",
    "href": "kapitel02.html#llm-lernspiel",
    "title": "LLM vs RAG vs Agent",
    "section": "",
    "text": "(am besten auf dem Computer spielen). Hier auch Online abrufbar (so etwas nennt sich “Artifact” beim Sprachmodell “Claude”) https://claude.site/artifacts/d8e3cee4-ea47-48e3-a84c-a774d408aac8",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>LLM vs RAG vs Agent</span>"
    ]
  },
  {
    "objectID": "kapitel02.html#wie-denken-sprachmodelle-und-warum-halluzinieren-sie",
    "href": "kapitel02.html#wie-denken-sprachmodelle-und-warum-halluzinieren-sie",
    "title": "LLM vs RAG vs Agent",
    "section": "2.3 Wie denken Sprachmodelle und warum halluzinieren sie?",
    "text": "2.3 Wie denken Sprachmodelle und warum halluzinieren sie?\nEine Studie des KI-Labors Anthropic hat mit neuen Methoden den Denkprozess eines Sprachmodells im Detail nachgezeichnet Lindsey et al. (2025), was uns erstmals etwas genauer verstehen lässt, wie Sprachmodelle mit verschiedenen Sprachen umgehen, wie sie den Schreibprozess „planen“, wie sie bei Kalkulationen vorgehen, wie weit ihre Selbsterkenntnis reicht und warum sie manchmal Antworten erfinden („halluzinieren“).\n\n\n\n\n\n\nAbbildung 2.2: Visualisierte Gedanken eines Sprachmodells [@lindsey2025a]\n\n\n\n\nSprachübergreifend gleich: Das Modell nutzt einen gemeinsamen sprachübergreifenden Bedeutungsraum.\nTextplanung: Bei der Texterstellung plant das Modell mehrere Wörter im Voraus.\nParalleles Rechnen: Für Kalkulationen nutzt das Modell parallele Rechenpfade, die am Ende verbunden werden.\nMan traue nicht der Selbstkenntnis: Das Modell erfindet manchmal Argumentationsketten (motivated reasoning).\nBekanntheit führt zu Halluzinationen: Wenn das Modell eine genannte Entität „kennt“ (hier: den Namen des Forschers, Karpathy), aber nicht die Antwort auf die Frage (Titel des Fachartikels) führt das zu erfundenen Antworten (die „can’t answer“-Funktion wird unterdrückt).\n\nClaude nutzt einen gemeinsamen Bedeutungsraum für verschiedene Sprachen – ein Hinweis auf eine Art „universelle Denksprache“. Claude verarbeitet Informationen in einem sprachunabhängigen, abstrakten Bedeutungsraum. Bei der Frage nach dem „Gegenteil von klein“ in verschiedenen Sprachen (z. B. Englisch, Französisch, Chinesisch) aktivieren sich im Modell dieselben internen Merkmale für „Kleinheit“ und „Gegenteil“, unabhängig von der Eingabesprache. Erst in einem späteren Schritt wird die Antwort in die jeweilige Zielsprache übersetzt. Diese Erkenntnis legt nahe, dass Claude Wissen und Konzepte sprachübergreifend anwenden kann.\nPlant das Sprachmodell die Textgeneration? Entgegen der Annahme, dass Sprachmodelle Texte strikt Wort für Wort basierend auf dem unmittelbaren Kontext generieren, zeigt Claude die Fähigkeit, mehrere Wörter im Voraus zu planen. In Aufgaben zur Gedichtgenerierung identifiziert Claude beispielsweise Reimwörter, bevor es die vorhergehenden Zeilen formuliert. Ein Beispiel: Soll ein Gedicht mit dem Wort „Kaninchen“ enden, wählt Claude dieses Zielwort frühzeitig aus und gestaltet die Zeile so, dass sie darauf hinführt. ​Diese Fähigkeit zur Vorausplanung deutet darauf hin, dass Claude in der Lage ist, komplexe Textstrukturen zu erstellen, die über einfache Wortassoziationen hinausgehen.\nWie kalkulieren Sprachmodelle? Anthropic hat in seiner Studie zu Claude 3.5 Haiku detailliert untersucht, wie das Modell mathematische Berechnungen intern verarbeitet. Dabei wurde festgestellt, dass Claude bei Aufgaben wie der Addition von Zahlen parallele Rechenpfade nutzt, um zu einem Ergebnis zu gelangen.​ Claude verwendet zwei Hauptpfade, um Additionen durchzuführen: 1. Grobabschätzung: Ein Pfad schätzt das Ergebnis basierend auf den Größenordnungen der Zahlen. 2. Präzise Berechnung: Ein anderer Pfad fokussiert sich auf die genaue Berechnung, insbesondere auf die Bestimmung der letzten Ziffer der Summe.\nDiese beiden Pfade arbeiten zusammen, um das finale Ergebnis zu erzeugen. Wenn beispielsweise der Pfad für die letzte Ziffer deaktiviert wird, liefert Claude nur eine grobe Schätzung, ohne die genaue Endziffer korrekt zu bestimmen.\nKönnen wir das Modell fragen, wie es zu einem Ergebnis gekommen ist? Eher nicht. Anthropics Studie zeigt, dass das Modell bei komplexen Aufgaben manchmal überzeugende, aber erfundene Argumentationsketten präsentiert. Bei einfachen Berechnungen, wie der Quadratwurzel von 0,64, lassen sich klare interne Rechenschritte nachweisen. Bei schwierigeren Aufgaben, etwa der Berechnung des Kosinus einer großen Zahl, gibt Claude jedoch vor, Berechnungen durchgeführt zu haben, obwohl keine entsprechenden internen Prozesse erkennbar sind. In solchen Fällen konstruiert das Modell plausible, aber unbegründete Erklärungen – ein Verhalten, das als „motiviertes Denken“ bezeichnet wird. Diese Fähigkeit, überzeugend zu argumentieren, ohne tatsächlich die zugrunde liegende Logik zu befolgen, kann für Nutzer irreführend sein. Die von Anthropic entwickelten Interpretationswerkzeuge ermöglichen es, solche untreuen Denkprozesse zu identifizieren, indem sie die tatsächlichen internen Abläufe des Modells sichtbar machen. Dies ist ein wichtiger Schritt, um die Zuverlässigkeit und Transparenz von KI-Systemen zu verbessern.\nWas kann zu Halluzinationen führen? Wie wir im oben gezeigten Beispiel sehen, ist den Antworten des Sprachmodells nicht immer zu trauen. Das LLM verfügt über einen standardmäßig aktiven „Refusal Circuit“, der das Modell dazu bringt, keine Antwort zu geben, wenn es keine ausreichenden Informationen hat. Wenn eine bekannte Entität erfasst wird, aktiviert sich ein konkurrierender „Known Entity“-Mechanismus, der den Refusal Circuit hemmt und eine Antwort ermöglicht. Problematisch wird es, wenn Claude einen Namen erkennt, aber keine spezifischen Informationen dazu hat. In solchen Fällen kann der „Known Entity“-Mechanismus fälschlicherweise den Refusal Circuit unterdrücken, was zu einer Halluzination führt. Ein Beispiel: Bei der Frage nach einem Fachartikel des bekannten Forschers Karpathy gibt Claude einen erfundenen Titel an, da das Modell zwar den Namen kennt, in diesem Fall aber keine Informationen über den Artikel hat. Bei weniger bekannten Namen gibt das Modell an, die Antwort nicht zu kennen Lindsey et al. (2025).",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>LLM vs RAG vs Agent</span>"
    ]
  },
  {
    "objectID": "kapitel02.html#welches-modell-wählen",
    "href": "kapitel02.html#welches-modell-wählen",
    "title": "LLM vs RAG vs Agent",
    "section": "2.4 Welches Modell wählen?",
    "text": "2.4 Welches Modell wählen?\nWas für LLMs gibt es aktuell? Die großen Anbieter mit den jeweils stärksten Modellen (s. @fig-leaderboard) sind OpenAI (Chat GPT-5), Google (Gemini 2.5) und Anthropic (Claude Opus 4.1 / Sonnet 4). Je nach Anwendung werden günstigere Modelle angeboten, die weniger Rechenaufwand benötigen, meist mit dem Zusatz „Mini“. Starke Reasoning Modelle (die komplexe Fragestellungen bearbeiten können) von OpenAI sind GPT 5 oder Gemini 2.5 Flash (Stand 08/2025). Kostenfrei nutzbare Open Source Alternativen sind z.B. Mistral (eines der wenigen europäischen Modelle) und Llama4 (von Meta/Facebook) sowie die chinesische Konkurrenz DeepSeek V3.1 E. Mollick (2025a); sowie Vellum (2024).\nWelches Sprachmodell sollte man aktuell nutzen? Die kurze Antwort ist, dass aktuell GPT-5 eine gute Wahl ist. Für Lehrende kostenfrei nutzbar gibt es aktuell (August 2025) den zentralen Dienst „Chat-AI“ / Academic Cloud der Gesellschaft für wissenschaftliche Datenverarbeitung Göttingen (GWDG) (https://chat-ai.academiccloud.de/), über den neben einer Reihe von quelloffenen Modellen mittlerweile auch Chat GPT-5 nutzbar ist. Hier kann man sich einfach mit einer Hochschuladresse registrieren und den Dienst nutzen. Hochschulen bieten teils einen eigenen KI-Zugang an, die TH-Köln etwa einen begrenzten Zugang zu ChatGPT und einzelnen quelloffenen Modellen über das THKI-Lab (https://ki.th-koeln.de/login.php). Ab dem 15.9. soll an der TH Köln und weiteren NRW-Hochschulen die Lösung KI:connect ausgerollt werden, die ähnliche Funktionalitäten bereitstellt (https://kiconnect.pages.rwth-aachen.de/pages/).\nAußerdem können Lehrende über die Hochschullizenz Microsoft 365 Copilot herunterladen und dann einen KI-Chat als Desktop-Anwendung nutzen, eine Anwendung, unter deren Haube auch wieder verschiedene Versionen von ChatGPT stecken (hier einloggen und einfach herunterladen: https://www.office.com/). Hier kann man auch GPT 5 nutzen, Chats speichern und komplexere Anweisungen als „Agenten“ entwerfen und teilen.\nDiese kostenfreien Lösungen sind in den letzten Monaten stark ausgebaut worden und mittlerweile schon sehr nützlich geworden. Sie stellen allerdings i.d.R. nicht den aktuellen Stand der Performanz der KI-Modelle dar. Lehrende sollten daher unbedingt 1 bis 2 Monate die 20 Euro investieren und auch die stärksten Bezahlmodelle ausprobieren (also ChatGPT oder Gemini in der Bezahlversion). Nur so erhält man ein Gefühl dafür, was aktuell technisch möglich ist und wie „sicher“ die eigenen Prüfungsleistungen sind (z.B. „im Gespräch“ mit der KI, über das Voice Modell, was bei den kostenfreien Zugängen aktuell meist abgeklemmt ist).\n \nQuelle: Vellum (2024), Stand 08/2025.\nHier kann man vergleichen: In der LM-Arena kann man verschiedene Modelle ausprobieren und ihre Antwort auf eine bestimmte Frage gegenüberstellen: https://lmarena.ai/ (Untermenü: „Arena (side-by-side)“).",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>LLM vs RAG vs Agent</span>"
    ]
  },
  {
    "objectID": "kapitel02.html#was-können-die-modelle-und-was-nicht",
    "href": "kapitel02.html#was-können-die-modelle-und-was-nicht",
    "title": "LLM vs RAG vs Agent",
    "section": "2.5 Was können die Modelle – und was nicht?",
    "text": "2.5 Was können die Modelle – und was nicht?\nWas für Aufgaben LLMs beherrschen ist sehr uneinheitlich und verändert sich dynamisch. Es gibt Bereiche, in denen heutige KI auf menschlichem Niveau oder besser agiert, und andere, oft nur geringfügig andersartige Aufgaben, an denen die KI (noch) scheitert Dell’Acqua et al. (2023). Mollick und Kollegen prägen hierfür den Begriff einer „Jagged Technological Frontier“ (zerklüftete Technik-Grenze) Dell’Acqua et al. (2023). Zwei Aufgaben von ähnlicher Schwierigkeit für Menschen können mit sehr unterschiedlicher Qualität durch ein LLM gelöst werden – eine liegt innerhalb der KI-Frontier (d. h. die KI kann sie lösen), die andere außerhalb (KI liefert unbrauchbare oder falsche Resultate) Dell’Acqua et al. (2023).\nIn einem Experiment mit Consultants wurden 18 verschiedene Beratungsaufgaben gestellt. Für die meisten („inside the frontier“) brachte KI enorme Vorteile, doch bei einer gezielt außerhalb der Frontier gewählten Aufgabe schnitt die KI-Gruppe deutlich schlechter ab: Hier waren die Consultants in der Gruppe mit KI 19 Prozentpunkte weniger häufig korrekt als die ohne KI Dell’Acqua et al. (2023). Dieses Ergebnis unterstreicht die Gefahr, LLMs unkritisch auf Probleme anzuwenden, die ihre aktuellen Fähigkeiten übersteigen – die Leistung fällt dann hinter menschliches Niveau zurück. Praktisch bedeutet die Jagged Frontier, dass Organisationen und Individuen lernen müssen, die Grenze der KI-Fähigkeiten zu erkennen und entsprechend zu navigieren Dell’Acqua et al. (2023).\nFür folgende Anwendungsfälle sind LLMs mittlerweile gut nutzbar Handa et al. (2025); Korinek (2024-12 (update)); Schwarcz et al. (2025):\n\nZusammenfassung von Fachartikeln\nFortgeschrittene mathematische Ableitungen\nAnspruchsvolle Codierungsaufgaben\nErstellen eines Podcasts zu einer Forschungsarbeit\nErstellen von Präsentationsfolien\nVerfassen von Blogbeiträgen\nSimulieren von Interviews mit der Sprachausgabe von ChatGPT oder Gemini\nKI-gestützte Suche (mit kritischer Prüfung natürlich)\n\nDie Fähigkeiten der Modelle wuchsen in den letzten Monaten rasant und damit werden die Aufgaben, die man an sie delegieren kann komplexer. Die Länge der Aufgaben, die KI Sprachmodelle relativ genau erledigen können, verdoppelt sich seit 2019 etwa alle 7 Monate Kwa et al. (2025). Auch die Bewertung von Forschungsarbeiten im Rahmen des Peer-Reviews wird zunehmend teil-automatisiert, etwa durch die automatische Prüfung von Quellen oder Code und Teilbewertungen durch Dienste wie Veracity oder Paper Wizard Lovely (2025); Naddaf (2025).\nIst das ein Mensch, oder ein Bot? Eine neuere Studie zeigt, dass neue Sprachmodelle uns bei dieser Frage mittlerweile erfolgreich täuschen können und so den Turing Test bestehen, da sie in einer sozialen Interaktion Menschen erfolgreich imitieren können Jones & Bergen (2025). In einem randomisierten Drei-Parteien-Turing-Test mit über 1.000 Spielen wurde ein mit speziellen Eingabe-Anweisungen (Persona-Prompt) versehenes Sprachmodell (GPT-4.5) von den Respondenten zu 73 % für den Menschen gehalten, häufiger als echte Menschen in der Vergleichsgruppe. Weniger komplexe Modelle (wie Llama 3.1) schritten schlechter ab. Die Autoren diskutieren daraus resultierende Risiken von sozialer Manipulation oder Arbeitsplatzsubstitution, sowie die Notwendigkeit robusterer menschlicher Erkennungsstrategien.\nAuch durch diesen Fähigkeitsschub ist der Einsatz von Sprachmodellen in Support-Funktionen wie Call Centern stark gestiegen, empirische Studien belegen hier einen starken Produktivitätszuwachs Brynjolfsson et al. (2025).\nDie Gründe für die Produktivitätssteigerung von KI-Modellen lassen sich durch Scaling Laws (Training Scaling Law, Inference Scaling Law, E. Mollick (2025b), S. 3) beschreiben: KI-Modelle werden einerseits exponentiell besser, je mehr Daten, Rechenleistung und Parameter genutzt werden und andererseits, wenn sie mehr Zeit zum „nachdenken“ erhalten.\nDer erste Zusammenhang (Training Scaling Law) besagt, dass größere KI-Modelle mit mehr Parametern und Trainingsdaten systematisch leistungsfähiger werden​. Allerdings sind solche Ertragszuwächse mit hohen Kosten verbunden: Eine 10-fache Steigerung an Rechenaufwand führt etwa zu einer Erhöhung der Leistungsmetriken um einen festen Betrag, was abnehmende Grenzerträge andeutet.\nNeben dem positiven Effekt der Modellgröße wurde in den letzten Monaten ein zweiter Scaling-Effekt (Inference Scaling Law) auf der Anwenderseite deutlich: LLMs liefern bessere Lösungen, wenn man ihnen mehr „Denkzeit“ gibt. OpenAI fand heraus, dass ein Modell mit längerer Schritt-für-Schritt-Reasoning-Phase merklich bessere Ergebnisse erzielt, analog zu einem Menschen, dem man mehr Zeit für eine schwierige Aufgabe gibt. Dieser Inference Scaling Law führte zur Entwicklung von Reasonern – KI-Systemen, die bei Bedarf intern zusätzliche Rechenschritte durchführen, um schwierige Probleme genauer zu lösen Gottweis et al. (2025); OpenAI (2024); Schwarcz et al. (2025).\nZusammengenommen bedeuten diese Skalierungsgesetze, dass KI-Systeme durch höheren Ressourceneinsatz (beim Training und bei der Nutzung) immer leistungsfähiger und vielseitiger werden, wenn auch zu steigenden Kosten. Ökonomisch relevant ist hier vor allem, dass die Grenzkosten der KI-Nutzung sehr niedrig bleiben, sobald ein großes Modell einmal trainiert ist: Ist das Modell erstellt, kann es millionenfach eingesetzt werden, was Skaleneffekte in der Verbreitung ermöglicht. Somit schafft das Scaling Law die Grundlage dafür, dass hochleistungsfähige KI als allgemein verfügbares Gut in Wirtschaft und Bildung eingesetzt werden kann. Durch diese Eigenschaft ermöglicht KI eine schnelle und kosteneffiziente Skalierung personalisierter und adaptiver Lernangebote E. R. Mollick & Mollick (2024). Dieses exponentielle Wachstum unterscheidet KI grundlegend von bisherigen technologischen Entwicklungen, bei denen Verbesserungen oft linear verliefen.\nOpenAI hat allein in den ersten Monaten von 2025 mehrere neue Funktionen eingeführt, die den Einsatz von KI in der Hochschullehre deutlich erweitern könnten: Mit der Bildgenerierungsfunktion in GPT4o lassen sich nun auch fotorealistische Visualisierungen erstellen, was z.B. in der technischen Bildung oder bei Designprojekten didaktisch genutzt werden kann (März 2025). Die neuen Audio-Modelle ermöglichen eine präzise Steuerung von Sprachstil und Tonfall – hilfreich etwa für simulierte Rollenspiele, interaktive Lernbegleiter oder barrierefreie Lerninhalte (März 2025). Das im Februar eingeführte deep research-Modul erlaubt KI-gestützte Rechercheprozesse, die Studierende bei komplexen Projektarbeiten oder der Literatursichtung unterstützen könnten (Februar 2025). Zusätzlich wurde mit o3-mini ein kostengünstigeres Modell vorgestellt, das den Zugang zu leistungsfähigen KI-Anwendungen auch in Bildungseinrichtungen erleichtert (Januar 2025).\n. Quelle: Lovely (2025), basierend auf Kwa et al. (2025)\nEs lassen sich nach dieser Studie zwei Kooperationsmodelle zwischen Mensch und LLM unterscheiden, um die Technologiegrenze optimal auszunutzen Dell’Acqua et al. (2023): Der Centaur-Ansatz teilt die Aufgabe, indem der Mensch der KI die Teilprobleme überlässt, die innerhalb der Frontier liegen, und sich selbst auf den Rest konzentriert. Der Cyborg-Ansatz integriert die KI tiefer, indem der Mensch kontinuierlich mit der KI interagiert und Feedback-Schleifen nutzt. Beide setzen implizit voraus, dass der Nutzer um die Stärken und Schwächen des LLM weiß.\nEine spätere Studie des weitgehend selben Teams mit 776 Praktikern bei Procter & Gamble zeigt, dass Individuen mit LLM Unterstützung deutlich produktiver Probleme lösen oder neue Ideen generieren konnten. Das Sprachmodell scheint einen deutlichen Mehrwert als „Cybernetic Teammate“ zu bringen und Einzelne teils auf das Leistungsniveau von ganzen Teams zu bringen Dell’Acqua et al. (2025).\nWenn man ältere oder weniger starke (offene) Modelle nutzt, fährt man mit dem Fahrrad auf der Autobahn. Vergleiche zeigen starke Performanzunterschiede zwischen GPT-3.5 und den folgenden Updates zu GPT-4 und GPT-4o. Auch die frei verfügbaren Modelle wie Llama sind teils deutlich weniger „schlau“! Hier muss man insofern aufpassen, dass die einfache Verfügbarkeit solcher Modelle über Plattformen wie Academic Cloud nicht zu einem falschen Bild führt.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>LLM vs RAG vs Agent</span>"
    ]
  },
  {
    "objectID": "kapitel02.html#wo-und-wie-spreche-ich-mit-der-ki",
    "href": "kapitel02.html#wo-und-wie-spreche-ich-mit-der-ki",
    "title": "LLM vs RAG vs Agent",
    "section": "2.6 Wo und wie spreche ich mit der KI?",
    "text": "2.6 Wo und wie spreche ich mit der KI?\n\nWo sprechen? Verschiedene Zugänge zu Sprachmodellen\nWo sprechen wir mit dem Sprachmodell? Welche Zugänge zur KI gibt es? Es gibt grob gesagt drei Ansätze:\n\nDie einfache Eingabe in das Chat-Interface (z.B. bei Chat GPT oder Claude), ist am leichtesten umzusetzen. Um verschiedene Modelle zu nutzen, muss man sich aber neu einloggen und evtl. ein weiteres Abonnement bezahlen. Die meisten Modelle erlauben aber auch recht umfangreiche kostenlose Nutzung, was meist zum Kennenlernen ausreicht. Für Hochschulen werden zentral nach und nach verschiedene Dienste mit solchen Oberflächen aufgesetzt, die meist aber aus Gründen des Datenschutzes einige Funktionen abklemmen (z.B. meist die direkte Sprachinteraktion und das Speichern von Benutzerprofilen).\nNutzung einer Bedienoberfläche wie Witsy oder Typingmind, die Prompts speichert und Agenten erstellen lässt, die mit verschiedenen Modellen funktionieren Schwarze (2025). Hier muss man einmalig das System aufsetzen (Witsy) und für den höheren Komfort teils eine eine Lizenz kaufen (TypingMind, ca. 40 $ für Hochschulangehörige), dafür kann man dann einfacher Modelle wechseln und über einen sogenannten API Key nur die tatsächliche Nutzung abrechnen (was sich bei einfacher Nutzung auf ein paar Cent beläuft, siehe die oben gezeigte Übersicht der Preise pro Millionen Token).\nWenn man sich nicht vor etwas Code scheut, kann man auch einfach selbst programmieren (mit KI-Unterstützung in Tools wie Google Colab) und kleine Sprachagenten aufsetzen. (Evtl. dann in Verbindung mit Replit für die Online-Bereitstellung und Diensten wie Voiceflow für die Oberfläche.) Auch hierfür braucht man eigentlich nur API Keys zur Identifizierung. Fragen Sie Chat GPT, wie das geht und lassen sich den Code schreiben, es ist überraschend einfach! Es gibt bei Youtube auch eine Vielzahl von kurzen Erläuterungen.\n\n\n\nWie sprechen? Prompt-Befehle\nWie spreche ich mit dem LLM? Vorab die vielleicht wichtigste, wenn auch banale Empfehlung: Es hilft, genau zu sagen, was man eigentlich will. Man sollte nicht auf den Hiwi schimpfen, wenn man sich nicht die Zeit genommen hat, zu sagen, was eigentlich die Aufgabe ist!\nWie beschreibe ich genau, was ich will? Einfache Daumenregeln für Prompts gliedern das in vier Schritte: dem Sprachmodell eine Rolle zuzuweisen („Du bist Verhandlungsexpertin“), ein klares Ziel zu definieren („Du hilfst mir dabei, mich auf Geschäftsverhandlungen vorzubereiten“), es zu bitten, sein Vorgehen (den Gedankengang / „chain of thought“) offenzulegen und Schritt-für-Schritt vorzugehen („Erstelle zunächst einen Plan und frag mich nach Feedback. Warte meine Antwort ab und passe den Plan eventuell an. Wenn ich zufrieden bin, beginne mit dem ersten Schritt in deinem Plan.“) sowie Beispiele („few shot“) für eine gewünschte Struktur oder Analyse mitzuliefern („Formatiere die Dateinamen in dieser Form [Autor]-[Jahr]-[Kurztitel]“, oder „Gib mir 5 Handlungsoptionen und nenne jeweils Vor- und Nachteile“).\nDabei veranlasst die Chain of Thought-Methode das LLM, seine Gedankengänge offen zu legen. Das Modell zeigt seine Überlegungen Schritt für Schritt, was die Nachvollziehbarkeit seiner Antworten verbessert. So können wir auch besser nachsteuern und das Ergebnis an unsere Ziele anpassen.\n\n\n\n\n\n\nHinweis\n\n\n\nWollen Sie sich interaktiv einen ausführlichen Prompt erstellen lassen? Nutzen Sie diesen Prompt-Bot, den wir für Sie auf Basis der Best-Practice Empfehlungen von OpenAI, Anthropic und wissenschaftlichen Studien zu Prompt-Strategien erstellt haben: https://chatgpt.com/g/g-sF6vTgq2U-prompt-bot\n\n\nNeuere empirische Untersuchungen haben eine Reihe von anekdotischen Hausrezepten des Promptings systematisch geprüft und meist widerlegt. Prompts funktionieren nicht immer gleich und so kommt es schnell zu anektodischer Evidenz, dass eine Formulierung „besser geklappt“ hätte. Die wenigsten der Empfehlungen helfen zuverlässig Meincke et al. (2025b); Meincke et al. (2025a); Meincke et al. (2025c). Hilft es, höflich zu sein (nein), zu drohen (nein), Geld anzubieten (nein), oder den Hiwi-Bot Schritt für Schritt vorgehen zu lassen (ja, aber das machen die neueren Reasoning-Sprachmodelle auch selbst)?\nFür die Lehre wollen wir den Prompts speziell didaktische Elemente hinzufügen, also etwa verhindern, dass den Studierenden sofort eine Lösung ausgegeben wird, da das eigene Nachdenken in Form von Fragen und sokratischem Dialog ihnen dabei hilft, die Ergebnisse auch zu behalten Roediger & Pyc (2012). Konkrete und sehr detaillierte Prompt-Beispiele speziell für die Lehre finden Sie im Appendix 3: Ausgewählte Prompts zur Lehr- und Lernunterstützung. Weitere Beispiele dafür finden sich in der Prompt-Bibliothek von Ethan Mollick (https://www.moreusefulthings.com/prompts).\nGerade für „Agenten“, die einigermaßen zuverlässig bestimmte Aufgaben erfüllen sollen, lohnt es sich aber im Sinne der o.g. Empfehlung (sag, was Du willst), sehr detaillierte Prompts mit Beispielen zu formulieren. Wer hier tiefer einsteigen will, kann hier die detaillierten Empfehlungen der KI-Labore zum Prompt-Design lesen: von Anthropic/Claude, alternativ hier die Details von OpenAI.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>LLM vs RAG vs Agent</span>"
    ]
  },
  {
    "objectID": "kapitel02.html#wie-steht-es-mit-dem-energieverbrauch-der-modelle",
    "href": "kapitel02.html#wie-steht-es-mit-dem-energieverbrauch-der-modelle",
    "title": "LLM vs RAG vs Agent",
    "section": "2.7 Wie steht es mit dem Energieverbrauch der Modelle?",
    "text": "2.7 Wie steht es mit dem Energieverbrauch der Modelle?\nDurch das starke Wachstum der neuen Technologie, werden wir verstärkt mit den möglichen Effekten von KI auf Ressourcenverbrauch und Umweltbelastung konfrontiert Spencer & Singh (2025). Auch bei der Nutzung in der Lehre wird dies regelmäßig von Studierenden angesprochen. In diesem Bereich gibt es viel Hype und Desinformation in beide Richtungen (von „Weltuntergang durch KI-Energiehunger!“ zu „keinerlei Problem“), so dass hier ein kurzer Überblick seriöser Studien nützlich erscheint. Dieser sehr knappe Abriss soll vor allem eine kurze Orientierung und den Verweis auf weiterführende Literatur zur vertieften Beschäftigung bieten.\nWie schmutzig ist es also, KI zu nutzen? Die kurze Antwort ist, dass ein typischer Prompt aktuell etwa soviel Energie verbraucht wie ca. 10 Sekunden Netflix-Streaming oder eine typische Google Suche im Jahre 2008 Elsworth et al. (2025); E. Mollick (2025b). Die gute Nachricht ist, dass die Modelle effizienter werden und der Energieverbrauch pro Output-Token rasant sinkt und dass die Anreize für die großen Anbieter stark darauf ausgerichtet sind, den Energieverbrauch weiter zu senken. Gegenläufig und problematisch ist die stark steigende Nutzung, die z.B. zur Ausweitung gerade umweltbelastender Energieformen wie Gasturbinen führt Wittenberg (2025).\nSolche Vergleiche sind nicht trivial, da etwa bei der Nutzung in Unternehmen auch die Umweltfolgen der aktuellen Alternativen „bepreist“ werden müssen, um einen sinnvollen Vergleich zu erzielen. Wie belastet die Lieferkette eines physischen Buchs die Umwelt im Vergleich zu einem E-Book? Ein aktueller Mitarbeiter im physischen Callcenter mit seinem Arbeitsweg, Schreibtisch und Heizbedarf im Vergleich zum KI-Chatbot? Unabhängig davon, wie diese Rechnungen ausgehen, sind sie sichtlich komplex.\nIm Folgenden sollen dazu einige Kernaussagen aus Untersuchungen der International Energy Agency (IEA), dem World Economic Forum und des MIT Technology Reviews zusammengefasst werden. Basierend auf die aktuelle Untersuchung des MIT Technology Survey O’Donnell & Crownhart (2025) gliedere ich diesen kurzen Abriss zum Energieverbrauch in vier Teile: Die Modellbildung, die Anfrage (query), die Emissionen und Prognosen für das weitere Wachstum.\nModellbildung. Daten-Zentren und KI-Nutzung machen aktuell nur wenige Prozent der globalen Energienutzung aus. Schätzungen der Energieagentur IEA liegen etwa bei 3-5%. Deutlich höhere Anteile liegen in den Bereichen Gebäude, Industrie und Fahrzeuge Ritchie (2024a); Spencer & Singh (2024). Mit Blick auf die Zukunft ist der rasant wachsende Energiebedarf durch Bevölkerungswachstum und wachsenden Wohlstand ärmerer Bevölkerungsgruppen bei weitem ein stärkerer Treiber für Emissionswachstum und Klimawandel Spencer & Singh (2024). Einige Klimaaktivisten warnen sogar vor „distraction“ - davor, sich durch solche Ablenkungen und Modethemen wie KI Energieverbrauch von dem Fokus auf die großen Hebel der Emissionsvermeidung ablenken zu lassen Masley (2025); Ritchie (2024b). Während die Einmalaufwände für das Training der Modelle erheblich sind, hat das schnelle Wachsen der Nutzerzahlen sie mittlerweile in den Schatten gestellt. Die Energieaufwände für Anfragen (Inferenz) bedingen nunmehr einen größeren Energieverbrauch als das Training der Modelle O’Donnell & Crownhart (2025); Spencer & Singh (2025).\nAnfrage. Der Energieverbrauch einer einzelnen KI-Textanfrage ist relativ gering. Er liegt unter dem Energieverbrauch von wenigen Minuten für eine kleine LED-Lampe. Konkret liegen die Schätzungen hier aktuell zwischen 0.3 Wattstunden (Wh) für GPT-4o und 0.03 Wh für kleine Modelle O’Donnell & Crownhart (2025); You (2025)].\nIm Vergleich zu anderen Energieverbrauchen ist das nicht viel. Vergleicht man den höheren Wert von 0.3 Wh mit den 12.000 Wattstunden, die ein durchschnittlicher britischen Haushalt pro Tag verbraucht (für US-Haushalte wird die deutlich höhere Zahl von 28.000 Wattstunden pro Tag genannt!), wird schnell klar, dass weniger KI-Nutzung zumindest aktuell kein großer Hebel für Energiesparen oder Klimaschutz ist. Die oft zitierte Statistik, nach der eine Anfrage bei ChatGPT 10x mehr verbraucht als eine Google Suche vergisst meist zu erwähnen, dass die Basisrate dieser Internetnutzung im Vergleich zu anderen Dingen, in die unser Energieverbrauch fließt, extrem niedrig ist Ritchie (2024b).\nModellgröße ist allerdings ein zentraler Faktor für den Energiebedarf pro Anfrage und hieraus speisen sich plausiblere Sorgen. Zwar ist Bildgenerierung i.d.R. weniger energieintensiv als Textgenerierung, da Modelle zur Bildgenerierung oft mit weniger Parametern arbeiten als Textmodelle. Aber komplexere Anfragen (etwa mehrstufige lange Reasoning Aufträge) und speziell Video-Generierung benötigen deutlich mehr Energie: Ein hochqualitatives Video von 5 Sekunden kann bis zu 1.000 Wattstunden verbrauchen (0.94 kWh), was etwas mehr als einer Stunde Mikrowellennutzung entspricht – ein deutlicher Unterschied O’Donnell & Crownhart (2025).\nDer Anteil größerer Modelle und komplexerer Anfragen wird voraussichtlich deutlich zunehmen, wenn die Modellgrößen weiter ansteigen und komplexere Anfragen, wie Video-Generierung zunehmen. Gegenläufig wirkt der starke Anreiz für die Anbieter (und speziell für die kleineren Konkurrenten von OpenAI, die über geringere finanzielle Mittel verfügen), den Energieverbrauch pro Inferenz durch effizientere Chip-Konstruktionen und neue Trainingsansätze zu senken. Wie die Analysten der IEA zusammenfassen: „The efficiency of AI-related computer chips has doubled roughly every two-and-a-half to three years, and a modern AI-related computer chip uses 99% less power to perform the same calculations as a model from 2008” Spencer & Singh (2024).\nInsgesamt wird perspektivisch die punktuelle Einzelnutzung durch einzelne Anfragen weniger wichtig werden, als die strukturell bedingte Integration der KI-Technologien in immer mehr digitale Anwendungen, die als Folge des rasanten technologischen Wandels und der hohen Investitionen absehbar ist O’Donnell & Crownhart (2025).\nEmissionen. In diesem Zusammenhang wird der ungünstige Energiemix der aktuell entstehenden Datenzentren kritisiert: Da KI-Rechenzentren rund um die Uhr laufen und meist in Regionen mit fossilen Energieträgern stehen, ist der durchschnittliche CO₂-Ausstoß ihrer Stromversorgung etwa 48 % höher als der US-Durchschnitt O’Donnell & Crownhart (2025). Dem gegenüber stehen gegenläufige Effekte wie höhere Effizienz der Steuerung, etwa von Energienetzen Greene-Dewasmes & Tladi (2025) und dem Ersatz von manuellen menschlichen Aufwänden durch Digitalisierung, etwa durch Reisen für einen Film-Dreh (ohne KI) oder dem Energiebedarf eines menschlichen Call-Centers. Das starke Wachstum der Nutzung muss insofern mit politischer Anreizsetzung für emissionslose Energiegewinnung verbunden sein, wenn eine starke Zunahme an Emissionen vermieden werden soll. Hierfür gibt etwa die IEA klare Empfehlungen und technische Lösungen sind bekannt. Besorgt stimmt die Analysten die Prognose eines starken Wachstums von Datencentern im asiatischen Raum, die meist nicht mit emissionsfreier Energie betrieben werden Spencer & Singh (2025).\nPrognose. In der Summe sehen viele der Untersuchungen Probleme eher in der prognostizierten zukünftigen Entwicklung als in den aktuellen Energieaufwänden. Das starke prognostizierte Wachstum könnte etwa dazu führen, dass KI-Anwendungen bis 2028 mehr als 12% des US-Strombedarfs ausmachen O’Donnell & Crownhart (2025).",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>LLM vs RAG vs Agent</span>"
    ]
  },
  {
    "objectID": "kapitel02.html#energieverbrauch-und-politische-steuerung",
    "href": "kapitel02.html#energieverbrauch-und-politische-steuerung",
    "title": "LLM vs RAG vs Agent",
    "section": "2.8 Energieverbrauch und politische Steuerung",
    "text": "2.8 Energieverbrauch und politische Steuerung\nDie IEA prognostiziert ebenfalls eine Verdreifachung des Energieverbrauchs von Rechenzentren bis 2030, getrieben durch KI. Maßnahmen wie Effizienzgewinne und nachhaltige Architektur können diese Entwicklung abbremsen (Spencer & Singh (2025)).\nWie der MIT-Bericht hervorhebt, sollte vor diesem Hintergrund der starke und kurzfristig induzierte Ausbau der Infrastruktur politisch durch Anreize zur Emissionsvermeidung gesteuert werden, sodass ein starkes Wachstum der Emissionen durch diesen – wahrscheinlich im Kern unvermeidlichen – technologischen Wandel vermieden wird (O’Donnell & Crownhart (2025)).\nSo besteht die Hoffnung, dass positive Effekte auf Emissionen in den Hauptbereichen von CO₂-Emissionen (Gebäude, Industrie, Transport sowie die verbundenen Energienetze) durch höhere Effizienz in Planung und Nutzung genutzt werden können, ohne dass sie durch die wachsenden Kosten von immer komplexeren Inferenz-Anfragen überlagert werden (Greene-Dewasmes & Tladi (2025); Spencer & Singh (2025)).\nPolitisch gesehen ergibt sich insofern ein Bedarf an Steuerung dieses strukturellen technologischen Wandels, damit die Ziele denen der Gesellschaft entsprechen. Dazu müssen die Fakten klar sein: Um Kosten und Effekte abschätzen, abfedern und verteilen zu können, fordern die Forscher eine deutlich höhere Transparenz der Energiebedarfe durch die Modellanbieter (O’Donnell & Crownhart (2025)).",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>LLM vs RAG vs Agent</span>"
    ]
  },
  {
    "objectID": "kapitel03.html",
    "href": "kapitel03.html",
    "title": "3  Ziele und didaktische Mechanismen",
    "section": "",
    "text": "3.1 Was für Ziele verfolgen wir mit dem Einsatz von GenAI in der Lehre?\nBevor wir uns der konkreten Umsetzung zuwenden, müssen wir uns zunächst fragen, was wir überhaupt bezwecken: Was sind unsere Ziele für die konkrete Umsetzung in Lehrsituationen?\nMollick & Mollick (2023) argumentieren, dass KI als “Kraftverstärker” für Lehrkräfte dienen kann, indem sie die Implementierung evidenzbasierter Lehransätze erleichtert, die sonst aufgrund von Zeit- und Arbeitsaufwand oft schwer umzusetzen sind. Aber wie wirkt das? Was begründet die erhoffte Wirkung?\nZur Orientierung sollen hier kurz Kategorien von Wissen und Lernmethoden eingeführt werden. Dann können wir im Detail diskutieren, für welche Ziele und Methodenwahl welche Art der Unterstützung geeignet ist. Ziele? Was für Wissen? Fakten, Prozesse, Übertrag.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Ziele und didaktische Mechanismen</span>"
    ]
  },
  {
    "objectID": "kapitel03.html#wissenstypen",
    "href": "kapitel03.html#wissenstypen",
    "title": "3  Ziele und didaktische Mechanismen",
    "section": "3.2 Wissenstypen",
    "text": "3.2 Wissenstypen\nHattie (2023, S.358, 340ff.) unterscheidet drei Stufen des Lernens (s. Abbildung 3.1).\nZunächst geht es um „knowing that“, also das reine Fakten- und Begriffswissen, das erworben und dann gefestigt werden muss: Hier soll eine belastbare Wissensbasis entstehen, weshalb Lehrkräfte häufig Vorwissensaktivierung oder Drill-and-Practice einsetzen und durch unmittelbares Feedback die korrekte Erinnerung verankern.\nDarauf baut „knowing how“ auf, das prozedurale und strategische Können. Auch hier müssen Abläufe zunächst erworben und dann gefestigt werden. Lernende erwerben Prozesswissen, indem sie modellierte Beispiele studieren, in gelenkten Übungen selbst anwenden und mithilfe von „worked examples“ sowie Fehleranalysen Schritt für Schritt ihre Vorgehensweisen optimieren. Festigen können Lernende dieses Prozesswissen besonders gut durch Interaktion oder Wettbewerb mit anderen Lernenden, da diese Auseinandersetzung ihnen dabei hilft, verschiedene Nutzungskontexte zu vergleichen (Chi et al., 2018).\nDie höchste Stufe nennt Hattie „knowing with“: Wissen wird flexibel auf neue Situationen übertragen. Problembasiertes Lernen, authentische Fallstudien, bewusste Reflexionsphasen und kooperativ angelegte Projekte fördern dabei, Konzepte in unbekannten Kontexten sicher anzuwenden und weiterzuentwickeln.\nMit welchen Methoden werden diese Wissenstypen in der Lehre vertieft?\n\n\n\n\n\n\nAbbildung 3.1: Abbildung 8: Methoden nach Wissenstyp: Fakten, Prozess und Transfer. Quelle: Basierend auf Hattie (2023), S. 358, 340ff.\n\n\n\nWo können wir neue technische Hilfsmittel wie LLMs zur Unterstützung dieser Methoden besonders effektiv einsetzen?",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Ziele und didaktische Mechanismen</span>"
    ]
  },
  {
    "objectID": "kapitel03.html#anwendungsbeispiele-nach-wissenskategorien",
    "href": "kapitel03.html#anwendungsbeispiele-nach-wissenskategorien",
    "title": "3  Ziele und didaktische Mechanismen",
    "section": "3.3 Anwendungsbeispiele nach Wissenskategorien",
    "text": "3.3 Anwendungsbeispiele nach Wissenskategorien\nZur Unterstützung des Aufbaus von Faktenwissen („knowing that“) können neuere LLMs inzwischen gut grundlegende Konzepte erklären (Korinek, 2024-12 (update), S.48) und zum Selbststudium komplette Abruf-Übungen erzeugen: Sie formulieren Multiple-Choice- und Kurzantwortfragen, bewerten die Eingaben sofort und erklären fehlerhafte Distraktoren – ein Verfahren, das in einer STEM-Untersuchung zur automatischen Item-Generierung überzeugende Validitätswerte zeigte (Säuberli & Clematide, 2024).\nEbenso lassen sich sehr schnell Definitionen, Paraphrasen oder Mini-Zusammenfassungen erzeugen, was personalisierte Glossare ermöglicht (Chen et al., 2024). Wang et al. (2024) sprechen von KI als „Confusion Helper“. Um Halluzinationen zu vermeiden, wird das Modell häufig per Retrieval-Augmentation an externe Wissensbasen gekoppelt (also z.B. durch Beigabe von Skripten oder Fachartikeln als PDF. Siehe auch das Harvard-Tutor-Bot Beispiel in Abschnitt 4.3, wo Musterlösungen beigegeben werden.).\nZur Festigung von Prozessen und Strategien („knowing how“) dient das LLM als dialogischer Coach: Feingranulierte Prompts („Erkläre den Beschaffungsprozess in 5 Schritten und stelle nach jeder Stufe eine Kontrollfrage“) steigern die Lösungswahrscheinlichkeit in Tutorendialogen (Scarlatos et al., 2025). Sprachmodelle können Lehrenden dabei helfen, komplette „worked examples“ mitsamt Zwischenschritten zu generieren (Hassany et al., 2024).\nAngepasste Sprachmodelle können Lernende zur Selbstkorrektur anleiten, vor allem, wenn sie Zugriff auf die individuelle Lernhistorie haben und theoriegeleitetes Verständnis Gründen für Fehler zugrunde liegt. Zhang et al. (2025) demonstrieren dies am Beispiel eines selbst entwickelten multimodalen Mathematik-Tutor-Bots (MathCCS, Mathematical Classification and Constructive Suggestions).\nDer Teachable-Agent-Ansatz nutzt umgekehrt das Lernen-durch-Lehren-Prinzip: Studierende bringen dem LLM eine Methode bei und reflektieren dabei ihre eigene Strategie. Dies basiert auf der Annahme, dass Interaktionen besonders effektiv zum Lernen beitragen (Chi et al., 2018; Hayashi et al., 2025). Wie auch in der persönlichen Interaktion scheint hierbei wichtig zu sein, welche „Persönlichkeit“ der KI-Bot hat, dem Studierende etwas beibringen sollen (Lyu et al., 2025) und mehr Anstrengung in der Interaktion (etwa durch ausführlicheres Formulieren beim Erklären) führt zu mehr Lernerfolg (Love et al., 2025).\nSprachmodelle können genutzt werden, um komplexe mathematische Anwendungsprobleme mit einem simulierten User „durchzuspielen“, so dass logische Fehler im Lösungsprozess sichtbar werden, wie der Prototyp „MathChat“ von Wu et al. (2024) zeigt.\nFür Transfer und Anwendung („knowing with“) entwirft das LLM realitätsnahe Szenarien – etwa Rollenspiele zu Lieferantenausfällen – und übernimmt Stakeholder-Rollen, wobei Analysen des Brookings-Instituts das Potenzial für kollaboratives Reasoning hervorheben (Korinek, 2024). Cross-Domain-Prompts fördern Analogiebildung („Welche Parallelen bestehen zwischen agilem Projektmanagement und Lean-Procurement?“) (Mollick & Mollick, 2023).\nIn Gruppenarbeiten funktioniert das Modell als Co-Autor: KI-unterstützte Schreibprozesse können die Menge und Vielfalt der Ideen steigern (Meincke et al., 2024; Shaer et al., 2024). Auch hier ist jedoch die sorgfältige Gestaltung des Lernprozesses wichtig, so dass nicht erwünschte Schwierigkeiten an die KI delegiert und so kritische Denkprozesse nicht eingeübt werden (Lee et al., 2025).",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Ziele und didaktische Mechanismen</span>"
    ]
  },
  {
    "objectID": "kapitel03.html#effektive-lerntechniken-und-unterstützung-mit-ki",
    "href": "kapitel03.html#effektive-lerntechniken-und-unterstützung-mit-ki",
    "title": "3  Ziele und didaktische Mechanismen",
    "section": "3.4 Effektive Lerntechniken und Unterstützung mit KI",
    "text": "3.4 Effektive Lerntechniken und Unterstützung mit KI\nWie lernen wir besonders effektiv? In diesem Abschnitt verdeutlichen wir kurz die angestrebten Wirkmechanismen mit Fokus auf drei Lehrtechniken, die die Kognitionswissenschaft als besonders effektiv heraushebt (siehe Mörth et al. (2021) für eine gute deutschsprachige Übersicht).\nDie moderne Lernforschung der Kognitionspsychologie stellt drei Gruppen von Techniken als besonders gute Kombination zwischen Effektivität und einfacher Anwendung heraus: Verteiltes und gemischtes Lernen, testgestütztes Lernen und fragebasierte Ausarbeitung (Dunlosky, Rawson, Marsh, Nathan & Willingham, 2013; Mörth et al. (2021); Roediger & Pyc (2012)). Diese Wirkung gibt es allerdings nicht umsonst: Den positiven Effekten der Techniken steht oft ein deutlich höherer Vorbereitungsaufwand gegenüber. Wie im Folgenden kurz skizziert wird, lassen sich KI-Tools nutzen, um den Aufwand dieser drei Mechanismen zu verringern, was die Lernwirkung im Vergleich zu traditionellen Ansätzen deutlich erhöhen kann.\nZeitliche Verteilung und inhaltliche Mischung von Lerninhalten (Spacing & interleaving): Diese Technik basiert auf dem Prinzip, dass Informationen besser behalten werden, wenn das Lernen über die Zeit verteilt und in verschiedenen Kontexten stattfindet, anstatt in einer einzigen, intensiven Sitzung (Brown et al., 2014; Murre & Dros, 2015; Roediger & Pyc, 2012). Abstände zwischen Lerneinheiten und die wiederholte Aktivierung von Wissensstrukturen stärken die Verbindung zwischen Hinweisreizen und Gedächtnis und geben dem Gehirn Zeit, Erinnerungen effektiv zu speichern. Dies fördert die Langzeiterinnerung, denn der wiederholte Abruf verstärkt die gespeicherten Muster und vertieft sie so.\nWeiterhin hilft es, zu „mischen“: inhaltlich gemischtes Üben (interleaving) ist effektiver als die isolierte Behandlung von Themenblöcken, die linear im Semesterverlauf abgehandelt werden (Mörth et al., 2021). Das liegt daran, dass das gemischte Üben die Unterscheidung zwischen verschiedenen Aufgabentypen fördert, was entscheidend für die spätere Anwendungskompetenz ist. Nur durch den geübten Vergleich verschiedener Kombinationen von Anwendungskontexten und Lösungsansätzen kann ein Gefühl dafür ausgebildet werden, welches Werkzeug zu welchem Problem passt. Fallstudien und Simulationen bieten sich hier an, wenn diese ausreichend komplex sind, um bekannte Analysen in neuen Kontexten anzuwenden und neue einzuführen.\nTestgestütztes Lernen (Test-enhanced learning): Das Abrufen von Informationen durch Tests fördert das Langzeitgedächtnis deutlich stärker als das erneute Lesen des Stoffes. Für Studierende ist das anstrengender, es bringt aber deutlich mehr (Brown et al., 2014). Ein ‚Test‘ kann dabei auch die Bearbeitung von Lerninhalten im Rahmen einer Fallstudie, die kritische Bewertung potenziell falscher Aussagen eines LLMs oder die Beantwortung von Verständnisfragen im Dialog mit einem Tutor-Bot sein.\nHäufige Aktivierung von Lerninhalten durch Fragen verbessert den Lernerfolg durch mehrere Mechanismen (Roediger & Karpicke, 2006). Erstens fördert solches Testen das transfergerechte Verarbeiten, da die mentalen Prozesse beim Testen und beim späteren Abrufen ähnlich sind, was die Erinnerungsfähigkeit verbessert. Zweitens stärkt die Wiederholung durch Tests einerseits den erinnerten Inhalt und fügt andererseits neue ‚Haken‘ hinzu, mit denen wir den Inhalt aus dem Gedächtnis ziehen: die Beziehungen zwischen Hinweisreizen (cues) und dem Inhalt im Gedächtnis, indem zusätzliche Abrufwege zu gespeicherten Wissensmustern geschaffen werden, was den Abruf verbessert. Praktisch kann man diesen tollen Effekt auch recht einfach durch regelmäßige kurze Fragerunden nutzen: Wie die Lernforscher herausstellen: „frequent low-stakes quizzes (last only 5 or 10 min) can produce a large boost in performance“ (Roediger & Pyc, 2012, S.246).\nFragebasierte Ausarbeitung (Explanatory questioning): Bei dieser Technik wird das tiefergehende Verständnis von Material durch das Stellen und Beantworten von „Warum“-Fragen gefördert. In Rollenspielen und Simulationen können Teilnehmer durch bewusste Praxis aktiv Szenarien durchspielen, während sie gleichzeitig durch gezielte Fragen angeleitet werden, die zum tieferen Nachdenken und zur Reflexion anregen. Diese Fragen können dazu dienen, die Teilnehmer dazu zu bringen, ihre Entscheidungen und Handlungen im Kontext des Rollenspiels zu erklären, wodurch das Verständnis für die Anwendung von Konzepten in realen oder simulierten Situationen vertieft wird.\nIndem Lernende über die Gründe hinter den Fakten nachdenken, werden Verbindungen zu bereits bekanntem Wissen hergestellt, was zu einem tieferen Verständnis und besserer Erinnerung führt. Dies deckt sich mit dem Postulat der ICAP-Theorie des kognitiven Engagements (Chi et al., 2018): Interaktion (I) ist effektiver als individuelle Konstruktion, was wiederum effektiver ist als aktive (aber nicht konstruktive) Beteiligung, was wiederum die passive Lernteilnahme schlägt (I &gt; C &gt; A &gt; P).\nWie können LLMs genutzt werden, um diese Lerntechniken zu unterstützen?\nWir skizzieren das hier kurz an einem Seminar zum interkulturellen Management. Um zeitliche Verteilung und Mischung zu fördern, kann mit LLMs eine Serie von kurzen, thematisch variierenden Aufgaben und Fallstudien über das Semester verteilt erstellt werden. Diese könnten reale Szenarien abbilden, in denen Studierende ihre Fähigkeiten im interkulturellen Management anwenden müssen. Beispielsweise könnte das Sprachmodell Aufgaben generieren, bei denen Studierende Strategien für die Überwindung kultureller Barrieren in internationalen Teams entwickeln.\nWas sind Beispiele für testgestütztes Lernen? Regelmäßige, durch LLMs generierte Quizze bringen Studierende dazu, ihr Wissen häufiger aktiv abzurufen. Durch LLMs können Multiple-Choice-Fragen, Fallstudienanalysen und Szenariobeschreibungen zu interkulturellen Missverständnissen erzeugt werden, welche die Studierenden lösen müssen.\nZur Unterstützung von fragebasierter Ausarbeitung können LLMs die Erstellung von Fallstudien, Simulationen und Rollenspielen unterstützen, damit Studierende über interkulturelle Dynamiken und Managementstrategien nachdenken. Diese könnten als Ausgangspunkt für Diskussionen im Kurs oder als Teil von Hausaufgaben dienen, wobei die Studierenden angehalten werden, über die Verbindungen zwischen dem Kursmaterial und den simulierten interkulturellen Interaktionen zu reflektieren. Viele weitere Beispiele hierfür besprechen wir im folgenden Kapitel, wo wir Anwendungsfälle von KI in der Lehre nach der didaktischen Rolle des Werkzeugs darstellen: Hilfskraft, Copilot, Tutor oder Simulator.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Ziele und didaktische Mechanismen</span>"
    ]
  },
  {
    "objectID": "kapitel04.html",
    "href": "kapitel04.html",
    "title": "4  Vier Szenarien: Hiwi, Copilot, Tutor, Simulator",
    "section": "",
    "text": "4.1 KI als Hiwi\nWie nutzen Lehrende aktuell generative KI? Zur ersten Orientierung stellen wir in Tabelle 1 eine Reihe von exemplarischen aktuellen Anwendungsfällen aus deutschen und internationalen Hochschulen zusammen (Stand April 2025). Die Abgrenzung der verschiedenen Kategorien und Details der Umsetzung erklären wir im Folgenden.",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Vier Szenarien: Hiwi, Copilot, Tutor, Simulator</span>"
    ]
  },
  {
    "objectID": "kapitel04.html#ki-als-hiwi",
    "href": "kapitel04.html#ki-als-hiwi",
    "title": "4  Vier Szenarien: Hiwi, Copilot, Tutor, Simulator",
    "section": "",
    "text": "Wobei soll die Hilfskraft unterstützen?\nBeschäftigte in Forschung und Lehre erfüllen eine Vielzahl sehr heterogener Aufgaben, mit einem wachsenden Teil an „Verwaltung“. Wer lehrt, merkt schnell, dass die Präsenzveranstaltung nur die Spitze eines ganzen Eisbergs an Aufgaben darstellt. Eine Umfrage unter Lehrenden in Österreich zeigt, dass sie etwa ein Drittel ihrer Zeit mit Lehraktivitäten verbringen (32%) und etwa ein Fünftel mit Verwaltungstätigkeiten in der Hochschule (20%) sowie ein weiteres Fünftel mit externen Verpflichtungen wie Gutachten oder Tätigkeiten in wissenschaftlichen Gesellschaften (9%, 10%) (Österreichischer Universitätsprofessor/innenverband, 2018). Wie Unkraut im Garten, wächst der Anteil, den Lehrende mit „sonstigem“ verbringen: Vor allem der Zeitaufwand für Verwaltung stieg an (Schomburg et al., 2012).\nWoraus besteht das im Detail und wo könnten LLMs helfen? Vor- und Nachbereitung, Evaluation, Beratung, Planung und vieles mehr lassen die Stunden eines Tages schnell vergehen. Abbildung 9 zeigt die 25 Hauptaufgaben, die Lehrende nach Umfragen des US Arbeitsministeriums verrichten (https://www.onetonline.org/link/summary/25-1011.00). Welche Auswirkungen können wir von LLM auf diese konkreten Aufgaben erwarten?\n\n\n\n\n\n\nAbbildung 4.1: Abbildung 9: Was für Aufgaben erledigen Lehrende? 25 Einzelaufgaben am Beispiel „Business Teachers, Postsecondary“ nach Umfragen des US Arbeitsministeriums auf ONet. Quelle: ONet, 2025\n\n\n\nHistorische Studien zeigen, dass Technologie typischerweise Tätigkeiten (tasks) beeinflusst und eher selten ganze Jobs ersetzt. Führend sind dazu Untersuchungen von David Autor und dem Nobelpreisträger Daron Acemoglu (Acemoglu & Restrepo, 2019; Autor, 2015). Eine nützliche Kategorisierung unterscheidet drei Effekte neuer Technologien auf den Faktor Arbeit: Technologische Veränderungen können menschliche Arbeit ersetzen (Verdrängungseffekt / displacement effect), spezifische Arbeitskräfte produktiver machen (Produktivitätseffekt / productivity effect / augmentation), oder neue Aufgaben (und Jobs) schaffen (Wiedereinsetzungseffekt / reinstatement effect) (Acemoglu & Restrepo, 2019).\n\n\n\nTabelle 4.2: Tabelle 2: Für welche Aufgaben in der Lehre erwarten wir Verdrängung und Erhöhung der Produktivität und welche Aufgaben kommen hinzu? Legende: x = klarer Effekt, ? = gemischter Effekt. Quelle: Theorierahmen nach Acemoglu & Restrepo (2019)\n\n\n\n\n\n\n\n\n\n\nEffekt\nBeschreibung\nAufgaben in der Lehre (Beispiele)\n\n\n\n\nVerdrängung\nTechnologie übernimmt Aufgaben\n• Erstellung, Durchführung und Bewertung von Prüfungen (x)• Verwaltung von Noten und Anwesenheit (x)• Vorbereitung standardisierter Lehrmaterialien (x)• Zusammenstellung von Bibliographien (x)\n\n\nProduktivität\nTechnologie macht Arbeit effizienter\n• Vorbereitung und Durchführung von Vorlesungen (x)• Durchführung von Seminaren und Diskussionen (x)• Akademische und berufliche Beratung (?/x)• Forschung und Publikation (x)• Pflege von Webseiten und digitalen Ressourcen (?/x)\n\n\nWiedereinsetzung\nTechnologie schafft neue Aufgaben\n• Entwicklung KI-gestützter Lehrkonzepte (x)• Qualitätskontrolle von KI-Materialien (x)• Gestaltung individueller Lernpfade (x)• Ethische und rechtliche Begleitung (x)• Weiterbildung des Personals (x)\n\n\n\n\n\n\nIn Tabelle 4.2 übertragen wir die genannten drei Effekte auf konkrete Aufgaben in der Hochschullehre.\nDer Verdrängungseffekt betrifft hauptsächlich administrative und stark standardisierte Tätigkeiten. Aufgaben wie das Erstellen, Durchführen und Bewerten von Prüfungen, die Verwaltung von Noten und Anwesenheiten sowie die Vorbereitung standardisierter Lehrmaterialien oder Literaturzusammenstellungen werden voraussichtlich vollständig oder überwiegend von KI übernommen. Anwendungsstudien und Umfragen der letzten zwei Jahre geben hierzu deutliche Hinweise (Morgan, 2024; Naddaf, 2025b; Ogunleye et al., 2024; Ou et al., 2024; Tutton & Cohen, 2025).\nDer Produktivitätseffekt bezieht sich auf zentrale Lehr-, Forschungs- und Betreuungstätigkeiten, die durch KI effizienter werden. Dazu zählen die Vorbereitung und Durchführung von Vorlesungen, Seminaren und Diskussionen, akademische und berufliche Beratung der Studierenden sowie Forschung und Publikationen. KI unterstützt hier durch automatische Literaturauswertungen, personalisierte Lerninhalte oder Pflege digitaler Ressourcen, sodass Lehrende ihre Kernaufgaben besser und effektiver erfüllen können (Gottweis et al., 2025; Meincke et al., 2024; E. R. Mollick & Mollick, 2023b, 2024; Schwarcz et al., 2025).\nGemischte Effekte treten bei einigen Aufgaben wie der Entwicklung und Pflege von Kurswebseiten, dem digitalen Aufzeichnen von Vorträgen und der Auswahl von Lehrmaterialien auf, bei denen KI sowohl Teile der Aufgaben ersetzt als auch deren Durchführung produktiver macht.\nDer Wiedereinsetzungseffekt zeigt, dass durch den Einsatz von generativer KI gänzlich neue Aufgaben entstehen. Dazu gehören beispielsweise die Entwicklung neuer KI-gestützter Lehrkonzepte und -methoden, Qualitätskontrollen von KI-generierten Lehrmaterialien, Gestaltung individueller Lernpfade, ethische und rechtliche Begleitung des KI-Einsatzes sowie die Weiterbildung des Lehrpersonals im Umgang mit KI-Technologien (Dihan et al., 2025; E. Mollick et al., 2024; E. R. Mollick & Mollick, 2024).\nDurch diese differenziertere Analyse der drei Effekte wird klar, dass die Einführung von KI in die Lehre zwar mit hoher Sicherheit deutliche Änderungen im Aufgaben-Mix und der Zeitanteile bedeutet, die wir mit verschiedenen Aufgaben verbringen. Das ist nicht neu: Wer bestellt heute noch regelmäßig per Fernleihe, schickt Briefe oder kopiert in großem Umfang? Wir sehen, dass generative KI wahrscheinlich mittelfristig einen Teil der aktuellen Tätigkeiten verdrängen, zentrale Kernaufgaben produktiver gestalten und zugleich neue, spezialisierte Aufgaben in der Lehre schaffen wird.\nOb das insgesamt zu einer Zeitersparnis führt, ist keineswegs sicher, denn die neuen Aufgaben um die Einrichtung und Betreuung der KI-Unterstützung können sehr zeitintensiv sein, als Beispiel sei hier etwa die Einrichtung eines Physik-Tutor-Bots (Kestin et al., 2024) oder einer Startup-Simulation, in der KI in verschiedenen Rollen beim Aufsetzen und Verbessern von Geschäftsplänen hilft (E. Mollick et al., 2024). Beide Konzepte führen sichtlich zu einer Verbesserung der Lehre, aber die gibt es auch hier nicht umsonst.\n\n\nWobei unterstützt KI besonders gut?\nWas sind typische Anwendungsfelder für Lehrende und Studierende? KI unterstützt Lehrende ähnlich einer Hilfskraft beim Erstellen von Lehrmaterialien, indem sie Beispiele generiert, die abstrakte Konzepte in realen Kontexten veranschaulichen (E. R. Mollick & Mollick, 2023b). Dies fördert ein tieferes Verständnis und eine breitere Anwendbarkeit der Inhalte. Ebenso kann KI den Verwaltungsaufwand für Kurse verringern, indem sie dabei hilft, Übersichten, Dokumente und Präsentationen zu erstellen. Idealerweise verschiebt sich dann die Energie der Lehrenden auf Kernkompetenzen wie individuelle Erläuterung, Motivation und Coaching von Arbeitsgruppen.\nKI kann dabei helfen: Von der Analyse der Lernenden über die Erstellung, Anpassung und Verknüpfung von Inhalten bis hin zur Unterstützung bei Recherche und Literaturarbeit. Während die Sprachmodelle noch vor drei Jahren vor allem einfache Fragen beantworten konnten, können die stärksten Modelle mittlerweile ganze Aufgabenbündel abarbeiten, (s. Abbildung 7), wie etwa komplexe Recherchen, Datenanalyse oder Code-Generierung (Naddaf, 2025a, 2025b). KI als „Co-Scientist“ (Gottweis et al., 2025) – positiv gesehen werden die Hiwis immer schlauer.\nErste Untersuchungen zeigen positive Effekte auf Lehrende – weniger Stress, mehr Energie - wenn sie ChatGPT zur Unterstützung einsetzen. Wie auch bei anderen neuen Technologien hängen die positiven Effekte mit der Einfachheit der Nutzung und der empfundenen Nützlichkeit zusammen, wie etwa eine neuere Umfrage unter 401 Dozierenden zeigt (Cambra-Fierro et al., 2025).\nDie folgende Tabelle fasst eine Reihe von Anwendungsfeldern zusammen.\n\n\n\nTabelle 4.3: Tabelle 3: Detaillierte Anwendungsfelder von KI zur Kursvorbereitung. Quelle: Basierend auf Gimpel et al. (2023); E. R. Mollick & Mollick (2023b); E. R. Mollick & Mollick (2022)\n\n\n\n\n\n\n\n\n\n\nKategorie\nEmpfehlung\nBeispiele\n\n\n\n\nAnalyse der Lernenden\nVorkenntnisse und Lerntypen analysieren\nAuswertung von Fragebögen, Lernstandserhebungen\n\n\n\nRückmeldungen zusammenfassen und auswerten\nAnalyse von Feedbackformularen, Forenbeiträgen\n\n\nGenerierung von Inhalten\nVielfältige Beispiele und Erklärungen\nAnwendungsbeispiele, Analogien, Visualisierungen\n\n\n\nÜbungsaufgaben, Quizfragen und Tests\nAufgaben verschiedener Schwierigkeitsgrate und Formate\n\n\n\nZusammenfassungen und Analysen von Materialien\nKernaussagen von Texten, Vergleich von Konzepten\n\n\nAnpassung von Materialien\nAutomatische Anpassung an Niveaus und Formate\nVereinfachung von Texten, Ergänzung von Erklärungen\n\n\n\nOptimierung basierend auf Rückmeldungen\nÜberarbeitung von Beispielen, Aufgaben, Erklärungen\n\n\nVerknüpfung und Wiederholung\nBezüge zwischen Themen herstellen\nQuerverweise, Analogien, Anwendung in neuen Kontexten\n\n\n\nIntegration in Aufgaben und Tests zum verteilten Üben\nWiederholungsfragen zu Vorwissen in späteren Einheiten\n\n\nRecherche und Literatur\nSuche und Vorschläge relevanter Quellen\nLiteraturempfehlungen passend zum Thema\n\n\n\nZusammenfassungen und Vergleiche von Literatur\nSynopsen, Gegenüberstellungen, Forschungsüberblicke\n\n\n\n\n\n\nKI kann bei Schreib- und Formatierarbeiten viel Zeit sparen. Textbausteine in eine Tabelle zusammenfassen, Tabellen umformatieren oder Tabelleninhalte in Fließtext verwandeln, Hauptpunkte mit anschaulichen Beispielen für verschiedene Adressatenkreise illustrieren, Literaturangaben in ein bestimmtes Format wie BibTeX verwandeln, das sich mit einem Klick in Zotero einlesen lässt, Übersetzungen in verschiedene Sprachen, Erstellung von Übersichtsdokumenten oder Websites… Viele Fleißarbeiten lassen sich bei sorgfältiger Aufsicht sehr gut an den digitalen Hiwi delegieren. Nutzungsberichte und Experimente zeigen einen deutlichen Mehrwert etwa bei Recherche, Texterstellung und Zusammenfassung (Brynjolfsson et al., 2025; Handa et al., 2025; Schwarcz et al., 2025).\nFür die Recherche und Textgenerierung lässt sich der Hiwi gut nutzen (McKnight, 2022): Machen Sie die KI zu Recherche-Assistenten, um Themen umfassend zu recherchieren und Texte zur Überprüfung sowie Referenzen für nachfolgende Untersuchungen der Studierenden zu kompilieren (z.B. mit Complexity.ai oder dem Consensus GPT (Add-on zu ChatGPT) sowie neueren Lösungen wie Deep Research (Schwarcz et al., 2025) und spezialisierte Lösungen wie Elicit, die auf akademische Datenbanken zurückgreifen (jedoch oft nur auf Abstracts, keine Volltexte). Diese Materialien können als Grundlage für originale und sorgfältig referenzierte Schreibarbeiten dienen. Nutzen Sie KI-Tools für routinemäßige Texte, wie Blog-Inhalte, und bewerten Sie kritisch, wo und warum KI-Texte, menschliche Texte oder Hybridtexte angebracht sind. Erforschen Sie die spezifischen Möglichkeiten von KI-basierten Inhalts-Generatoren für Ihr Fachgebiet, beispielsweise die Produktion von Texten in mehreren Sprachen innerhalb von Sekunden oder die Erstellung von für Suchmaschinen optimierten Texten.\nSpeziell zur Kursvorbereitung schlagen Experten eine Reihe von Möglichkeiten vor, wie die KI Lehrende unterstützen kann (Gimpel et al., 2023; E. R. Mollick & Mollick, 2022, 2023b): KI kann die Vorkenntnisse der Studierenden analysieren, um Materialien und Methoden passgenau auszuwählen und anzupassen – etwa um Startup Pitches vorzubereiten (E. Mollick et al., 2024). Durch Zusammenfassung und Analyse von Rückmeldungen der Studierenden können Verständnisprobleme und Lernlücken identifiziert werden. KI kann weiterhin Beispiele und Erklärungen zu Kursthemen generieren, um das Verständnis zu fördern. Lehrende können Zusammenfassungen und Analysen von Kursmaterialien und Literatur anfertigen, Lernmaterialien an verschiedene Niveaus und Formate anpassen, Erklärungen und Materialien basierend auf Rückmeldungen der Studierenden optimieren. So bieten etwa Mollick und andere Teilnehmern angepasste Feedbacks und Videos an, je nachdem was in einem anfänglichen Fragebogen berichtet wurde und welches Level an Vorwissen die User zeigen (E. Mollick et al., 2024). KI kann Bezüge zwischen aktuellen und zuvor gelernten Themen herstellen und diese in Aufgaben und Tests zum verteilten Üben über den Kursverlauf hinweg integrieren. Der effektive Einsatz erfordert aber stets die Prüfung, Auswahl und Einbettung durch die Lehrenden auf Basis ihrer didaktischen Expertise (E. R. Mollick & Mollick, 2023b, 2024).\nÜbungsaufgaben, Quizfragen und Tests mit adaptivem Feedback können in kurzer Zeit erstellt werden. Wie eine neuere Studie zeigt, können auch „simulierte Studierende“ genutzt werden, um die Qualität neuer Multiple-Choice Fragen zu bewerten (Lu & Wang, 2024).\nWas für konkrete Nutzungsbeispiele finden wir Anfang 2025 in aktuellen Berichten? Ein Artikel der Fachzeitschrift Nature (Tabelle 4) fasst Anwendungen aus verschiedenen Bereichen zusammen, die von Fehlersuche zur Erstellung von Simulationsübungen und Wochenplänen reicht (Heidt, 2025).\n\n\n\nTabelle 4.4: Tabelle 4: Aktuelle Nutzungsbeispiele von KI zur Lehrunterstützung. Quelle: Zusammengestellt nach Heidt (2025)\n\n\n\n\n\n\n\n\n\nFachgebiete\nKI-Nutzung\n\n\n\n\nInformatik\nSelbstentwickelter KI-Chatbot „Class Primer“ analysiert mithilfe von ChatGPT-4 Kursinhalte und erstellt strukturierte Zusammenfassungen sowie visuelle Lernhilfen, um komplexe Themen bereits vor der Vorlesung zu verstehen.\n\n\nWirtschaftswissenschaften (Geschichte/Wirtschaftsgeschichte)\nIm Rahmen der Erstellung wissenschaftlicher Essays simulieren Studierende mithilfe von ChatGPT historische Persönlichkeiten (z.B. Henry Kissinger), um deren Perspektiven und Argumente bezüglich historischer Ereignisse besser nachvollziehen und kritisch hinterfragen zu können.\n\n\nPsychologie und Sprachbildung\nNutzung von KI-basierten Chatbots („Language Buddy“), um Fremdsprachenkenntnisse interaktiv und dialektspezifisch zu trainieren und damit sprachliche Kompetenzen zu verbessern.\n\n\nNeurowissenschaften (Data Science)\nEinsatz von Chatbots als „technische Assistenten“ zur effizienteren Fehlersuche in datenanalytischen Programmiercodes, was den Rechercheaufwand reduziert und direkte, spezifische Lösungsvorschläge bietet.\n\n\nLiteratur- und Wissenschaftskommunikation\nNutzung von KI (NotebookLM), um wissenschaftliche Literatur in Form von automatisch generierten Podcasts aufzubereiten. Dabei entstehen fiktive Dialoge zwischen Moderatoren, was einen kreativeren Zugang zu wissenschaftlichen Inhalten ermöglicht.\n\n\nLuft- und Raumfahrttechnik (Projektmanagement)\nKI-Chatbots unterstützen bei der Erstellung detaillierter Wochenpläne und der rollenbasierten Aufgabenverteilung in studentischen Gruppenprojekten. Dies verbessert die organisatorischen Abläufe und berücksichtigt individuelle Stärken der Gruppenmitglieder.\n\n\nAllgemeine Studierendenberatung und persönliche Entwicklung\nHilfe für Studierende verschiedener Fachrichtungen durch KI-basierte Tools, um individuelle Zeitpläne für Studium, Freizeitaktivitäten und soziales Leben zu erstellen. KI unterstützt sie dabei, persönliche Ziele (wie Sport, Musik oder zwischenmenschliche Beziehungen) effektiver und bewusster zu gestalten.\n\n\n\n\n\n\nDie Aufgaben für Studierende müssen unter diesen neuen Rahmenbedingungen angepasst werden. Einfache Recherche-Übungen werden stark entwertet, da der Arbeitsfluss mittlerweile weitgehend automatisiert ist. Abbildung 10 zeigt den Unterschied für eine einfache Recherche-Übung. Was für Einzelschritte müssen Studierende erledigen, um einen Bericht zum Stand der Industrie 4.0 (etwa: sensorgestützte Vernetzung von Maschinen) in Deutschland zu erstellen? Links sehen wir einige typische Arbeitsschritte, die Studierende manuell durchführen müssen: Begriffe klären, Quellen recherchieren und zusammenfassen, Gliederung erstellen und Bericht formulieren und formatieren. Rechts sehen wir, wie die selben Arbeitsschritte mit der Unterstützung von LLMs durchgeführt werden. Grün markierte Aufgaben führt das LLM automatisch durch, Gelb markiert Aufgaben, die Iterationen mit den Usern erfordern (etwa: mehrere Prompts, Fine-Tuning, Anpassung). Das Beispiel setzt sorgfältige Nutzung der technischen Hilfsmittel voraus – wenn Studierende nur den Aufwand minimieren wollen, kann ihnen das LLM auch in einem einzigen Schritt einen (meist: weniger guten, aber zum Bestehen dieser Aufgabe wahrscheinlich noch ausreichenden) Bericht erstellen.\n\n\n\n\n\n\nAbbildung 4.2: Abbildung 10: Einfache Aufgaben müssen angepasst werden: Die traditionelle Erstellung eines Berichts durch Studierende (Szenario A) kann durch LLMs weitgehend automatisiert werden (Szenario B). Blau = manuell, grün = automatisch, gelb = hybrid. Quelle: Selbst erstellt mit GPT-o und Google Colab im Mermaid-Format.\n\n\n\nWie einfach das tatsächlich mittlerweile für Studierende geht, verdeutlicht ein Beispiel (s. Abbildung 11): Wir nutzen die im Hochschulnetz frei verfügbare Lizenz von Statista und die hier angebotene LLM-Funktion „Research AI“, um einen Textausschnitt zum Thema „Industrie 4.0 in Deutschland“ zu generieren und erhalten auf einen sehr einfachen Prompt praktisch sofort einen korrekt formulierten und formatierten Ausschnitt mit 5 von Statista kuratierten Quellen zurück. Der hier angebotene Mehrwert zu breiteren Modellen wie GPT oder Gemini besteht vor allem in der Auswahl und Zusammenstellung der Quellen durch Statista. Ähnliche Angebote gibt es inzwischen aus verschiedenen Bereichen, etwa vom juristischen Verlag Wolters Kluwer (https://www.wolterskluwer.com/de-de/solutions/wolters-kluwer-online).\n\n\n\n\n\n\nAbbildung 4.3: Abbildung 11: Beispiel mit ResearchAI von statista – automatisierte Recherche, Zusammenfassung und Zitation",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Vier Szenarien: Hiwi, Copilot, Tutor, Simulator</span>"
    ]
  },
  {
    "objectID": "kapitel04.html#ki-als-copilot",
    "href": "kapitel04.html#ki-als-copilot",
    "title": "4  Vier Szenarien: Hiwi, Copilot, Tutor, Simulator",
    "section": "4.2 KI als Copilot",
    "text": "4.2 KI als Copilot\nIn dieser Kategorie hilft das Sprachmodell uns dabei, etwas zu tun, was wir sonst nicht könnten. E. R. Mollick & Mollick (2024) beschreiben mehrere solcher Ansätze: Bei der “Case Co-Creation” (E. R. Mollick & Mollick, 2024, S.25–28) arbeiten Studierende mit der KI zusammen, um ein Fallbeispiel für Kommilitonen zu erstellen. Dies fördert die Artikulation von Ideen und die kritische Auseinandersetzung mit dem KI-Output, da die initialen Entwürfe oft oberflächlich sind und durch studentische Expertise verbessert werden müssen. Die Übung “Critique the AI” lässt die KI ein Szenario zu einem Konzept (z.B. Groupthink) erstellen, das die Studierenden dann kritisch bewerten und ggf. verbessern müssen. Dies schult das Erkennen von Konzeptmerkmalen und die Fähigkeit, Wissen durch Korrektur zu artikulieren. Eine Herausforderung ist, dass die KI Konzepte manchmal unvollständig oder fehlerhaft illustriert, was aber Teil des Lerneffekts sein kann (E. R. Mollick & Mollick, 2024).\nWie können LLMs als Programmierassistenten bei Coden und Datenanalyse helfen? Bien & Mukherjee (2025) beschreiben den Einsatz von GitHub Copilot in einer Einführung in die Datenanalyse für MBA-Studierende an der University of Southern California. Studierende lernen, englische Prompts zu schreiben, die Copilot in R-Code übersetzt, um Datenanalysen durchzuführen, ohne selbst R-Syntax lernen zu müssen (Bien & Mukherjee, 2025, S.129). Der Mehrwert ist, dass Studierende direkt mit Daten interagieren und experimentieren können (“translator-in-your-ear”), was das Verständnis fördert und die Hemmschwelle senkt (Bien & Mukherjee, 2025). Herausforderungen liegen in der Inkonsistenz der KI (gleicher Prompt kann unterschiedlichen Code erzeugen), der Notwendigkeit, spezifische Prompting-Fähigkeiten zu lehren, und der Schwierigkeit für Studierende, die Korrektheit des generierten Codes zu überprüfen, was durch häufiges Plotten und Prüfen der Ergebnisse mitigiert werden muss (Bien & Mukherjee, 2025, S.131, 133).\nLiang et al. (2024) untersuchten in einer großangelegten Umfrage die Usability von KI-Programmierassistenten wie GitHub Copilot. Sie fanden heraus, dass Entwickler diese Tools vor allem nutzen, um Tastenanschläge zu reduzieren, Aufgaben schneller zu erledigen und Syntax abzurufen (Liang et al., 2024, S.2). Erfolgreiche Anwendungen sind die Generierung von repetitivem Code oder Code mit einfacher Logik sowie Unterstützung beim Lernen neuer Sprachen/APIs (Liang et al., 2024, S.5–6). Als zentrale Herausforderungen wurden genannt, dass der generierte Code oft funktionale oder nicht-funktionale Anforderungen nicht erfüllt, die Steuerung des Tools schwierig ist und Nutzer oft nicht verstehen, welcher Input zum Output führte (Liang et al., 2024, S.2, 7).\nWeitere Anwendungsbeispiele nutzen LLM als Hilfe für Schreibprozesse: Aus Deutschland wird das Projekt “DeepWrite” (U Passau, FAU, HöD Bayern) beschrieben, das KI-Assistenzsysteme zur Förderung der Schreib- und Argumentationskompetenz in Jura und Wirtschaft entwickelt (Wannemacher et al., 2025, Case 66). An der Universität Kiel erproben Studierende der Mittelalterlichen Geschichte den Einsatz von KI zur Unterstützung des Hausarbeitenprozesses (Recherche, Übersetzung, Gliederung) und diskutieren den Mehrwert im Vergleich zu traditionellen Methoden (Wannemacher et al., 2025, Case 193). An der Universität Marburg wird KI testweise zur Hilfe beim Verfassen von Laborprotokollen in der Pharmazie eingesetzt, um insbesondere sprachliche Hürden zu überwinden (Wannemacher et al., 2025, Case 25).\nAn der LMU München nutzen Soziologie-Studierende im Projekt “Mit KI über KI qualitativ forschen” verschiedene KI-Tools (Qualia, MAXQDA AI assist) zur Durchführung und Auswertung qualitativer Interviews, um deren Potenzial und Grenzen im Forschungsprozess kritisch zu reflektieren (Wannemacher et al., 2025, S.29–31, Case 040). Herausforderungen hierbei sind der hohe Einarbeitungsaufwand für Lehrende, die dynamische Tool-Entwicklung und offene datenschutzrechtliche und methodologische Fragen (Wannemacher et al., 2025, S.30).\nIm Projekt “Held:innenreise mit KI” an der Universität des Saarlandes dient KI (ChatGPT, Transkribus) Studierenden der Mittelalterlichen Geschichte als Werkzeug zur Transkription, Übersetzung und Interpretation handschriftlicher lateinischer Quellen, was den Zugang erleichtert und digitale Kompetenzen fördert (Wannemacher et al., 2025, Case 146). Als Hürde wird der Umgang mit unterschiedlichen Vorkenntnissen der Studierenden und die Notwendigkeit genannt, die KI-Nutzung eng zu begleiten, ohne bei Fehlern sofort einzugreifen (Wannemacher et al., 2025, S.33). Im Lehrkonzept “TEAM with AI” (DHBW Heilbronn) nutzt KI Geschäftsberichte, um Analysen durchzuführen und Entwürfe für Geschäftsmodellanalysen zu erstellen, was die Studierenden bei komplexen Aufgaben unterstützt (Wannemacher et al., 2025, S.27, Case 172).\nGenerell besteht bei Co-Pilot-Anwendungen die Gefahr der Überabhängigkeit (E. R. Mollick & Mollick, 2024). Die Notwendigkeit einer kritischen Prüfung der KI-Ergebnisse (“Human in the Loop”) durch die Nutzer ist zentral (E. R. Mollick & Mollick, 2024, S.7).\n\nBesser schreiben – als Cyborg\nWer akademisch schreibt, lässt sich zunehmend von einer Vielzahl an unterstützenden KI-Systemen über die Schultern schauen – oder die Hand führen - , die Vorschläge zur besseren Sprachverwendung machen, wie DeepL, Grammarly, oder ChatGPT (Ou et al., 2024). Ou et al. (2024) sprechen von AI-assisted language tools (AILT), die Studierenden dabei helfen, ihre Sprachfähigkeiten etwa von einer in die andere Sprache zu übertragen und das Sprachniveau ihrer Schreibprodukte generell zu verbessern. In ihrer Studie analysieren sie die Kommentare von 1703 schwedischen Studierenden und stellen komplexe Muster der Nutzung fest: „…students align their own languages, writing skills and thinking with the algorithm-based language processes (e.g., lexical, grammatical, and textual corrections, word choice suggestions, language translation) within AI chatbots, writing assistance, and machine language translation to optimise the outcomes of their academic writing. … students have become ‘spatially extended cyborg[s]’”.\nStudierende schreiben durch die zunehmend mächtigere technische Unterstützung ihre Haus- und Abschlussarbeiten deutlich anders. Bedeutet dies das Ende der Hausarbeit? Wohl eher einen starken Wandel, denn es wird weiter wichtig sein, die saubere Argumentation zu üben (Friedrich, 2023; Klein, 2023).\n\n\n\n\n\n\nProbieren Sie mal\n\n\n\nHier haben wir einen kleinen Schreib-Trainer-Bot für Studierende erstellt, der ihnen dabei helfen soll, eine Einleitung für die Abschlussarbeit zu schreiben. Dabei werden zunächst Beispiele gezeigt die nach richtig/falsch sortiert werden müssen, dann kommen nach und nach komplexere Fragen: Link zum Einleitungstrainer\nHier eine zweite Übung (erstellt von Julia Schmid), zum die strukturiertes Schreiben mit Einleitungssätzen (Topic-Sentences) beibringen soll: Link zum Topic-Sentence-Bot.\n\n\nDie Studienberatung der Universität Frankfurt hat eine Übersicht nach Phasen des Prozesses erstellt (Lehre virtuell - Universität Frankfurt, 2023), s. Tabelle 5:\n\n\n\nTabelle 4.5: Tabelle 5: Integration von KI in den Schreibprozess. Quelle: Studienberatung der Universität Frankfurt (Lehre virtuell - Universität Frankfurt, 2023), Stand 10.3.2024\n\n\n\n\n\n\n\n\n\n\nPhase im Schreibprozess\nUnterstützung durch KI\nEigenanteil\n\n\n\n\nThemenfindung und Literaturrecherche\nBrainstormingGrober Themenüberblick\nSchwerpunktsetzungWissenschaftliche Quellen finden\n\n\nLesen und Exzerpieren\nZusammenfassung/Gliederung für ersten ÜberblickTextpassagen vereinfachen\nGründliches LesenKI-generierte Texte überarbeiten\n\n\nRohfassung\nAusformulieren von StichpunktenKooperatives Freewriting\nStichpunkte festhalten“Schreiben, um eigene Gedanken zu klären”KI-generierte Texte überarbeiten\n\n\nÜberarbeiten\nVerschiedene Textversionen generierenStil/Perspektive anpassen\nPassende Textversion aussuchen und anpassenMenschliches Feedback einholen\n\n\nSprachliche Korrektur\nSpezialisierte Tools wie DeepL, Write und Duden Mentor\nPrüfen, ob Bedeutung verändert wurde\n\n\n\n\n\n\nMit einer einfachen Skala lässt sich auch die Intensität der LLM-Nutzung grob beschreiben. (s. Tabelle 6): Je nach Phase im Arbeitsprozess kann LLM zur Ideenfindung, zur Ausarbeitung möglicher Fragestellungen oder Inhalte dienen. Je nach Intensität sollte dann die Nutzung stärker begründet und durch Prüfschritte abgesichert werden (Baresel et al., 2024; Rowland, 2023).\n\n\n\nTabelle 4.6: Tabelle 6: Erläuterungen zum Grad der LLM-Nutzung. Quelle: Baresel et al. (2024), basierend auf Rowland (2023)\n\n\n\n\n\n\n\n\n\n\nGrad der KI-Nutzung\nCharakterisierung\nBeispiele\n\n\n\n\n1\nZur Inspiration\nSie haben sich Vorschläge für Themen unterbreiten lassen; Tools eingesetzt, um sich aus eigenen Notizen heraus Themenschwerpunkte zu bilden; sich Formulierungen vorschlagen lassen; die Rechtschreibung-/Grammatikprüfung genutzt.\n\n\n2\nErgänzend\nSie haben sich mögliche Fragestellungen vorschlagen lassen, einzelne Begriffe der Aufgabenstellung oder Stellen in der Literatur erklären lassen, Gliederungen der eigenen Notizen vorschlagen oder eigene Texte zusammenfassen lassen, Reverse Outline zum eigenen Text (eine basierend auf dem Geschriebenen erzeugte Gliederung) generieren lassen.\n\n\n3\nUnterstützend\nSie haben sich Anforderungen der Aufgabe (z.B. Aufbau einer HA) erklären, Literatur zusammenfassen, mögliche Gliederungen zum Thema vorschlagen lassen; Sie haben die Fragestellung dialogisch verfeinert bzw. Textteile dialogisch verfasst und dabei LLM-Output iterativ ergänzt; Sie haben sich Überarbeitungsvorschläge bzgl. Leserlichkeit und Stil generieren lassen.\n\n\n4\nInhaltsgestaltend\nSie haben sich Hintergrundwissen zur Aufgabe bzw. Antworten auf Fragestellung generieren, Gliederung zum Thema vorgeben, Kürzungen und Ergänzungen vornehmen lassen oder KI-generierten Text direkt übernommen.\n\n\n\n\n\n\nWie können wir konstruktiv mit den neuen technischen Möglichkeiten umgehen? Die folgende Tabelle fasst konkrete Beispiele für Hausarbeiten unter Einbindung von KI zusammen, die Ethan und Lilach Mollick in verschiedenen Beiträgen ausgeführt haben (E. R. Mollick & Mollick, 2023a, 2023b). Der übergeordnete Gedanke ist, KI nicht nur zur Automatisierung einzusetzen, sondern neue, interaktivere und individuellere Lernerfahrungen zu ermöglichen - mit mehr Reflexion, verschiedenen Perspektiven, Kreativität und Kollaboration. Die Rolle der Lehrenden wandelt sich hin zur Begleitung und Moderation dieser KI-gestützten Prozesse.\n\n\n\nTabelle 4.7: Tabelle 7: Neue Ansätze für Hausarbeiten mit KI. Quelle: E. R. Mollick & Mollick (2023b) sowie die verlinkten Blogeinträge\n\n\n\n\n\n\n\n\n\nAnsatz\nBeschreibung\n\n\n\n\nCopilot: Kollaboratives Schreiben mit KI\nGruppen von Studierenden schreiben gemeinsam einen Text und nutzen KI als zusätzliches “Teammitglied”. Sie dokumentieren die Interaktion mit KI und reflektieren Vor- und Nachteile.\n\n\nCopilot: Multimediale Anreicherung mit KI\nStudierende nutzen KI, um ihre Arbeiten mit Visualisierungen, Animationen oder Audio anzureichern und reflektieren, wie dies Verständnis und Attraktivität erhöht.\n\n\nCopilot: KI als Coach und Reflexionspartner\nKI stellt Fragen bezogen auf die Teamarbeit, um Studierende zur Reflexion ihrer Lernerfahrungen, Herausforderungen und Lehren anzuregen.\n\n\nTutor: KI-generierte Beispiele zur Erklärung von Konzepten\nKI erstellt schnell viele Beispiele, die ein abstraktes Konzept in unterschiedlichen realen Kontexten illustrieren. Dies hilft Studierenden, die Idee zu erfassen und breiter anzuwenden.\n\n\nTutor: KI-Tutor, den Studierende kritisieren\nKI erstellt einen Essay zu einem Thema, den Studierende dann kollaborativ verbessern, indem sie Informationen ergänzen, Punkte klären, Belege liefern etc. Fördert kritische Analyse.\n\n\nTutor: Simulation von Anwendungsszenarien mit KI\nBesonders in praxisorientierten Fächern erstellen Studierende mit KI Simulationen, in denen sie ihre Erkenntnisse anwenden, z.B. Unterrichtsszenarien in der Lehramtsausbildung.\n\n\n\n\n\n\nPrompts für ausgewählte Anwendungen finden Sie im Appendix. Im Anwendungsteil des Workshops wollen wir diese Ansätze intensiv üben und diskutieren. Letztlich ist die Anpassung der didaktischen Ansätze und technischen Möglichkeiten auf die konkrete Kombination von Lerninhalt und Studierendengruppe entscheidend. Es besteht die Hoffnung, dass die neuen Möglichkeiten der administrativen Entlastung, höheren Niveaus bei Arbeitsaufgaben und schnellerer Individualisierung der Lernunterstützung in der Summe zu einem höheren Niveau des Lehrens und Lernens führt. Voraussetzung dafür ist sicherlich eine Anpassung der Lehrstrategie und die nüchterne und proaktive Beschäftigung mit den unvermeidlichen Risiken und Nebenwirkungen von neuen technischen Möglichkeiten. Wie kann kritisches Denken in diesen neuen Recherche- und Schreibprozessen erfolgen (Lee et al., 2025)? In diesem Fall darf man vermuten, dass die negativen Effekte noch höher wären, wenn wir die Lehre nicht anpassen.\n\n\nJeder kann jetzt programmieren\nMit KI als Copilot können wir viel umfangreicher und schneller mit Code arbeiten. Ein Beispiel ist Programmieren: Professionelle Programmierer werden mit KI Copiloten deutlich schneller (Peng et al., 2023) und Lehrbücher haben zunehmend Namen wie „Learn AI-assisted Python Programming“ (Porter & Zingaro, 2024). Studierende können so zum Beispiel viel schneller ein funktionierendes Spiel oder eine Simulation erstellen, was die Motivation erhöht. Der Raum der kreativen Möglichkeiten weitet sich deutlich aus. Mit KI-Unterstützung können Schüler/innen mit Sonic Pi Musikstücke programmieren (Gieselmann, 2024) oder mit Tools wie Violentmonkey kleine Skripte für die individuelle Anzeige von Lieblings-Websites erstellen (Eikenberg, 2025).\nWie helfen solche Copiloten beim Coden? Aktuelle Studien untersuchen etwa, wie man mit KI Copiloten auch Nicht-Informatiker an fortgeschrittene statistische Auswertungen heranführen kann (Bien & Mukherjee, 2025). In einer Einführungsvorlesung für MBA-Studierende wurde GitHub Copilot genutzt, wobei die Studierenden natürliche Spracheingaben verwendeten, um R-Code automatisch generieren zu lassen. Das Ziel war, komplexe Syntax zu vermeiden und die Studierenden direkt mit Datenanalyse vertraut zu machen. Im Ergebnis ermöglichte die Nutzung von GitHub Copilot es Studierenden ohne Programmierkenntnisse, statistische Methoden effektiv und eigenständig anzuwenden. Studierende bewerteten die Nutzung der KI-Tools überwiegend positiv, da diese die Lernerfahrung verbesserten und den Zugang zur Programmierung erleichterten. Die empirische Untersuchung zeigte, dass ein Großteil der universitären Programmieraufgaben teilweise oder vollständig durch die KI-Tools gelöst werden konnte.\nEine weitere Studie sammelt qualitative Erfahrungen in einem Einführungskurs in Informatik, wie sich die Nutzung von Copilot auf das Lernen auswirkte (Puryear & Sprint, 2022). Studierende profitierten deutlich von Copilot, insbesondere bei der Entwicklung von Programmierfähigkeiten und beim Lösen konkreter Programmierprobleme. Allerdings zeigte sich, dass die Studierenden weiterhin ein fundiertes Verständnis der Programmiersprache benötigen, um KI-generierte Lösungen richtig beurteilen und gegebenenfalls korrigieren zu können. Die KI unterstützte den Lernprozess effektiv, konnte aber die grundlegenden Konzepte nicht vollständig ersetzen.\nMehrere Studien testen, wie gut ein KI Assistent typische Programmieraufgaben aus einer Einführungsveranstaltung löst – zunächst allein durch KI und dann mit Anpassung der Eingaben durch Studierende (GitHub Copilot) (Denny et al., 2023). Eine öffentliche Datenbank mit 166 typischen CS1-Problemen wurde genutzt, um Copilot zu testen. Wenn Copilot anfangs scheiterte, versuchten Studierende, die Beschreibung der Aufgaben in natürlicher Sprache anzupassen („Prompt Engineering“), um das Ergebnis zu verbessern. Copilot löste etwa die Hälfte der Programmieraufgaben auf Anhieb korrekt. Durch gezieltes Prompt Engineering konnten weitere 60 % der anfänglich nicht gelösten Aufgaben erfolgreich bearbeitet werden. Dies deutet darauf hin, dass die bewusste Formulierung von Aufgabenstellungen ein wichtiger Bestandteil der Lernaktivitäten wird und das Erlernen von Programmierkompetenzen verändert.\nEine weitere Studie an der niederländischen Universität Twente zeigt basierend auf Interviews und Umfragen mit Studierenden, dass ein Großteil der universitären Programmieraufgaben teilweise oder vollständig durch die KI-Tools gelöst werden konnte. Dies erfordert, dass Lehrende ihre Unterrichtsstrategien anpassen, um sicherzustellen, dass Kernkompetenzen dennoch vermittelt werden (Nizamudeen et al., 2024).\nWofür nutzen professionelle Programmierer*innen die Copiloten? Eine Studie untersucht dies mit einer Umfrage unter 410 Entwicklern (Liang et al., 2024). Die wichtigsten Gründe der Nutzung waren Autovervollständigung, schnelleres Abschließen von Programmieraufgaben sowie Unterstützung beim Erinnern von Syntax. Als besonders erfolgreich erwiesen sich die Tools bei repetitiven und einfachen Programmieraufgaben. Häufige Probleme waren jedoch, dass generierter Code oft nicht die gewünschten funktionalen oder nicht-funktionalen Anforderungen erfüllte, wodurch Entwickler diesen oft modifizieren mussten oder ganz darauf verzichteten.\nAlle fünf Studien zeigen, dass KI-Programmierassistenten, insbesondere GitHub Copilot, effektiv dabei helfen, Einstiegshürden beim Programmieren zu reduzieren, indem sie Entwicklern helfen, repetitive und einfache Programmieraufgaben effizienter zu erledigen (Bien & Mukherjee, 2025; Liang et al., 2024; Nizamudeen et al., 2024; Puryear & Sprint, 2022). Ein wesentliches Potenzial dieser Tools liegt in der Steigerung der Motivation und der Verkürzung der Lernkurve bei Programmieranfängern. Besonders wichtige neue Kompetenzbereiche sind „Prompt Engineering“, die gezielte Steuerung der KI-Ausgaben (Denny et al., 2023), sowie das Verständnis dafür, wie Input den generierten Output beeinflusst (Liang et al., 2024). Jedoch treten auch Herausforderungen auf: Häufig erfüllen KI-generierte Lösungen nicht alle funktionalen oder nicht-funktionalen Anforderungen, weshalb Entwickler oft erhebliche Anpassungen vornehmen müssen oder den KI-generierten Code ganz verwerfen (Liang et al., 2024). Dies unterstreicht, dass trotz erheblicher Erleichterungen durch KI grundlegende Programmierkenntnisse weiterhin notwendig sind, um Lösungen kritisch zu bewerten und effektiv anzupassen (Puryear & Sprint, 2022).\nPraktisch alles, was Code ist, lässt sich mit Sprachmodellen erstellen und anpassen. Wir brauchen also nur Code-Schnittstellen. Das klingt kompliziert, ist aber überall schon vorhanden. Im Schreibprozess importieren wir Zitationen über das Bibtex-Format (.bib). Kalendertermine werden im Kalenderstandard (.ics) geführt. Für Flußdiagramme gibt es z.B. den Mermaid Standard. Wir können insofern mit Sprachmodellen:\n\nZitationen von einem Foto aus importieren („Scanne das Foto und gib mir die Quellen als Bibtex Code aus. Erkläre mir dann, wie ich ihn importiere“)\nKalendereinträge aus einer Liste in unser Terminprogramm überführen („Erstelle mir aus dieser Liste Einträge im ICS Standard. Erkläre mir dann, wie ich den Code in Google Calendar importiere.“)\nAblaufdiagramme in Mermaid visualisieren und als Grafik speichern („Erstelle mir einen typischen Kaufprozess in Mermaid. Erkläre mir dann, wie ich ihn visualisieren und als Grafik exportieren kann.“\nInteraktive Simulationen mit den Claude Artifacts erstellen (s.o.)\nDialogbasiert Grafiken und statistische Analysen in Google Colab erstellen (s.u.)\n(Für viele weitere Ideen für solche Hilfsmittel können wir einfach das Sprachmodell fragen.)\n\n\n\n\n\n\n\nAbbildung 4.4: Abbildung 12: Visualisierung von Ablaufdiagrammen in Mermaid (Chat GPT – https://mermaid.live/)\n\n\n\nWichtig für Hochschulen: Mit verschiedenen browserbasierten Tools wie Google Colab oder Cursor steht mittlerweile eine sehr mächtige Programmierhilfe mit integriertem Sprachmodell (Gemini) zur kostenlosen Verfügung. Visualisierungen und statistische Analysen können hier komplett dialogbasiert begonnen werden. Auch ohne Grundkenntnisse in der Programmiersprache Python sind Studierende hier gleich handlungsfähig und können durch häufige Nutzung Wissen aufbauen. Dadurch wird es etwa möglich, von Studierenden durchgängig die Nutzung von Programmiertools zur Erstellung von Visualisierungen zu verlangen. Die Hilfestellung durch die KI Assistenz lässt dies deutlich leichter werden, als das händische Gefrickel in den Grafiken von Excel oder gar PowerPoint. Zur Illustration hier ein Beispiel-Notebook. Rechts können die Prompts eingegeben werden: Beispiel-Notebook\nBeispiel-Prompts: * Erstelle mir eine einfache Visualisierung von vertikalen und horizontalen Balkendiagrammen in Python. * Passe die Balken so an, dass die Prozentwerte auf den Balken sichtbar sind. * Füge Beispiele für Violin Charts mit einem etwas komplexeren Beispieldatensatz hinzu. * Erstelle jetzt einen Beispieldatensatz und führe eine einfache Explorative Datenanalyse (EDA) mit Visualisierungen durch.\n\n\n\n\n\n\nAbbildung 4.5: Abbildung 13: Visualisierung im Dialog mit Google Colab und KI\n\n\n\nAnmerkung: Rechts schreibt man den Prompt, links entsteht der Code und die Grafik. Besondere Stärken sind die Nachvollziehbarkeit (da alles im Code steht) und die einfachen Anpassungsmöglichkeiten (da die KI sich um die Syntax kümmert). Code ist hier einsehbar: Link zum Code.\nSolche Hilfestellungen sind mittlerweile Alltag geworden: Alle großen Anbieter von Code Editoren wie Pycharm, VS Code (Microsoft/GitHub) und neue Anbieter wie Cursor und (noch extremer, als Agent) Devin (https://preview.devin.ai/) bieten mittlerweile Programmierung mit KI-Unterstützung an. Für Hochschulen stellt sich die Frage, wie diese Fähigkeit am Besten trainiert werden kann. Ein extremes Anwendungsbeispiel ist dieser Youtuber, der in Trainingsvideos mit einer Vielzahl verschiedener KI-Tools programmiert, auch selbst beschrieben eher in der Rolle eines Supervisors, der die verschiedenen KI Helfer überwacht und koordiniert: Build Anything with Cursor, David Ondrej, 2024-09-1.",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Vier Szenarien: Hiwi, Copilot, Tutor, Simulator</span>"
    ]
  },
  {
    "objectID": "kapitel04.html#ki-als-tutor",
    "href": "kapitel04.html#ki-als-tutor",
    "title": "4  Vier Szenarien: Hiwi, Copilot, Tutor, Simulator",
    "section": "4.3 KI als Tutor",
    "text": "4.3 KI als Tutor\nDiese Kategorie umfasst KI-Systeme, die Studierende direkt beim Lernen anleiten, beraten oder ihnen Feedback geben.\n\nBeispiele für einfache Tutoren\nE. R. Mollick & Mollick (2024) beschreiben eine Reihe allgemeiner Tutorenkonzepte: Der “Integration Agent” (E. R. Mollick & Mollick, 2024, S.31–33) fordert Studierende durch offene Fragen heraus, Verbindungen zwischen verschiedenen Kurskonzepten herzustellen, was vernetztes Denken fördert. Der “Reflection Coach” (E. R. Mollick & Mollick, 2024, S.30) regt zur Reflexion über Erfahrungen an, um das Gelernte zu konsolidieren. Der “AI Tutor Blueprint” (E. R. Mollick & Mollick, 2024, S.38–40) ermöglicht es Lehrenden, eigene, auf ihre spezifischen Themen zugeschnittene Tutoren-Prompts zu erstellen.\nAn deutschen Hochschulen gibt es ebenfalls vielfältige Tutor-Anwendungen: Der Lern- und Informationsassistent “LISA” an der Hochschule Hof unterstützt Studierende bei der Prüfungsvorbereitung durch personalisierte Lernpläne, Übungsaufgaben und Feedback basierend auf hochgeladenen Materialien (Wannemacher et al., 2025, Case 208). Herausforderungen sind hier die Bekanntmachung des Tools und die potenziell geringere Ergebnisqualität im Vergleich zu großen kommerziellen Modellen. An der FernUniversität in Hagen bietet “COFFEE” skalierbares, kriterienbasiertes Feedback zu Freitextaufgaben, während “MIND” Feedback zu Lernaktivitäten liefert, um die Selbstreflexion zu fördern (Wannemacher et al., 2025, Case 61). Hier sind der hohe initiale Implementierungsaufwand, Datenschutzanforderungen und die Notwendigkeit interdisziplinärer Expertise einschränkende Faktoren (Wannemacher et al., 2025).\n“KI-Folio” (U Passau, LMU München) gibt als Chatbot Feedback zu E-Portfolio-Aufgaben und Reflexionen, um begrenzte Betreuungsressourcen zu kompensieren (Wannemacher et al., 2025, Case 36). “THI Success AI” (TH Ingolstadt) ermöglicht individualisierte Lernpfade und bietet einen Chatbot für Übungsaufgaben und Fragen (Wannemacher et al., 2025, S.17–18, Case 210). Der “Mentor-Bot” an der CBS Köln unterstützt bei der Übungsvorbereitung und bietet Trainingsmodi (Wannemacher et al., 2025, Case 98). An der HU Berlin wird KI für formatives Assessment-Feedback in der Sprachbildung genutzt, wobei Lehrende als “Human in the Loop” die KI-Vorschläge prüfen (Wannemacher et al., 2025, Case 222). An der Hochschule Kempten bewertet KI Freitextantworten in Übungen automatisch und gibt direktes Feedback (Wannemacher et al., 2025, S.18, Case 169). Die Wilhelm Büchner Hochschule setzt “WBH A[I]ssist” als allgemeinen KI-Tutor im Fernstudium ein (Wannemacher et al., 2025, Case 63).\nFür all diese allgemeinen Tutoren gilt: Ihre Effektivität hängt von der Qualität des Prompts und der Fähigkeit der KI ab, die Tutor-Rolle konsistent und pädagogisch sinnvoll auszufüllen, was nicht immer gegeben ist und von Modell zu Modell variieren kann (E. R. Mollick & Mollick, 2024, S.36). Die KI kann oberflächlich bleiben oder halluzinieren (E. R. Mollick & Mollick, 2024, S.36).\nSprachen lernen und schwierige Situationen simulieren kann man jetzt sehr einfach und auf hohem Niveau mit KI-Modellen wie ChatGPT oder Gemini (Jurran, 2025). Vorreiter war der „Voice Mode“ von OpenAI, den man als App auf dem Handy ausprobieren kann (gut in der kostenfreien, sehr gut in der kostenpflichtigen Version), inzwischen bietet Google/Gemini ähnliche Funktionen an. Die KI spricht auf Wunsch über ein beliebiges Thema in einer beliebigen Sprache. Im fortgeschrittenen Modus („Advanced Voice Mode“, für Abonnenten) ist die Stimme noch realistischer und man kann unter anderem die Geschwindigkeit und andere Stimmparameter anpassen. Im Standardmodus kann man Dokumente hinzufügen, auf die sich die Unterhaltung beziehen soll (s. das zweite Beispiel für Anwendungen). Damit lassen sich zum Beispiel im Hochschulunterricht interaktive und unmittelbare Anwendungen realisieren: Studierende könnten ihre Fragen in Seminar- oder Vorlesungsphasen mündlich stellen, wobei die KI entsprechende Antworten gibt, visuelle Inhalte erklärt oder sogar aktuelle Daten aus dem Internet integriert. Besonders gut eignet es sich auch zum Lernen von Sprachen: Man kann die englische Präsentation ausprobieren und sich Feedback geben lassen. Solche Interaktionen kommen dem Ideal eines persönlichen Tutors schon sehr nahe, ermöglicht eine enge, interaktive und sehr auf die eigenen Bedürfnisse und Lernziele zugeschnittene Zusammenarbeit und kann so Lernprozesse dynamischer gestalten.\nWie passt man die Lehre an? Ein aktueller Artikel bespricht, wie sich diese neuen Möglichkeiten auf die Rolle des Sprachunterrichts an Hochschulen auswirken (Tutton & Cohen, 2025): Es werden eine breite Reihe an Tools besprochen und konkrete Empfehlungen zur Umsetzung angeboten: Lehrende sollen mit Studierenden die Stärken und Schwächen der Tools erproben und sie so an die Nutzung heranführen. Unterrichtskonzepte sollten so angepasst werden, dass sich die Stärken der KI-Tools und des Präsenz-Unterrichts ergänzen.\n\n\nKomplexer Physik Tutor mit Musterlösungen\nAls Beispiel für einen ausführlich getesteten Tutor-Bot wollen wir hier exemplarisch einen Physik-Tutor der Harvard Universität etwas ausführlicher darstellen (Kestin et al., 2024). Der Physik-Tutor “PS2 Pal” betreut Studierende in Physik-Einsteigerkursen interaktiv und mit adaptiven Fragestellungen, was in der Evaluation zu einem deutlich verbesserten Lernerfolg führte. Im Verbund mit kürzeren Input-Phasen erhalten die Studierenden Aufgaben und Fragestellungen, die sie direkt in Interaktion mit dem KI-Tutor bearbeiten können. Der Tutor stellt Fragen, gibt bei Bedarf Hinweise und passt den Schwierigkeitsgrad an den Fortschritt der bzw. des Lernenden an.\nStudierenden loggen sich über eine Weboberfläche – oder in manchen Fällen eine in den Kurs integrierte Lernplattform – ein und erhalten dann Aufgabenpakete zu Teilthemen (z. B. Kinematik, Kräfte oder Energieerhaltung). Die KI analysiert die eingegebenen Antworten und entscheidet anhand vorab definierter Parameter und eines Maschinenlern-Modells, ob und wie viel zusätzliche Hilfestellung nötig ist. Bei korrekten oder fast korrekten Lösungen wird ein vertiefender Schritt vorgeschlagen (etwa eine weiterführende Frage), während bei fehlerhaften Lösungsschritten gezielt ein Tipp oder ein Hinweis auf das entsprechende Lehrmaterial gegeben wird. Dadurch werden die Lernenden kontinuierlich im Lernprozess unterstützt, ohne gleich eine komplette Lösung zu sehen.\nAus didaktischer Sicht entfaltet der Tutor seinen Mehrwert vor allem in vier Punkten: * Individuelle Anpassung: Das System erkennt unterschiedliche Lernstände (etwa durch Analyse typischer Fehler oder wiederkehrender Wissenslücken) und kann dadurch passgenauere Folgefragen stellen. * Unmittelbares Feedback: Während in großen Lehrveranstaltungen Lehrende nur sehr eingeschränkt auf einzelne Fragen von Studierenden eingehen können, liefert das KI-Tool praktisch sofort Rückmeldungen. * Motivation und aktive Teilhabe: Studierende werden durch die permanenten Interaktionsmöglichkeiten stärker einbezogen, was sich positiv auf die Lernergebnisse auswirkt. * Zeitersparnis für Lehrende: Ein Teil der individuellen Betreuung kann – bei inhaltlich gut vorbereitetem KI-System – durch den Tutor übernommen werden. Allerdings behält die Lehrkraft jederzeit die Oberaufsicht, indem sie zum Beispiel relevante KI-Antworten stichprobenartig überprüft oder spezielle Fälle selbst übernimmt (z. B. wenn die KI Auskünfte gibt, die nicht zur jeweiligen Kursstruktur passen).\nGenerell ist bei KI-Tutoren die Gefahr von Fehlinformationen und Halluzinationen zu beachten. Hierfür gibt es jedoch gute Gegenmaßnahmen, vor allem durch Kontrolle des Inputs und systematische Qualitätstests der LLM-Tools. Eine interessante Möglichkeit, die beim Physik-Tutor der Harvard Studie besprochen wird (Kestin et al., 2024), ist die Bereitstellung von Musterlösungen als Input (nicht nur der Fragen), was die Gefahr von Ungenauigkeiten, Halluzinationen und Inkonsistenzen in den Antworten des Sprachmodells deutlich reduziert. Der Aufwand für die Erstaufsetzung steigt hier zwar, aber im Gegenzug verspricht dieser Ansatz die Vorteile der individuellen Anleitung ohne die Nachteile der Qualitätsunsicherheit. Insgesamt ist eine solche Durchsicht und intensive Qualitätskontrolle klar zu empfehlen (dieser Aspekt der intensiven Qualitätstests wird bei der Kurzvorstellung einiger deutscher Fallstudien in Wannemacher et al. (2025) vernachlässigt).",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Vier Szenarien: Hiwi, Copilot, Tutor, Simulator</span>"
    ]
  },
  {
    "objectID": "kapitel04.html#ki-als-simulator",
    "href": "kapitel04.html#ki-als-simulator",
    "title": "4  Vier Szenarien: Hiwi, Copilot, Tutor, Simulator",
    "section": "4.4 KI als Simulator",
    "text": "4.4 KI als Simulator\nHier erstellt die KI interaktive Umgebungen für praxisnahes Training. In einfachen Rollenspielen simuliert das Sprachmodell ein Gegenüber, um z.B. Analyse- oder Verhaltensmuster einzuüben. E. R. Mollick & Mollick (2024) unterscheiden dabei Role Play (Rollenspiele) und Goal Play (zielgerichtete Spiele).\n\nRole Play\nRollenspiel-Simulationen z.B. für Verhandlungen lassen Studierende eine neue Rolle einnehmen und dadurch risikofrei zu Üben, etwa von Verhandlungssituationen. In Deutschland wird an der TH Brandenburg das Format “Talk2Transform” eingesetzt, das Mitarbeitergespräche in Transformationsprozessen simuliert, wobei KI die Mitarbeiterrollen spielt (Wannemacher et al., 2025, Case 132). Der Mehrwert liegt im praxisnahen Training von Kommunikations- und Führungskompetenz. Herausforderungen sind der hohe Konfigurationsaufwand, die technische Stabilität und die Tatsache, dass KI menschliche Interaktion nicht vollständig ersetzen kann und Rollen nicht immer fehlerfrei spielt (Wannemacher et al., 2025). In der HAW Hamburg werden Gesprächssimulationen zur deeskalierenden Kommunikation genutzt (Wannemacher et al., 2025, Case 177). An der Hochschule Kempten kommen KI-Avatare zur Simulation von Führungsgesprächen zum Einsatz (Wannemacher et al., 2025, Case 95). An der Deutschen Hochschule der Polizei dient eine Simulation der Sensibilisierung für LLM-Missbrauchspotenziale, indem Studierende explorativ deren missbräuchliche Nutzung erproben (Wannemacher et al., 2025, Case 031).\nDirekt mit der KI zu sprechen kann die Situation dabei noch realistischer machen: Barra et al. (2024) beschreiben den Einsatz von ChatGPT’s Advanced Voice Mode (AVM) in medizinischen Simulationen, speziell für das CPR-Training (s. Abbildung 14). AVM ermöglicht der Simulationspuppe, mit einer natürlichen, emotional reagierenden Stimme zu “sprechen”, was den Realismus steigert. Der Mehrwert liegt in der verbesserten Immersion, Zugänglichkeit und Entlastung der Trainer. Herausforderungen sind die Sicherstellung der Konsistenz, die Abhängigkeit von den Prompting-Fähigkeiten des Trainers und technische Limitierungen des AVM bezüglich vorab eingebetteten Wissens.\nAuch Juristen simulieren: Einen ähnlichen Ansatz verfolgt die simulierte Zeugenbefragung von Heetkamp, der es so etwa Rechtsreferendaren ermöglicht, diese Kompetenz im Rollenspiel mit VR-Brillen einzuüben (Heetkamp, 2023).\n\n\n\n\n\n\nAbbildung 4.6: Abbildung 14: Nutzung der Voice Modes von ChatGPT für medizinische Simulationen. Quelle: Barra et al. (2024)\n\n\n\nEine umfangreiche Simulation beschreiben E. Mollick et al. (2024): “Pitch Quest” an der Wharton School ist ein Simulator für Venture-Capital-Pitches, der mehrere KI-Agenten (Mentor, Investor, Bewerter) nutzt, um personalisierte Übung und Feedback zu ermöglichen (E. Mollick et al., 2024, S.5–10). Der Mehrwert liegt in der skalierbaren Bereitstellung von Übungsmöglichkeiten für komplexe Skills. Herausforderungen sind die Aufrechterhaltung der Konsistenz, die Vermeidung von Bias und Halluzinationen sowie der hohe Entwicklungsaufwand für solche Multi-Agenten-Systeme (E. Mollick et al., 2024, S.2–3).\n\n\nGoal Play – zielgerichtete Spiele\nIn zielgerichteten Spielen (“Goal Play”, E. R. Mollick & Mollick (2024)) bleiben Studierende in ihrer normalen Rolle und wenden in einer Situation bestimmtes Wissen oder theoretische Konzepte an (z.B. Zielsetzung, Selbst-Distanzierung oder Analyseraster wie Transaktionskostenanalyse), indem sie einen KI-Charakter anleiten. Wichtig dabei: Die Studierenden wissen etwas, das das KI-Gegenüber im Spiel nicht weiß.\nSo nehmen etwa bei dem einfachen Rollenspiel “Teach the AI” (E. R. Mollick & Mollick, 2024, S.21–23) Studierende die Rolle des Lehrenden ein und erklären der KI (die einen unwissenden Studenten spielt) ein Konzept. Der Mehrwert liegt im vertieften Lernen durch Lehren (Protégé-Effekt) und dem Aufdecken eigener Wissenslücken. Als Herausforderung kann die KI manchmal vom Thema abweichen oder Fragen stellen, die die Studierenden an ihre Grenzen bringen; zudem ist die Simulation eines “Novizen” durch die KI nur begrenzt realistisch (E. R. Mollick & Mollick, 2024, S.24).\nFür beide Typen gilt: Die KI kann von der Rolle abweichen oder inkonsistent agieren, und die Qualität der Erfahrung kann variieren. Eine sorgfältige Einbettung und Reflexion durch Lehrende ist entscheidend (E. R. Mollick & Mollick, 2024). Bei allen Simulatoren ist die Notwendigkeit einer klaren didaktischen Rahmung und eines Debriefings durch Lehrende (“Human in the Loop”) zentral, um den Lernerfolg zu sichern und die Grenzen sowie potenzielle Fehler der KI zu reflektieren (E. R. Mollick & Mollick, 2024, S.16).",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Vier Szenarien: Hiwi, Copilot, Tutor, Simulator</span>"
    ]
  },
  {
    "objectID": "kapitel05.html",
    "href": "kapitel05.html",
    "title": "5  Empfehlungen zur Umsetzung",
    "section": "",
    "text": "5.1 Typische Aufgaben und Fragestellungen mit der KI durchspielen, Prompts anpassen, experimentieren\nLehrende sollten zunächst Informationen sammeln, um zu verstehen, was KI mit den Aufgaben in ihrem Kurs bewirken kann (MIT Teaching + Learning Lab, 2023). Melden Sie sich bei einem der professionellen KI-Dienste an wie ChatGPT oder Claude an und spielen Sie mit exemplarischen Konzepten, Fragen und Aufgabensets aus dem Kurs. Dabei ist es wichtig, nicht gleich bei der ersten schlechten Antwort aufzugeben, sondern Anpassungsmöglichkeiten durchzugehen: Lässt sich der Input beschränken? (Fragen auf einen Text-Input, eine gute Internetquelle oder eine hochgeladene PDF beschränken.) Lässt sich der Prompt anpassen? (Bearbeitung schrittweise durchführen lassen, Optionen und Szenarien durchgehen lassen usw., siehe den Abschnitt 2.5.2 zu Prompt Engineering.)\nWichtig ist, sich zu überlegen, welches Lernziel jede Aufgabe hat und wie die KI damit umgeht. Es sollte bewertet werden, bei welchen Arten von Fragen die KI gut abschneidet und wo ihre Grenzen liegen (Dell’Acqua et al., 2023). Diese Erkenntnisse können dann genutzt werden, um etwa Aufgabensets und andere Aufgabenstellungen besser zu strukturieren.",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Empfehlungen zur Umsetzung</span>"
    ]
  },
  {
    "objectID": "kapitel05.html#ausrichtung-der-anpassungen-nach-empfehlungen-der-lernforschung",
    "href": "kapitel05.html#ausrichtung-der-anpassungen-nach-empfehlungen-der-lernforschung",
    "title": "5  Empfehlungen zur Umsetzung",
    "section": "5.2 Ausrichtung der Anpassungen nach Empfehlungen der Lernforschung",
    "text": "5.2 Ausrichtung der Anpassungen nach Empfehlungen der Lernforschung\nUm die Empfehlungen der Lernforschung in das Vorgehen mit Künstlicher Intelligenz (KI) und Aufgabensets zu integrieren, könnten folgende Schritte unternommen werden (MIT Teaching + Learning Lab, 2023):\n\nZeitliche Verteilung und inhaltliche Mischung von Lerninhalten (Spacing & interleaving): Die Aufgabensets sollten so gestaltet werden, dass sie über das Semester verteilt sind und eine Vielfalt an Themen abdecken. Dies fördert die Langzeiterinnerung und hilft den Studierenden, die Anwendung der Konzepte in verschiedenen Kontexten zu üben. KI kann genutzt werden, um personalisierte Lernpläne zu erstellen, die auf den individuellen Fortschritt der Studierenden abgestimmt sind und eine Mischung aus verschiedenen Aufgabentypen bieten.\nTestgestütztes Lernen (Test-enhanced learning): Regelmäßige, durch KI unterstützte Quizze und Tests können in den Lehrplan integriert werden, um das Abrufen von Informationen zu fördern. Diese Tests könnten auch die kritische Bewertung von KI-generierten Antworten beinhalten, um die kritische Denkfähigkeit der Studierenden zu schärfen.\nFragebasierte Ausarbeitung (Explanatory questioning): KI-Tutor-Bots könnten entwickelt werden, um Studierende durch gezielte “Warum”-Fragen zu leiten, die ein tieferes Verständnis des Materials fördern. Diese Bots könnten in Simulationen und Rollenspielen eingesetzt werden, um die Studierenden dazu zu bringen, ihre Entscheidungen zu erklären und zu reflektieren, wodurch die Anwendung von Konzepten in realen oder simulierten Situationen vertieft wird.",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Empfehlungen zur Umsetzung</span>"
    ]
  },
  {
    "objectID": "kapitel05.html#einführung-der-studierenden-planen-besser-praktisch-häufig-und-niedrigschwellig",
    "href": "kapitel05.html#einführung-der-studierenden-planen-besser-praktisch-häufig-und-niedrigschwellig",
    "title": "5  Empfehlungen zur Umsetzung",
    "section": "5.3 Einführung der Studierenden planen: Besser praktisch, häufig und niedrigschwellig",
    "text": "5.3 Einführung der Studierenden planen: Besser praktisch, häufig und niedrigschwellig\nDen Einsatz von KI lernen die Studierenden, wenn sie häufig und über das Semester zeitversetzt damit experimentieren dürfen und müssen. Auch hier führen wieder die Empfehlungen des Spacing & Interleaving zu höherer Effektivität. Unterstützend können externe Lernvideos von seriösen Plattformen wie dem KI-Campus genutzt werden (z.B. https://ki-campus.org/videos/generativeki) oder selbst erstellte hochschulweite Angebote wie die Lehrpfade der TH Köln (https://lehrpfade.th-koeln.de/kategorie/ki/).\nUm ein gemeinsames Verständnis über Grundlagen herzustellen, ist es hilfreich, Zeit in einer der ersten Präsenzveranstaltungen einzuräumen, um das gemeinsam zu üben. Der Sprung ins kalte Wasser ist dabei meist besser, als eine lange Theorieeinführung: Gleich anfangen, dann problembasiert erläutern. Aspekte von testbasiertem Lernen und fragebasierte Ausarbeitung lassen sich gut über Anwendungsaufgaben in der Präsenzveranstaltung einbauen.\n\nBeispiel: KI-Übung in Präsenzveranstaltung am Ende eines Theorieblock zu Nachhaltigkeit in Lieferketten\nAufgabe: Nicht lange schnacken, anpacken! Mit der KI einen Projektplan für erste konkrete Schritte einer Nachhaltigkeitsstrategie erstellen (Edge Browser, Bing Copilot = GPT-4). Prompts zum Einstieg werden den Studierenden vorgegeben. Anfang mit:\n\nPrompt #1: „KI als Tutor“ oder ähnlich (siehe Appendix: Beispiel KI als Tutor #1/ Allgemeiner Tutor. Prompts im Folgenden immer kursiv.)\nPrompt #2: Ich will eine Cradle-to-cradle Nachhaltigkeitsstrategie für ein Unternehmen entwerfen. Helfen Sie mir, konkrete erste Schritte nach der Cradle-to-cradle Zertifizierung zu planen.\n\nStudierende sollen ein Unternehmen auswählen, bei dem sie schon einmal gearbeitet haben, oder das sie gut kennen. Hier ein Beispiel.\n\nPrompt #3: Ich denke über Voss Automotive nach, die folgende Produkte herstellen: innovative Leitungs-und Verbindungssysteme, die überall auf der Welt in Pkw und Nutzfahrzeugen sowie Land- und Baumaschinen eingesetzt werden. Unser Produktportfolio umfasst dabei einbaufertige Leitungsmodule mit Rohren, Schläuchen, Verbindungselementen, Ventilen und Sensoren. Zur Verbindungstechnik gehören Stecksysteme, Verschraubungen, Mehrfachkupplungen und Verteiler.\nPrompt #4: Erstelle einen Zeitplan als Tabelle mit Aufwandsschätzungen für 3 Personen in 4 Wochen.\nPrompt #5: Mehr Details bitte: Erstelle Unteraufgaben für die jeweiligen Aufgabenpakete, jeweils auch wieder mit Aufwandsschätzungen.\n\nDie Studierenden sollen den Projektplan dann weiter verbessern und diskutieren. Erweiternd können sie auch z.B. Projektrisiken, Indikatoren und Gegenmaßnahmen und Szenarien erheben und diskutieren.",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Empfehlungen zur Umsetzung</span>"
    ]
  },
  {
    "objectID": "kapitel05.html#wie-prüfen-wir-jetzt-jenseits-der-homework-apocalypse",
    "href": "kapitel05.html#wie-prüfen-wir-jetzt-jenseits-der-homework-apocalypse",
    "title": "5  Empfehlungen zur Umsetzung",
    "section": "5.4 Wie prüfen wir jetzt? Jenseits der Homework Apocalypse",
    "text": "5.4 Wie prüfen wir jetzt? Jenseits der Homework Apocalypse\nJenseits der vielen produktiven Anwendungen besteht die Gefahr, dass Studierende wichtige Teile des Denkprozesses an Sprachmodelle delegieren (Lee et al., 2025). Klassische „Hausaufgaben“ wie Seminararbeiten, Gruppenprojekte und Abschlussarbeiten drohen entwertet zu werden. Ohne Anpassung der Aufgabenstellung werden die Aufgaben potenziell sinnlos, da Studierende etwa Aufsätze oder Reflexionsaufgaben einfach von Chat GPT schreiben und einreichen. Interviews mit Studierenden und Nutzungsstudien zeigen, dass diese Gefahr akut ist. Wie wir in der umfassenden empirische Nutzungsstudie von Handa et al. (2025) sehen, nutzen Studierende Sprachmodelle gerade zur Schreibunterstützung intensiv und häufig. Das New York Magazine betitelt eine aktuelle Recherche mit „Everyone is cheating their way through college”, auf der Grundlage einer Vielzahl von Interviews mit desillusionierten Studierenden und Lehrenden (Walsh, 2025). Der o.g. Artikel der Fachzeitschrift Nature (s. Tabelle 4) skizziert ebenfalls basierend auf Interviews ein breites Spektrum an aktiver Nutzung im höheren Bildungsbereich (Heidt, 2025).\nSchon 2023 kündigte der Wharton Professor Mollick die „Homework Apocalypse“ an (Mollick, 2023). Dabei geht es Mollick weniger um das Tricksen mit den neuen technischen Möglichkeiten („Cheating was already common in schools“), sondern mehr um die empfundene Sinnlosigkeit von klassischen Hausaufgaben. „Students will want to understand why they are doing assignments that seem obsolete thanks to AI.“. Wer gibt noch reine Rechenübungen auf, wenn alle Taschenrechner haben? Wie kann Eigen- und Fremdleistung unter diesen neuen technischen Bedingungen getrennt werden? Wie können auch jetzt noch Anreize für Studierende gesetzt werden, Texte noch selbst zu lesen und Sätze noch selbst zu formulieren?\n\n\n\n\n\n\nAbbildung 5.1: Abbildung 15: Etwa gleichverteilt: Vier Arten der Interaktion von Studierenden mit Sprachmodellen. Quelle: Handa et al. (2025-04-08, 2025)\n\n\n\nEine Unterscheidung der empirischen Anthropic-Studie von Studierenden Interaktionen mit Sprachmodellen ist dabei hilfreich, um das Problem einzuordnen (Handa et al., 2025-04-08, 2025): Hier werden vier Arten von LLM-Nutzung unterschieden, je nachdem, ob ein Problem gelöst, oder ein Ergebnis generiert werden soll und je nachdem, ob dies direkt oder interaktiv erfolgt. Kollaborative Nutzungsformen (Typ 3 und 4) sind dabei für den Lernerfolg eher hilfreich, während das direkte Bereitstellen von Problemlösungen oder Texten aufgrund mangelnder Beschäftigung der Studierenden mit den Problemen und Materialien für Hausarbeiten eher hinderlich sein könnte (anders als für die Vorbereitung von kontrollierten Tests wie Klausuren). Studierende werden so eher in eine passive Rolle gedrängt und es fehlen die erwünschten Schwierigkeiten (desirable difficulties, (Roediger & Karpicke, 2006)), das fragebasierte Durchkauen und Hin- und Herüberlegen, das die Lernforschung als Wichtig für langfristiges Behalten ansieht (Roediger & Pyc, 2012).\nGrob gesagt wollen wir also kollaborative Interaktion und Hilfestellung fördern und einfaches Übernehmen bereitgestellter Lösungen verhindern. Wie können wir dafür die Hausarbeiten anpassen? Im Folgenden werden einige Empfehlungen zusammengefasst. Der Vier-Säulen-Ansatz nach Gmeiner bietet Orientierung. Er unterscheidet vier Gegenmaßnahmen für das Prüfen unter KI-Bedingungen: Mündlichkeit, Prozessorientierung, Kontextualisierung sowie Kollaboration (Gmeiner, 2025).\n\n\n\n\n\n\nAbbildung 5.2: Abbildung 16: KI-resistente Aufgabenstellungen – 4 Säulen nach Gmeiner (2025)\n\n\n\n\nMündlichkeit\nMündlichkeit stärkt Verständnis, Transfer und Autorschaft. Disputation, Präsentationen mit strukturiertem Q&A und gezielte Kolloquien machen eigene Entscheidungen sichtbar. So verlieren generische KI-Texte an Wert. Leitfäden empfehlen diese Formate ausdrücklich als Ergänzung zu schriftlichen Arbeiten. Detektionsscores dienen nicht als Beweis, sondern höchstens als Anlass zur Klärung (QAA, n. d.; Jisc, n. d.). Die University of Melbourne verweist auf skalierbare, mündliche Validierungen. Die folgende Übersicht zeigt typische Formate der mündlichen Prüfung.\n\n\n\n\n\n\nAbbildung 5.3: Abbildung 17: Vergleich mündlicher Prüfungsformen (Ward et al. (2024))\n\n\n\nHier sollen exemplarisch einzelne mündliche Prüfungsformate beschrieben werden, die Lehrende nutzen können.\nDas erste Format ist das Kurzkolloquium („Viva Voce Exam“ in der Abbildung). Ziel ist der Nachweis von Verständnis und Autorschaft. Hier wird die schriftliche Arbeit vom Leistungsnachweis getrennt (Gmeiner, 2025) und die Lernenden müssen ihre Entscheidungen in der schriftlichen Arbeit erläutern und verteidigen. Die Studierenden reichen ihre schriftliche Arbeit ein, die auch mit KI-Unterstützung erstellt werden darf und führen ein dann ein etwa zehnminütiges Gespräch über die Arbeit. Die Prüfenden wählen zum Beispiel zwei Kernentscheidungen zur weiteren Erläuterung aus: Datenaufbereitung und Argumentation. Die Studierenden erklären Vorgehen, Alternativen und Grenzen. Es folgt ein kurzes Transfer-Szenario: „Was würden Sie ändern, wenn…?“ Bewertet werden Klarheit, Begründung, Umgang mit Unsicherheit und Konsistenz zur Schriftfassung. KI-Regeln: KI-Nutzung wird offengelegt; Antworten sind persönlich und ohne Hilfsmittel. Skalierung gelingt mit standardisierten Leitfragen, Doppelprüfungen im Stichprobenprinzip und Aufzeichnung für Zweitbewertungen. Dieses Format eignet sich besonders für die Prüfung von Abschlussarbeiten und lässt sich leicht auch auf Seminararbeiten übertragen. Ähnlich wie auch für das folgende Format müssen hierfür initial Bewertungsmatrizen erstellt werden, potentielle Herausforderungen sind situativer Stress und Aspekte von Validität (Form vs. Inhalt, einfache vs. schwere Fragen, mündliche vs. schriftliche Ausdrucksfähigkeit), Reliabilität (Rating-Unterschiede bei verschiedenen Nachfragen und Bewertenden, verschiedenen Szenarien usw.) und Fairness (z.B. Sprachfähigkeiten, Vorwissen). Vorteile sind die Reaktivität und die Möglichkeit, durch vertiefende Nachfragen Hintergrundwissen und Begründungen abzufragen (Akimov & Malin, 2020, S.31; Kearney, 2019).\nEin ähnliches Format, aber mit anderem Fokus ist die interaktive mündliche Prüfung (interactive oral assessment, IO). Hier erhalten die Studierenden ein praxisnahes Szenario, das sie in Interaktion mit den Prüfenden analysieren und bearbeiten müssen (Ward et al., 2024). Gestaltet werden IOs als offene, nicht im Detailablauf vorgegebene Gespräche in realitätsnahen Szenarien, geführt zwischen Studierenden und Prüfenden (oder zwischen Studierenden). So wird etwa gefordert, eine Situation oder eine Fallstudie mit Bezug auf das erlesene Vorwissen zu analysieren. Bewertet wird die Interaktion durch unterlegt durch präzise Rubriken (die auch gemeinsam mit den Studierenden entwickelt werden können (Ní Bheoláin et al., 2020)), Beispielaufnahmen zur Vorbereitung und formative Einbettung über das Semester. Beispiele für die Einbettung umfassen etwa, dass Studierende die Rolle von Interviewten in einer Talkshow einnehmen, oder im Duo ihre Erkenntnisse von einer Konferenzteilnahme erläutern müssen. International wird diese Prüfungsform durchaus in sehr großen Kohorten eingesetzt, von Erstsemester-Kursen mit ca. 200 bis zu 800 Studierenden, mit 4 bis 10 Prüfenden (https://sway.cloud.microsoft/yQ2s0Bm3ILkWtGll). Es gibt eine Reihe detaillierter Leitfäden zur Umsetzung solcher Szenario-Prüfungen mit Aufnahmen von Beispielprüfungen und den Bewertungsrubriken (https://www.dcu.ie/sites/default/files/inline-files/interactive-oral-io-user-guide_0.pdf , siehe speziell die Übersicht der Ressourcen auf S.11).\n\n\n\n\n\n\nAbbildung 5.4: Abbildung 18: Mündlich prüfen geht auch in großen Kohorten – Beispiele von verschiedenen Universitäten\n\n\n\n\n\n\n\n\n\nAbbildung 5.5: Abbildung 19: Drei Szenarien für eine mündliche Prüfung in Pädagogik\n\n\n\nEin drittes Format ist die Posterpräsentation mit strukturiertem Q&A. Die Studierenden erstellen ein Forschungs- oder Praxisposter und präsentieren für fünf Minuten. Danach folgen gezielte Fragen zu Methode, Evidenz und Limitationen. Artefakte sind Poster, ein einseitiges Handout und ein Frageprotokoll. Bewertet wird die Evidenzführung, Passung von Methode und Frage sowie die Qualität der Antworten. KI darf für Layout und Sprachpolitur helfen, nicht für Inhalt. Offenlegung ist Pflicht. Große Gruppen lassen sich mit parallelen „Poster-Sessions“ und festen Zeitslots prüfen.\nFür Abschlussarbeiten kann diese Ausweitung der mündlichen Prüfungskomponente so operationalisiert werden, dass die Gewichtung des Kolloquiums erhöht wird, bzw. ein zweites Kolloquium hinzugefügt wird (um die Belastung der mündlichen Prüfung zu verteilen), in dem die Studierenden ca. 1 Monat nach dem Beginn der Abschlussarbeit mündlich den Stand der Forschung zum Thema darstellen und die Forschungslücke begründen müssen. Ein aktueller Entwurf an der TH Köln hierfür sieht so aus: * Kolloquium 1: Stand der Forschung und resultierende Forschungsfragen (3 ECTS) * Schriftliche Arbeit (8 ECTS) * Kolloquium 2: Ergebnis der Abschlussarbeit (4 ECTS) (Früher: Schriftliche Arbeit = 12 ECTS, Kolloquium = 3 ECTS).\n\n\nProzessorientierung\nProzessorientierung rückt den Weg zum Ergebnis in den Mittelpunkt und liefert über die stärkere Teilhabe der Prüfenden am Erstellungsprozess Evidenz für Autorschaft und verantwortliche KI-Nutzung. Insofern empfehlen die meisten Ratgeber, das Gewicht vom Produkt auf den Prozess zu verlagern. Ein Ratgeber der Melbourne University empfiehlt ausdrücklich, „vom Produkt zum Prozess“ zu wechseln, Prozess-Notizbücher und Reflexionen einzubauen und mit Umgebungen wie Cadmus digitale Prozess-Spuren zu erfassen (Mulder et al., 2023). Eine Studie von Hanover Research fordert gestaffelte Abgaben über die Zeit mit intensiver, iterativer Rückmeldung und betont, dass die Sichtbarmachung individueller und kollaborativer Arbeitsprozesse KI-Nutzung unattraktiv macht (Hanover Research, 2024). Empfehlungen der Monash University konkretisieren dies: Prozessbewertungen, verbundene Aufgaben und Einbindung der Prüfenden in den Entstehungsprozess (Monash University, 2025). Gmeiner operationalisiert Prozessfokus zudem durch transparente KI-Nutzungsdokumentation mit Prompt-/Output-Belegen und reflektierter Einbettung in die Eigenleistung (Gmeiner, 2025).\n\n\n\n\n\n\nAbbildung 5.6: Abbildung 20: Abhilfe durch Interaktion oder engere Prozessbetreuung: Aufgabentypen nach der Schwierigkeit, durch KI repliziert zu werden (Hanover Research (2024))\n\n\n\nEin zentrales Format ist das Prozessjournal mit Audit-Trail: Studierende dokumentieren Suche, Auswahl, Analyse, Entscheidungen und Revisionen fortlaufend; ein Versionsverlauf in Overleaf oder Git macht Änderungen nachvollziehbar. Abgegeben werden Journal, Query-Protokolle, Daten-/Code-Paket und Endprodukt. Bewertet werden Nachvollziehbarkeit, Qualität der Entscheidungen, Reproduzierbarkeit und eine reflektierte Darstellung der KI-Nutzung (Tool, Version, Prompts, Zweck, Umfang, Korrekturen). Detektoren entfallen; der dokumentierte Prozess bildet die Hauptgrundlage der Beurteilung.\nAls zweites Format bietet sich die gestaffelte Hausarbeit an: Outline, Annotated Bibliography, Methoden-Memo, Rohanalyse, Draft und Final werden über das Semester verteilt, jeweils mit Feedback und klar getrennten Prozess- und Produktpunkten in der Rubrik. KI kann bei Ideenfindung und Sprachpolitur helfen, nicht bei Theoriebildung oder Ergebnissen; Nutzung und kritische Einordnung sind offenzulegen. In großen Kohorten tragen Peer-Reviews nach Rubrik und stichprobenhafte Dozierenden-Checks zur Skalierung bei.\n\n\nKontextualisierung und empirischer Bezug\nKontextualisierung und Empirie binden Leistung an reale Daten, Orte und Rollen und entwerten generische KI-Outputs. Die Leitfäden empfehlen realweltliche, lokal verankerte, persönlich bezogene Aufgaben. Melbourne CSHE listet explizit „authentische, kontextspezifische oder persönliche“ Aufgaben – etwa Analysen weniger bekannter lokaler Objekte, Bezüge zu persönlicher Erfahrung oder Aufgaben, die genuine Berufsprodukte erzeugen (Mulder et al., 2023). Monash rät, Essayaufgaben so zu verändern, dass personalisierte Anwendung und Kontextualisierung zwingend sind; außerdem werden multimodale Artefakte als KI-resistenter eingestuft (Monash University, 2025). Gmeiner präzisiert diese Logik: biografisches Lernen, Aufgaben an außerschulischen Lernorten oder tagesaktuelle Kontexte machen die Aufgabe „un-promptbar“, weil sie persönliche, physische oder nicht-öffentliche Informationen, sinnliche Beobachtung und Gegenwartsbezug erfordern (Gmeiner, 2025).\nSelbst erhobene Empirie zählt, reine Literaturstudien oder theoretische Ausarbeitungen sind zu vermeiden. Interviews, Prozessanalysen, der Bau eines Prototypen oder sonstige Erhebungen von Primärdaten verlangen, dass Studierende einen passenden Fall auswählen, Daten erheben oder kuratieren, diese methodengerecht analysieren und eine Entscheidungsvorlage erstellen. Abzugeben sind Datensatz, Methodenprotokoll, Analyse-Notebook und eine kurze Empfehlung; bewertet werden Kontextpassung, Datenqualität, methodische Angemessenheit und die Tragfähigkeit der Handlungsempfehlung. KI darf strukturieren, nicht aber Evidenz ersetzen. Alternativ können Replikations- und Verifikationsaufgaben genutzt werden: Studierende replizieren eine veröffentlichte Analyse, dokumentieren Abweichungen und prüfen Robustheit mit alternativen Spezifikationen. Artefakte sind ein vollständiges Repro-Paket, ein Abweichungsprotokoll und ein Kurzbericht, der klar ausweist, was trägt und was nicht. KI kann Code-Snippets vorschlagen, doch jede Zeile wird verstanden, kommentiert und getestet. Offenlegung der Tool-Nutzung bleibt Pflicht. Automatisierte Checks und präzise Rubriken halten den Korrekturaufwand im Rahmen.\nFür Abschlussarbeiten kann dies so operationalisiert werden, dass reine Literatur- oder Theoriearbeiten ohne empirischen Bezug vom Prüfungsausschuss zu genehmigen sind.\n\n\nKollaboration und Kreation\nKollaboration und Kreation prüfen die soziale, evaluative und kreative Dimension des Lernens und machen Aushandlung und Revision sichtbar. Die Leitfäden schlagen in diesem Kontext etwa In-Class- und Gruppenaufgaben, Peer-/Selbstbeurteilung und gestufte Projekte vor. Melbourne CSHE zeigt in mehreren Fallbeispielen, wie verschachtelte Aufgaben mit Gruppen-Literaturarbeit, Projektplänen, Peer-Review und Präsentationen kombiniert werden. Diese Designs stärken Prozess-Transparenz, evaluative Urteilskraft und erschweren KI-Missbrauch (Mulder et al., 2023). Hanover Research betont ähnlich Gruppenarbeiten, In-Class-Aktivitäten und Aufgaben, die die Nutzung von KI explizit erlauben, aber kritisch auswerten lassen – also Kreation plus Metareflexion (Hanover Research, 2024).\nWie kann so etwas aussehen? Ein peer-reviewtes Multimedia-Projekt etwa verlangt, dass kleine Teams ein konkretes Produkt – Podcast, Video oder Infografik – für ein definiertes Publikum erstellen. Der Prozess umfasst Briefing, Drehbuch, Quellenkurzprüfungen, Prototyp, Peer-Feedback und Finalisierung. Bewertet werden Evidenzbasis, Storyline, Zielgruppenpassung, Feedbackqualität und die Umsetzung der Rückmeldungen; neben dem Produkt liefern Teams Quellenlisten, Peer-Feedback-Protokolle und individuelle Reflexionen. Alternativ können Rollen- oder Planspiele erstellt oder bearbeitet und reflektiert werden (Gmeiner, 2025). KI kann als Ideengeber dienen, doch Entscheidungen und Quellenhoheit verbleiben beim Team; kurze Nachgespräche sichern Autorschaft ab.\nAls Abschlussformat eignet sich ein Team-Capstone mit getrennter Team- und Individualnote: Das Team liefert ein belastbares Artefakt – etwa einen Prototyp, eine Konzeptstudie oder einen Policy-Brief mit Daten –, während jede Person einen individuellen Methoden-Anhang und eine Reflexion zum eigenen Beitrag und zur KI-Nutzung abgibt. Bewertet werden Teamprodukt, individueller methodischer Beitrag und die Qualität der Reflexion; klare KI-Regeln fordern Offenlegung, Bias-Prüfung und Quellenverifikation. Milestone-Boards, strukturierte Peer-Assessments und stichprobenhafte mündliche Abfrage pro Team sichern Skalierbarkeit und Integrität.\nKombiniert man die vier Säulen, entsteht eine Vielzahl von Optionen für ein konsistentes, skalierbares Prüfungsdesign, das auf Transparenz, Prozessnähe und reale Anwendung setzt. Mündliche Elemente sichern Autorschaft und Transfer, prozessorientierte Formate liefern nachvollziehbare Evidenz, kontextgebundene Aufgaben prüfen Verständnis unter realen Bedingungen, und kollaborative Produkte stärken Urteilskraft, Feedbackkultur und Kreativität. Klare Richtlinien, Offenlegung und belastbare Rubriken tragen das Konstrukt. KI-Detektoren werden überflüssig, weil die Beweise im Prozess liegen und Prüfende enger an diesem Prozess teilnehmen und in den vorgestellten Prüfungsformen interaktiv nachfragen können. Dies alles aufzusetzen bedeutet durchaus hohe Initialaufwände und die neuen Prüfungsformen müssen evaluiert werden, um bekannte Probleme etwa des Prüfens in direkter Interaktion (Validität, Reliabilität, Fairness, s.o.) einzudämmen (Akimov & Malin, 2020). Positiv dabei: Es gibt schon viele Vorlagen, auf die man aufbauen kann und durch diese Anstrengungen bleiben Integrität und Qualität der Prüfungen gewahrt – die oben genannte Furcht vor Betrug und Sinnlosigkeit der Prüfungen wird eingedämmt, ohne dass auf reines Klausurlernen zurückgefallen werden muss, während Studierende lernen, KI verantwortlich, nachvollziehbar und wirksam einzusetzen.",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Empfehlungen zur Umsetzung</span>"
    ]
  },
  {
    "objectID": "kapitel05.html#richtlinien-zur-ki-nutzung---welche-handreichungen-geben-hochschulen-und-was-wird-empfohlen",
    "href": "kapitel05.html#richtlinien-zur-ki-nutzung---welche-handreichungen-geben-hochschulen-und-was-wird-empfohlen",
    "title": "5  Empfehlungen zur Umsetzung",
    "section": "5.5 Richtlinien zur KI-Nutzung - welche Handreichungen geben Hochschulen und was wird empfohlen?",
    "text": "5.5 Richtlinien zur KI-Nutzung - welche Handreichungen geben Hochschulen und was wird empfohlen?\n\nÜbersicht: Was regeln aktuelle Richtlinien?\nWie reagieren Hochschulen auf die Chancen und Herausforderungen von LLM? Eine Übersichtsstudie von An et al. (2025) untersucht die Richtlinien der Top 50 US Hochschulen zur Nutzung von LLM. Mittels Topic Modeling identifizieren sie vier zentrale Themenfelder: die Integration von LLM in Lehre und Prüfungen, die Nutzung in visuellen und interaktiven Medien, Fragen der Sicherheit und Ethik sowie die Wahrung akademischer Integrität. Die Sentimentanalyse zeigt eine insgesamt positive Haltung gegenüber LLM, insbesondere in Richtlinien für Lehrende und Verwaltungspersonal. Studierendenrichtlinien sind hingegen zurückhaltender und stärker auf Einschränkungen fokussiert. Die Analyse differenziert die Inhalte nach Zielgruppen: Während Lehrende vor allem Unterstützung für Kursdesign und Prüfungsformate erhalten, stehen bei Studierenden Regelungen zur Integrität im Vordergrund. Forschende und Verwaltungspersonal werden bislang weniger berücksichtigt, obwohl sie ebenfalls spezifische Herausforderungen und Potenziale im Umgang mit LLM aufweisen. Die Autor:innen empfehlen daher eine stärkere Differenzierung und kontinuierliche Weiterentwicklung der Richtlinien, den Verzicht auf unzuverlässige Detektionstools sowie eine institutionenübergreifende Reflexion über ethische, rechtliche und didaktische Implikationen.\nSpeziell deutsche Leitlinien an 27 Hochschulen untersuchte das Hochschulforum Digitalisierung im Jahr 2024 (Tobor, 2024), ein Update im Februar 2025 ergänzt neuere Entwicklungen (Tobor, 2025). Die Analyse umfasst hochschulweiten Leitlinien deutscher Universitäten zum Umgang mit generativer KI. Dabei hebt Tobor eine Reihe bewährter Praktiken hervor, die sich in mehreren Leitfäden wiederfinden (Für konkrete Beispiele siehe Appendix 2: Beispiele für KI-Richtlinien):\n\nEin zentrales Element ist die Anpassung der Eigenständigkeitserklärung in schriftlichen Prüfungen ohne Aufsicht. Viele Hochschulen – exemplarisch die Vorlage der Hochschule RheinMain – fordern darin von Studierenden eine explizite Erklärung, ob und in welcher Weise KI-Tools verwendet wurden. Diese Erklärungen dienen der Transparenz und ermöglichen Lehrenden, KI-Nutzung regelkonform einzuordnen.\nIm Umgang mit Verdachtsfällen unzulässiger KI-Nutzung betonen viele Leitlinien die Grenzen technischer Erkennung. Tools wie GPTZero gelten als unzuverlässig. Stattdessen wird – wie im Leitfaden der Universität Vechta – ein multifaktorielles Vorgehen empfohlen, das Indikatoren wie nicht reale Quellen oder auffällige Formulierungen einbezieht. Bestätigt sich der Verdacht, erfolgt ein Klärungsgespräch, um das Verständnis der Studierenden für ihre Arbeit zu überprüfen.\nIm Bereich Urheberrecht wird festgehalten, dass KI-Systeme wie ChatGPT derzeit keine Urheber im juristischen Sinne sind. Ihre Inhalte stellen daher nicht automatisch ein Plagiat dar, können aber Rechte Dritter verletzen. Die Verantwortung für eine rechtskonforme Nutzung liegt bei den Studierenden – klare gesetzliche Regelungen stehen noch aus.\nKritisch sehen viele Hochschulen die Verwendung von KI zur automatisierten Bewertung von Prüfungsleistungen. Diese widerspricht in der Regel Prüfungsordnungen, die eine begründete Bewertung durch eine prüfende Person verlangen. Zudem wird das Hochladen studentischer Arbeiten in KI-Systeme als urheberrechtlich bedenklich eingestuft.\nSchließlich fordern zahlreiche Leitlinien eine didaktische Weiterentwicklung von Prüfungsformaten. Empfehlungen reichen von stärker reflexionsorientierten Aufgaben über Zwischenfeedback und methodische Transparenz bis hin zu ergänzenden mündlichen Prüfungen. Ziel ist es, den Kompetenznachweis trotz verfügbarer KI-Tools aussagekräftig zu gestalten. Dabei sollte auch der Umgang mit KI selbst – inklusive Prompt-Gestaltung oder kritischer Reflexion – zum Prüfungsgegenstand werden. Lehrende werden ermutigt, den Einsatz von KI gemeinsam mit den Studierenden zu reflektieren und klare Regeln im Kurs zu kommunizieren.\n\nIm Update von 2025 stellt Tobor auch kritisch die thematische Zersplitterung der verschiedenen Handreichungen fest: Die Richtlinien versuchen, eine Vielzahl von Einzelthemen für eine Vielzahl von Gruppen zu integrieren, speziell regulatorische und didaktische. Hinzu kommen Anforderungen zur Risikoaufklärung über Themen wie Halluzinationen, Vorurteile von LLM in den Ergebnissen und Ressourcenverbrauch. Die europäische KI-Verordnung (KI-VO) verschärft die Anforderungen an Hochschulen, insbesondere im Hinblick auf KI-Kompetenzen und Risikoeinstufungen bei Prüfungen. Positiv werden integrierende Formate wie “Landing Pages“ genannt, etwa der KI-Hub der Universität Vechta (https://www.uni-vechta.de/ki-hub). Ein solcher zentraler Startpunkt kann allgemeine und spezielle Themen verbinden und – bei guter Kuratierung – helfen, Komplexität zu reduzieren.\n\n\nAllgemeine Empfehlungen zu Richtlinien\nAn et al. (2025) plädieren für ausgewogenere, zielgruppenspezifische Leitlinien, die sowohl regulatorische Klarheit als auch didaktische Impulse bieten – insbesondere für Studierende, deren Perspektive bislang zu wenig berücksichtigt wird. Was für didaktische und regulatorische Aspekte für Lehrende und Studierende werden hier festgelegt?\nFür Lehrende stehen didaktische Empfehlungen im Vordergrund, die auf eine bewusste Integration generativer KI in die Hochschullehre zielen. In 94 % der untersuchten Richtlinien werden konkrete Hinweise gegeben, wie LLM in Kursdesign, Aufgabenstellungen und Prüfungsformate eingebunden werden kann. Lehrende werden ermutigt, im Syllabus klar zu definieren, ob und wie der Einsatz von KI erlaubt ist – etwa durch gestufte Erlaubnisformen (verboten, erlaubt mit Dokumentation, ausdrücklich gewünscht). Zudem wird empfohlen, Prüfungsformate so umzugestalten, dass sie weniger anfällig für unreflektierte KI-Nutzung sind, z. B. durch individuelle Reflexionen, Gruppenarbeit oder mündliche Komponenten. Regulatorisch wird betont, dass die Verantwortung für die Formulierung und Durchsetzung dieser Regeln bei den Lehrenden liegt, jedoch unterstützt durch hochschulweite Orientierungshilfen. KI-Detektionstools wie Turnitin oder GPTZero werden hingegen kritisch gesehen: Viele Hochschulen raten von deren Einsatz ab, da ihre Ergebnisse unzuverlässig seien und leicht zu Fehlinterpretationen führen können.\nFür Studierende betonen die Richtlinien vor allem regulatorische Aspekte im Sinne der akademischen Integrität. Häufig wird darauf hingewiesen, dass LLM nicht uneingeschränkt eingesetzt werden darf, und dass ein nicht genehmigter Einsatz als Täuschungsversuch gewertet werden kann. Die Verantwortung zur Klärung, ob LLM zulässig ist, wird den Studierenden zugeschrieben – sie sollen aktiv Rücksprache mit Lehrenden halten. Didaktisch werden Studierende allerdings meist weniger unterstützt: Nur wenige Richtlinien bieten Anleitungen zur kompetenten Nutzung von LLM oder reflektieren über sinnvolle Lernstrategien im Umgang mit KI. Eine Ausnahme bilden vereinzelte Hinweise zur Förderung von AI Literacy, etwa zur kritischen Bewertung von KI-generierten Texten oder zur Transparenzpflicht bei der Nutzung von LLM in Hausarbeiten. Insgesamt dominiert jedoch eine restriktive und kontrollierende Perspektive, die stärker auf Vermeidung von Fehlverhalten als auf befähigende Lernangebote setzt.\nDie deutsche Untersuchung von Tobor (2025) betont, dass die Wirksamkeit solcher Leitlinien maßgeblich davon abhängt, ob sie bekannt gemacht, kontinuierlich diskutiert und weiterentwickelt werden. Zentral ist es, die Leitlinien User-adäquat zu gestalten und bekannt zu machen. (Auch hier begegnen uns implizit wieder die zentralen Kategorien Nutzerfreundlichkeit und wahrgenommene Nützlichkeit des Technology Acceptance Models.) Tobor warnt davor, Leitlinien als bloße Beruhigungsmittel zu betrachten, und fordert stattdessen eine dialogische, ko-kreative Weiterentwicklung – etwa durch Beteiligung von Studierenden, verbundweite Zusammenarbeit und neue Formate wie Prompt-Battles. Leitlinien sollten als lebendige Rahmenwerke verstanden werden, die zur aktiven Gestaltung des KI-bedingten Wandels in Studium und Lehre beitragen.\nWie sehen solche Richtlinien aus? Konkrete Formulierungen und Links hierzu finden Sie im Appendix 2: Beispiele für KI-Richtlinien.",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Empfehlungen zur Umsetzung</span>"
    ]
  },
  {
    "objectID": "kapitel05.html#wie-können-studierende-die-nutzung-von-llm-dokumentieren-stichworte-nach-arbeitsphase-nach-werkzeug-oder-als-reflexionstagebuch",
    "href": "kapitel05.html#wie-können-studierende-die-nutzung-von-llm-dokumentieren-stichworte-nach-arbeitsphase-nach-werkzeug-oder-als-reflexionstagebuch",
    "title": "5  Empfehlungen zur Umsetzung",
    "section": "5.6 Wie können Studierende die Nutzung von LLM dokumentieren? Stichworte, nach Arbeitsphase, nach Werkzeug oder als Reflexionstagebuch",
    "text": "5.6 Wie können Studierende die Nutzung von LLM dokumentieren? Stichworte, nach Arbeitsphase, nach Werkzeug oder als Reflexionstagebuch\nFrühe Handreichungen zur Dokumentation von LLM in Studierendenarbeiten waren noch sehr allgemein formuliert und bestanden etwa darauf, dass jegliche Nutzung im Schreibprozess genau protokolliert würde. Bei täglicher und stark integrierter Nutzung ist das etwa so sinnvoll, wie die Forderung, jegliche Internetnutzung in einem Tagebuch zu erfassen. Sinnlose Forderungen führen schnell dazu, dass die dahinter stehende Forderung nach prinzipieller Nachvollziehbarkeit des Forschungsvorgehens entwertet und Umgehungshandlungen normalisiert werden.\nNeuere Empfehlungen der Hochschulen sind hier deutlich realistischer: So bietet etwa eine Handreichung von niedersächsischen Hochschulen eine gute Reihe von Optionen, die von einer einfachen Stichpunktliste („elicit.com zur Literaturrecherche, perplexity.ai zur Internetrecherche, gamma.app zur Präsentationserstellung, stablediffusionweb.com zur Bildgeneration“) bis zu detaillierten Tagebüchern mit Reflexionshilfen reicht (Baresel et al., 2024).\nIm Folgenden zeigen wir drei weitere Beispiele für Dokumentationen nach Arbeitsphasen, nach Werkzeugen und in Form eines Reflexionstagebuches (Baresel et al., 2024).\nDie Dokumentation nach Arbeitsphasen (s. Tabelle 8) zielt auf eine strukturierte Erfassung des KI-Einsatzes entlang typischer wissenschaftlicher Arbeitsphasen (z. B. Themenfindung, Recherche, Schreiben). Studierende bewerten selbst den Grad der KI-Nutzung (von „inspirierend“ bis „inhaltsgestaltend“) und dokumentieren Tool, Einsatzkontext und Wirkung. Ziel ist Transparenz über den konkreten Einfluss auf das Ergebnis.\nBei der werkzeugorientierten Dokumentation (s. Tabelle 9) werden in tabellarischer Form die verwendeten Tools (z. B. ChatGPT, DeepL Write) samt Quelle, Zweck, Funktion und Einsatzbereich gelistet. Diese Variante erleichtert die Nachvollziehbarkeit, gibt aber wenig Einblick in den Kontext oder den Einfluss der Tools auf den Arbeitsprozess.\nBeim Reflexionstagebuch (s. Tabelle 10) steht die kontinuierliche, persönliche Auseinandersetzung mit dem eigenen KI-Einsatz im Vordergrund. Studierende führen während des Arbeitsprozesses ein Tagebuch, das später in eine prüfungsrelevante Dokumentation überführt wird. Diese Methode fördert den Aufbau von KI-Literacy und metakognitiver Kompetenz, ist jedoch zeitaufwändig und betreuungsintensiv.\n\n\n\nTabelle 5.1: Tabelle 8: Beispiel arbeitsphasenorientierte Dokumentation der LLM Nutzung. Quelle: (Baresel et al. (2024), S. 11)\n\n\n\n\n\n\n\n\n\n\nPhase im Arbeitsprozess\nDokumentation: Eingesetzte Tools, Verwendungszweck, Funktionsweise, Ergebnis\nGrad der KI-Nutzung\n\n\n\n\nIdeenfindung/Strukturierung\nTools: ChatGPT, PerplexityZweck: Brainstorming zu Forschungsfragen, GliederungsideenErgebnis: 5 Themenvorschläge, davon 1 weiterverfolgt\n1\n\n\nRecherche\nTools: Elicit, Semantic ScholarZweck: Suche nach passender LiteraturErgebnis: Liste mit 15 Quellen, 8 davon verwendet\n2\n\n\nSchreiben/Formulieren\nTools: DeepL WriteZweck: Verbesserung des sprachlichen AusdrucksErgebnis: Überarbeitete Einleitung\n3\n\n\nÜberarbeitung/Korrektur\nTools: GrammarlyZweck: Prüfung auf Grammatik- und RechtschreibfehlerErgebnis: Fehlerfreier Text\n2\n\n\n\n\n\n\n\n\n\nTabelle 5.2: Tabelle 9: Beispiel werkzeugorientierte Dokumentation der LLM Nutzung. Quelle: (Baresel et al. (2024), S. 8)\n\n\n\n\n\n\n\n\n\n\n\n\nSoftware/Programm/KI-Anwendung\nLink/Quelle\nVerwendungszweck\nGenutzte Funktion\nNutzungsbeschreibung/Anwendungsbereich\n\n\n\n\nappypie\nhttps://www.appypie.com/design/de/infografik/ersteller\nInfografiken zur Erläuterung\nEntspricht Verwendungszweck\nInfografik für einen Überblick in der Einleitung, S. 3\n\n\nClaude\nhttps://claude.ai/new\nAssistenz zur Programmierung, Vorschläge für Gliederung\nChat und Code-Ausgabe\nProgrammierung des Auswertungsprogramms, siehe S.13 Erstaufschlag der Gliederung, wurde überarbeitet\n\n\nDeepL Write\nhttps://www.deepl.com/de/write\nÜberarbeiten der Texte\nEntspricht Verwendungszweck\nGesamter Text\n\n\nDeepL Übersetzer\nhttps://www.deepl.com/de/translator\nÜbersetzung von französischsprachigen Papers\nÜbersetzung Französisch–Deutsch\nDie Paper Lacroix, 2007 & Macron, 2020 wurden übersetzt.\n\n\nKiCad²\nhttps://www.kicad.org/\nLayout der Testplatine\nPCB Layout\nLayout der Platine, siehe Abb. 15 S. 20\n\n\nMATLab\nHochschullizenz\nSimulation der Empfängerschaltung\nSimulink\nSchaltung xyz auf S. 14 simuliert und optimiert\n\n\nMaxQDA\nHochschullizenz\nAuswertung Interviews\nMaxQDA und AI Assist\nKategorienbildung, siehe Kap 4.2 und Anhang C\n\n\nOpenknowledgemap\nhttps://openknowledgemaps.org/\nRecherche des Forschungsfelds\nEntspricht Verwendungszweck\nFür die Einarbeitung wurde mit diesem Tool der Zugang zum Forschungsfeld erschlossen.\n\n\nSPSS\nHochschullizenz\nAuswertung Daten zur Gesundheitsversorgung\nHypothesentest mittels xy\nDatenauswertung siehe S. 15 und Anhang S. 77\n\n\nVisual Studio C++\nHochschullizenz\nProgrammierung einer Navigationslösung\nEntspricht Verwendungszweck\nProgrammierung des zentralen Programms der Arbeit, siehe Kap. 4\n\n\nWhisper (openAI)\nhttps://openai.com/index/whisper/\nTranskribieren von Interviews\nTranskribieren ohne Übersetzung\nTranskribieren der Interviews, wurden korrigierend überarbeitet. Siehe Anhang B\n\n\n\n\n\n\n\n\n\nTabelle 5.3: Tabelle 10: Beispiel Reflexionstagebuch zur LLM Nutzung. Quelle: (Baresel et al. (2024), S. 16)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDatum\nWoran habe ich gearbeitet? (Stichpunkte)\nWelche digitalen Tools habe ich verwendet?\nNotizen zum Einsatz digitaler Tools\nReflexion\nBeleg/Beispiel\nGrad der Nutzung\n\n\n\n\n1.9.24\nThemenfindung\nChatGPT 3.5 über Academic Cloud\nVersuch, einige Begriffe zu schärfenFragestellungen vorschlagen lassen\nHilfreich, um Fachbegriffe zu identifizierenAus den Begriffen mal Fragestellungen machen lassen. Das traf es aber nicht wirklich. Ich muss noch weitermachen.\n\n12\n\n\n2.9.24\nTexte lesen\nChatPDF\n2 Texte hochgeladen, geprüft, ob relevant\nToll, dass ich deutsch fragen kann, auch wenn der Text englisch/italienisch ist. Entlastet! Macht das Lesen gezielter. Merke aber auch, dass ich dann den Text nicht mehr ganz lese.\n\n2\n\n\n5.9.24\nBild generieren\nbing.com/create\nIllustration für die Präsentation zum Projekt\nMacht Spaß! Ist aber auch aufwändig, genau das zu prompten, was man haben will. Zeitfresser.\nDenken findet in der Auseinandersetzung von Mensch mit Maschine statt; Künstliche Intelligenz ist ein Partner des Menschen beim Denken. Helle, motivierende Farben = 07_Denken-externalisiert_Utopie_01.jpeg\n4\n\n\n10.9.24\nText bearbeiten\nChatGPT 4.0 über Academic Cloud\nFormulierungsalternativen gesucht\nUnentschieden. Manches klingt gut, aber irgendwie auch nicht. Weiß nicht so recht, was ich davon halten soll.\n24-09-10_Chat-Verlauf.docx\n3",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Empfehlungen zur Umsetzung</span>"
    ]
  },
  {
    "objectID": "kapitel05.html#beispiele-für-die-kurs-integration-von-ki",
    "href": "kapitel05.html#beispiele-für-die-kurs-integration-von-ki",
    "title": "5  Empfehlungen zur Umsetzung",
    "section": "5.7 Beispiele für die Kurs-Integration von KI",
    "text": "5.7 Beispiele für die Kurs-Integration von KI\nAbschließend wollen wir uns Beispiele ansehen, wie ein Kurs aussehen könnte, der mit LLM in der Vorbereitung arbeitet und sie in Übungsaufgaben und die Prüfungsvorbereitung einbindet. Anmerkung: Hier wird nur die KI-Ergänzung beschrieben, natürlich werden außerdem Lehrbücher und Fachartikel als Input genutzt.\nZeitliche Struktur und Inhalte (Fokus auf den Einsatz von KI-Tools)\nWoche 1–4: Vorbereitung und KI-gestützte Materialerstellung (KI als „Hiwi“) * Kursvorbereitung mit LLM: Erstellung und Anpassung vielfältiger Programmieraufgaben an unterschiedliche Lernniveaus mithilfe von Large Language Models. * DeepResearch: Unterstützung bei der Recherche aktueller Trends in der Programmierdidaktik und relevanter Beispiele, um realitätsnahe Aufgabenstellungen zu entwickeln. * NotebookLM für Podcast-Episoden: Aus den erstellten Materialien werden mithilfe von NotebookLM kurze Podcast-Folgen generiert, die Studierende zur Einführung in die Kursstruktur, grundlegende Programmierkonzepte und organisatorische Aspekte anhören können. Dies dient als motivierende, niederschwellige Form der Wissensvermittlung.\nWoche 5–8: Vertiefung und individuelle Lernwege (KI als „Copilot“) * Individuelle Programmieraufgaben: Die Studierenden nutzen Google Colab oder ein ähnliches Tool, das KI-unterstützte Programmierung erlaubt (z.B. DeepNote). Sie lösen damit gleich am Anfang Anwendungsaufgaben und müssen die Code-Bestandteile in der Präsenzzeit anderen Gruppen erklären. Die Übungsaufgaben werden fortlaufend angepasst, indem die Lehrenden zusammen mit einem LLM bestehende Aufgaben je nach Lernfortschritt der Studierenden variieren (z.B. mehr Code-Komplexität oder zusätzliche Anwendungsfälle). * Voice Mode für Simulationen: Interaktive Rollenspiele bzw. Simulationen (z.B. „Debugging-Dialog“) mit einem KI-Avatar in Voice Mode. Die Studierenden können live Fragen stellen, sich Lösungswege erklären lassen oder sich ein Code-Review im Gesprächsformat geben lassen. * DeepResearch: Zur Vertiefung konkreter Themen (z.B. Algorithmendesign, Datenstrukturen) recherchieren die Studierenden mithilfe von DeepResearch in Fachartikeln, Blogposts und Dokumentationen. Sie lernen, verschiedene Quellen kritisch zu bewerten und für ihr Projekt nutzbar zu machen.\nWoche 9–12: Konsolidierung und Prüfungsvorbereitung (KI als „Lernhilfe“) * NotebookLM zur Zusammenfassung: Aus den im Kurs genutzten Lernmaterialien (Skripte, Forumsdiskussionen, Beispielcode) generiert NotebookLM automatisiert Zusammenfassungen und kurze Podcasts zu Schlüsselkonzepten. Studierende können diese unterwegs anhören oder gezielt zur Prüfungsvorbereitung nutzen. * LLM für Übungsfragen: Auf Grundlage der bisherigen Lernfortschritte generiert das LLM individuelle Übungsfragen sowie Quizformate zur Selbstüberprüfung. * Voice Mode für Prüfungssimulation: Studierende simulieren mündliche Prüfungssituationen oder Code-Erklärungen über Voice Mode. Dies fördert die Fähigkeit, Inhalte klar und strukturiert zu präsentieren.\n\nBeispielkurs 2: Ergänzung eines Kurses Interkulturelles Management durch KI-Unterstützung\nWoche 1–4: KI als „Hiwi“ * Ziel: Erstellung vielfältiger, kulturell spezifischer Fallstudien und Szenarien, die als Diskussions- und Analysegrundlage dienen. * LLM für Fallstudien & Szenarien: Die Lehrenden nutzen LLM (z.B. ChatGPT oder andere) zur Generierung von Fallstudien, die spezifische interkulturelle Kontexte beleuchten (z.B. Verhandlungen in ostasiatischen vs. europäischen Kulturen, Führungsstile in verschiedenen Regionen etc.). * Gegenmaßnahme zur Qualitätssicherung: Die Ergebnisse werden stichprobenartig auf Richtigkeit, kulturelle Sensibilität und Relevanz überprüft. * DeepResearch zur Materialrecherche: Lehrende recherchieren mithilfe von DeepResearch nach relevanter Literatur, neuesten Studien und Praxisberichten im Bereich interkulturelles Management. Die gefundenen Quellen fließen ein in vorbereitende Leselisten und Hintergrundinformationen für die Studierenden. * NotebookLM für Podcast-Folgen: Für einen motivierenden Einstieg ins Thema werden kurze Podcasts (ca. 5–10 Minuten) mithilfe von NotebookLM erstellt. Themen könnten sein: „Einführung in kulturelle Dimensionen“ (bspw. nach Hofstede), „Erfolgsbeispiele im interkulturellen Management“, „Warum interkulturelle Kompetenz immer wichtiger wird“. Studierende können diese Podcasts vor oder nach den Präsenz- bzw. Online-Sitzungen anhören, um zentrale Konzepte zu festigen.\nWoche 5–8: KI als „Copilot“ für Anwendungsaufgaben * Ziel: Entwicklung praxisnaher Simulationen, Rollenspiele und Fallübungen, um die Studierenden für reale interkulturelle Managementkonflikte zu sensibilisieren. * LLMs für Rollenspiel- und Simulationsszenarien: Studierende entwickeln in Kleingruppen Szenarien (z.B. Konflikte in multikulturellen Teams, Verhandlungen in internationalen Projekten), wobei sie LLM nutzen, um die Settings, Dialoge oder Konfliktpunkte zu konkretisieren. Lehrende moderieren den Prozess und überprüfen die Plausibilität, sodass sichergestellt wird, dass kulturelle Nuancen realitätsnah abgebildet werden. * Zusätzlicher Einsatz: Chinesische OpenSource-Sprachmodelle wie „DeepSeek“ und japanische Sprachmodelle wie „Sakana“ werden gezielt eingesetzt, um denselben Input zu unterschiedlichen interkulturellen Situationen zu liefern. Ziel: Die Lehrenden vergleichen die Outputs in Bezug auf die verwendeten Beispiele, die Fokussierung auf kulturelle Werte (z.B. Kollektivismus, Hierarchie, Entscheidungsfindung) und die Tonalität der Texte. Daraus entstehen potenziell Fallstudien mit Abweichungen, die im Kurs aktiv diskutiert werden. * Voice Mode für interaktive Simulationen: Mithilfe von Voice Mode können die Studierenden verschiedene „Akteure“ in einem simulierten interkulturellen Gespräch übernehmen. Beispielsweise könnte ein Studierender die Rolle eines japanischen Managers übernehmen, der mit einem französischen CEO verhandelt – unterstützt und angeleitet durch das KI-gestützte Voice Mode. Diese Live-Simulationen fördern besonders die Aussprache, interkulturelle Kommunikation und nonverbale Signale (sofern Video/Audio-Komponenten integriert sind). * DeepResearch für Problemlösungsvorschläge: Nach durchgeführten Simulationen nutzen die Studierenden DeepResearch, um Best Practices, wissenschaftliche Artikel und Fallbeispiele zu finden, die ähnliche interkulturelle Herausforderungen beschreiben. Auf dieser Basis erstellen sie Handlungsempfehlungen für die Konfliktlösung. Die Lehrenden geben Feedback, um die studierendenzentrierte Reflexion zu stärken.\nWoche 9–12: KI als „Lernhilfe“ * Ziel: Effektive Prüfungsvorbereitung, Vertiefung und Wiederholung zentraler Inhalte im interkulturellen Management. * LLMs für Zusammenfassungen und Wiederholungsfragen: Studierende lassen sich von Sprachmodellen kurze Zusammenfassungen zentraler Konzepte erstellen (z.B. kulturelle Dimensionen nach Hofstede, Schein, Trompenaars). Die LLMs generieren auf Basis des bisherigen Kursverlaufs zusätzlich Quiz-Fragen oder Kurzantwortaufgaben, um das Verständnis zu überprüfen. * Gegenmaßnahme zur Qualitätssicherung: Die Lehrenden behalten die Kontrolle über die Endversion der Fragen, um unsinnige oder unpassende Aufgaben zu erkennen und zu eliminieren. * NotebookLM für Audio-Lerninhalte: Aus bereits vorhandenen Materialien (Skripte, Diskussionsergebnisse, Fallstudien) generiert NotebookLM weitere Podcast-Folgen, in denen Schlüsselkonzepte erläutert oder wiederholt werden. Studierende können diese Folgen gezielt zur Prüfungsvorbereitung nutzen und dadurch Zeit- und Ortsunabhängigkeit beim Lernen erlangen. * Voice Mode für Prüfungssimulationen: Studierende üben z.B. mündliche Prüfungen oder Präsentationen im interkulturellen Kontext. Sie können sich von Voice Mode Fragen stellen lassen („Wie würden Sie in Situation X reagieren?“) und ihre Antwort direkt in einer realistischen Simulation üben. Dies fördert die rhetorische Sicherheit sowie das spontane Reagieren auf unvorhergesehene Fragen.\n\n\nVorteile und Chancen der Ergänzung der Lehrmaterialien durch KI\n\nRealitätsnahe Lernsituationen: Durch Voice Mode-Simulationen und DeepResearch-gestützte Recherche wirken die Szenarien authentisch und praxisrelevant. Studierende lernen, ihre kulturelle Sensibilität in unterschiedlichen Rollen aktiv zu trainieren.\nZeit- und Ressourcenersparnis: Lehrende profitieren von teilautomatisierten Prozessen (z.B. Erstellung von Fallstudien, Zusammenfassungen, Podcasts). Studierende haben jederzeit Zugriff auf zusätzliche Lernressourcen wie Podcasts oder interaktive Übungen.\nAdaptives Lernen und Diversität: LLMs und DeepResearch ermöglichen personalisierte Aufgabenstellungen und themenspezifische Vertiefungen. Kulturelle Diversität kann in den generierten Szenarien leichter abgebildet werden, indem verschiedene Regionen und Blickwinkel integriert werden.\n\n\n\nRisiken und Gegenmaßnahmen\n\nQualität und kulturelle Sensibilität: Gegenmaßnahme: Lehrende prüfen alle generierten Inhalte (Text, Podcasts, Simulationen) auf kulturelle Stereotype und potenzielle Fehlinformationen. Durch Peer-Review unter Studierenden werden Vorurteile oder unangemessene Darstellung früh erkannt.\nVertrauenswürdigkeit und akademische Redlichkeit: Gegenmaßnahme: Studierende werden darin geschult, die KI-generierten Inhalte kritisch zu hinterfragen und zu validieren. Sie müssen Quellen nennen und sachlich begründen, wie und warum sie bestimmte KI-Ausgaben nutzen.\nDatenschutz und ethische Aspekte: Gegenmaßnahme: Sensible Informationen werden anonymisiert, Zugriffsrechte klar geregelt. Studierende erhalten eine Einführung, wie sie KI-Tools sicher und verantwortungsbewusst einsetzen.\nTechnische Abhängigkeit: Gegenmaßnahme: Lehrmaterialien sind zusätzlich offline verfügbar (Skripte, Reader). Auch ohne KI-Tools kann der Kurs fortgesetzt werden.",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Empfehlungen zur Umsetzung</span>"
    ]
  },
  {
    "objectID": "kapitel05.html#wie-bleiben-sie-informiert",
    "href": "kapitel05.html#wie-bleiben-sie-informiert",
    "title": "5  Empfehlungen zur Umsetzung",
    "section": "5.8 Wie bleiben Sie informiert?",
    "text": "5.8 Wie bleiben Sie informiert?\nBei einem solch aktuellen Thema helfen gute Sammelstellen für Information, um auf dem Laufenden zu bleiben. Abschließend einige Empfehlungen für gute Informationsquellen zum Thema Generative KI:\n\nNewsletter / Substack von Ethan Mollick der Wharton Business School mit sehr praktischen Übersichten und Empfehlungen: https://www.oneusefulthing.org/. Abonnieren Sie ihn, es lohnt sich.\nHochschulforum Digitalisierung: Themendossier Generative KI: https://hochschulforumdigitalisierung.de/dossier/generative-ki/\nE-Teaching.org: KI in Studium und Lehre: https://www.e-teaching.org/praxis/themenseiten/ki-in-studium-und-lehre\nEine große Anzahl an sehr guten didaktischen Prompts vom Team der Wharton Business School findet sich hier: https://www.moreusefulthings.com/prompts. Hervorzuheben sind v.a. die „Blueprints“, also Vorlagen, die für die eigene Lehre angepasst werden können (s.u. für zwei Beispiele).\nDie Universität Harvard gibt hier eine Reihe von Beispielen, wie GenAI in der Lehre genutzt wird, u.a. mit Beispielen für Simulationen, Sprachdidaktik u.v.m.: https://bokcenter.harvard.edu/examples-and-ideas-for-using-AI-for-your-teaching.\nEtwas breiter – wie nutzen 76.000 Lehrende KI an Hochschulen? Die KI-Firma Anthropic hat gerade einen Bericht herausgebracht, der anonymisiert basierend auf echten Interaktionen betrachtet, wie KI in der Lehre genutzt wird: https://www.anthropic.com/news/anthropic-education-report-how-educators-use-claude (Bent et al., 2025-08-26, 2025). Im Kontext von Rollenspielen ist hier interessant, wie die Online-Interaktion des GPT-Konkurrenten genutzt werden („Claude Artifacts“), speziell für „Interactive Educational Games“.\nFortbildungen und Übersichten mit Anwendungsfokus: Sowohl Google als auch Claude und OpenAI bieten Kurse für die technischen Aspekte der Nutzung von KI in der Lehre an: https://grow.google/ai-for-educators/, https://anthropic.skilljar.com/ai-fluency-framework-foundations.",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Empfehlungen zur Umsetzung</span>"
    ]
  }
]