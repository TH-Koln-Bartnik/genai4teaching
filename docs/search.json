[
  {
    "objectID": "kapitel01.html",
    "href": "kapitel01.html",
    "title": "1Â  Einleitung",
    "section": "",
    "text": "1.1 KI als Hilfe fÃ¼r die Lehre\nWie kann uns generative kÃ¼nstliche Intelligenz (KI) in der Lehre helfen? Hoffnung besteht hier fÃ¼r zwei typische Probleme: Erstens haben Studierende individuelle BedÃ¼rfnisse, aber wir haben nur begrenzte Zeit, auf diese einzugehen. Wie kÃ¶nnen wir Einzelne mÃ¶glichst intensiv fÃ¶rdern, ohne vor Arbeit unterzugehen? Zweitens ist der Aufwand gerade fÃ¼r effektive Lehrmethoden oft sehr hoch, so etwa fÃ¼r hÃ¤ufige niedrigschwellige Tests oder individuelles Feedback zu Studienarbeiten (Brown et al., 2014; s. etwa Hattie, 2023, Kap.13). Wer lehrt, fÃ¼hlt sich aus Zeit- und Stoffdruck oft gezwungen, Abstriche von idealen Lehrsetups zu machen (Henderson & Dancy, 2007; Schmidt & Tippelt, 2005, S.104â€“105). Gerade Lehrmethoden, die didaktisch sinnvoll, aber mit hÃ¶herem Aufwand verbunden sind, drohen dabei auf der Strecke zu bleiben (s. etwa Dunlosky et al., 2013; Roediger & Pyc, 2012).\nFÃ¼r die Lehre erschlieÃŸen sich durch die groÃŸen KI-Sprachmodelle (LLM = Large Language Models) neue MÃ¶glichkeiten. Sie sind, wie es eine Analyse des MIT Professors Andrew McAfee auf den Punkt bringt, â€generally fasterâ€œ (McAfee, 2024). Lehrende kÃ¶nnen mit KI-UnterstÃ¼tzung etwa deutlich schneller eine Recherche durchfÃ¼hren, ein Set von Ãœbungsaufgaben erstellen, mehrere Anwendungsbeispiele pro Konzept hinzufÃ¼gen, Quizfragen zur schnellen LernÃ¼berprÃ¼fung generieren oder mit den Studierenden Rollenspiele durchfÃ¼hren (Meincke et al., 2024; Mollick & Mollick, 2023). Der Berg ist noch da, aber mit dem E-Bike kommt man weiter.",
    "crumbs": [
      "<span class='chapter-number'>1</span>Â  <span class='chapter-title'>Einleitung</span>"
    ]
  },
  {
    "objectID": "kapitel01.html#ki-als-hilfe-fÃ¼r-die-lehre",
    "href": "kapitel01.html#ki-als-hilfe-fÃ¼r-die-lehre",
    "title": "1Â  Einleitung",
    "section": "",
    "text": "Schnelles Brainstorming mit der KI\n\n\n\n\n  \n    \n      ğŸ’¡\n      Wie kann ich GenAI in meiner Lehre nutzen?\n      KI\n    \n    \n    \n      Geben Sie Ihren Fachbereich ein. Das Sprachmodell hilft beim Brainstormen.\n    \n    \n    \n      \n      \n        Los\n      \n    \n    \n    \n      \n      \n        âš¡ Antworten von GPT-4o-mini - ein effizientes, aber nicht das schlauste Modell Â· Kann Fehler enthalten\n      \n    \n  \n\n\n\n\n\n\n\n\n\n\n\n\nAbbildungÂ 1.1: GenAI als KraftverstÃ¤rker. Quelle: Gemini 2",
    "crumbs": [
      "<span class='chapter-number'>1</span>Â  <span class='chapter-title'>Einleitung</span>"
    ]
  },
  {
    "objectID": "kapitel01.html#was-2025-mÃ¶glich-ist-praktische-beispiele-fÃ¼r-recherche-Ã¼bungsaufgaben-erklÃ¤rungen",
    "href": "kapitel01.html#was-2025-mÃ¶glich-ist-praktische-beispiele-fÃ¼r-recherche-Ã¼bungsaufgaben-erklÃ¤rungen",
    "title": "1Â  Einleitung",
    "section": "1.2 Was 2025 mÃ¶glich ist: Praktische Beispiele fÃ¼r Recherche, Ãœbungsaufgaben, ErklÃ¤rungen",
    "text": "1.2 Was 2025 mÃ¶glich ist: Praktische Beispiele fÃ¼r Recherche, Ãœbungsaufgaben, ErklÃ¤rungen\nSchauen wir uns einige praktische Beispiele an. Wir wollen wissen, was es fÃ¼r aktuelle Fallstudien zu Lieferketten-Problemen gibt. Als Recherche-Hiwi lassen wir das Sprachmodell auf akademischen Blogs und Fachzeitschriften nach aktuellen Beispielen suchen.\n\n\n\n\n\n\nAbbildungÂ 1.2: Recherche-Hiwi-Vorgehen. Quelle: Gemini 3 Pro\n\n\n\nSolche Suchen fÃ¼hren Sprachmodelle mittlerweile in mehreren Schritten durch. Hier sehen wir den â€œDenkprozessâ€.\n\n\n\n\n\n\nAbbildungÂ 1.3: Recherche-Hiwi-Denkprozess. Quelle: Gemini 3 Pro\n\n\n\nHier das Ergebnis: Ein erster ausformulierter Bericht von 13 Seiten nach ca. 5 Minuten Recherche. Die Abbildung zeigt den Auszug mit der tabellarischen Zusammenfassung der Forschungsartikel.\n\n\n\n\n\n\nAbbildungÂ 1.4: Recherche-Hiwi-Ergebnis. Quelle: Gemini 3 Pro\n\n\n\nWie kann man Konzepte einfach und mit Beispielen erklÃ¤ren? Wir bitten ChatGPT um VorschlÃ¤ge zu zwei Konzepten aus der Wissenschaftstheorie: Der Duhem-Quine-These, die beschreibt, warum Wissenschaft nur graduell, mosaik-bauend zu Erkenntnissen kommen kann und Mayos Konzept der â€œStrengen Testsâ€ (severe testing), nach denen man wissenschaftliche Aussagen graduell auf ihre Belastbarkeit bewerten kann.\n\n\n\n\n\n\nAbbildungÂ 1.5: Recherche-Hiwi-KonzepterklÃ¤rung. Quelle: ChatGPT-5.2\n\n\n\nWie kÃ¶nnte man das in einem Test abfragen? Auch hierzu bitten wir ChatGPT (5.2) um VorschlÃ¤ge.\n\n\n\n\n\n\nAbbildungÂ 1.6: Recherche-Hiwi-ErklÃ¤rung-Ergebnis. Quelle: ChatGPT-5.2\n\n\n\nEnde 2025 kann GenAI professionelle Folien-PrÃ¤sentationen sehr schnell erstellen. Sprachmodelle wie Googleâ€™s Gemini kÃ¶nnen mittlerweile auch Text erstellen (Willison, 2025b) und damit auch komplexe Infografiken (und Folien). Das Sprachmodell Claude liefert eine Beschreibung (â€˜Skillâ€™) von 3500 WÃ¶rtern mit, die dem Sprachmodell genau erklÃ¤rt, wie es Schritt fÃ¼r Schritt eine PowerPoint PrÃ¤sentation erstellt und testet (Anthropic, 2025).\nEine grafisch ansprechende PrÃ¤sentation zu erstellen ist recht zeitaufwÃ¤ndig â€“ und Brillanz als Grafiker gehÃ¶rt vielleicht auch nicht zu den Kernkompetenzen von Lehrenden. Wir bitten daher Gemini (NotebookLM) und Claude, uns basierend auf Ãœberblicksartikeln zwei PrÃ¤sentationen zu erstellen: Eine zur Frage, welche Lerntechniken fÃ¼r Studierende besonders gut funktionieren (s. Kapitel 2) und die zweite zur Frage, welche Best-Practices es gibt, Aufgabenstellungen mit der intensiven Nutzung von GenAI zu verbinden (s. Anhang B).\nZu integrierten Aufgaben mit GenAI liefert uns das Sprachmodell nach wenigen Minuten 15 sehr schicke Folien (NotebookLM, basierend auf 13 Quellen-PDFs).\n\n\n\n\n\n\nAbbildungÂ 1.7: Recherche-Hiwi-Ergebnis - Quelle: NotebookLM\n\n\n\nZu Lerntechniken erhielten wir nach etwa 5 Minuten basierend auf einem Fachartikel 8 professionelle Folien (mit kleineren Formatierungsfehlern, etwa ZeilenumbrÃ¼chen).\n\n\n\n\n\n\nAbbildungÂ 1.8: Recherche-Hiwi-Ergebnis. Quelle: Claude",
    "crumbs": [
      "<span class='chapter-number'>1</span>Â  <span class='chapter-title'>Einleitung</span>"
    ]
  },
  {
    "objectID": "kapitel01.html#nutzung-von-genai-in-der-forschung",
    "href": "kapitel01.html#nutzung-von-genai-in-der-forschung",
    "title": "1Â  Einleitung",
    "section": "1.3 Nutzung von GenAI in der Forschung",
    "text": "1.3 Nutzung von GenAI in der Forschung\nImmer mehr Aspekte von typischen ForschungstÃ¤tigkeiten â€“ ein zentraler Ausbildungsinhalt der Hochschulen â€“ kÃ¶nnen von der KI Ã¼bernommen werden und zwar auf hohem Niveau. Vorbei sind die Zeiten, in denen wir die banalen Schreibprodukte der KI nur belÃ¤cheln konnten. Ein Ãœberblicksartikel des Forschers Anton Korinek im renommierten Journal of Economic Literature vom Dezember 2024 fasst die deutlich hÃ¶here QualitÃ¤t des Outputs zusammen: â€die derzeitige Generation von LLMs ist in hohem MaÃŸe in der Lage, die wichtigsten Erkenntnisse von Forschungsarbeiten zu verarbeitenâ€ (Korinek, 2024, S.3, Ãœbersetzung RB mit DeepL).\nDie professionelle Nutzung durch Forscher etwa in Laborumgebungen oder der Mathematik ist hier teils noch weiter. Eine schÃ¶ne visuelle Verdeutlichung davon, was jetzt mÃ¶glich ist, findet sich hier: Eine Visualisierung von Ã¼ber 6000 KonferenzbeitrÃ¤gen, die jeweils zusammengefasst werden und denen durch ein Sprachmodell eine ErklÃ¤rung in einfacher Sprache beigefÃ¼gt wurde (â€œexplain-it-like-Iâ€™m-5â€): Hier kann man das interaktiv ausprobieren: https://jalammar.github.io/assets/neurips_2025.html.\n\n\n\n\n\n\nAbbildungÂ 1.9: Visualisierung und ErlÃ¤uterung in einfacher Sprache von 6000+ KonferenzbeitrÃ¤gen (Alammar, 2025).\n\n\n\nWie kann GenAI uns bei der Forschung direkt unterstÃ¼tzen? Google demonstrierte 2025 ein mehrstufiges Modell fÃ¼r die Pharma-Forschung (â€˜AI co-scientistâ€™), das den Forschenden zeitintensive Zwischenschritte abnimmt (Gottweis et al., 2025) (s. AbbildungÂ 1.10). OpenAI zeigte Ende 2023 schon in einem ausfÃ¼hrlichen Bericht eine Vielzahl mÃ¶glicher Hilfsanwendungen im Wissenschaftsbereich. Mit deutlichen Warnhinweisen (speziell wegen selbstbewusst vertretenen Halluzinationen) aber auch teils erstaunlich hoher QualitÃ¤t (Bubeck et al., 2023). Auch im Peer-Review werden zunehmend Sprachmodelle eingesetzt â€“ mit allen Vor- und Nachteilen, die das mit sich bringt (Naddaf, 2025). Wie wir in den spÃ¤teren Kapiteln sehen, experimentieren Hochschulen weltweit intensiv mit den neuen MÃ¶glichkeiten fÃ¼r Lehre und Forschung.\n\n\n\n\n\n\nAbbildungÂ 1.10: Googleâ€™s Co-Scientist Ansatz an einem Beispiel aus der Pharmaforschung (Gottweis et al., 2025).\n\n\n\nEnde 2025 hat sich der potenzielle Mehrwert (und speziell Zeitgewinn) bei fachgemÃ¤ÃŸer Nutzung noch einmal erweitert. Ein aktueller Bericht (November 2025) von OpenAI stellt eine Reihe von Fallstudien dar, wie Forschende starke Sprachmodelle nutzen (Bubeck et al., 2025). Die Quelle der Ergebnisse ist natÃ¼rlich nicht neutral (OpenAI), die Ergebnisse sind aber m. E. mit Blick auf die eigene Nutzungserfahrung sehr plausibel: Als Mehrwert wird hÃ¤ufig eine auÃŸerordentliche Zeitersparnis bei RoutinetÃ¤tigkeiten genannt, speziell bei der Nutzung von Verfahren und Wissensquellen, die die Forscher zwar bewerten kÃ¶nnen, deren Aneignung aber ohne die Hilfe der Sprachmodelle deutlich lÃ¤nger dauern wÃ¼rde. Dies ist sehr wertvoll und wird die Verbreitung solcher Tools treiben. Wir sehen in den Einzelberichten aber auch klare Warnsignale: Wenn man die Zwischenergebnisse mangels Fachkenntnis nicht kritisch hinterfragen kann, ist die Wahrscheinlichkeit hoch, Fehler zu Ã¼bernehmen. Auch starke Sprachmodelle vertreten sehr Ã¼berzeugend falsche Ergebnisse und AnsÃ¤tze. Nur durch Fachwissen haben Nutzer die erforderlichen Bewertungsmuster. Erst durch eigenes Fachwissen und der Erfahrung im kritischen Umgang mit dem Tool entsteht der Mehrwert. Man muss insofern das Terrain kennen und lernen, wie man den Sportwagen Sprachmodell fahren muss. Nur so kÃ¶nnen UnfÃ¤lle vermieden werden.\nAm Ende dieses Kapitels haben wir aus einer aktuellen Studie Schlaglichter zu Forschungs-Versuchen aus den verschiedenen Disziplinen zusammengestellt (Bubeck et al., 2025) Schlaglichter Forschung mit GenAI.\nWie ein Laie im Cockpit eines Verkehrsflugzeugs fÃ¤llt es Lehrenden teils schwer zu entscheiden, welche der neuen MÃ¶glichkeiten sinnvoll fÃ¼r die eigene Lehre sind. ZunÃ¤chst gibt es immer wieder Hype-Zyklen: Virtuelle RealitÃ¤t, Blockchain, Roboter, Internet der Dingeâ€¦ (Allen & Edelson, 2024), viel wurde schon ins Rampenlicht gestellt und dann wieder vergessen. Es werden gerade fÃ¼r die Lehre regelmÃ¤ÃŸig neue Technologien beworben und gehyped, so dass Lehrende schon aus Selbstschutz eine gewisse Grundskepsis mitbringen (sollten), ob ein neuer technischer Zugang wirklich auch didaktischen Nutzen bringt (fÃ¼r eine wirkungsbasierte Ãœbersicht von Technologien s. etwa Hattie, 2023, Kap.14). Lehrende sind auÃŸerdem paradoxen Spannungen zwischen den IdentitÃ¤ten als Experten und Innovatoren/Fazilitatoren ausgesetzt (Fischer & Dobbins, 2024): Ausgestrahlte Kompetenz ist einerseits Teil ihres Wertversprechens, was zur Abwehr ungewohnter Technologien einlÃ¤dt. Andererseits sollen Lehrende auch zu Neugier und Innovation anleiten und insofern den Umgang mit neuen, auch fÃ¼r die Lehrenden selbst ungewohnten Technologien erleichtern.\n\n\n\n\n\n\nAbbildungÂ 1.11: Neue technologische Chancen und Herausforderungen mit GenAI. Quelle: Mit Gemini 2 generiert.",
    "crumbs": [
      "<span class='chapter-number'>1</span>Â  <span class='chapter-title'>Einleitung</span>"
    ]
  },
  {
    "objectID": "kapitel01.html#aktuelle-weiterentwicklungen-der-sprachmodelle",
    "href": "kapitel01.html#aktuelle-weiterentwicklungen-der-sprachmodelle",
    "title": "1Â  Einleitung",
    "section": "1.4 Aktuelle Weiterentwicklungen der Sprachmodelle",
    "text": "1.4 Aktuelle Weiterentwicklungen der Sprachmodelle\n2025 lernen die groÃŸen Sprachmodelle noch besser â€œnachzudenkenâ€ â€“ sogenannte â€œReasoningâ€-Modelle werden breit verfÃ¼gbar. Aus didaktischer Sicht ist das auch deshalb interessant, weil man Lernenden jetzt Denkstrategien vorfÃ¼hren kann, speziell Hypothesenbildung und PrÃ¼fung (etwa (Brown et al., 2014), S.90-94, â€œgenerative learningâ€, oder die Studien von Willemain zur Modellierung von Problemen durch Experten (Willemain, 1994, 1995)). Ein neuer Ansatzpunkt zur Verbesserung der Ergebnisse wird hier genutzt (Grootendorst, 2025): Statt (nur) mehr Ressourcen in das Training immer komplexerer Modelle zu investieren (train-time compute), werden die Modelle jetzt dazu angehalten, lÃ¤nger â€œnachzudenkenâ€, bevor sie ein Ergebnis anbieten (test-time compute). Hinter diesem â€œbesseren Nachdenkenâ€ stehen zwei Prinzipien (Grootendorst, 2025; Snell et al., 2024): Die Sprachmodelle werden einerseits instruiert, schrittweise vorzugehen (Input-Verbesserung der Vorschlagsverteilung) und andererseits dazu angehalten, die eigenen Antworten zu prÃ¼fen (Output-Verbesserung, Verifizierer). Die Sprachmodelle fÃ¼hren insofern jetzt teils selbststÃ¤ndig PrÃ¼fschritte durch, die man frÃ¼her durch komplexe Prompts induziert hÃ¤tte. Ende 2025 sehen wir in der Konsequenz, dass die Sprachbots immer selbststÃ¤ndiger werden, man spricht vom â€œAgentic Turnâ€ (Mollick, 2025a; Steinberger, 2025; Willison, 2025a): Als Nutzer solcher Reasoning Modelle verbringen wir jetzt weniger Zeit damit, Ã¼ber die â€˜ZaubersprÃ¼cheâ€™ einzelner Prompts nachzudenken und mehr Zeit in â€˜MitarbeitergesprÃ¤chenâ€™ â€“ Anleitung und Kritik der digitalen â€œAgentenâ€ â€“ Sprachmodelle, die selbststÃ¤ndig und auf hohem Niveau mehrere Arbeitsschritte durchfÃ¼hren. Insgesamt steigt seit 2023 die QualitÃ¤t der Aufgaben, die Sprachmodelle erledigen kÃ¶nnen, rasant. Empirische Untersuchungen zeigen, dass die Sprachmodelle immer lÃ¤ngere Aufgaben auf hohem Niveau erledigen kÃ¶nnen (Kwa et al., 2025).\nDie neuen Modelle sind auÃŸerdem gÃ¼nstiger und effizienter geworden: die Kosten pro Interaktion sind stark gesunken. Illustratives Beispiel: Eine Million Token kosteten mit GPT-4 noch 50 Dollar, jetzt nur noch 14 Cent (InvertedStone, 2025; Mollick, 2025b). Das Modell halluziniert (weiterhin, also Vorsicht, aber) deutlich seltener als seine VorgÃ¤nger: OpenAI gibt hier ca. 1% Halluzinationen der Antworten statt ca. 5% bei VorgÃ¤ngermodellen (o3, 4o) an, je nach KomplexitÃ¤t der Frage und erlaubter â€Bedenkzeitâ€œ (OpenAI, 2025).\nWeiterhin hat sich die Internetsuche mit LLMs deutlich verbessert. WÃ¤hrend man frÃ¼her noch oft Ã¼ber sinnlose oder erfundene Ergebnisse lachte, stellt die Suche von ChatGPT, Google/Gemini oder speziellen Suchanbietern wie Perplexity mittlerweile eine groÃŸe Zeitersparnis dar: â€a useful tool to provide up-to-date answers to questions that are grounded in facts found on the internet, together with the requisite citationsâ€”a crucial capability for researchersâ€œ (Korinek, 2024, S.3). Das gilt zunehmend fÃ¼r die stÃ¤rksten allgemeinen Modelle und erst recht fÃ¼r Anbieter, die auf Forschungsrecherche (und Studierende) spezialisiert sind, wie Elicit oder Paperpal. Auch breite Internet-Recherchen und Textproduktionen sind zunehmend komplett delegierbar (â€deep researchâ€œ), mit deutlichen Auswirkungen auf den Arbeitsprozess in der Wissensarbeit (s. etwa Schwarcz et al. (2025) fÃ¼r juristische Recherchen, Korinek (2024) fÃ¼r Ã–konomie und Liang et al. (2025) fÃ¼r PR-TÃ¤tigkeiten).",
    "crumbs": [
      "<span class='chapter-number'>1</span>Â  <span class='chapter-title'>Einleitung</span>"
    ]
  },
  {
    "objectID": "kapitel01.html#wie-nutzen-studierende-und-lehrende-genai",
    "href": "kapitel01.html#wie-nutzen-studierende-und-lehrende-genai",
    "title": "1Â  Einleitung",
    "section": "1.5 Wie nutzen Studierende und Lehrende GenAI?",
    "text": "1.5 Wie nutzen Studierende und Lehrende GenAI?\nFÃ¼r Studierende sind GenAI Chatbots zum Standard fÃ¼r Informationssuche und Schreibaufgaben geworden: So berichten 92 % der befragten britischen Vollzeitstudierenden (n=1.041, Erhebung im Dezember 2024), dass sie KI-Tools wie ChatGPT regelmÃ¤ÃŸig verwenden, und 88 % geben an, solche Tools fÃ¼r PrÃ¼fungsleistungen (â€œfor assessmentsâ€) zu nutzen (Freeman, 2025). Deutsche Daten des CHE-Centrum fÃ¼r Hochschulentwicklung bestÃ¤tigen dies: etwa zwei Drittel der Studierenden gaben Ende 2024 an, KI-Tools mindestens wÃ¶chentlich zu nutzen (HÃ¼sch, Marc et al., 2025) (65%, n=23.288 von 171 Hochschulen).\nWofÃ¼r genau nutzen Studierende GenAI? Studierende geben an, dass sie sich am hÃ¤ufigsten Konzepte erklÃ¤ren lassen, Artikel zusammenfassen oder Ideen fÃ¼r Schreib- und Forschungsprojekte sammeln (Freeman, 2025). Nutzungsstudien zeigen sogar noch stÃ¤rkeren Einsatz speziell fÃ¼r Schreibprojekte (s. AbbildungÂ 1.12): Wie eine Auswertung von 1 Million anonymisierten Chats zwischen Usern mit UniversitÃ¤tskonto und dem Sprachmodell zeigt, nutzen Studierende die KI-Bots vor allem zum Erstellen neuer Inhalte und das Analysieren komplexer Themen, was hÃ¶heren Ebenen der Bloomschen Taxonomie entspricht (s. AbbildungÂ 1.13). Ein GroÃŸteil der befragten britischen Studierenden gibt an, PrÃ¼fungsleistungen durch GenAI zu unterstÃ¼tzen. Dieser Anteil sprang zwischen den ErhebungszeitrÃ¤umen Ende 2023 und 2024 von der HÃ¤lfte auf fast 90% (53% auf 88%, Freeman, 2025).\n\n\n\n\n\n\nAbbildungÂ 1.12: WofÃ¼r Studierende LLMs nutzen (Handa et al., 2025-04-08, 2025).\n\n\n\nHochschulen mÃ¼ssen insofern sicherstellen, dass PrÃ¼fungsleistungen nicht entwertet und Studierende die produktive Nutzung solcher Tools erlernen. Studierende dÃ¼rfen einerseits wesentliche kognitive Aufgaben nicht vollstÃ¤ndig an GenAI delegieren: Aufgaben und PrÃ¼fungsleistungen mÃ¼ssen angepasst werden. Weiterhin entsteht ein neuer Bedarf an Kompetenzschulung, den Studierende wie Unternehmen Ã¤uÃŸern: der produktive Umgang mit den neuen GenAI Tools muss eingeÃ¼bt werden. Deutsche Studierende fÃ¼hlen sich hierauf nicht gut vorbereitet: In der CHE-Studie bewerten sie das bestehende Angebot zum Erwerb von KI-Kompetenzen mit nur 2,7 von 5 Sternen (HÃ¼sch, Marc et al., 2025).\n\n\n\n\n\n\nAbbildungÂ 1.13: Schwerpunkte der Nutzung von LLMs (Claude) durch Studierende nach der Bloomâ€™schen Taxonomie (Handa et al., 2025-04-08, 2025).\n\n\n\nDie zunehmende Verwendung von KI in der Lehre hat gute GrÃ¼nde. Wie oft eine neue Technologie genutzt wird, hÃ¤ngt nach dem Technology Acceptance Model (TAM, s. AbbildungÂ 1.14) von der wahrgenommenen Benutzerfreundlichkeit (perceived ease of use) und der wahrgenommenen NÃ¼tzlichkeit (perceived usefulness) ab (MaranguniÄ‡ & GraniÄ‡, 2015). Generative KI wie ChatGPT decken sichtlich beide Aspekte ab: Sie sind einfach zu nutzen (Kestin et al., 2025; Lee et al., 2025; Monib et al., 2025; Naddaf, 2025) und erzeugen einen deutlichen Mehrwert, wie Studierende und Lehrende in einer Vielzahl von Umfragen der letzten zwei Jahren berichten (Heidt, 2025; Morgan, 2024; Ou et al., 2024). Lehrende ziehen nach: Meta-Untersuchungen zeigen ein extremes Wachstum an Publikationen zur Nutzung von LLM im Hochschulalltag (Ma, 2025; Ogunleye et al., 2024).\n\n\n\n\n\n\nAbbildungÂ 1.14: GrÃ¼nde fÃ¼r die Verbreitung von GenAI nach dem Technologie-Akzeptanz-Modell. Quelle: Mit ChatGPT 5 im Mermaid Live Editor generiert - https://mermaid.live/edit\n\n\n\nAuch auÃŸerhalb der Hochschule steigt die Nutzung. Eine Reihe von Studien zeigen erhÃ¶hte ProduktivitÃ¤t von BÃ¼roarbeitenden mit LLM-UnterstÃ¼tzung: der Kundensupport arbeitet 15% schneller, wenn das Sprachmodell Antwortoptionen vorschlÃ¤gt und Verweise auf interne technische Dokumentation anbietet (Brynjolfsson et al., 2025), Programmierer programmieren schneller (Peng et al., 2023), Consultants sind produktiver bei komplexen Beratungsprojekten (Dellâ€™Acqua et al., 2023) und Sprachmodelle wie ChatGPT kÃ¶nnen eine Vielzahl kleiner Aufgaben beschleunigen (Handa et al., 2025-04-08, 2025) und werden insofern gerade zur Texterstellung schon millionenfach als Hilfsmittel im Beruf genutzt: Von Kundenbewertungen Ã¼ber Pressemitteilungen und Stellenanzeigen (Liang et al., 2025).\nSchauen wir auf die Abnehmer unserer Graduierten: Wie nutzen die Unternehmen Mitte 2025 solche Sprachmodelle? Eine aktuelle Studie (2025/12) zur Nutzung von GenAI in Unternehmen stellt ein extremes Wachstum fest sowie einen deutlichen Unterschied in der Nutzung von erfahrenen und weniger routinierten Usern (Chatterji, 2025). Der OpenAI-Report zeigt, dass die Nutzung von Sprachmodellen in Unternehmen 2025 deutlich breiter und tiefer wird: ChatGPT-Enterprise-Nachrichten stiegen im Jahresvergleich etwa um das Achtfache, gleichzeitig wachsen wiederholbare ArbeitsablÃ¤ufe stark (Nutzung von Projects/Custom GPTs ~19-fach seit Jahresbeginn; rund 20 % der Enterprise-Nachrichten laufen bereits Ã¼ber solche strukturierten Workflows). Gleichzeitig bleibt bei fortgeschritteneren Funktionen noch viel ungenutztes Potenzial. Vor allem der Mehrwert von neueren Funktionen wie DeepSearch (Delegation ausfÃ¼hrlicher Recherchen), Reasoning (schrittweises, sorgfÃ¤ltiges Antworten mit deutlich hÃ¶herer QualitÃ¤t) und Datenanalyse mit Coding Tools wie Codex werden von Praktikern mit Firmen-Lizenz noch sehr selten genutzt. Selbst unter monatlich aktiven Enterprise-Nutzern haben 19 % noch nie Datenanalyse, 14 % noch nie Reasoning und 12 % noch nie (Deep) Search genutzt (bei tÃ¤glich Aktiven sinkt das auf 3 %, 1 % und 1 %).",
    "crumbs": [
      "<span class='chapter-number'>1</span>Â  <span class='chapter-title'>Einleitung</span>"
    ]
  },
  {
    "objectID": "kapitel01.html#risiken-und-nebenwirkungen",
    "href": "kapitel01.html#risiken-und-nebenwirkungen",
    "title": "1Â  Einleitung",
    "section": "1.6 Risiken und Nebenwirkungen",
    "text": "1.6 Risiken und Nebenwirkungen\nDie Metapher mit dem E-Bike trÃ¤gt allerdings auch, was die Risiken und Nebenwirkungen angeht: Ab wann lÃ¤sst die maschinelle UnterstÃ¼tzung wichtige Muskeln verkÃ¼mmern? Solche Gefahren bestehen â€“ wie empirische Studien zeigen, erfordern die neuen Workflows der Wissensarbeit durch KI-UnterstÃ¼tzung auch neue Formen der kritischen Auseinandersetzung mit den Inhalten.\nWird der Umgang mit GenAI nicht geÃ¼bt, droht ein RÃ¼ckgang des kritischen Denkens. Eine Studie von 319 Wissensarbeitern zeigt, dass sich das Gewicht zwischen den Einzelaufgaben der Wissensarbeit mit LLMs verschiebt: Der Aufwand fÃ¼r die Recherchen selbst sinkt, es steigt andererseits der Aufwand fÃ¼r Management-Ã¤hnliche Aufgaben: Koordination der Einzelaufgaben fÃ¼r Mensch und Maschine, kritische PrÃ¼fung der berichteten Ergebnisse und die Integration von Ergebnissen in den Gesamtprozess (etwa zur Erstellung eines Gesamtberichtes, einer Test-Spezifikation oder eines Protokolls) (Lee et al., 2025).\nIm Gegensatz zur einfachen Faktensuche im Internet werden hier nicht nur ein paar dornige Zweige im AufgabenbÃ¼ndel mechanisch â€˜geerntetâ€™, sondern gleich das gesamte BÃ¼ndel fertig verschnÃ¼rt bereitgestellt. Schlimmstenfalls droht das, was ein Artikel von Walsh (2025) prÃ¤gnant betitelt: â€œEverybody is cheating their way through collegeâ€. Wenn klassische Projektaufgaben quasi auf Knopfdruck erstellt werden kÃ¶nnen, droht diese Form von Leistung sinnlos zu werden. Mit etwas Lust an Dramatik kÃ¶nnen wir uns Endzeit-Szenarien vorstellen, in denen Lehrende klagend durch die TrÃ¼mmer ihrer schÃ¶nen Portfolio-PrÃ¼fungen stolpern: Die Homework-Apocalypse (Mollick, 2023).\nAber so schlimm muss es nicht werden. Es gibt schon eine Reihe plausibler AnsÃ¤tze, Lehrformate so umzugestalten, dass erwÃ¼nschte Schwierigkeiten nach Bjork & Bjork (2011) beibehalten oder sogar verstÃ¤rkt werden, trotz der (wohl praktisch unvermeidbaren) breiten allgemeinen Nutzung von GenAI durch Studierende.\nWie kann man also verhindern, dass die Studierenden kritische kognitive Aufgaben allein den KI-Systemen Ã¼bergeben? Lehre heiÃŸt in diesem Kontext auch, empfohlene Arbeitsweisen mit der neuen Technik zu Ã¼ben. Wie das gehen kann, sehen wir in den folgenden Kapiteln.",
    "crumbs": [
      "<span class='chapter-number'>1</span>Â  <span class='chapter-title'>Einleitung</span>"
    ]
  },
  {
    "objectID": "kapitel01.html#kapitelÃ¼bersicht",
    "href": "kapitel01.html#kapitelÃ¼bersicht",
    "title": "1Â  Einleitung",
    "section": "1.7 KapitelÃ¼bersicht",
    "text": "1.7 KapitelÃ¼bersicht\nIm folgenden Kapitel werden wir zunÃ¤chst einige Grundbegriffe (Kapitel 2) klÃ¤ren: Was sind groÃŸe Sprachmodelle und was ist mit Begriffen wie Token, Prompt und RAG gemeint? Welche Modelle kÃ¶nnen Lehrende aktuell nutzen und welche Empfehlungen fÃ¼r Prompts sind belastbar? Dann fragen wir nach Zielen (Kapitel 3): Welche Art von Wissen und Methoden unterscheidet und empfiehlt die Lernforschung? Welche didaktischen Wirkmechanismen kÃ¶nnen durch KI genutzt werden, um typische Probleme der Hochschullehre anzugehen? Im Abschnitt 4 schauen wir auf Praxisbeispiele (Kapitel 4) fÃ¼r vier Anwendungsfelder von Sprachmodellen an Hochschulen: KI als Hiwi (direkte Arbeitserleichterung), KI als Copilot (UnterstÃ¼tzung beim Schreiben und Coden) und KI als Tutor (Feedback und LernunterstÃ¼tzung) sowie KI als Simulator (Role Play und Goal Play). AbschlieÃŸend zeigen wir verschiedene Anwendungen von KI in verschiedenen Kurstypen und gehen auf neue Herausforderungen fÃ¼r PrÃ¼fungen ein (Kapitel 5). Im Appendix finden Sie eine breite Sammlung von didaktischen Prompts und auf GenAI ausgerichteten Aufgabenstellungen von fÃ¼hrenden Hochschulen. Dabei erlÃ¤utern wir zunÃ¤chst, wie die Prompts aufgebaut sind (Anhang A) und zeigen dann eine Liste strukturierter Best-Practice Beispiele (Anhang B).",
    "crumbs": [
      "<span class='chapter-number'>1</span>Â  <span class='chapter-title'>Einleitung</span>"
    ]
  },
  {
    "objectID": "kapitel01.html#sec-forschung-details",
    "href": "kapitel01.html#sec-forschung-details",
    "title": "1Â  Einleitung",
    "section": "1.8 Schlaglichter aus der Forschung mit GenAI: Erfahrungsberichte aus den Disziplinen (GPT-5 und 5-Pro)",
    "text": "1.8 Schlaglichter aus der Forschung mit GenAI: Erfahrungsberichte aus den Disziplinen (GPT-5 und 5-Pro)\nWie und wofÃ¼r lassen sich die stÃ¤rksten Sprachmodelle aktuell in der Forschung nutzen? Zum optionalen Abschluss dieses Kapitels finden Sie hier kurze Zusammenfassungen der Ergebnisse aus den verschiedenen Disziplinen (Bubeck et al., 2025).\n\n\n\n\n\n\nMathematik / Optimierung der Schrittweite\n\n\n\n\n\nForschender: SÃ©bastien Bubeck\nThema: Untersuchung, ob GPT-5 ein kÃ¼rzlich verÃ¶ffentlichtes Resultat zur KonvexitÃ¤t von Optimierungskurven verbessern oder reproduzieren kann.\nMehrwert:\nâ€â€¦one can see that GPT-5 claims to have improved the condition from Î·â‰¤1/L to Î·â‰¤1.5/L, thus approaching the optimal bound (but not quite getting there) of Î·â‰¤1.75/L. But is this claim substantiated? It is indeed, and the proof given by GPT-5 is shown in Figure I.2, which the present author has verified to be correct.â€œ\nâ€â€¦the proof given by GPT-5 is quite different from the one in v2. Indeed, the GPT-5 proof can be viewed as a more canonical variant of the v1 proofâ€¦â€œ\nProbleme:\nâ€GPT-5 did not manage to fully rederive the v2 result, but it basically went half-way between v1 and v2.â€œ\nSchlussfolgerungen:\nâ€To say it plainly, such a result (improving from 1/L to 1.5/L) could probably have been achieved by some experts in the field in a matter of hours, and likely for most experts it would have taken a few days. This is the type of science acceleration that we will see time and again in this report.â€œ\n\n\n\n\n\n\n\n\n\nMathematik / Literaturrecherche zu ErdÅ‘s-Problemen\n\n\n\n\n\nForschende: Mehtaab Sawhney und Mark Sellke\nThema: Nutzung von GPT-5 zur Identifizierung bereits verÃ¶ffentlichter LÃ¶sungen fÃ¼r Probleme aus der ErdÅ‘s-Datenbank, die dort als â€offenâ€œ gelistet waren.\nMehrwert:\nâ€GPT-5 located references solving the above problemsâ€¦ Identifying these decades-old papers required GPT-5 to go far beyond the functionality of a search engine, and indeed to read each of these papers in detail and apply a genuine understanding of mathematics.â€œ\nâ€GPT-5 translated and explained the proofs from [Pom59] to us so that we could verify them ourselves.â€œ\nâ€GPT-5 assisted us in pointing out parts of the paper that made the intended definition clear.â€œ\nProbleme:\nâ€â€¦in some cases it was overly enthusiastic about partial progress it had found.â€œ\nSchlussfolgerungen:\nâ€GPT-5 therefore provides the practicing mathematician a new mechanism to access the collective breadth of the mathematical literature.â€œ\nâ€This provides a convenient, crowd-sourceable â€˜soft certificateâ€™ that the solution is unlikely to appear in the published literature.â€œ\n\n\n\n\n\n\n\n\n\nMathematik / LLMs als Forschungspartner\n\n\n\n\n\nForschender: Timothy Gowers\nThema: Erfahrungen bei der Nutzung von LLMs fÃ¼r mathematische Probleme im FrÃ¼hstadium.\nMehrwert:\nâ€â€¦with GPT-5 my experience has been that the references are rarely hallucinated, and even the hallucinations can turn out to be pointers to references that exist and are useful.â€œ\nâ€â€¦GPT-5 has solved them [well-defined subproblems] for me in a matter of seconds.â€œ\nâ€â€¦I have had reasonably precise ideas for solving problems that I have run past GPT-5 Pro, which has explained to me why them cannot work.â€œ\nâ€â€¦even the less good ideas of an LLM can sometimes stimulate me to make progress. (I think of this as the â€˜That clearly doesnâ€™t work â€¦ but wait a minute!â€™ phenomenon.)â€œ\nProbleme:\nâ€â€¦on the negative side, if I ask more open-ended questions, or offer more sketchy ideas for proof attempts, then that seems to encourage the more annoying characteristics of LLMs to come to the fore: they will tell me that my ideas do indeed work, and will write something that supposedly fleshes out the details but that does not withstand close scrutiny.â€œ\nâ€â€¦it gave me a hallucinated reference but by an author who had written on closely related topics.â€œ\nSchlussfolgerungen:\nâ€â€¦my current assessment of LLMs is that they are just beginning to be useful as research collaboratorsâ€¦â€œ\nâ€â€¦LLMs can speed up the process of thinking about a problem, especially if that problem is a little outside oneâ€™s primary domain of expertiseâ€¦â€œ\nâ€â€¦they are capable of playing this knowledgeable-research-supervisor role with meâ€¦ but that they are not yet at the levelâ€¦ at which a human mathematicianâ€¦ would ask for joint authorship.â€œ\n\n\n\n\n\n\n\n\n\nMathematik / Neue Resultate zum ErdÅ‘s-Problem #848\n\n\n\n\n\nForschende: Mehtaab Sawhney und Mark Sellke\nThema: LÃ¶sung eines offenen Problems Ã¼ber Teilmengen von {1, â€¦, N}, bei denen ab+1 nicht quadratfrei ist.\nMehrwert:\nâ€GPT-5 put forward the new idea that led to our solutionâ€¦â€œ\nâ€The idea suggested by GPT-5â€™s replyâ€¦ gives a method to use any single number b âˆˆ A to obtain similarly harsh constraints on all other a âˆˆ A.â€œ\nProbleme:\nâ€GPT-5 made attempts in this direction but had numerous errors in its implementation (as can be seen in the transcript).â€œ\nâ€â€¦current models remain limited in perceiving the â€˜negative spaceâ€™ of mathematics. While models are able to suggest plausible proof strategies, they often do not realize certain â€˜obviousâ€™ examples which block progress, and are overly confident in the power of existing methods.â€œ\nSchlussfolgerungen:\nâ€â€¦GPT-5 has the ability to serve as an effective mathematical assistant, capable of recalling relevant lemmas, identifying analogies and locating relevant results from vague, ill-specified prompts.â€œ\n\n\n\n\n\n\n\n\n\nMathematik / Graphentheorie: Teilgraphen-ZÃ¤hlungen\n\n\n\n\n\nForschende: SÃ©bastien Bubeck, Mark Sellke und Steven Yin\nThema: Beweis von Ungleichungen fÃ¼r die Anzahl bestimmter induzierter Teilgraphen in BÃ¤umen.\nMehrwert:\nâ€Both of GPT-5â€™s proofs are quite different from any of the arguments in [BL16; Bub+16].â€œ\nâ€â€¦GPT-5â€™s proof is short and elegant, and based on a somewhat miraculous identity.â€œ\nProbleme:\nâ€A few incorrect proofs were also generated and rejected by human checking.â€œ\nSchlussfolgerungen:\nâ€â€¦GPT-5 was able to reprove the first inequality, and then build on this to also prove the second (open) inequality.â€œ\n\n\n\n\n\n\n\n\n\nMathematik / Lerntheorie: Dynamische Netzwerke\n\n\n\n\n\nForschende: SÃ©bastien Bubeck, Mark Sellke und Steven Yin\nThema: Identifizierbarkeit des Parameters w in einem modifizierten prÃ¤ferenziellen Bindungsprozess.\nMehrwert:\nâ€GPT-5 was able to prove that w is indeed identifiableâ€¦â€œ\nâ€â€¦this illustrates that GPT-5â€™s decision to focus on the quantity L(t) is already non-obvious.â€œ\nProbleme:\nâ€â€¦when we asked (an unscaffolded) GPT-5 to provide more detail for these latter arguments, it made several false startsâ€¦ After some human pushback, GPT-5 eventually came up with a correct but unnecessarily complicated proofâ€¦â€œ\nSchlussfolgerungen:\nâ€While all major proof ideas below are due to GPT-5, a few details of proof writing are human-supplied.â€œ\n\n\n\n\n\n\n\n\n\nPhysik / Symmetrien Schwarzer LÃ¶cher\n\n\n\n\n\nForschender: Alex Lupsasca\nThema: (Re-)Derivation nichttrivialer Lie-Punkt-Symmetrien der Wellengleichung in einer Kerr-Raumzeit.\nMehrwert:\nâ€Within 18 minutes, the model produced the correct curved-space generators closing into SL(2, R)â€¦â€œ\nâ€The final generators are too structured to be a lucky guess. The model likely executed (implicitly) a mix of: recognizing conformal invariance in the flat equation, hypothesizing a curved analogue, and/or exploiting a coordinate mapâ€¦â€œ\nProbleme:\nâ€The model initially failed on the curved-space problem, but then succeeded after a flat-space warm-upâ€¦â€œ\nâ€What GPT-5 got wrong (along the way). The cold start on Eq. (I.1) incorrectly concluded â€˜no symmetries.â€™â€œ\nSchlussfolgerungen:\nâ€AI as a symmetry engine. With minimal domain scaffolding, current models can carry out nontrivial Lie-symmetry discovery for PDEs with non-constant coefficients.â€œ\nâ€Research velocity. Given such capabilities, the time from idea to publishable result can compress from months to days once the right prompts and scaffolds are in place.â€œ\nâ€â€¦contemporary LLMs can act as practical assistants for symmetry discovery and analytic structure mining in theoretical physics.â€œ\n\n\n\n\n\n\n\n\n\nPhysik / Fusionsforschung: Thermonukleare Brandwellen\n\n\n\n\n\nForschender: Brian Keith Spears\nThema: Entwicklung eines reduzierten physikalischen Modells fÃ¼r thermonuklearer Brandwellen in ICF-Kapseln.\nMehrwert:\nâ€GPT-5 is quite good at this kind of model development and setup. It required little intervention on my part to make this plausible and complete.â€œ\nâ€The point is that I can now deliver in minutes as if I were at the highest level I have ever been at for this kind of work. â€¦ to have it in minutes is remarkable.â€œ\nâ€However, when re-prompted to examine a pathological result or null signal, GPT-5 offered quite sophisticated solutions, including different implementations of FFTs to prevent aliasing, improved resolutions to track burn frontsâ€¦â€œ\nProbleme:\nâ€GPT-5 was a bad designer, offering results that were null, noisy, or invalid (NaNs), while claiming that glory had been achieved.â€œ\nâ€The model, in its eagerness to please, often introduces numerical duct tape to smooth over a thorny issue, silently swaps out detailed numerical solves for approximations with trends it knows I want, and confidently declares victory when numerical signals are still obviously noise.â€œ\nSchlussfolgerungen:\nâ€â€¦executing this workflow from concept, to numerical exploration, to theoretical supporting statement in hours is rather amazing.â€œ\nâ€I feel like my 6 hours of work here yielded something I could have done over a month or two with a very good pair of postdocsâ€¦ That is a compression of about a factor of 1000.â€œ\nâ€â€¦users must be expert enough to catch the oversimplifications, must persist to get the model to reconsider, and must be vigilantâ€¦â€œ\n\n\n\n\n\n\n\n\n\nPhysik / Astrophysik: Gravitationsstrahlung\n\n\n\n\n\nForschender: Robert Scherrer\nThema: Analytische Integration des Leistungsspektrums von Garfinkle-Vachaspati-Strings.\nMehrwert:\nâ€After reasoning for 40 minutes, GPT-5 Pro produced a result for large odd n identical to the asymptotic result I had previously derivedâ€¦ It used a completely different method of solution from my own.â€œ\nâ€GPT-5 Pro also gave the leading order correction term to this formulaâ€¦ I was not aware of this correction termâ€¦â€œ\nProbleme:\nâ€The program hung up for quite a long time, giving me no details about its thought process. After several hours I became frustrated and killed it.â€œ\nSchlussfolgerungen:\nâ€GPT-5 Pro is capable of solving complex analytic integrations that are beyond the reach of symbolic manipulation programs such as Mathematica.â€œ\n\n\n\n\n\n\n\n\n\nBiologie / Immunologische In-vitro-Experimente\n\n\n\n\n\nForschender: Derya Unutmaz\nThema: Mechanistische Analyse der Wirkung von 2-DG auf die Differenzierung von T-Zellen und Vorhersage der ZytotoxizitÃ¤t von CAR-T-Zellen.\nMehrwert:\nâ€GPT-5 Pro provided the key mechanism that could explain these findings and, in addition, made highly relevant experimental suggestions.â€œ\nâ€The mechanistic insight and further hypothesis to dissect these findings were highly valuable and not immediately obvious, despite our deep expertise in this field.â€œ\nâ€GPT-5 Pro perfectly analyzed and described the data in the figureâ€¦â€œ\nâ€â€¦GPT-5 Pro made sufficient contributions to this work to the extent that it would warrant its inclusion as a co-author in this new study.â€œ\nProbleme:\nâ€â€¦a caveat for this suggestion is that GPT-5 Pro may have known about this finding and made the connection with this result.â€œ\nSchlussfolgerungen:\nâ€GPT-5 Pro can function as a true mechanistic co-investigator in biomedical research, compressing months of reasoning into minutes, uncovering non-obvious hypotheses, and directly shaping experimentally testable strategies.â€œ\nâ€Precision interpretation of complex biology. GPT-5 Pro rapidly connected the observed phenotypes to a mechanistic hypothesisâ€¦â€œ\nâ€The net effect will be a much higher discovery rate per experiment and a shorter route from observation to discovery to intervention, thus profoundly accelerating the biomedical scientific process.â€œ\n\n\n\n\n\n\n\n\n\nInformatik / Geometrie: Literaturrecherche zur Optimierung\n\n\n\n\n\nForschender: Nikita Zhivotovskiy\nThema: Suche nach Anwendungen und verwandter Literatur fÃ¼r eine neue geometrische Aussage Ã¼ber â€Î±-ratio coversâ€œ.\nMehrwert:\nâ€â€¦given only a core mathematical statement, GPT-5 can rapidly surface nontrivial and technically aligned links across areasâ€¦ providing context for new applications.â€œ\nâ€At first sightâ€¦ this seems unrelated to Theorem II.1.1 and could be mistaken for a hallucination. However, unpacking their proof shows that their result can be phrased as a coordinatewise (1+Ïµ)-ratio coverâ€¦â€œ\nSchlussfolgerungen:\nâ€â€¦GPT-5 can rapidly surface nontrivial and technically aligned links across areasâ€¦ providing context for new applications.â€œ\n\n\n\n\n\n\n\n\n\nInformatik / Schranken fÃ¼r Online-Algorithmen\n\n\n\n\n\nForschender: Christian Coester\nThema: Verbesserung der unteren Schranken fÃ¼r das Problem des â€Convex Body Chasingâ€œ.\nMehrwert:\nâ€Given a single short prompt, GPT-5 produced a rather non-obvious counter-example against the algorithm.â€œ\nâ€GPT-5 suggested a much simpler and cleaner solution: trigger the switch once the algorithm is below the semicircle at distance â‰¥ Îµ from pt.Â This avoids the freezeâ€¦ The idea seems obvious in hindsight, yet far more elegantâ€¦â€œ\nâ€â€¦the inspiring appearance of the number Ï€/2 in its reasoning traceâ€¦â€œ\nProbleme:\nâ€The argument it gives for this [feasibility of the construction] is actually incorrect, but a correct argument is easy to seeâ€¦â€œ\nâ€â€¦it initially failed to understand how viewing the problem in continuous time could yield stronger bounds, and upon later attemptsâ€¦ it presented arguments containing serious flaws.â€œ\nâ€â€¦GPT-5â€™s responses also contained some errors, but these were easy to fix for a human, overall accelerating the research process.â€œ\nSchlussfolgerungen:\nâ€Perhaps the most impressive part is its proof refuting the follow-the-leader algorithm, produced from a single prompt without any guidance on how to approach the task.â€œ\n\n\n\n\n\n\n\n\n\nInformatik / Clique-avoiding Codes (Warnbeispiel)\n\n\n\n\n\nForschende: Venkatesan Guruswami und Parikshit Gopalan\nThema: Suche nach einer unteren Schranke fÃ¼r die Co-Dimension von Codes, die Clique-Indikatoren vermeiden.\nMehrwert:\nKein expliziter Mehrwert im Text auÃŸer der Reproduktion bekannter Beweise.\nProbleme:\nâ€Initially, it was convinced that this bound was tight (up to an additive constant), and tried to convince us of this using a sequence of buggy arguments, resorting to linear algebra and proof by authorityâ€¦â€œ\nâ€The most amusing was a hallucinated response to the effect that one of us had asked this question on TCS Stack Exchangeâ€¦ Both these claims are incorrect.â€œ\nâ€â€¦it appears that GPT-5 reproduced Alonâ€™s proof and passed it along to us without realizing its source.â€œ\nSchlussfolgerungen:\nâ€Our experience illustrates a pitfall in using AI: although GPT-5 possesses enormous internal knowledgeâ€¦ it may not always report the original information sources accurately. This has the potential to deceive even seasoned researchers into thinking their findings are novel.â€œ\n\n\n\nLink zurÃ¼ck zum FlieÃŸtext: SieheÂ 1.11",
    "crumbs": [
      "<span class='chapter-number'>1</span>Â  <span class='chapter-title'>Einleitung</span>"
    ]
  },
  {
    "objectID": "kapitel02.html",
    "href": "kapitel02.html",
    "title": "2Â  Grundbegriffe",
    "section": "",
    "text": "2.1 Definition einiger Grundbegriffe\nIn diesem Abschnitt wollen wir einige Definitionen und Bedeutungen klÃ¤ren. Dabei nutzen wir immer wieder kleine Interaktionen und Lernspiele, auch um so zu zeigen, wie wir einfacher â€œfragendâ€ und aktivierend lehren kÃ¶nnen.\nWo finden Sie zusÃ¤tzliches oder vertiefendes Material? Als visuelle Begleitung empfehle ich das sehr schÃ¶ne EinfÃ¼hrungsvideo des Mathematik-Didaktikers Grant Sanderson (7 Minuten, https://youtu.be/LPZh9BOjkQs). Tiefer in die mathematischen Details geht die grafische und interaktive EinfÃ¼hrung als Animation von Brendan Bycroft (https://bbycroft.net/llm). Wer sich auch die technischen HintergrÃ¼nde genauer erschlieÃŸen will, kann das Lehrbuch-Standardwerk von Jurafsky & Martin (2025) nutzen, das online frei verfÃ¼gbar ist.\nVon Prompt bis Token, Ã¼ber Temperatur und RAG: Was ist Ihnen schon an Grundbegriffen in diesem Kontext vertraut? Testen Sie sich selbst mit dem folgenden kleinen Spiel. Bei voller Punktzahl winkt Ihnen ein Preis!\nEin Large Language Model (LLM) ist ein fortschrittliches maschinelles Lernmodell, das speziell darauf trainiert ist, menschliche Sprache zu verstehen und Texte zu erzeugen, die natÃ¼rlich erscheinen. Ein Sprachmodell ist ein Rechensystem, das das nÃ¤chste Wort in einer Wortkette vorhersagt, basierend auf den vorher genannten WÃ¶rtern in dieser Kette (Jurafsky & Martin, 2025, Kap.7, S.2). Die Modelle kÃ¶nnen erstaunliche Mengen von Textdaten verarbeiten, um vielseitige Sprachanwendungen zu ermÃ¶glichen.\nDie generative KÃ¼nstliche Intelligenz (GenAI) bezieht sich auf Systeme, die fÃ¤hig sind, neue Inhalte zu erzeugen, wie etwa Texte, die noch nicht existierten. LLMs sind ein zentraler Teil dieser generativen KI und kÃ¶nnen eigenstÃ¤ndig Texte zu einem breiten Spektrum von Themen generieren.\nDas Sprachmodell zerlegt dazu grob gesagt Inputs wie Texte in kleine Bausteine (Tokens), verwandelt diese in Zahlen (Embeddings), erkennt mithilfe komplexer Muster (Transformer und Attention) deren ZusammenhÃ¤nge, und erzeugt auf diese Weise selbststÃ¤ndig basierend auf kontextbezogen berechneten Wahrscheinlichkeiten neue Texte (generative Sprachproduktion).\nDamit Sprachmodelle wie ChatGPT Sprache verstehen und erzeugen kÃ¶nnen, zerlegen sie Text in sogenannte Tokens â€“ kleine Bausteine wie WÃ¶rter, Wortteile oder Satzzeichen (s. etwa Jurafsky & Martin, 2025, Kap.2). Jedes dieser Tokens wird in einen Vektor umgewandelt â€“ eine Zahlenreihe, die das Wort mathematisch beschreibt. Dieser Vorgang nennt sich Embedding. Dabei wird darauf geachtet, dass Ã¤hnliche WÃ¶rter Ã¤hnliche Vektoren erhalten, beispielsweise â€Hundâ€œ und â€Katzeâ€œ.\nHier kann man das selbst einfach ausprobieren: Das interaktive Widget simuliert eine GPT-2-Ã¤hnliche Tokenisierung.\nDie kleine Simulation hier soll nur ein GefÃ¼hl fÃ¼r den Prozess geben. Wie die Umwandlung eines bestimmten Textes genau in verschiedenen Sprachmodellen aussieht, kÃ¶nnen Sie interaktiv auf Webseiten wie Tiktokenizer ausprobieren: https://tiktokenizer.vercel.app/.\nEin Prompt ist eine Eingabeaufforderung, die an ein LLM gesendet wird, um eine spezifische Antwort zu erhalten. Die Gestaltung dieser Prompts ist entscheidend fÃ¼r die QualitÃ¤t der generierten Antworten und wird als Prompt Engineering bezeichnet.",
    "crumbs": [
      "<span class='chapter-number'>2</span>Â  <span class='chapter-title'>Grundbegriffe</span>"
    ]
  },
  {
    "objectID": "kapitel02.html#definition-einiger-grundbegriffe",
    "href": "kapitel02.html#definition-einiger-grundbegriffe",
    "title": "2Â  Grundbegriffe",
    "section": "",
    "text": "Lernspiel: Welche Grundbegriffe kennen Sie schon?\n\n\n\nOrdnen Sie die Begriffe den korrekten Definitionen zu!\n\n\n(am besten auf dem Computer spielen). Hier auch Online abrufbar (so etwas nennt sich â€œArtifactâ€ beim Sprachmodell â€œClaudeâ€): https://claude.site/artifacts/d8e3cee4-ea47-48e3-a84c-a774d408aac8\n\n\n\n\n\n\n\n\n\n\nTipp: Mini-Interaktionen einfach als HTML erstellen\n\n\n\nKÃ¶nnen Sie in HTML programmieren? Jetzt schon. Die Lernspiele in diesem Abschnitt wurden mit Hilfe von Sprachmodellen erstellt (Gemini, ChatGPT, Claude). Meist mit einer Variation des einfachen Prompts: â€Erstelle mir ein browser-basiertes Lernspiel zum Thema / zur Illustration von â€¦â€œ. Oft hat man nach 5â€“10 Minuten eine gute erste Version. In der Lehre mache ich das oft auch als Ãœbung mit Studierenden. Sie sollen dann erst mit Hilfe der KI ein Lernspiel erstellen und dann begrÃ¼ndet bewerten, welcher Spiel-Prototyp das Konzept am besten darstellt. Bei etwas mehr Zeit kann man sie gegenseitig bewerten lassen, selbst Kriterien erstellen oder stÃ¤rkere Gamification hinzufÃ¼gen. Im Ergebnis beschÃ¤ftigen sich idealerweise die Teilnehmer intensiv mit einem theoretischen Konzept (Bei komplexeren Themen hilft es, einen Fachtext als Hintergrund zum Konzept hochzuladen.)\n\n\n\n\n\n\n\n\n\n\n\nGeben Sie eigenen Text ein, unten wird er dann in Tokens und Zahlen umgewandelt\n\n\n\n\n\n\n\n\n\n2.1.1 Was heiÃŸt hier GPT?\nGPT steht fÃ¼r Generative Pre-trained Transformer. Wir schauen zunÃ¤chst, was diese drei Begriffe bedeuten.\nâ€˜Generativeâ€™: Der Begriff â€generativâ€œ bedeutet in diesem Zusammenhang, dass GPT eigenstÃ¤ndig neue, sinnvolle Texte erzeugen kann, indem es gelernte Muster neu kombiniert, anstatt fertige Texte zu Ã¼bernehmen.\nâ€˜Pretrainedâ€™: GPT wurde mit riesigen Textmengen vortrainiert (Pretraining), ohne konkrete Aufgaben lÃ¶sen zu mÃ¼ssen â€“ dieser Vorgang erfolgt unÃ¼berwacht (unsupervised learning). Sprachmodelle nutzen hÃ¤ufig die Methode â€Reinforcement Learning with Human Feedbackâ€œ (RLHF), um noch bessere Texte zu generieren. Dabei erzeugt das LLM zunÃ¤chst verschiedene Textversionen, die von menschlichen Bewertern nach QualitÃ¤t beurteilt werden. Diese Bewertungen dienen dazu, das Modell zusÃ¤tzlich zu trainieren und zu steuern, indem Texte belohnt werden, die von Menschen als besonders gut, klar oder hilfreich eingeschÃ¤tzt wurden. Durch diesen Prozess â€lerntâ€œ das LLM, Texte zu bevorzugen, die nicht nur sprachlich richtig, sondern fÃ¼r Menschen besonders verstÃ¤ndlich und nÃ¼tzlich sind. Das macht es mÃ¶glich, dass GPT spÃ¤ter aus wenigen Stichworten neue Texte generieren kann â€“ also kreativ Sprache produziert, ohne bloÃŸ zu kopieren (generativ).\nâ€˜Transformerâ€™: Das HerzstÃ¼ck des GPT ist der sogenannte Transformer â€“ ein Rechenmodell, das durch ein spezielles Aufmerksamkeitsverfahren (Attention) erkennt, welche WÃ¶rter im Zusammenhang wichtig sind. Dadurch kann GPT die Bedeutung von WÃ¶rtern im Kontext richtig einschÃ¤tzen.\nIm Transformer bedeutet â€Attentionâ€œ: Jedes Wort (genauer: jedes Token) entscheidet dynamisch, auf welche anderen Tokens es beim Verstehen oder Generieren am stÃ¤rksten â€hÃ¶renâ€œ sollte. Technisch ist das eine gewichtete Mischung von Informationen: Das Modell bildet eine Art Relevanzscore zwischen einem â€aktuellen Interesseâ€œ und mÃ¶glichen â€Informationsquellenâ€œ und erstellt daraus Gewichte, die sich zu 1 aufsummieren. Die Ausgabe ist dann eine gewichtete Summe der Informationsinhalte. Das ist wie bei einer Literaturrecherche: Eine Fragestellung (Query) wird mit Titeln/Abstracts als â€Hinweis-Schilderâ€œ (Keys) abgeglichen; die eigentlichen Inhalte (Values) aus den passenden Quellen flieÃŸen dann stÃ¤rker in das GesamtverstÃ¤ndnis ein.\nBeispielsweise erkennt GPT so in einem Satz wie â€Die Bank steht unter einem Baumâ€œ anhand des Kontextes, ob â€Bankâ€œ ein MÃ¶belstÃ¼ck oder eine Institution meint. (Der zentrale Fachartikel von 2017, ein zentraler AuslÃ¶ser der aktuellen KI-Welle, hatte den knackigen Titel â€œAttention is all you needâ€ Vaswani et al. (2017) - der Artikel wurde mittlerweile mehr als 200.000-fach zitiert.)\nWas behÃ¤lt das Sprachmodell von unserer Unterhaltung? Wie viel Text kann ich â€“ auch als PDF â€“ hochladen? Neuere LLMs kÃ¶nnen schon ganze BÃ¼cher schnell aufsaugen und dann zusammenfassen (z.B. Claude, ChatGPT oder Gemini). Das Kontext-Fenster eines LLM beschreibt die Menge an vorherigem Text, die das Modell bei der Verarbeitung neuer Informationen berÃ¼cksichtigt, um den Kontext und die ZusammenhÃ¤nge zu verstehen.\nEin Agent im Kontext von Automation und kÃ¼nstlicher Intelligenz meint zunÃ¤chst allgemein etwas, das seine Umwelt wahrnimmt (durch Sensoren) und auf sie einwirkt (durch Aktoren) (Russell & Norvig, 2021, S.54). Agenten bestehen aus einer Architektur, die bestimmt, was mÃ¶glich ist und einem Programm, das vorgibt, wie der Agent handeln soll (Russell & Norvig, 2021, S.65ff.). Ersteres meint bildlich gesprochen die Augen und HÃ¤nde des Agenten: Die Agenten-Architektur beschreibt den spezifischen Setup von Sensoren und Aktoren, die bestimmen, was fÃ¼r den Agenten wahrnehmbar und handelbar ist. FÃ¼r GenAI Agenten fragt das etwa: Hat er Web-Anbindung? Kann er programmieren? Das Agenten-Programm ist das Regelbuch: es bestimmt, wie der Agent reagiert. Von einfachen Wenn-Dann-Regeln bis hin zu komplexen Weltmodellen (z.B. Physik-Modelle, die die Schwerkraft berÃ¼cksichtigen oder Kosten-Gewinn Rechnungen fÃ¼r eine Wirtschaftssimulation).\nGPT-basierte Agenten kÃ¶nnen Text analysieren, generieren und verschiedene Aufgaben automatisieren, indem sie vorab definierte Muster und Regeln befolgen. Durch die Erstellung solcher Agenten kÃ¶nnen Lehrende interaktive und personalisierte Lerninhalte einfacher gestalten.\nRAG (Retrieval-Augmented Generation) beschreibt die MÃ¶glichkeit, zusÃ¤tzliche Daten wie Fachtexte, Statistiken oder GesetzesbÃ¼cher in Kombination mit einem KI Modell zu nutzen. Die KI ist das Gehirn, die zusÃ¤tzliche Wissensdatenbank quasi das BÃ¼cherregal, das zu Rate gezogen werden kann. Je nach Kontextfenster stehen dort mehr oder weniger BÃ¼cher. Insofern umschreibt RAG ein KI-Modell, das die FÃ¤higkeiten von Textgenerierungsmodellen (wie GPT) mit einer Wissensdatenbank kombiniert. So wird etwa der Prompt-Agent (s.u.) mit einer Reihe von Fachtexten â€gefÃ¼ttertâ€œ, in denen Best Practices des Prompting erklÃ¤rt werden.\nEinige Unterschiede zwischen einem einfachen Sprachmodell (LLM) und dem Setup mit Zusatzmaterial (RAG) und erlaubter Werkzeugnutzung (Tool Use, Agenten) sehen wir an der folgenden Interaktion. WÃ¤hlen Sie hier jeweils die passende Antwort (einfach, aber so bleiben Sie dran!).\n\n\n\n\n\n\nLernspiel: LLM, RAG oder Agent, was sind mÃ¶gliche Probleme und Anwendungsfelder?\n\n\n\nRunter scrollen und â€œLos gehts!â€ auswÃ¤hlen, dann nacheinander die Interaktionen fÃ¼r LLM, RAG und Agent auswÃ¤hlen und die Fragen beantworten.\n\n\n\n\nDas Modell sucht nach relevanten Daten und integriert diese in die generierte Antwort. In der Lehre kann RAG verwendet werden, um den Studierenden Fachtexte oder besonders aktuelle Informationen zur VerfÃ¼gung zu stellen. Beispielsweise kÃ¶nnten Studierende in einem Geschichtsseminar eine KI befragen, die externe Quellen durchforstet, um aktuelle Erkenntnisse zu historischen Ereignissen zu prÃ¤sentieren. Unternehmen nutzen diese Technik, um etwa 1000-seitige Gebrauchsanweisungen mit KI durchsuchbar zu machen, oder Chatbots zu trainieren, die typische, repetitive Kundenanfragen beantworten. Insofern ermÃ¶glicht RAG eine dynamische und zeitgemÃ¤ÃŸe Wissensvermittlung, die nicht auf das festgelegte Wissen des KI-Modells beschrÃ¤nkt ist.\n\n\n2.1.2 Was nutzen - LLM, RAG oder Agent?\nWie unterscheiden sich die verschiedenen Nutzungs-Muster, die wir bis jetzt kennengelernt haben? Frage ich nur das Sprachmodell? Oder lieber das Sprachmodell mit Zusatz-Material (RAG)? Oder vielleicht das Sprachmodell mit Tools (Agenten)? PrÃ¼fen Sie Ihr VerstÃ¤ndnis: Welche der links gezeigten Antworten passen zu welchem der rechts gezeigten Muster? Nutzt das Sprachmodell nur sein â€œStandard-Wissenâ€ (LLM only), oder werden â€œWerkzeugeâ€ wie Internet-Nutzung erlaubt?\n\n\n\n\n\n\nLernspiel: Welche Art des LLM-Setups passt zu den links gezeigten Antworten oder Denkprozessen?\n\n\n\n\n\n\n\nDas beendet unsere kurze Begriffsbestimmung. Ein etwas breiteres Glossar fÃ¼r Anwender finden Sie etwa bei der populÃ¤rwissenschaftlichen Zeitschrift CIO (Chief Intelligence Officer): https://www.cio.de/article/3700849/die-wichtigsten-begriffe-im-genai-umfeld.html.",
    "crumbs": [
      "<span class='chapter-number'>2</span>Â  <span class='chapter-title'>Grundbegriffe</span>"
    ]
  },
  {
    "objectID": "kapitel02.html#wie-denken-sprachmodelle-und-warum-halluzinieren-sie",
    "href": "kapitel02.html#wie-denken-sprachmodelle-und-warum-halluzinieren-sie",
    "title": "2Â  Grundbegriffe",
    "section": "2.2 Wie denken Sprachmodelle und warum halluzinieren sie?",
    "text": "2.2 Wie denken Sprachmodelle und warum halluzinieren sie?\nEine Studie des KI-Labors Anthropic hat mit neuen Methoden den Denkprozess eines Sprachmodells im Detail nachgezeichnet (Lindsey et al., 2025), was uns erstmals etwas genauer verstehen lÃ¤sst, wie Sprachmodelle mit verschiedenen Sprachen umgehen, wie sie den Schreibprozess â€planenâ€œ, wie sie bei Kalkulationen vorgehen, wie weit ihre Selbsterkenntnis reicht und warum sie manchmal Antworten erfinden (â€halluzinierenâ€œ).\n\n\n\n\n\n\nAbbildungÂ 2.1: Visualisierte Gedanken eines Sprachmodells [@lindsey2025]\n\n\n\n\nSprachÃ¼bergreifend gleich: Das Modell nutzt einen gemeinsamen sprachÃ¼bergreifenden Bedeutungsraum.\nTextplanung: Bei der Texterstellung plant das Modell mehrere WÃ¶rter im Voraus.\nParalleles Rechnen: FÃ¼r Kalkulationen nutzt das Modell parallele Rechenpfade, die am Ende verbunden werden.\nMan traue nicht der Selbstkenntnis: Das Modell erfindet manchmal Argumentationsketten (motivated reasoning).\nBekanntheit fÃ¼hrt zu Halluzinationen: Wenn das Modell eine genannte EntitÃ¤t â€kenntâ€œ (hier: den Namen des Forschers, Karpathy), aber nicht die Antwort auf die Frage (Titel des Fachartikels) fÃ¼hrt das zu erfundenen Antworten (die â€canâ€™t answerâ€œ-Funktion wird unterdrÃ¼ckt).\n\nClaude nutzt einen gemeinsamen Bedeutungsraum fÃ¼r verschiedene Sprachen â€“ ein Hinweis auf eine Art â€universelle Denkspracheâ€œ. Claude verarbeitet Informationen in einem sprachunabhÃ¤ngigen, abstrakten Bedeutungsraum. Bei der Frage nach dem â€Gegenteil von kleinâ€œ in verschiedenen Sprachen (z.â€¯B. Englisch, FranzÃ¶sisch, Chinesisch) aktivieren sich im Modell dieselben internen Merkmale fÃ¼r â€Kleinheitâ€œ und â€Gegenteilâ€œ, unabhÃ¤ngig von der Eingabesprache. Erst in einem spÃ¤teren Schritt wird die Antwort in die jeweilige Zielsprache Ã¼bersetzt. Diese Erkenntnis legt nahe, dass Claude Wissen und Konzepte sprachÃ¼bergreifend anwenden kann.\nPlant das Sprachmodell die Textgeneration? Entgegen der Annahme, dass Sprachmodelle Texte strikt Wort fÃ¼r Wort basierend auf dem unmittelbaren Kontext generieren, zeigt Claude die FÃ¤higkeit, mehrere WÃ¶rter im Voraus zu planen. In Aufgaben zur Gedichtgenerierung identifiziert Claude beispielsweise ReimwÃ¶rter, bevor es die vorhergehenden Zeilen formuliert. Ein Beispiel: Soll ein Gedicht mit dem Wort â€Kaninchenâ€œ enden, wÃ¤hlt Claude dieses Zielwort frÃ¼hzeitig aus und gestaltet die Zeile so, dass sie darauf hinfÃ¼hrt. â€‹Diese FÃ¤higkeit zur Vorausplanung deutet darauf hin, dass Claude in der Lage ist, komplexe Textstrukturen zu erstellen, die Ã¼ber einfache Wortassoziationen hinausgehen.\nWie kalkulieren Sprachmodelle? Anthropic hat in seiner Studie zu Claude 3.5 Haiku detailliert untersucht, wie das Modell mathematische Berechnungen intern verarbeitet. Dabei wurde festgestellt, dass Claude bei Aufgaben wie der Addition von Zahlen parallele Rechenpfade nutzt, um zu einem Ergebnis zu gelangen.â€‹ Claude verwendet zwei Hauptpfade, um Additionen durchzufÃ¼hren: 1. GrobabschÃ¤tzung: Ein Pfad schÃ¤tzt das Ergebnis basierend auf den GrÃ¶ÃŸenordnungen der Zahlen. 2. PrÃ¤zise Berechnung: Ein anderer Pfad fokussiert sich auf die genaue Berechnung, insbesondere auf die Bestimmung der letzten Ziffer der Summe.\nDiese beiden Pfade arbeiten zusammen, um das finale Ergebnis zu erzeugen. Wenn beispielsweise der Pfad fÃ¼r die letzte Ziffer deaktiviert wird, liefert Claude nur eine grobe SchÃ¤tzung, ohne die genaue Endziffer korrekt zu bestimmen.\nKÃ¶nnen wir das Modell fragen, wie es zu einem Ergebnis gekommen ist? Eher nicht. Anthropics Studie zeigt, dass das Modell bei komplexen Aufgaben manchmal Ã¼berzeugende, aber erfundene Argumentationsketten prÃ¤sentiert. Bei einfachen Berechnungen, wie der Quadratwurzel von 0,64, lassen sich klare interne Rechenschritte nachweisen. Bei schwierigeren Aufgaben, etwa der Berechnung des Kosinus einer groÃŸen Zahl, gibt Claude jedoch vor, Berechnungen durchgefÃ¼hrt zu haben, obwohl keine entsprechenden internen Prozesse erkennbar sind. In solchen FÃ¤llen konstruiert das Modell plausible, aber unbegrÃ¼ndete ErklÃ¤rungen â€“ ein Verhalten, das als â€motiviertes Denkenâ€œ bezeichnet wird. Diese FÃ¤higkeit, Ã¼berzeugend zu argumentieren, ohne tatsÃ¤chlich die zugrunde liegende Logik zu befolgen, kann fÃ¼r Nutzer irrefÃ¼hrend sein. Die von Anthropic entwickelten Interpretationswerkzeuge ermÃ¶glichen es, solche untreuen Denkprozesse zu identifizieren, indem sie die tatsÃ¤chlichen internen AblÃ¤ufe des Modells sichtbar machen. Dies ist ein wichtiger Schritt, um die ZuverlÃ¤ssigkeit und Transparenz von KI-Systemen zu verbessern.\nWas kann zu Halluzinationen fÃ¼hren? Wie wir im oben gezeigten Beispiel sehen, ist den Antworten des Sprachmodells nicht immer zu trauen. Das LLM verfÃ¼gt Ã¼ber einen standardmÃ¤ÃŸig aktiven â€Refusal Circuitâ€œ, der das Modell dazu bringt, keine Antwort zu geben, wenn es keine ausreichenden Informationen hat. Wenn eine bekannte EntitÃ¤t erfasst wird, aktiviert sich ein konkurrierender â€Known Entityâ€œ-Mechanismus, der den Refusal Circuit hemmt und eine Antwort ermÃ¶glicht. Problematisch wird es, wenn Claude einen Namen erkennt, aber keine spezifischen Informationen dazu hat. In solchen FÃ¤llen kann der â€Known Entityâ€œ-Mechanismus fÃ¤lschlicherweise den Refusal Circuit unterdrÃ¼cken, was zu einer Halluzination fÃ¼hrt. Ein Beispiel: Bei der Frage nach einem Fachartikel des bekannten Forschers Karpathy gibt Claude einen erfundenen Titel an, da das Modell zwar den Namen kennt, in diesem Fall aber keine Informationen Ã¼ber den Artikel hat. Bei weniger bekannten Namen gibt das Modell an, die Antwort nicht zu kennen (Lindsey et al., 2025).",
    "crumbs": [
      "<span class='chapter-number'>2</span>Â  <span class='chapter-title'>Grundbegriffe</span>"
    ]
  },
  {
    "objectID": "kapitel02.html#welches-modell-wÃ¤hlen",
    "href": "kapitel02.html#welches-modell-wÃ¤hlen",
    "title": "2Â  Grundbegriffe",
    "section": "2.3 Welches Modell wÃ¤hlen?",
    "text": "2.3 Welches Modell wÃ¤hlen?\nWas fÃ¼r LLMs gibt es aktuell? Die groÃŸen Anbieter mit den jeweils stÃ¤rksten Modellen (s. AbbildungÂ 2.2) sind OpenAI (Chat GPT-5), Google (Gemini 2.5) und Anthropic (Claude Opus 4.1 / Sonnet 4). Je nach Anwendung werden gÃ¼nstigere Modelle angeboten, die weniger Rechenaufwand benÃ¶tigen, meist mit dem Zusatz â€Miniâ€œ. Starke Reasoning Modelle (die komplexe Fragestellungen bearbeiten kÃ¶nnen) von OpenAI sind GPT 5 oder Gemini 2.5 Flash (Stand 08/2025). Kostenfrei nutzbare Open Source Alternativen sind z.B. Mistral (eines der wenigen europÃ¤ischen Modelle) und Llama4 (von Meta/Facebook) sowie die chinesische Konkurrenz DeepSeek V3.1 (Mollick, 2025a; sowie Vellum, 2024).\nWelches Sprachmodell sollte man aktuell nutzen? Die kurze Antwort ist, dass aktuell GPT-5 eine gute Wahl ist. FÃ¼r Lehrende kostenfrei nutzbar gibt es aktuell (August 2025) den zentralen Dienst â€Chat-AIâ€œ / Academic Cloud der Gesellschaft fÃ¼r wissenschaftliche Datenverarbeitung GÃ¶ttingen (GWDG) (https://chat-ai.academiccloud.de/), Ã¼ber den neben einer Reihe von quelloffenen Modellen mittlerweile auch Chat GPT-5 nutzbar ist. Hier kann man sich einfach mit einer Hochschuladresse registrieren und den Dienst nutzen. Hochschulen bieten teils einen eigenen KI-Zugang an, die TH-KÃ¶ln etwa einen begrenzten Zugang zu ChatGPT und einzelnen quelloffenen Modellen Ã¼ber das THKI-Lab (https://ki.th-koeln.de/login.php). Im September 2025 wurde an der TH KÃ¶ln und weiteren NRW-Hochschulen die LÃ¶sung KI:connect ausgerollt, die Ã¤hnliche FunktionalitÃ¤ten bereitstellt (https://kiconnect.pages.rwth-aachen.de/pages/).\nAuÃŸerdem kÃ¶nnen Lehrende Ã¼ber die Hochschullizenz Microsoft 365 Copilot herunterladen und dann einen KI-Chat als Desktop-Anwendung nutzen, eine Anwendung, unter deren Haube auch wieder verschiedene Versionen von ChatGPT stecken (hier einloggen und einfach herunterladen: https://www.office.com/). Hier kann man auch GPT 5 nutzen, Chats speichern und komplexere Anweisungen als â€Agentenâ€œ entwerfen und teilen.\nDiese kostenfreien LÃ¶sungen sind in den letzten Monaten stark ausgebaut worden und mittlerweile schon sehr nÃ¼tzlich geworden. Sie stellen allerdings i.d.R. nicht den aktuellen Stand der Performanz der KI-Modelle dar. Lehrende sollten daher unbedingt 1 bis 2 Monate die 20 Euro investieren und auch die stÃ¤rksten Bezahlmodelle ausprobieren (also ChatGPT oder Gemini in der Bezahlversion). Nur so erhÃ¤lt man ein GefÃ¼hl dafÃ¼r, was aktuell technisch mÃ¶glich ist und wie â€sicherâ€œ die eigenen PrÃ¼fungsleistungen sind (z.B. â€im GesprÃ¤châ€œ mit der KI, Ã¼ber das Voice Modell, was bei den kostenfreien ZugÃ¤ngen aktuell meist abgeklemmt ist).\n\n\n\n\n\n\nAbbildungÂ 2.2: Je nach Ziel ein anderer Platz in der Bestenliste\n\n\n\nQuelle: Vellum (2024), Stand 08/2025.\nHier kann man vergleichen: In der LM-Arena kann man verschiedene Modelle ausprobieren und ihre Antwort auf eine bestimmte Frage gegenÃ¼berstellen: https://lmarena.ai/ (UntermenÃ¼: â€Arena (side-by-side)â€œ).",
    "crumbs": [
      "<span class='chapter-number'>2</span>Â  <span class='chapter-title'>Grundbegriffe</span>"
    ]
  },
  {
    "objectID": "kapitel02.html#was-kÃ¶nnen-die-modelle-und-was-nicht",
    "href": "kapitel02.html#was-kÃ¶nnen-die-modelle-und-was-nicht",
    "title": "2Â  Grundbegriffe",
    "section": "2.4 Was kÃ¶nnen die Modelle â€“ und was nicht?",
    "text": "2.4 Was kÃ¶nnen die Modelle â€“ und was nicht?\nWas fÃ¼r Aufgaben LLMs beherrschen ist sehr uneinheitlich und verÃ¤ndert sich dynamisch. Es gibt Bereiche, in denen heutige KI auf menschlichem Niveau oder besser agiert, und andere, oft nur geringfÃ¼gig andersartige Aufgaben, an denen die KI (noch) scheitert (Dellâ€™Acqua et al., 2023). Mollick und Kollegen prÃ¤gen hierfÃ¼r den Begriff einer â€Jagged Technological Frontierâ€œ (zerklÃ¼ftete Technik-Grenze) (Dellâ€™Acqua et al., 2023). Zwei Aufgaben von Ã¤hnlicher Schwierigkeit fÃ¼r Menschen kÃ¶nnen mit sehr unterschiedlicher QualitÃ¤t durch ein LLM gelÃ¶st werden â€“ eine liegt innerhalb der KI-Frontier (d.Â h. die KI kann sie lÃ¶sen), die andere auÃŸerhalb (KI liefert unbrauchbare oder falsche Resultate) (Dellâ€™Acqua et al., 2023).\nIn einem Experiment mit Consultants wurden 18 verschiedene Beratungsaufgaben gestellt. FÃ¼r die meisten (â€inside the frontierâ€œ) brachte KI enorme Vorteile, doch bei einer gezielt auÃŸerhalb der Frontier gewÃ¤hlten Aufgabe schnitt die KI-Gruppe deutlich schlechter ab: Hier waren die Consultants in der Gruppe mit KI 19 Prozentpunkte weniger hÃ¤ufig korrekt als die ohne KI (Dellâ€™Acqua et al., 2023). Dieses Ergebnis unterstreicht die Gefahr, LLMs unkritisch auf Probleme anzuwenden, die ihre aktuellen FÃ¤higkeiten Ã¼bersteigen â€“ die Leistung fÃ¤llt dann hinter menschliches Niveau zurÃ¼ck. Praktisch bedeutet die Jagged Frontier, dass Organisationen und Individuen lernen mÃ¼ssen, die Grenze der KI-FÃ¤higkeiten zu erkennen und entsprechend zu navigieren (Dellâ€™Acqua et al., 2023).\nFÃ¼r folgende AnwendungsfÃ¤lle sind LLMs mittlerweile gut nutzbar (Handa et al., 2025-04-08, 2025; Korinek, 2024; Schwarcz et al., 2025):\n\nZusammenfassung von Fachartikeln\nFortgeschrittene mathematische Ableitungen\nAnspruchsvolle Codierungsaufgaben\nErstellen eines Podcasts zu einer Forschungsarbeit\nErstellen von PrÃ¤sentationsfolien\nVerfassen von BlogbeitrÃ¤gen\nSimulieren von Interviews mit der Sprachausgabe von ChatGPT oder Gemini\nKI-gestÃ¼tzte Suche (mit kritischer PrÃ¼fung natÃ¼rlich)\n\nDie FÃ¤higkeiten der Modelle wuchsen in den letzten Monaten rasant und damit werden die Aufgaben, die man an sie delegieren kann komplexer. Die LÃ¤nge der Aufgaben, die KI Sprachmodelle relativ genau erledigen kÃ¶nnen, verdoppelt sich seit 2019 etwa alle 7 Monate (Kwa et al., 2025). Auch die Bewertung von Forschungsarbeiten im Rahmen des Peer-Reviews wird zunehmend teil-automatisiert, etwa durch die automatische PrÃ¼fung von Quellen oder Code und Teilbewertungen durch Dienste wie Veracity oder Paper Wizard (Lovely, 2025; Naddaf, 2025).\nIst das ein Mensch, oder ein Bot? Eine neuere Studie zeigt, dass neue Sprachmodelle uns bei dieser Frage mittlerweile erfolgreich tÃ¤uschen kÃ¶nnen und so den Turing Test bestehen, da sie in einer sozialen Interaktion Menschen erfolgreich imitieren kÃ¶nnen (Jones & Bergen, 2025). In einem randomisierten Drei-Parteien-Turing-Test mit Ã¼ber 1.000 Spielen wurde ein mit speziellen Eingabe-Anweisungen (Persona-Prompt) versehenes Sprachmodell (GPT-4.5) von den Respondenten zu 73 % fÃ¼r den Menschen gehalten, hÃ¤ufiger als echte Menschen in der Vergleichsgruppe. Weniger komplexe Modelle (wie Llama 3.1) schritten schlechter ab. Die Autoren diskutieren daraus resultierende Risiken von sozialer Manipulation oder Arbeitsplatzsubstitution, sowie die Notwendigkeit robusterer menschlicher Erkennungsstrategien.\nAuch durch diesen FÃ¤higkeitsschub ist der Einsatz von Sprachmodellen in Support-Funktionen wie Call Centern stark gestiegen, empirische Studien belegen hier einen starken ProduktivitÃ¤tszuwachs (Brynjolfsson et al., 2025).\nDie GrÃ¼nde fÃ¼r die ProduktivitÃ¤tssteigerung von KI-Modellen lassen sich durch Scaling Laws (Training Scaling Law, Inference Scaling Law, (Mollick, 2025a)) beschreiben: KI-Modelle werden einerseits exponentiell besser, je mehr Daten, Rechenleistung und Parameter genutzt werden und andererseits, wenn sie mehr Zeit zum â€nachdenkenâ€œ erhalten. (FÃ¼r eine schÃ¶ne visuelle Beschreibung, s. Grootendorst (2025))\nDer erste Zusammenhang (Training Scaling Law) besagt, dass grÃ¶ÃŸere KI-Modelle mit mehr Parametern und Trainingsdaten systematisch leistungsfÃ¤higer werden. Allerdings sind solche ErtragszuwÃ¤chse mit hohen Kosten verbunden: Eine 10-fache Steigerung an Rechenaufwand fÃ¼hrt etwa zu einer ErhÃ¶hung der Leistungsmetriken um einen festen Betrag, was abnehmende GrenzertrÃ¤ge andeutet.\nNeben dem positiven Effekt der ModellgrÃ¶ÃŸe wurde in den letzten Monaten ein zweiter Scaling-Effekt (Inference Scaling Law) auf der Anwenderseite deutlich: LLMs liefern bessere LÃ¶sungen, wenn man ihnen mehr â€Denkzeitâ€œ gibt. OpenAI fand heraus, dass ein Modell mit lÃ¤ngerer Schritt-fÃ¼r-Schritt-Reasoning-Phase merklich bessere Ergebnisse erzielt, analog zu einem Menschen, dem man mehr Zeit fÃ¼r eine schwierige Aufgabe gibt. Dieser Inference Scaling Law fÃ¼hrte zur Entwicklung von Reasonern â€“ KI-Systemen, die bei Bedarf intern zusÃ¤tzliche Rechenschritte durchfÃ¼hren, um schwierige Probleme genauer zu lÃ¶sen (Gottweis et al., 2025; OpenAI, 2024; Schwarcz et al., 2025).\nZusammengenommen bedeuten diese Skalierungsgesetze, dass KI-Systeme durch hÃ¶heren Ressourceneinsatz (beim Training und bei der Nutzung) immer leistungsfÃ¤higer und vielseitiger werden, wenn auch zu steigenden Kosten. Ã–konomisch relevant ist hier vor allem, dass die Grenzkosten der KI-Nutzung sehr niedrig bleiben, sobald ein groÃŸes Modell einmal trainiert ist: Ist das Modell erstellt, kann es millionenfach eingesetzt werden, was Skaleneffekte in der Verbreitung ermÃ¶glicht. Somit schafft das Scaling Law die Grundlage dafÃ¼r, dass hochleistungsfÃ¤hige KI als allgemein verfÃ¼gbares Gut in Wirtschaft und Bildung eingesetzt werden kann. Durch diese Eigenschaft ermÃ¶glicht KI eine schnelle und kosteneffiziente Skalierung personalisierter und adaptiver Lernangebote (Mollick, 2025a). Dieses exponentielle Wachstum unterscheidet KI grundlegend von bisherigen technologischen Entwicklungen, bei denen Verbesserungen oft linear verliefen.\nOpenAI hat allein in den ersten Monaten von 2025 mehrere neue Funktionen eingefÃ¼hrt, die den Einsatz von KI in der Hochschullehre deutlich erweitern kÃ¶nnten: Mit der Bildgenerierungsfunktion in GPT4o lassen sich nun auch fotorealistische Visualisierungen erstellen, was z.B. in der technischen Bildung oder bei Designprojekten didaktisch genutzt werden kann (MÃ¤rz 2025). Die neuen Audio-Modelle ermÃ¶glichen eine prÃ¤zise Steuerung von Sprachstil und Tonfall â€“ hilfreich etwa fÃ¼r simulierte Rollenspiele, interaktive Lernbegleiter oder barrierefreie Lerninhalte (MÃ¤rz 2025). Das im Februar eingefÃ¼hrte deep research-Modul erlaubt KI-gestÃ¼tzte Rechercheprozesse, die Studierende bei komplexen Projektarbeiten oder der Literatursichtung unterstÃ¼tzen kÃ¶nnten (Februar 2025). ZusÃ¤tzlich wurde mit o3-mini ein kostengÃ¼nstigeres Modell vorgestellt, das den Zugang zu leistungsfÃ¤higen KI-Anwendungen auch in Bildungseinrichtungen erleichtert (Januar 2025).\n. Quelle: Kwa et al. (2025)\nEs lassen sich nach dieser Studie zwei Kooperationsmodelle zwischen Mensch und LLM unterscheiden, um die Technologiegrenze optimal auszunutzen (Dellâ€™Acqua et al., 2023): Der Centaur-Ansatz teilt die Aufgabe, indem der Mensch der KI die Teilprobleme Ã¼berlÃ¤sst, die innerhalb der Frontier liegen, und sich selbst auf den Rest konzentriert. Der Cyborg-Ansatz integriert die KI tiefer, indem der Mensch kontinuierlich mit der KI interagiert und Feedback-Schleifen nutzt. Beide setzen implizit voraus, dass der Nutzer um die StÃ¤rken und SchwÃ¤chen des LLM weiÃŸ.\nEine spÃ¤tere Studie des weitgehend selben Teams mit 776 Praktikern bei Procter & Gamble zeigt, dass Individuen mit LLM UnterstÃ¼tzung deutlich produktiver Probleme lÃ¶sen oder neue Ideen generieren konnten. Das Sprachmodell scheint einen deutlichen Mehrwert als â€Cybernetic Teammateâ€œ zu bringen und Einzelne teils auf das Leistungsniveau von ganzen Teams zu bringen (Dellâ€™Acqua et al., 2025).\nWenn man Ã¤ltere oder weniger starke (offene) Modelle nutzt, fÃ¤hrt man mit dem Fahrrad auf der Autobahn. Vergleiche zeigen starke Performanzunterschiede zwischen GPT-3.5 und den folgenden Updates zu GPT-4 und GPT-4o. Auch die frei verfÃ¼gbaren Modelle wie Llama sind teils deutlich weniger â€schlauâ€œ! Hier muss man insofern aufpassen, dass die einfache VerfÃ¼gbarkeit solcher Modelle Ã¼ber Plattformen wie Academic Cloud nicht zu einem falschen Bild fÃ¼hrt.",
    "crumbs": [
      "<span class='chapter-number'>2</span>Â  <span class='chapter-title'>Grundbegriffe</span>"
    ]
  },
  {
    "objectID": "kapitel02.html#wo-und-wie-spreche-ich-mit-der-ki",
    "href": "kapitel02.html#wo-und-wie-spreche-ich-mit-der-ki",
    "title": "2Â  Grundbegriffe",
    "section": "2.5 Wo und wie spreche ich mit der KI?",
    "text": "2.5 Wo und wie spreche ich mit der KI?\n\n2.5.1 Wo sprechen? Verschiedene ZugÃ¤nge zu Sprachmodellen\nWo sprechen wir mit dem Sprachmodell? Welche ZugÃ¤nge zur KI gibt es? Es gibt grob gesagt drei AnsÃ¤tze:\n\nDie einfache Eingabe in das Chat-Interface (z.B. bei Chat GPT oder Claude), ist am leichtesten umzusetzen. Um verschiedene Modelle zu nutzen, muss man sich aber neu einloggen und evtl. ein weiteres Abonnement bezahlen. Die meisten Modelle erlauben aber auch recht umfangreiche kostenlose Nutzung, was meist zum Kennenlernen ausreicht. FÃ¼r Hochschulen werden zentral nach und nach verschiedene Dienste mit solchen OberflÃ¤chen aufgesetzt, die meist aber aus GrÃ¼nden des Datenschutzes einige Funktionen abklemmen (z.B. meist die direkte Sprachinteraktion und das Speichern von Benutzerprofilen).\nNutzung einer BedienoberflÃ¤che wie Witsy oder Typingmind, die Prompts speichert und Agenten erstellen lÃ¤sst, die mit verschiedenen Modellen funktionieren (Schwarze, 2025). Hier muss man einmalig das System aufsetzen (Witsy) und fÃ¼r den hÃ¶heren Komfort teils eine Lizenz kaufen (TypingMind, ca. 40 $ fÃ¼r HochschulangehÃ¶rige), dafÃ¼r kann man dann einfacher Modelle wechseln und Ã¼ber einen sogenannten API Key nur die tatsÃ¤chliche Nutzung abrechnen (was sich bei einfacher Nutzung auf ein paar Cent belÃ¤uft, siehe die oben gezeigte Ãœbersicht der Preise pro Millionen Token).\nWenn man sich nicht vor etwas Code scheut, kann man auch einfach selbst programmieren (mit KI-UnterstÃ¼tzung in Tools wie Google Colab) und kleine Sprachagenten aufsetzen. (Evtl. dann in Verbindung mit Replit fÃ¼r die Online-Bereitstellung und Diensten wie Voiceflow fÃ¼r die OberflÃ¤che.) Auch hierfÃ¼r braucht man eigentlich nur API Keys zur Identifizierung. Fragen Sie Chat GPT, wie das geht und lassen sich den Code schreiben, es ist Ã¼berraschend einfach! Es gibt bei Youtube auch eine Vielzahl von kurzen ErlÃ¤uterungen.\n\n\n\n2.5.2 Wie sprechen? Prompt-Befehle\nWie spreche ich mit dem LLM? In einem modernen MÃ¤rchen von N.K. Jemisin gibt es gefangene GÃ¶tter. Sie erfÃ¼llen ihren WÃ¤chtern jeden Wunsch, sind ihnen aber nicht wohlgesonnen: Eine falsche Formulierung kann so katastrophale Folgen haben. Den Baum, der im Weg liegt, kann man schlieÃŸlich auch durch einen Vulkanausbruch beseitigen. In dieser neuen Midas-ErzÃ¤hlung wird PrÃ¤zision zentral. Diesen Tenor finden wir auch in den wichtigsten Empfehlungen zum Prompting: PrÃ¤zise Anweisungen geben.\nWie das geht, zeigen wir zuerst an einem einfachen Schema. Dann schauen wir uns an, welche Prompting-Strategien die drei groÃŸen KI-Labore Ende 2025 empfehlen.\n\n\n2.5.3 Zentrale Bausteine: Rolle, Aufgabe, Format und Beispiele\nWie beschreibe ich genau, was ich will? Einfache Daumenregeln fÃ¼r Prompts gliedern das in vier Schritte: dem Sprachmodell eine Rolle zuzuweisen (â€Du bist Verhandlungsexpertinâ€œ), ein klares Ziel zu definieren (â€Du hilfst mir dabei, mich auf GeschÃ¤ftsverhandlungen vorzubereitenâ€œ), es zu bitten, sein Vorgehen (den Gedankengang / â€chain of thoughtâ€œ) offenzulegen und Schritt-fÃ¼r-Schritt vorzugehen (â€Erstelle zunÃ¤chst einen Plan und frag mich nach Feedback. Warte meine Antwort ab und passe den Plan eventuell an. Wenn ich zufrieden bin, beginne mit dem ersten Schritt in deinem Plan.â€œ) sowie Beispiele (â€few shotâ€œ) fÃ¼r eine gewÃ¼nschte Struktur oder Analyse mitzuliefern (â€Formatiere die Dateinamen in dieser Form [Autor]-[Jahr]-[Kurztitel]â€œ, oder â€Gib mir 5 Handlungsoptionen und nenne jeweils Vor- und Nachteileâ€œ). Dabei veranlasst die Chain of Thought-Methode das LLM, seine GedankengÃ¤nge offen zu legen. Das Modell zeigt seine Ãœberlegungen Schritt fÃ¼r Schritt, was die Nachvollziehbarkeit seiner Antworten verbessert. So kÃ¶nnen wir auch besser nachsteuern und das Ergebnis an unsere Ziele anpassen.\n\n\n\n\n\n\nStrukturierten Prompt einfach erstellen lassen\n\n\n\nWollen Sie sich interaktiv einen ausfÃ¼hrlichen, strukturierten Prompt erstellen lassen? Hier finden Sie einen Beispiel-Bot, dem man Prompts fÃ¼ttern kann, die er dann in ein kurzes oder detaillierteres Schema packt: https://chatgpt.com/g/g-695a8a7c9c888191a683135100f623d0-prompt-strukturierer-rtf-oder-create-format).\n\n\n\n\n2.5.4 Wie Prompten? Was Ende 2025 die grÃ¶ÃŸten KI-Labore empfehlen.\nEnde 2025 geben die drei fÃ¼hrenden KI-Labs uns detaillierte Tipps, wie wir mit ihren GeschÃ¶pfen GPT, Gemini und Claude reden sollen (Anthropic, 2025; Google, 2025; Kotha et al., 2025). Die Empfehlungen sind recht Ã¤hnlich und es lohnt sich, sie hier kurz zu referieren.\nDie drei fÃ¼hrenden Anbieter betonen die Bedeutung von PrÃ¤zision der Anweisungen - wenig Ã¼berraschend, aber im Detail nicht einfach zu bewerkstelligen: (1) Vorab die vielleicht wichtigste, wenn auch banale Empfehlung: Es hilft, genau zu sagen, was man eigentlich will.\n\n\n\n\n\n\nMeta-Prompts: Den Bot den Prompt verbessern lassen\n\n\n\nProbleme mit dem Prompt? OpenAI schlÃ¤gt vor, man soll mit einer klaren Problembeschreibung wie folgt prompten:\nHier ist ein Prompt: [PROMPT EINFÃœGEN] Das gewÃ¼nschte Verhalten dieses Prompts ist, dass der Agent [GEWÃœNSCHTES VERHALTEN BESCHREIBEN] ausfÃ¼hrt, stattdessen fÃ¼hrt er jedoch [UNERWÃœNSCHTES VERHALTEN BESCHREIBEN] aus. Wie wÃ¼rdest Du die Eingabeaufforderung mÃ¶glichst unverÃ¤ndert lassen und dennoch minimale Ã„nderungen/ErgÃ¤nzungen vornehmen, um den Agenten dazu zu bewegen, diese MÃ¤ngel konsequenter zu beheben?\n\n\n\nAufgaben prÃ¤zise beschreiben: Man sollte nicht auf den Hiwi schimpfen, wenn man sich nicht die Zeit genommen hat, zu sagen, was eigentlich die Aufgabe ist! Die immer schlaueren Bots brauchen klare Anweisungen ohne innere Ungereimtheiten oder vage Formulierungen.\nBeispiele helfen der KI, nicht nur EinzelwÃ¼nsche sondern den breiteren Kontext zu berÃ¼cksichtigen - genau wie man das von einem guten Butler gerne hÃ¤tte. Positiv-Beispiele sind dabei besser als Negativbeispiele (â€œgib mirâ€¦â€/â€œbemÃ¼he dich umâ€¦â€ ist besser als â€œgib mir nichtâ€ / â€œvermeideâ€¦â€) (Google, 2025). Man sollte nicht zu viele Beispiele geben, sonst kann es passieren, dass sich das LLM zu stark an diesen orientiert und den Suchraum einengt.\nOrdnung macht hier Meisterschaft: durch klare Strukturierung des Textflusses durch  sogenannte [Tags]. Ob solche â€˜Post-it-Notizenâ€™ fÃ¼r die Bots in eckigen Klammern oder mit grÃ¶ÃŸer/kleiner Zeichen als  markiert sind, ist dabei nicht wichtig, es muss nur einheitlich sein.\nZunehmend wird bei einer interaktiven Form der Zusammenarbeit mit dem Sprachmodell der Weg zum Ziel. Prompten wird hier zum iterativen Prozess, in dem die Interaktion den eigentlichen Mehrwert bietet, da nach und nach mit dem Sprachmodell ein LÃ¶sungsweg erarbeitet wird. Dies verlangt eine deutlich andere Herangehensweise als Werkzeuge wie Taschenrechner, von denen wir erwarten, dass sie sofort eine LÃ¶sung ausspucken.\nAgenten erfordern neue Verhaltensweisen. Da die Zeitspanne des autonomen Handelns immer breiter wird, in denen Sprachmodelle selbststÃ¤ndig suchen, bewerten und zusammenfassen kÃ¶nnen, mÃ¼ssen wir sie auch anders steuern. Zweitens gewinnt die Frage an Bedeutung, wieviel EigenstÃ¤ndigkeit wir uns von dem Bot denn wÃ¼nschen. Bei GPT kann man dies z.B. als â€˜Eagerness-Kalibrierungâ€™ einstellen (Kotha et al., 2025). Bei solchen mehrstufigen, lÃ¤ngeren Prozessen mÃ¼ssen wir auch Ã¼ber das â€˜GedÃ¤chtnisâ€™ des Agenten-Bots nachdenken. Im Detail wird hier etwa empfohlen, den Agenten seine Zwischenergebnisse (â€˜statesâ€™) in hoch strukturierter Form ablegen zu lassen (im JSON-Format etwa, das sozusagen markierte Schubladen fÃ¼r die Daten bereitstellt) und kurze nummerierte Zwischennotizen im FlieÃŸtext zu erfragen (â€œIm letzten Schritt habe ich folgende Updates an dem Text vorgenommenâ€¦â€) (Anthropic, 2025). Wir sehen, dass hier die Empfehlungen schon stÃ¤rker in Richtung der FÃ¼hrung von Mitarbeitern gehen, eine Konsequenz der wachsenden SelbststÃ¤ndigkeit dieser â€˜cybernetic teammatesâ€™ (Dellâ€™Acqua et al., 2025).\nBots help bots: Die Sprachmodelle kÃ¶nnen uns dabei helfen, mit ihnen zu sprechen. So kÃ¶nnen wir mit dem Tool das Tool bedienen. Das kann man schon mit einfachen Prompts tun (s. den folgenden Einschub-Kasten), oder mit eingebauten Tools der Sprachmodelle, wie dem GPT Prompt Optimierer (Kotha et al., 2025) oder mit einem eigenen Prompt, der das Sprachmodell anweist, eine Anweisung in ein bestimmtes Muster zu packen.\n\nEs kÃ¶nntâ€™ alles so einfach sein! Es bringt nichts, Bots zu bedrohen oder zu bestechen. Neuere empirische Untersuchungen haben eine Reihe von anekdotischen Hausrezepten des Promptings systematisch geprÃ¼ft und meist widerlegt. Prompts funktionieren nicht immer gleich und so kommt es schnell zu anekdotischer Evidenz, dass eine Formulierung â€besser geklapptâ€œ hÃ¤tte. Die wenigsten der Empfehlungen helfen zuverlÃ¤ssig (Meincke et al., 2025b, 2025a, 2025c). Hilft es, hÃ¶flich zu sein (nein), zu drohen (nein), Geld anzubieten (nein), oder den Hiwi-Bot Schritt fÃ¼r Schritt vorgehen zu lassen (ja, aber das machen die neueren Reasoning-Sprachmodelle auch selbst)? Auch hier sehen wir, dass die stÃ¤rkeren neueren Modelle auch etwas andere Bedienung erfordern. Wie ein neuer Sportwagen kommen mit den neuen FÃ¤higkeiten auch neue AnfÃ¤lligkeiten: Die neuen Modelle kÃ¶nnen selbst iterativ vorgehen, das muss man ihnen nicht mehr empfehlen. Tut man es doch, sinkt teils die Performanz (Meincke et al., 2025a), etwa wenn man so verhindert, dass ein starkes Modell eine Frage aus seinem Vorwissen beantwortet und es stattdessen zu mehreren - eigentlich unnÃ¶tigen - Denkschritten mit entsprechendem Token-Verbrauch zwingt). Da sie schlauer sind, werden sie durch unprÃ¤zise Anweisungen teils schneller aus der Bahn geworfen. Die Modelle halten sich genauer an Anweisungen - aber eben auch an falsche (Anthropic, 2025; Google, 2025).\nWas heiÃŸt das fÃ¼r Prompts in der Lehre? FÃ¼r die Lehre wollen wir den Prompts speziell didaktische Elemente hinzufÃ¼gen, also etwa verhindern, dass den Studierenden sofort eine LÃ¶sung ausgegeben wird, da das eigene Nachdenken in Form von Fragen und sokratischem Dialog ihnen dabei hilft, die Ergebnisse auch zu behalten (Roediger & Pyc, 2012). Hier mÃ¼ssen wir also teils bewusst HÃ¼rden einfÃ¼hren, die die Studierenden zum Nachdenken, diskutieren und Ã¼berlegen anregen. Wie das geht, sehen wir in den nÃ¤chsten zwei Hauptkapiteln. Eine Vielzahl konkreter Beispiele von Prompts und didaktischer Aufgabenstellungen mit GenAI Tools finden Sie im Appendix (Anhang B).\nWie steht es mit dem Energieverbrauch der Modelle? Durch das starke Wachstum der neuen Technologie, werden wir verstÃ¤rkt mit den mÃ¶glichen Effekten von KI auf Ressourcenverbrauch und Umweltbelastung konfrontiert (Spencer & Singh, 2025). Auch bei der Nutzung in der Lehre wird dies regelmÃ¤ÃŸig von Studierenden angesprochen. In diesem Bereich gibt es viel Hype und Desinformation in beide Richtungen (von â€Weltuntergang durch KI-Energiehunger!â€œ zu â€keinerlei Problemâ€œ), so dass hier ein kurzer Ãœberblick seriÃ¶ser Studien nÃ¼tzlich erscheint. Dieser sehr knappe Abriss soll vor allem eine kurze Orientierung und den Verweis auf weiterfÃ¼hrende Literatur zur vertieften BeschÃ¤ftigung bieten.\nWie schmutzig ist es also, KI zu nutzen? Die kurze Antwort ist, dass ein typischer Prompt aktuell etwa soviel Energie verbraucht wie ca. 10 Sekunden Netflix-Streaming oder eine typische Google Suche im Jahre 2008 (Elsworth et al., 2025; Mollick, 2025b). Die gute Nachricht ist, dass die Modelle effizienter werden und der Energieverbrauch pro Output-Token rasant sinkt und dass die Anreize fÃ¼r die groÃŸen Anbieter stark darauf ausgerichtet sind, den Energieverbrauch weiter zu senken. GegenlÃ¤ufig und problematisch ist die stark steigende Nutzung, die z.B. zur Ausweitung gerade umweltbelastender Energieformen wie Gasturbinen fÃ¼hrt (Wittenberg, 2025).\nSolche Vergleiche sind nicht trivial, da etwa bei der Nutzung in Unternehmen auch die Umweltfolgen der aktuellen Alternativen â€bepreistâ€œ werden mÃ¼ssen, um einen sinnvollen Vergleich zu erzielen. Wie belastet die Lieferkette eines physischen Buchs die Umwelt im Vergleich zu einem E-Book? Ein aktueller Mitarbeiter im physischen Callcenter mit seinem Arbeitsweg, Schreibtisch und Heizbedarf im Vergleich zum KI-Chatbot? UnabhÃ¤ngig davon, wie diese Rechnungen ausgehen, sind sie sichtlich komplex.\nIm Folgenden sollen dazu einige Kernaussagen aus Untersuchungen der International Energy Agency (IEA), dem World Economic Forum und des MIT Technology Reviews zusammengefasst werden. Basierend auf die aktuelle Untersuchung des MIT Technology Survey (Oâ€™Donnell & Crownhart, 2025) gliedere ich diesen kurzen Abriss zum Energieverbrauch in vier Teile: Die Modellbildung, die Anfrage (query), die Emissionen und Prognosen fÃ¼r das weitere Wachstum.\nModellbildung. Daten-Zentren und KI-Nutzung machen aktuell nur wenige Prozent der globalen Energienutzung aus. SchÃ¤tzungen der Energieagentur IEA liegen etwa bei 3â€“5 %. Deutlich hÃ¶here Anteile liegen in den Bereichen GebÃ¤ude, Industrie und Fahrzeuge (Ritchie, 2024a; Spencer & Singh, 2024). Mit Blick auf die Zukunft ist der rasant wachsende Energiebedarf durch BevÃ¶lkerungswachstum und wachsenden Wohlstand Ã¤rmerer BevÃ¶lkerungsgruppen bei weitem ein stÃ¤rkerer Treiber fÃ¼r Emissionswachstum und Klimawandel (Spencer & Singh, 2024). Einige Klimaaktivisten warnen sogar vor â€distractionâ€œ - davor, sich durch solche Ablenkungen und Modethemen wie KI Energieverbrauch von dem Fokus auf die groÃŸen Hebel der Emissionsvermeidung ablenken zu lassen (Masley, 2025; Ritchie, 2024b). WÃ¤hrend die EinmalaufwÃ¤nde fÃ¼r das Training der Modelle erheblich sind, hat das schnelle Wachsen der Nutzerzahlen sie mittlerweile in den Schatten gestellt. Die EnergieaufwÃ¤nde fÃ¼r Anfragen (Inferenz) bedingen nunmehr einen grÃ¶ÃŸeren Energieverbrauch als das Training der Modelle (Oâ€™Donnell & Crownhart, 2025; Spencer & Singh, 2025).\nAnfrage. Der Energieverbrauch einer einzelnen KI-Textanfrage ist relativ gering. Er liegt unter dem Energieverbrauch von wenigen Minuten fÃ¼r eine kleine LED-Lampe. Konkret liegen die SchÃ¤tzungen hier aktuell zwischen 0,3 Wattstunden (Wh) fÃ¼r GPT-4o und 0,03 Wh fÃ¼r kleine Modelle (Oâ€™Donnell & Crownhart, 2025; You, 2025).\nIm Vergleich zu anderen Energieverbrauchen ist das nicht viel. Vergleicht man den hÃ¶heren Wert von 0,3 Wh mit den 12.000 Wattstunden, die ein durchschnittlicher britischer Haushalt pro Tag verbraucht (fÃ¼r US-Haushalte wird die deutlich hÃ¶here Zahl von 28.000 Wattstunden pro Tag genannt!), wird schnell klar, dass weniger KI-Nutzung zumindest aktuell kein groÃŸer Hebel fÃ¼r Energiesparen oder Klimaschutz ist. Die oft zitierte Statistik, nach der eine Anfrage bei ChatGPT 10x mehr verbraucht als eine Google Suche vergisst meist zu erwÃ¤hnen, dass die Basisrate dieser Internetnutzung im Vergleich zu anderen Dingen, in die unser Energieverbrauch flieÃŸt, extrem niedrig ist (Ritchie, 2024b).\nModellgrÃ¶ÃŸe ist allerdings ein zentraler Faktor fÃ¼r den Energiebedarf pro Anfrage und hieraus speisen sich plausiblere Sorgen. Zwar ist Bildgenerierung i.d.R. weniger energieintensiv als Textgenerierung, da Modelle zur Bildgenerierung oft mit weniger Parametern arbeiten als Textmodelle. Aber komplexere Anfragen (etwa mehrstufige lange Reasoning AuftrÃ¤ge) und speziell Video-Generierung benÃ¶tigen deutlich mehr Energie: Ein hochqualitatives Video von 5 Sekunden kann bis zu 1.000 Wattstunden verbrauchen (0,94 kWh), was etwas mehr als einer Stunde Mikrowellennutzung entspricht â€“ ein deutlicher Unterschied (Oâ€™Donnell & Crownhart, 2025).\nDer Anteil grÃ¶ÃŸerer Modelle und komplexerer Anfragen wird voraussichtlich deutlich zunehmen, wenn die ModellgrÃ¶ÃŸen weiter ansteigen und komplexere Anfragen, wie Video-Generierung zunehmen. GegenlÃ¤ufig wirkt der starke Anreiz fÃ¼r die Anbieter (und speziell fÃ¼r die kleineren Konkurrenten von OpenAI, die Ã¼ber geringere finanzielle Mittel verfÃ¼gen), den Energieverbrauch pro Inferenz durch effizientere Chip-Konstruktionen und neue TrainingsansÃ¤tze zu senken. Wie die Analysten der IEA zusammenfassen: â€The efficiency of AI-related computer chips has doubled roughly every two-and-a-half to three years, and a modern AI-related computer chip uses 99% less power to perform the same calculations as a model from 2008â€ (Spencer & Singh, 2024).\nInsgesamt wird perspektivisch die punktuelle Einzelnutzung durch einzelne Anfragen weniger wichtig werden, als die strukturell bedingte Integration der KI-Technologien in immer mehr digitale Anwendungen, die als Folge des rasanten technologischen Wandels und der hohen Investitionen absehbar ist (Oâ€™Donnell & Crownhart, 2025).\nEmissionen. In diesem Zusammenhang wird der ungÃ¼nstige Energiemix der aktuell entstehenden Datenzentren kritisiert: Da KI-Rechenzentren rund um die Uhr laufen und meist in Regionen mit fossilen EnergietrÃ¤gern stehen, ist der durchschnittliche COâ‚‚-AusstoÃŸ ihrer Stromversorgung etwa 48 % hÃ¶her als der US-Durchschnitt (Oâ€™Donnell & Crownhart, 2025). Dem gegenÃ¼ber stehen gegenlÃ¤ufige Effekte wie hÃ¶here Effizienz der Steuerung, etwa von Energienetzen (Greene-Dewasmes & Tladi, 2025) und dem Ersatz von manuellen menschlichen AufwÃ¤nden durch Digitalisierung, etwa durch Reisen fÃ¼r einen Film-Dreh (ohne KI) oder dem Energiebedarf eines menschlichen Call-Centers. Das starke Wachstum der Nutzung muss insofern mit politischer Anreizsetzung fÃ¼r emissionslose Energiegewinnung verbunden sein, wenn eine starke Zunahme an Emissionen vermieden werden soll. HierfÃ¼r gibt etwa die IEA klare Empfehlungen und technische LÃ¶sungen sind bekannt. Besorgt stimmt die Analysten die Prognose eines starken Wachstums von Datencentern im asiatischen Raum, die meist nicht mit emissionsfreier Energie betrieben werden (Spencer & Singh, 2025).\nPrognose. In der Summe sehen viele der Untersuchungen Probleme eher in der prognostizierten zukÃ¼nftigen Entwicklung als in den aktuellen EnergieaufwÃ¤nden. Das starke prognostizierte Wachstum kÃ¶nnte etwa dazu fÃ¼hren, dass KI-Anwendungen bis 2028 mehr als 12 % des US-Strombedarfs ausmachen (Oâ€™Donnell & Crownhart, 2025).\nEnergieverbrauch und politische Steuerung Die IEA prognostiziert ebenfalls eine Verdreifachung des Energieverbrauchs von Rechenzentren bis 2030, getrieben durch KI. MaÃŸnahmen wie Effizienzgewinne und nachhaltige Architektur kÃ¶nnen diese Entwicklung abbremsen (Spencer & Singh, 2025).\nWie der MIT-Bericht hervorhebt, sollte vor diesem Hintergrund der starke und kurzfristig induzierte Ausbau der Infrastruktur politisch durch Anreize zur Emissionsvermeidung gesteuert werden, sodass ein starkes Wachstum der Emissionen durch diesen â€“ wahrscheinlich im Kern unvermeidlichen â€“ technologischen Wandel vermieden wird (Oâ€™Donnell & Crownhart, 2025).\nSo besteht die Hoffnung, dass positive Effekte auf Emissionen in den Hauptbereichen von COâ‚‚-Emissionen (GebÃ¤ude, Industrie, Transport sowie die verbundenen Energienetze) durch hÃ¶here Effizienz in Planung und Nutzung genutzt werden kÃ¶nnen, ohne dass sie durch die wachsenden Kosten von immer komplexeren Inferenz-Anfragen Ã¼berlagert werden (Greene-Dewasmes & Tladi, 2025; Spencer & Singh, 2025).\nPolitisch gesehen ergibt sich insofern ein Bedarf an Steuerung dieses strukturellen technologischen Wandels, damit die Ziele denen der Gesellschaft entsprechen. Dazu mÃ¼ssen die Fakten klar sein: Um Kosten und Effekte abschÃ¤tzen, abfedern und verteilen zu kÃ¶nnen, fordern die Forscher eine deutlich hÃ¶here Transparenz der Energiebedarfe durch die Modellanbieter (Oâ€™Donnell & Crownhart, 2025).",
    "crumbs": [
      "<span class='chapter-number'>2</span>Â  <span class='chapter-title'>Grundbegriffe</span>"
    ]
  },
  {
    "objectID": "kapitel05.html",
    "href": "kapitel05.html",
    "title": "5Â  Empfehlungen zur Umsetzung",
    "section": "",
    "text": "5.1 Typische Aufgaben und Fragestellungen mit der KI durchspielen, Prompts anpassen, experimentieren\nLehrende sollten zunÃ¤chst Informationen sammeln, um zu verstehen, was KI mit den Aufgaben in ihrem Kurs bewirken kann (MIT Teaching + Learning Lab, 2023). Melden Sie sich bei einem der professionellen KI-Dienste an wie ChatGPT oder Claude an und spielen Sie mit exemplarischen Konzepten, Fragen und Aufgabensets aus dem Kurs. Dabei ist es wichtig, nicht gleich bei der ersten schlechten Antwort aufzugeben, sondern AnpassungsmÃ¶glichkeiten durchzugehen: LÃ¤sst sich der Input beschrÃ¤nken? (Fragen auf einen Text-Input, eine gute Internetquelle oder eine hochgeladene PDF beschrÃ¤nken.) LÃ¤sst sich der Prompt anpassen? (Bearbeitung schrittweise durchfÃ¼hren lassen, Optionen und Szenarien durchgehen lassen usw., siehe den Abschnitt 2.5.2 zu Prompt Engineering.)\nWichtig ist, sich zu Ã¼berlegen, welches Lernziel jede Aufgabe hat und wie die KI damit umgeht. Es sollte bewertet werden, bei welchen Arten von Fragen die KI gut abschneidet und wo ihre Grenzen liegen (Mollick, 2025). Diese Erkenntnisse kÃ¶nnen dann genutzt werden, um etwa Aufgabensets und andere Aufgabenstellungen besser zu strukturieren.",
    "crumbs": [
      "<span class='chapter-number'>5</span>Â  <span class='chapter-title'>Empfehlungen zur Umsetzung</span>"
    ]
  },
  {
    "objectID": "kapitel05.html#ausrichtung-der-anpassungen-nach-empfehlungen-der-lernforschung",
    "href": "kapitel05.html#ausrichtung-der-anpassungen-nach-empfehlungen-der-lernforschung",
    "title": "5Â  Empfehlungen zur Umsetzung",
    "section": "5.2 Ausrichtung der Anpassungen nach Empfehlungen der Lernforschung",
    "text": "5.2 Ausrichtung der Anpassungen nach Empfehlungen der Lernforschung\nUm die Empfehlungen der Lernforschung in das Vorgehen mit KÃ¼nstlicher Intelligenz (KI) und Aufgabensets zu integrieren, kÃ¶nnten folgende Schritte unternommen werden (MIT Teaching + Learning Lab, 2023):\n\nZeitliche Verteilung und inhaltliche Mischung von Lerninhalten (Spacing & interleaving): Die Aufgabensets sollten so gestaltet werden, dass sie Ã¼ber das Semester verteilt sind und eine Vielfalt an Themen abdecken. Dies fÃ¶rdert die Langzeiterinnerung und hilft den Studierenden, die Anwendung der Konzepte in verschiedenen Kontexten zu Ã¼ben. KI kann genutzt werden, um personalisierte LernplÃ¤ne zu erstellen, die auf den individuellen Fortschritt der Studierenden abgestimmt sind und eine Mischung aus verschiedenen Aufgabentypen bieten.\nTestgestÃ¼tztes Lernen (Test-enhanced learning): RegelmÃ¤ÃŸige, durch KI unterstÃ¼tzte Quizze und Tests kÃ¶nnen in den Lehrplan integriert werden, um das Abrufen von Informationen zu fÃ¶rdern. Diese Tests kÃ¶nnten auch die kritische Bewertung von KI-generierten Antworten beinhalten, um die kritische DenkfÃ¤higkeit der Studierenden zu schÃ¤rfen.\nFragebasierte Ausarbeitung (Explanatory questioning): KI-Tutor-Bots kÃ¶nnten entwickelt werden, um Studierende durch gezielte â€œWarumâ€-Fragen zu leiten, die ein tieferes VerstÃ¤ndnis des Materials fÃ¶rdern. Diese Bots kÃ¶nnten in Simulationen und Rollenspielen eingesetzt werden, um die Studierenden dazu zu bringen, ihre Entscheidungen zu erklÃ¤ren und zu reflektieren, wodurch die Anwendung von Konzepten in realen oder simulierten Situationen vertieft wird.",
    "crumbs": [
      "<span class='chapter-number'>5</span>Â  <span class='chapter-title'>Empfehlungen zur Umsetzung</span>"
    ]
  },
  {
    "objectID": "kapitel05.html#einfÃ¼hrung-der-studierenden-planen-besser-praktisch-hÃ¤ufig-und-niedrigschwellig",
    "href": "kapitel05.html#einfÃ¼hrung-der-studierenden-planen-besser-praktisch-hÃ¤ufig-und-niedrigschwellig",
    "title": "5Â  Empfehlungen zur Umsetzung",
    "section": "5.3 EinfÃ¼hrung der Studierenden planen: Besser praktisch, hÃ¤ufig und niedrigschwellig",
    "text": "5.3 EinfÃ¼hrung der Studierenden planen: Besser praktisch, hÃ¤ufig und niedrigschwellig\nDen Einsatz von KI lernen die Studierenden, wenn sie hÃ¤ufig und Ã¼ber das Semester zeitversetzt damit experimentieren dÃ¼rfen und mÃ¼ssen. Auch hier fÃ¼hren wieder die Empfehlungen des Spacing & Interleaving zu hÃ¶herer EffektivitÃ¤t. UnterstÃ¼tzend kÃ¶nnen externe Lernvideos von seriÃ¶sen Plattformen wie dem KI-Campus genutzt werden (z.B. https://ki-campus.org/videos/generativeki) oder selbst erstellte hochschulweite Angebote wie die Lehrpfade der TH KÃ¶ln (https://lehrpfade.th-koeln.de/kategorie/ki/).\nUm ein gemeinsames VerstÃ¤ndnis Ã¼ber Grundlagen herzustellen, ist es hilfreich, Zeit in einer der ersten PrÃ¤senzveranstaltungen einzurÃ¤umen, um das gemeinsam zu Ã¼ben. Der Sprung ins kalte Wasser ist dabei meist besser, als eine lange TheorieeinfÃ¼hrung: Gleich anfangen, dann problembasiert erlÃ¤utern. Aspekte von testbasiertem Lernen und fragebasierte Ausarbeitung lassen sich gut Ã¼ber Anwendungsaufgaben in der PrÃ¤senzveranstaltung einbauen.\n\n5.3.1 Beispiel: KI-Ãœbung in PrÃ¤senzveranstaltung am Ende eines Theorieblock zu Nachhaltigkeit in Lieferketten\nAufgabe: Nicht lange schnacken, gleich anpacken! Mit der KI einen Projektplan fÃ¼r erste konkrete Schritte einer Nachhaltigkeitsstrategie erstellen (Edge Browser, Bing Copilot = GPT-4). Prompts zum Einstieg werden den Studierenden vorgegeben. Anfang mit:\n\nPrompt #1: â€KI als Tutorâ€œ oder Ã¤hnlich (siehe Appendix: Beispiel KI als Tutor #1/ Allgemeiner Tutor. Prompts im Folgenden immer kursiv.)\nPrompt #2: Ich will eine Cradle-to-cradle Nachhaltigkeitsstrategie fÃ¼r ein Unternehmen entwerfen. Helfen Sie mir, konkrete erste Schritte nach der Cradle-to-cradle Zertifizierung zu planen.\n\nStudierende sollen ein Unternehmen auswÃ¤hlen, bei dem sie schon einmal gearbeitet haben, oder das sie gut kennen. Hier ein Beispiel.\n\nPrompt #3: Ich denke Ã¼ber Voss Automotive nach, die folgende Produkte herstellen: innovative Leitungs-und Verbindungssysteme, die Ã¼berall auf der Welt in Pkw und Nutzfahrzeugen sowie Land- und Baumaschinen eingesetzt werden. Unser Produktportfolio umfasst dabei einbaufertige Leitungsmodule mit Rohren, SchlÃ¤uchen, Verbindungselementen, Ventilen und Sensoren. Zur Verbindungstechnik gehÃ¶ren Stecksysteme, Verschraubungen, Mehrfachkupplungen und Verteiler.\nPrompt #4: Erstelle einen Zeitplan als Tabelle mit AufwandsschÃ¤tzungen fÃ¼r 3 Personen in 4 Wochen.\nPrompt #5: Mehr Details bitte: Erstelle Unteraufgaben fÃ¼r die jeweiligen Aufgabenpakete, jeweils auch wieder mit AufwandsschÃ¤tzungen.\n\nDie Studierenden sollen den Projektplan dann weiter verbessern und diskutieren. Erweiternd kÃ¶nnen sie auch z.B. Projektrisiken, Indikatoren und GegenmaÃŸnahmen und Szenarien erheben und diskutieren.",
    "crumbs": [
      "<span class='chapter-number'>5</span>Â  <span class='chapter-title'>Empfehlungen zur Umsetzung</span>"
    ]
  },
  {
    "objectID": "kapitel05.html#wie-prÃ¼fen-wir-jetzt-jenseits-der-homework-apocalypse",
    "href": "kapitel05.html#wie-prÃ¼fen-wir-jetzt-jenseits-der-homework-apocalypse",
    "title": "5Â  Empfehlungen zur Umsetzung",
    "section": "5.4 Wie prÃ¼fen wir jetzt? Jenseits der Homework Apocalypse",
    "text": "5.4 Wie prÃ¼fen wir jetzt? Jenseits der Homework Apocalypse\nJenseits der vielen produktiven Anwendungen besteht die Gefahr, dass Studierende wichtige Teile des Denkprozesses an Sprachmodelle delegieren (Lee et al., 2025). Klassische â€Hausaufgabenâ€œ wie Seminararbeiten, Gruppenprojekte und Abschlussarbeiten drohen entwertet zu werden. Ohne Anpassung der Aufgabenstellung werden die Aufgaben potenziell sinnlos, da Studierende etwa AufsÃ¤tze oder Reflexionsaufgaben einfach von Chat GPT schreiben und einreichen. Interviews mit Studierenden und Nutzungsstudien zeigen, dass diese Gefahr akut ist. Wie wir in der umfassenden empirische Nutzungsstudie von Handa et al. (2025-04-08, 2025) sehen, nutzen Studierende Sprachmodelle gerade zur SchreibunterstÃ¼tzung intensiv und hÃ¤ufig. Das New York Magazine betitelt eine aktuelle Recherche mit â€Everyone is cheating their way through collegeâ€, auf der Grundlage einer Vielzahl von Interviews mit desillusionierten Studierenden und Lehrenden (Walsh, 2025). Der o.g. Artikel der Fachzeitschrift Nature (s. Tabelle 4) skizziert ebenfalls basierend auf Interviews ein breites Spektrum an aktiver Nutzung im hÃ¶heren Bildungsbereich (Heidt, 2025).\nSchon 2023 kÃ¼ndigte der Wharton Professor Mollick die â€Homework Apocalypseâ€œ an (Mollick, 2023). Dabei geht es Mollick weniger um das Tricksen mit den neuen technischen MÃ¶glichkeiten (â€Cheating was already common in schoolsâ€œ), sondern mehr um die empfundene Sinnlosigkeit von klassischen Hausaufgaben. â€Students will want to understand why they are doing assignments that seem obsolete thanks to AI.â€œ. Wer gibt noch reine RechenÃ¼bungen auf, wenn alle Taschenrechner haben? Wie kann Eigen- und Fremdleistung unter diesen neuen technischen Bedingungen getrennt werden? Wie kÃ¶nnen auch jetzt noch Anreize fÃ¼r Studierende gesetzt werden, Texte noch selbst zu lesen und SÃ¤tze noch selbst zu formulieren?\n\n\n\n\n\n\nAbbildungÂ 5.1: Abbildung 15: Etwa gleichverteilt: Vier Arten der Interaktion von Studierenden mit Sprachmodellen. Quelle: Handa et al. (2025-04-08, 2025)\n\n\n\nEine Unterscheidung der empirischen Anthropic-Studie von Studierenden Interaktionen mit Sprachmodellen ist dabei hilfreich, um das Problem einzuordnen (Handa et al., 2025-04-08, 2025): Hier werden vier Arten von LLM-Nutzung unterschieden, je nachdem, ob ein Problem gelÃ¶st, oder ein Ergebnis generiert werden soll und je nachdem, ob dies direkt oder interaktiv erfolgt. Kollaborative Nutzungsformen (Typ 3 und 4) sind dabei fÃ¼r den Lernerfolg eher hilfreich, wÃ¤hrend das direkte Bereitstellen von ProblemlÃ¶sungen oder Texten aufgrund mangelnder BeschÃ¤ftigung der Studierenden mit den Problemen und Materialien fÃ¼r Hausarbeiten eher hinderlich sein kÃ¶nnte (anders als fÃ¼r die Vorbereitung von kontrollierten Tests wie Klausuren). Studierende werden so eher in eine passive Rolle gedrÃ¤ngt und es fehlen die erwÃ¼nschten Schwierigkeiten (desirable difficulties, (Roediger & Karpicke, 2006)), das fragebasierte Durchkauen und Hin- und HerÃ¼berlegen, das die Lernforschung als Wichtig fÃ¼r langfristiges Behalten ansieht (Roediger & Pyc, 2012).\nGrob gesagt wollen wir also kollaborative Interaktion und Hilfestellung fÃ¶rdern und einfaches Ãœbernehmen bereitgestellter LÃ¶sungen verhindern. Wie kÃ¶nnen wir dafÃ¼r die Hausarbeiten anpassen? Im Folgenden werden einige Empfehlungen zusammengefasst. Der Vier-SÃ¤ulen-Ansatz nach Gmeiner bietet Orientierung. Er unterscheidet vier GegenmaÃŸnahmen fÃ¼r das PrÃ¼fen unter KI-Bedingungen: MÃ¼ndlichkeit, Prozessorientierung, Kontextualisierung sowie Kollaboration (Gmeiner, 2025).\n\n\n\n\n\n\nAbbildungÂ 5.2: Abbildung 16: KI-resistente Aufgabenstellungen â€“ 4 SÃ¤ulen nach Gmeiner (2025)\n\n\n\n\n5.4.1 MÃ¼ndlichkeit\nMÃ¼ndlichkeit stÃ¤rkt VerstÃ¤ndnis, Transfer und Autorschaft. Disputation, PrÃ¤sentationen mit strukturiertem Q&A und gezielte Kolloquien machen eigene Entscheidungen sichtbar. So verlieren generische KI-Texte an Wert. LeitfÃ¤den empfehlen diese Formate ausdrÃ¼cklich als ErgÃ¤nzung zu schriftlichen Arbeiten. Detektionsscores dienen nicht als Beweis, sondern hÃ¶chstens als Anlass zur KlÃ¤rung (QAA, n.Â d.; Jisc, n.Â d.). Die University of Melbourne verweist auf skalierbare, mÃ¼ndliche Validierungen. Die folgende Ãœbersicht zeigt typische Formate der mÃ¼ndlichen PrÃ¼fung.\n\n\n\n\n\n\nAbbildungÂ 5.3: Abbildung 17: Vergleich mÃ¼ndlicher PrÃ¼fungsformen (Ward et al. (2024))\n\n\n\nHier sollen exemplarisch einzelne mÃ¼ndliche PrÃ¼fungsformate beschrieben werden, die Lehrende nutzen kÃ¶nnen.\nDas erste Format ist das Kurzkolloquium (â€Viva Voce Examâ€œ in der Abbildung). Ziel ist der Nachweis von VerstÃ¤ndnis und Autorschaft. Hier wird die schriftliche Arbeit vom Leistungsnachweis getrennt (Gmeiner, 2025) und die Lernenden mÃ¼ssen ihre Entscheidungen in der schriftlichen Arbeit erlÃ¤utern und verteidigen. Die Studierenden reichen ihre schriftliche Arbeit ein, die auch mit KI-UnterstÃ¼tzung erstellt werden darf und fÃ¼hren ein dann ein etwa zehnminÃ¼tiges GesprÃ¤ch Ã¼ber die Arbeit. Die PrÃ¼fenden wÃ¤hlen zum Beispiel zwei Kernentscheidungen zur weiteren ErlÃ¤uterung aus: Datenaufbereitung und Argumentation. Die Studierenden erklÃ¤ren Vorgehen, Alternativen und Grenzen. Es folgt ein kurzes Transfer-Szenario: â€Was wÃ¼rden Sie Ã¤ndern, wennâ€¦?â€œ Bewertet werden Klarheit, BegrÃ¼ndung, Umgang mit Unsicherheit und Konsistenz zur Schriftfassung. KI-Regeln: KI-Nutzung wird offengelegt; Antworten sind persÃ¶nlich und ohne Hilfsmittel. Skalierung gelingt mit standardisierten Leitfragen, DoppelprÃ¼fungen im Stichprobenprinzip und Aufzeichnung fÃ¼r Zweitbewertungen. Dieses Format eignet sich besonders fÃ¼r die PrÃ¼fung von Abschlussarbeiten und lÃ¤sst sich leicht auch auf Seminararbeiten Ã¼bertragen. Ã„hnlich wie auch fÃ¼r das folgende Format mÃ¼ssen hierfÃ¼r initial Bewertungsmatrizen erstellt werden, potentielle Herausforderungen sind situativer Stress und Aspekte von ValiditÃ¤t (Form vs.Â Inhalt, einfache vs.Â schwere Fragen, mÃ¼ndliche vs.Â schriftliche AusdrucksfÃ¤higkeit), ReliabilitÃ¤t (Rating-Unterschiede bei verschiedenen Nachfragen und Bewertenden, verschiedenen Szenarien usw.) und Fairness (z.B. SprachfÃ¤higkeiten, Vorwissen). Vorteile sind die ReaktivitÃ¤t und die MÃ¶glichkeit, durch vertiefende Nachfragen Hintergrundwissen und BegrÃ¼ndungen abzufragen (Akimov & Malin, 2020, S.31; Kearney, 2019).\nEin Ã¤hnliches Format, aber mit anderem Fokus ist die interaktive mÃ¼ndliche PrÃ¼fung (interactive oral assessment, IO). Hier erhalten die Studierenden ein praxisnahes Szenario, das sie in Interaktion mit den PrÃ¼fenden analysieren und bearbeiten mÃ¼ssen (Ward et al., 2024). Gestaltet werden IOs als offene, nicht im Detailablauf vorgegebene GesprÃ¤che in realitÃ¤tsnahen Szenarien, gefÃ¼hrt zwischen Studierenden und PrÃ¼fenden (oder zwischen Studierenden). So wird etwa gefordert, eine Situation oder eine Fallstudie mit Bezug auf das erlesene Vorwissen zu analysieren. Bewertet wird die Interaktion durch unterlegt durch prÃ¤zise Rubriken (die auch gemeinsam mit den Studierenden entwickelt werden kÃ¶nnen (NÃ­Â BheolÃ¡in et al., 2020)), Beispielaufnahmen zur Vorbereitung und formative Einbettung Ã¼ber das Semester. Beispiele fÃ¼r die Einbettung umfassen etwa, dass Studierende die Rolle von Interviewten in einer Talkshow einnehmen, oder im Duo ihre Erkenntnisse von einer Konferenzteilnahme erlÃ¤utern mÃ¼ssen. International wird diese PrÃ¼fungsform durchaus in sehr groÃŸen Kohorten eingesetzt, von Erstsemester-Kursen mit ca. 200 bis zu 800 Studierenden, mit 4 bis 10 PrÃ¼fenden (https://sway.cloud.microsoft/yQ2s0Bm3ILkWtGll). Es gibt eine Reihe detaillierter LeitfÃ¤den zur Umsetzung solcher Szenario-PrÃ¼fungen mit Aufnahmen von BeispielprÃ¼fungen und den Bewertungsrubriken (https://www.dcu.ie/sites/default/files/inline-files/interactive-oral-io-user-guide_0.pdf , siehe speziell die Ãœbersicht der Ressourcen auf S.11).\n\n\n\n\n\n\nAbbildungÂ 5.4: Abbildung 18: MÃ¼ndlich prÃ¼fen geht auch in groÃŸen Kohorten â€“ Beispiele von verschiedenen UniversitÃ¤ten\n\n\n\n\n\n\n\n\n\nAbbildungÂ 5.5: Abbildung 19: Drei Szenarien fÃ¼r eine mÃ¼ndliche PrÃ¼fung in PÃ¤dagogik\n\n\n\nEin drittes Format ist die PosterprÃ¤sentation mit strukturiertem Q&A. Die Studierenden erstellen ein Forschungs- oder Praxisposter und prÃ¤sentieren fÃ¼r fÃ¼nf Minuten. Danach folgen gezielte Fragen zu Methode, Evidenz und Limitationen. Artefakte sind Poster, ein einseitiges Handout und ein Frageprotokoll. Bewertet wird die EvidenzfÃ¼hrung, Passung von Methode und Frage sowie die QualitÃ¤t der Antworten. KI darf fÃ¼r Layout und Sprachpolitur helfen, nicht fÃ¼r Inhalt. Offenlegung ist Pflicht. GroÃŸe Gruppen lassen sich mit parallelen â€Poster-Sessionsâ€œ und festen Zeitslots prÃ¼fen.\nFÃ¼r Abschlussarbeiten kann diese Ausweitung der mÃ¼ndlichen PrÃ¼fungskomponente so operationalisiert werden, dass die Gewichtung des Kolloquiums erhÃ¶ht wird, bzw. ein zweites Kolloquium hinzugefÃ¼gt wird (um die Belastung der mÃ¼ndlichen PrÃ¼fung zu verteilen), in dem die Studierenden ca. 1 Monat nach dem Beginn der Abschlussarbeit mÃ¼ndlich den Stand der Forschung zum Thema darstellen und die ForschungslÃ¼cke begrÃ¼nden mÃ¼ssen. Ein aktueller Entwurf an der TH KÃ¶ln hierfÃ¼r sieht so aus: * Kolloquium 1: Stand der Forschung und resultierende Forschungsfragen (3 ECTS) * Schriftliche Arbeit (8 ECTS) * Kolloquium 2: Ergebnis der Abschlussarbeit (4 ECTS) (FrÃ¼her: Schriftliche Arbeit = 12 ECTS, Kolloquium = 3 ECTS).\n\n\n5.4.2 Prozessorientierung\nProzessorientierung rÃ¼ckt den Weg zum Ergebnis in den Mittelpunkt und liefert Ã¼ber die stÃ¤rkere Teilhabe der PrÃ¼fenden am Erstellungsprozess Evidenz fÃ¼r Autorschaft und verantwortliche KI-Nutzung. Insofern empfehlen die meisten Ratgeber, das Gewicht vom Produkt auf den Prozess zu verlagern. Ein Ratgeber der Melbourne University empfiehlt ausdrÃ¼cklich, â€vom Produkt zum Prozessâ€œ zu wechseln, Prozess-NotizbÃ¼cher und Reflexionen einzubauen und mit Umgebungen wie Cadmus digitale Prozess-Spuren zu erfassen (Mulder et al., 2023). Eine Studie von Hanover Research fordert gestaffelte Abgaben Ã¼ber die Zeit mit intensiver, iterativer RÃ¼ckmeldung und betont, dass die Sichtbarmachung individueller und kollaborativer Arbeitsprozesse KI-Nutzung unattraktiv macht (Hanover Research, 2024). Empfehlungen der Monash University konkretisieren dies: Prozessbewertungen, verbundene Aufgaben und Einbindung der PrÃ¼fenden in den Entstehungsprozess (Monash University, 2025). Gmeiner operationalisiert Prozessfokus zudem durch transparente KI-Nutzungsdokumentation mit Prompt-/Output-Belegen und reflektierter Einbettung in die Eigenleistung (Gmeiner, 2025).\n\n\n\n\n\n\nAbbildungÂ 5.6: Abbildung 20: Abhilfe durch Interaktion oder engere Prozessbetreuung: Aufgabentypen nach der Schwierigkeit, durch KI repliziert zu werden (Hanover Research (2024))\n\n\n\nEin zentrales Format ist das Prozessjournal mit Audit-Trail: Studierende dokumentieren Suche, Auswahl, Analyse, Entscheidungen und Revisionen fortlaufend; ein Versionsverlauf in Overleaf oder Git macht Ã„nderungen nachvollziehbar. Abgegeben werden Journal, Query-Protokolle, Daten-/Code-Paket und Endprodukt. Bewertet werden Nachvollziehbarkeit, QualitÃ¤t der Entscheidungen, Reproduzierbarkeit und eine reflektierte Darstellung der KI-Nutzung (Tool, Version, Prompts, Zweck, Umfang, Korrekturen). Detektoren entfallen; der dokumentierte Prozess bildet die Hauptgrundlage der Beurteilung.\nAls zweites Format bietet sich die gestaffelte Hausarbeit an: Outline, Annotated Bibliography, Methoden-Memo, Rohanalyse, Draft und Final werden Ã¼ber das Semester verteilt, jeweils mit Feedback und klar getrennten Prozess- und Produktpunkten in der Rubrik. KI kann bei Ideenfindung und Sprachpolitur helfen, nicht bei Theoriebildung oder Ergebnissen; Nutzung und kritische Einordnung sind offenzulegen. In groÃŸen Kohorten tragen Peer-Reviews nach Rubrik und stichprobenhafte Dozierenden-Checks zur Skalierung bei.\n\n\n5.4.3 Kontextualisierung und empirischer Bezug\nKontextualisierung und Empirie binden Leistung an reale Daten, Orte und Rollen und entwerten generische KI-Outputs. Die LeitfÃ¤den empfehlen realweltliche, lokal verankerte, persÃ¶nlich bezogene Aufgaben. Melbourne CSHE listet explizit â€authentische, kontextspezifische oder persÃ¶nlicheâ€œ Aufgaben â€“ etwa Analysen weniger bekannter lokaler Objekte, BezÃ¼ge zu persÃ¶nlicher Erfahrung oder Aufgaben, die genuine Berufsprodukte erzeugen (Mulder et al., 2023). Monash rÃ¤t, Essayaufgaben so zu verÃ¤ndern, dass personalisierte Anwendung und Kontextualisierung zwingend sind; auÃŸerdem werden multimodale Artefakte als KI-resistenter eingestuft (Monash University, 2025). Gmeiner prÃ¤zisiert diese Logik: biografisches Lernen, Aufgaben an auÃŸerschulischen Lernorten oder tagesaktuelle Kontexte machen die Aufgabe â€un-promptbarâ€œ, weil sie persÃ¶nliche, physische oder nicht-Ã¶ffentliche Informationen, sinnliche Beobachtung und Gegenwartsbezug erfordern (Gmeiner, 2025).\nSelbst erhobene Empirie zÃ¤hlt, reine Literaturstudien oder theoretische Ausarbeitungen sind zu vermeiden. Interviews, Prozessanalysen, der Bau eines Prototypen oder sonstige Erhebungen von PrimÃ¤rdaten verlangen, dass Studierende einen passenden Fall auswÃ¤hlen, Daten erheben oder kuratieren, diese methodengerecht analysieren und eine Entscheidungsvorlage erstellen. Abzugeben sind Datensatz, Methodenprotokoll, Analyse-Notebook und eine kurze Empfehlung; bewertet werden Kontextpassung, DatenqualitÃ¤t, methodische Angemessenheit und die TragfÃ¤higkeit der Handlungsempfehlung. KI darf strukturieren, nicht aber Evidenz ersetzen. Alternativ kÃ¶nnen Replikations- und Verifikationsaufgaben genutzt werden: Studierende replizieren eine verÃ¶ffentlichte Analyse, dokumentieren Abweichungen und prÃ¼fen Robustheit mit alternativen Spezifikationen. Artefakte sind ein vollstÃ¤ndiges Repro-Paket, ein Abweichungsprotokoll und ein Kurzbericht, der klar ausweist, was trÃ¤gt und was nicht. KI kann Code-Snippets vorschlagen, doch jede Zeile wird verstanden, kommentiert und getestet. Offenlegung der Tool-Nutzung bleibt Pflicht. Automatisierte Checks und prÃ¤zise Rubriken halten den Korrekturaufwand im Rahmen.\nFÃ¼r Abschlussarbeiten kann dies so operationalisiert werden, dass reine Literatur- oder Theoriearbeiten ohne empirischen Bezug vom PrÃ¼fungsausschuss zu genehmigen sind.\n\n\n5.4.4 Kollaboration und Kreation\nKollaboration und Kreation prÃ¼fen die soziale, evaluative und kreative Dimension des Lernens und machen Aushandlung und Revision sichtbar. Die LeitfÃ¤den schlagen in diesem Kontext etwa In-Class- und Gruppenaufgaben, Peer-/Selbstbeurteilung und gestufte Projekte vor. Melbourne CSHE zeigt in mehreren Fallbeispielen, wie verschachtelte Aufgaben mit Gruppen-Literaturarbeit, ProjektplÃ¤nen, Peer-Review und PrÃ¤sentationen kombiniert werden. Diese Designs stÃ¤rken Prozess-Transparenz, evaluative Urteilskraft und erschweren KI-Missbrauch (Mulder et al., 2023). Hanover Research betont Ã¤hnlich Gruppenarbeiten, In-Class-AktivitÃ¤ten und Aufgaben, die die Nutzung von KI explizit erlauben, aber kritisch auswerten lassen â€“ also Kreation plus Metareflexion (Hanover Research, 2024).\nWie kann so etwas aussehen? Ein peer-reviewtes Multimedia-Projekt etwa verlangt, dass kleine Teams ein konkretes Produkt â€“ Podcast, Video oder Infografik â€“ fÃ¼r ein definiertes Publikum erstellen. Der Prozess umfasst Briefing, Drehbuch, QuellenkurzprÃ¼fungen, Prototyp, Peer-Feedback und Finalisierung. Bewertet werden Evidenzbasis, Storyline, Zielgruppenpassung, FeedbackqualitÃ¤t und die Umsetzung der RÃ¼ckmeldungen; neben dem Produkt liefern Teams Quellenlisten, Peer-Feedback-Protokolle und individuelle Reflexionen. Alternativ kÃ¶nnen Rollen- oder Planspiele erstellt oder bearbeitet und reflektiert werden (Gmeiner, 2025). KI kann als Ideengeber dienen, doch Entscheidungen und Quellenhoheit verbleiben beim Team; kurze NachgesprÃ¤che sichern Autorschaft ab.\nAls Abschlussformat eignet sich ein Team-Capstone mit getrennter Team- und Individualnote: Das Team liefert ein belastbares Artefakt â€“ etwa einen Prototyp, eine Konzeptstudie oder einen Policy-Brief mit Daten â€“, wÃ¤hrend jede Person einen individuellen Methoden-Anhang und eine Reflexion zum eigenen Beitrag und zur KI-Nutzung abgibt. Bewertet werden Teamprodukt, individueller methodischer Beitrag und die QualitÃ¤t der Reflexion; klare KI-Regeln fordern Offenlegung, Bias-PrÃ¼fung und Quellenverifikation. Milestone-Boards, strukturierte Peer-Assessments und stichprobenhafte mÃ¼ndliche Abfrage pro Team sichern Skalierbarkeit und IntegritÃ¤t.\nKombiniert man die vier SÃ¤ulen, entsteht eine Vielzahl von Optionen fÃ¼r ein konsistentes, skalierbares PrÃ¼fungsdesign, das auf Transparenz, ProzessnÃ¤he und reale Anwendung setzt. MÃ¼ndliche Elemente sichern Autorschaft und Transfer, prozessorientierte Formate liefern nachvollziehbare Evidenz, kontextgebundene Aufgaben prÃ¼fen VerstÃ¤ndnis unter realen Bedingungen, und kollaborative Produkte stÃ¤rken Urteilskraft, Feedbackkultur und KreativitÃ¤t. Klare Richtlinien, Offenlegung und belastbare Rubriken tragen das Konstrukt. KI-Detektoren werden Ã¼berflÃ¼ssig, weil die Beweise im Prozess liegen und PrÃ¼fende enger an diesem Prozess teilnehmen und in den vorgestellten PrÃ¼fungsformen interaktiv nachfragen kÃ¶nnen. Dies alles aufzusetzen bedeutet durchaus hohe InitialaufwÃ¤nde und die neuen PrÃ¼fungsformen mÃ¼ssen evaluiert werden, um bekannte Probleme etwa des PrÃ¼fens in direkter Interaktion (ValiditÃ¤t, ReliabilitÃ¤t, Fairness, s.o.) einzudÃ¤mmen (Akimov & Malin, 2020). Positiv dabei: Es gibt schon viele Vorlagen, auf die man aufbauen kann und durch diese Anstrengungen bleiben IntegritÃ¤t und QualitÃ¤t der PrÃ¼fungen gewahrt â€“ die oben genannte Furcht vor Betrug und Sinnlosigkeit der PrÃ¼fungen wird eingedÃ¤mmt, ohne dass auf reines Klausurlernen zurÃ¼ckgefallen werden muss, wÃ¤hrend Studierende lernen, KI verantwortlich, nachvollziehbar und wirksam einzusetzen.",
    "crumbs": [
      "<span class='chapter-number'>5</span>Â  <span class='chapter-title'>Empfehlungen zur Umsetzung</span>"
    ]
  },
  {
    "objectID": "kapitel05.html#richtlinien-zur-ki-nutzung---welche-handreichungen-geben-hochschulen-und-was-wird-empfohlen",
    "href": "kapitel05.html#richtlinien-zur-ki-nutzung---welche-handreichungen-geben-hochschulen-und-was-wird-empfohlen",
    "title": "5Â  Empfehlungen zur Umsetzung",
    "section": "5.5 Richtlinien zur KI-Nutzung - welche Handreichungen geben Hochschulen und was wird empfohlen?",
    "text": "5.5 Richtlinien zur KI-Nutzung - welche Handreichungen geben Hochschulen und was wird empfohlen?\n\n5.5.1 Ãœbersicht: Was regeln aktuelle Richtlinien?\nWie reagieren Hochschulen auf die Chancen und Herausforderungen von LLM? Eine Ãœbersichtsstudie von An et al. (2025) untersucht die Richtlinien der Top 50 US Hochschulen zur Nutzung von LLM. Mittels Topic Modeling identifizieren sie vier zentrale Themenfelder: die Integration von LLM in Lehre und PrÃ¼fungen, die Nutzung in visuellen und interaktiven Medien, Fragen der Sicherheit und Ethik sowie die Wahrung akademischer IntegritÃ¤t. Die Sentimentanalyse zeigt eine insgesamt positive Haltung gegenÃ¼ber LLM, insbesondere in Richtlinien fÃ¼r Lehrende und Verwaltungspersonal. Studierendenrichtlinien sind hingegen zurÃ¼ckhaltender und stÃ¤rker auf EinschrÃ¤nkungen fokussiert. Die Analyse differenziert die Inhalte nach Zielgruppen: WÃ¤hrend Lehrende vor allem UnterstÃ¼tzung fÃ¼r Kursdesign und PrÃ¼fungsformate erhalten, stehen bei Studierenden Regelungen zur IntegritÃ¤t im Vordergrund. Forschende und Verwaltungspersonal werden bislang weniger berÃ¼cksichtigt, obwohl sie ebenfalls spezifische Herausforderungen und Potenziale im Umgang mit LLM aufweisen. Die Autor:innen empfehlen daher eine stÃ¤rkere Differenzierung und kontinuierliche Weiterentwicklung der Richtlinien, den Verzicht auf unzuverlÃ¤ssige Detektionstools sowie eine institutionenÃ¼bergreifende Reflexion Ã¼ber ethische, rechtliche und didaktische Implikationen.\nSpeziell deutsche Leitlinien an 27 Hochschulen untersuchte das Hochschulforum Digitalisierung im Jahr 2024 (Tobor, 2024), ein Update im Februar 2025 ergÃ¤nzt neuere Entwicklungen (Tobor, 2025). Die Analyse umfasst hochschulweiten Leitlinien deutscher UniversitÃ¤ten zum Umgang mit generativer KI. Dabei hebt Tobor eine Reihe bewÃ¤hrter Praktiken hervor, die sich in mehreren LeitfÃ¤den wiederfinden (FÃ¼r konkrete Beispiele siehe Appendix 2: Beispiele fÃ¼r KI-Richtlinien):\n\nEin zentrales Element ist die Anpassung der EigenstÃ¤ndigkeitserklÃ¤rung in schriftlichen PrÃ¼fungen ohne Aufsicht. Viele Hochschulen â€“ exemplarisch die Vorlage der Hochschule RheinMain â€“ fordern darin von Studierenden eine explizite ErklÃ¤rung, ob und in welcher Weise KI-Tools verwendet wurden. Diese ErklÃ¤rungen dienen der Transparenz und ermÃ¶glichen Lehrenden, KI-Nutzung regelkonform einzuordnen.\nIm Umgang mit VerdachtsfÃ¤llen unzulÃ¤ssiger KI-Nutzung betonen viele Leitlinien die Grenzen technischer Erkennung. Tools wie GPTZero gelten als unzuverlÃ¤ssig. Stattdessen wird â€“ wie im Leitfaden der UniversitÃ¤t Vechta â€“ ein multifaktorielles Vorgehen empfohlen, das Indikatoren wie nicht reale Quellen oder auffÃ¤llige Formulierungen einbezieht. BestÃ¤tigt sich der Verdacht, erfolgt ein KlÃ¤rungsgesprÃ¤ch, um das VerstÃ¤ndnis der Studierenden fÃ¼r ihre Arbeit zu Ã¼berprÃ¼fen.\nIm Bereich Urheberrecht wird festgehalten, dass KI-Systeme wie ChatGPT derzeit keine Urheber im juristischen Sinne sind. Ihre Inhalte stellen daher nicht automatisch ein Plagiat dar, kÃ¶nnen aber Rechte Dritter verletzen. Die Verantwortung fÃ¼r eine rechtskonforme Nutzung liegt bei den Studierenden â€“ klare gesetzliche Regelungen stehen noch aus.\nKritisch sehen viele Hochschulen die Verwendung von KI zur automatisierten Bewertung von PrÃ¼fungsleistungen. Diese widerspricht in der Regel PrÃ¼fungsordnungen, die eine begrÃ¼ndete Bewertung durch eine prÃ¼fende Person verlangen. Zudem wird das Hochladen studentischer Arbeiten in KI-Systeme als urheberrechtlich bedenklich eingestuft.\nSchlieÃŸlich fordern zahlreiche Leitlinien eine didaktische Weiterentwicklung von PrÃ¼fungsformaten. Empfehlungen reichen von stÃ¤rker reflexionsorientierten Aufgaben Ã¼ber Zwischenfeedback und methodische Transparenz bis hin zu ergÃ¤nzenden mÃ¼ndlichen PrÃ¼fungen. Ziel ist es, den Kompetenznachweis trotz verfÃ¼gbarer KI-Tools aussagekrÃ¤ftig zu gestalten. Dabei sollte auch der Umgang mit KI selbst â€“ inklusive Prompt-Gestaltung oder kritischer Reflexion â€“ zum PrÃ¼fungsgegenstand werden. Lehrende werden ermutigt, den Einsatz von KI gemeinsam mit den Studierenden zu reflektieren und klare Regeln im Kurs zu kommunizieren.\n\nIm Update von 2025 stellt Tobor auch kritisch die thematische Zersplitterung der verschiedenen Handreichungen fest: Die Richtlinien versuchen, eine Vielzahl von Einzelthemen fÃ¼r eine Vielzahl von Gruppen zu integrieren, speziell regulatorische und didaktische. Hinzu kommen Anforderungen zur RisikoaufklÃ¤rung Ã¼ber Themen wie Halluzinationen, Vorurteile von LLM in den Ergebnissen und Ressourcenverbrauch. Die europÃ¤ische KI-Verordnung (KI-VO) verschÃ¤rft die Anforderungen an Hochschulen, insbesondere im Hinblick auf KI-Kompetenzen und Risikoeinstufungen bei PrÃ¼fungen. Positiv werden integrierende Formate wie â€œLanding Pagesâ€œ genannt, etwa der KI-Hub der UniversitÃ¤t Vechta (https://www.uni-vechta.de/ki-hub). Ein solcher zentraler Startpunkt kann allgemeine und spezielle Themen verbinden und â€“ bei guter Kuratierung â€“ helfen, KomplexitÃ¤t zu reduzieren.\n\n\n5.5.2 Allgemeine Empfehlungen zu Richtlinien\nAn et al. (2025) plÃ¤dieren fÃ¼r ausgewogenere, zielgruppenspezifische Leitlinien, die sowohl regulatorische Klarheit als auch didaktische Impulse bieten â€“ insbesondere fÃ¼r Studierende, deren Perspektive bislang zu wenig berÃ¼cksichtigt wird. Was fÃ¼r didaktische und regulatorische Aspekte fÃ¼r Lehrende und Studierende werden hier festgelegt?\nFÃ¼r Lehrende stehen didaktische Empfehlungen im Vordergrund, die auf eine bewusste Integration generativer KI in die Hochschullehre zielen. In 94â€¯% der untersuchten Richtlinien werden konkrete Hinweise gegeben, wie LLM in Kursdesign, Aufgabenstellungen und PrÃ¼fungsformate eingebunden werden kann. Lehrende werden ermutigt, im Syllabus klar zu definieren, ob und wie der Einsatz von KI erlaubt ist â€“ etwa durch gestufte Erlaubnisformen (verboten, erlaubt mit Dokumentation, ausdrÃ¼cklich gewÃ¼nscht). Zudem wird empfohlen, PrÃ¼fungsformate so umzugestalten, dass sie weniger anfÃ¤llig fÃ¼r unreflektierte KI-Nutzung sind, z. B. durch individuelle Reflexionen, Gruppenarbeit oder mÃ¼ndliche Komponenten. Regulatorisch wird betont, dass die Verantwortung fÃ¼r die Formulierung und Durchsetzung dieser Regeln bei den Lehrenden liegt, jedoch unterstÃ¼tzt durch hochschulweite Orientierungshilfen. KI-Detektionstools wie Turnitin oder GPTZero werden hingegen kritisch gesehen: Viele Hochschulen raten von deren Einsatz ab, da ihre Ergebnisse unzuverlÃ¤ssig seien und leicht zu Fehlinterpretationen fÃ¼hren kÃ¶nnen.\nFÃ¼r Studierende betonen die Richtlinien vor allem regulatorische Aspekte im Sinne der akademischen IntegritÃ¤t. HÃ¤ufig wird darauf hingewiesen, dass LLM nicht uneingeschrÃ¤nkt eingesetzt werden darf, und dass ein nicht genehmigter Einsatz als TÃ¤uschungsversuch gewertet werden kann. Die Verantwortung zur KlÃ¤rung, ob LLM zulÃ¤ssig ist, wird den Studierenden zugeschrieben â€“ sie sollen aktiv RÃ¼cksprache mit Lehrenden halten. Didaktisch werden Studierende allerdings meist weniger unterstÃ¼tzt: Nur wenige Richtlinien bieten Anleitungen zur kompetenten Nutzung von LLM oder reflektieren Ã¼ber sinnvolle Lernstrategien im Umgang mit KI. Eine Ausnahme bilden vereinzelte Hinweise zur FÃ¶rderung von AI Literacy, etwa zur kritischen Bewertung von KI-generierten Texten oder zur Transparenzpflicht bei der Nutzung von LLM in Hausarbeiten. Insgesamt dominiert jedoch eine restriktive und kontrollierende Perspektive, die stÃ¤rker auf Vermeidung von Fehlverhalten als auf befÃ¤higende Lernangebote setzt.\nDie deutsche Untersuchung von Tobor (2025) betont, dass die Wirksamkeit solcher Leitlinien maÃŸgeblich davon abhÃ¤ngt, ob sie bekannt gemacht, kontinuierlich diskutiert und weiterentwickelt werden. Zentral ist es, die Leitlinien User-adÃ¤quat zu gestalten und bekannt zu machen. (Auch hier begegnen uns implizit wieder die zentralen Kategorien Nutzerfreundlichkeit und wahrgenommene NÃ¼tzlichkeit des Technology Acceptance Models.) Tobor warnt davor, Leitlinien als bloÃŸe Beruhigungsmittel zu betrachten, und fordert stattdessen eine dialogische, ko-kreative Weiterentwicklung â€“ etwa durch Beteiligung von Studierenden, verbundweite Zusammenarbeit und neue Formate wie Prompt-Battles. Leitlinien sollten als lebendige Rahmenwerke verstanden werden, die zur aktiven Gestaltung des KI-bedingten Wandels in Studium und Lehre beitragen.\nWie sehen solche Richtlinien aus? Konkrete Formulierungen und Links hierzu finden Sie im Appendix 2: Beispiele fÃ¼r KI-Richtlinien.",
    "crumbs": [
      "<span class='chapter-number'>5</span>Â  <span class='chapter-title'>Empfehlungen zur Umsetzung</span>"
    ]
  },
  {
    "objectID": "kapitel05.html#wie-kÃ¶nnen-studierende-die-nutzung-von-llm-dokumentieren-stichworte-nach-arbeitsphase-nach-werkzeug-oder-als-reflexionstagebuch",
    "href": "kapitel05.html#wie-kÃ¶nnen-studierende-die-nutzung-von-llm-dokumentieren-stichworte-nach-arbeitsphase-nach-werkzeug-oder-als-reflexionstagebuch",
    "title": "5Â  Empfehlungen zur Umsetzung",
    "section": "5.6 Wie kÃ¶nnen Studierende die Nutzung von LLM dokumentieren? Stichworte, nach Arbeitsphase, nach Werkzeug oder als Reflexionstagebuch",
    "text": "5.6 Wie kÃ¶nnen Studierende die Nutzung von LLM dokumentieren? Stichworte, nach Arbeitsphase, nach Werkzeug oder als Reflexionstagebuch\nFrÃ¼he Handreichungen zur Dokumentation von LLM in Studierendenarbeiten waren noch sehr allgemein formuliert und bestanden etwa darauf, dass jegliche Nutzung im Schreibprozess genau protokolliert wÃ¼rde. Bei tÃ¤glicher und stark integrierter Nutzung ist das etwa so sinnvoll, wie die Forderung, jegliche Internetnutzung in einem Tagebuch zu erfassen. Sinnlose Forderungen fÃ¼hren schnell dazu, dass die dahinter stehende Forderung nach prinzipieller Nachvollziehbarkeit des Forschungsvorgehens entwertet und Umgehungshandlungen normalisiert werden.\nNeuere Empfehlungen der Hochschulen sind hier deutlich realistischer: So bietet etwa eine Handreichung von niedersÃ¤chsischen Hochschulen eine gute Reihe von Optionen, die von einer einfachen Stichpunktliste (â€elicit.com zur Literaturrecherche, perplexity.ai zur Internetrecherche, gamma.app zur PrÃ¤sentationserstellung, stablediffusionweb.com zur Bildgenerationâ€œ) bis zu detaillierten TagebÃ¼chern mit Reflexionshilfen reicht (Baresel et al., 2024).\nIm Folgenden zeigen wir drei weitere Beispiele fÃ¼r Dokumentationen nach Arbeitsphasen, nach Werkzeugen und in Form eines Reflexionstagebuches (Baresel et al., 2024).\nDie Dokumentation nach Arbeitsphasen (s. Tabelle 8) zielt auf eine strukturierte Erfassung des KI-Einsatzes entlang typischer wissenschaftlicher Arbeitsphasen (z.â€¯B. Themenfindung, Recherche, Schreiben). Studierende bewerten selbst den Grad der KI-Nutzung (von â€inspirierendâ€œ bis â€inhaltsgestaltendâ€œ) und dokumentieren Tool, Einsatzkontext und Wirkung. Ziel ist Transparenz Ã¼ber den konkreten Einfluss auf das Ergebnis.\nBei der werkzeugorientierten Dokumentation (s. Tabelle 9) werden in tabellarischer Form die verwendeten Tools (z.â€¯B. ChatGPT, DeepL Write) samt Quelle, Zweck, Funktion und Einsatzbereich gelistet. Diese Variante erleichtert die Nachvollziehbarkeit, gibt aber wenig Einblick in den Kontext oder den Einfluss der Tools auf den Arbeitsprozess.\nBeim Reflexionstagebuch (s. Tabelle 10) steht die kontinuierliche, persÃ¶nliche Auseinandersetzung mit dem eigenen KI-Einsatz im Vordergrund. Studierende fÃ¼hren wÃ¤hrend des Arbeitsprozesses ein Tagebuch, das spÃ¤ter in eine prÃ¼fungsrelevante Dokumentation Ã¼berfÃ¼hrt wird. Diese Methode fÃ¶rdert den Aufbau von KI-Literacy und metakognitiver Kompetenz, ist jedoch zeitaufwÃ¤ndig und betreuungsintensiv.\n\n\n\nTabelleÂ 5.1: Tabelle 8: Beispiel arbeitsphasenorientierte Dokumentation der LLM Nutzung. Quelle: (Baresel et al. (2024), S. 11)\n\n\n\n\n\n\n\n\n\n\nPhase im Arbeitsprozess\nDokumentation: Eingesetzte Tools, Verwendungszweck, Funktionsweise, Ergebnis\nGrad der KI-Nutzung\n\n\n\n\nIdeenfindung/Strukturierung\nTools: ChatGPT, PerplexityZweck: Brainstorming zu Forschungsfragen, GliederungsideenErgebnis: 5 ThemenvorschlÃ¤ge, davon 1 weiterverfolgt\n1\n\n\nRecherche\nTools: Elicit, Semantic ScholarZweck: Suche nach passender LiteraturErgebnis: Liste mit 15 Quellen, 8 davon verwendet\n2\n\n\nSchreiben/Formulieren\nTools: DeepL WriteZweck: Verbesserung des sprachlichen AusdrucksErgebnis: Ãœberarbeitete Einleitung\n3\n\n\nÃœberarbeitung/Korrektur\nTools: GrammarlyZweck: PrÃ¼fung auf Grammatik- und RechtschreibfehlerErgebnis: Fehlerfreier Text\n2\n\n\n\n\n\n\n\n\n\nTabelleÂ 5.2: Tabelle 9: Beispiel werkzeugorientierte Dokumentation der LLM Nutzung. Quelle: (Baresel et al. (2024), S. 8)\n\n\n\n\n\n\n\n\n\n\n\n\nSoftware/Programm/KI-Anwendung\nLink/Quelle\nVerwendungszweck\nGenutzte Funktion\nNutzungsbeschreibung/Anwendungsbereich\n\n\n\n\nappypie\nhttps://www.appypie.com/design/de/infografik/ersteller\nInfografiken zur ErlÃ¤uterung\nEntspricht Verwendungszweck\nInfografik fÃ¼r einen Ãœberblick in der Einleitung, S. 3\n\n\nClaude\nhttps://claude.ai/new\nAssistenz zur Programmierung, VorschlÃ¤ge fÃ¼r Gliederung\nChat und Code-Ausgabe\nProgrammierung des Auswertungsprogramms, siehe S.13 Erstaufschlag der Gliederung, wurde Ã¼berarbeitet\n\n\nDeepL Write\nhttps://www.deepl.com/de/write\nÃœberarbeiten der Texte\nEntspricht Verwendungszweck\nGesamter Text\n\n\nDeepL Ãœbersetzer\nhttps://www.deepl.com/de/translator\nÃœbersetzung von franzÃ¶sischsprachigen Papers\nÃœbersetzung FranzÃ¶sischâ€“Deutsch\nDie Paper Lacroix, 2007 & Macron, 2020 wurden Ã¼bersetzt.\n\n\nKiCadÂ²\nhttps://www.kicad.org/\nLayout der Testplatine\nPCB Layout\nLayout der Platine, siehe Abb. 15 S. 20\n\n\nMATLab\nHochschullizenz\nSimulation der EmpfÃ¤ngerschaltung\nSimulink\nSchaltung xyz auf S. 14 simuliert und optimiert\n\n\nMaxQDA\nHochschullizenz\nAuswertung Interviews\nMaxQDA und AI Assist\nKategorienbildung, siehe Kap 4.2 und Anhang C\n\n\nOpenknowledgemap\nhttps://openknowledgemaps.org/\nRecherche des Forschungsfelds\nEntspricht Verwendungszweck\nFÃ¼r die Einarbeitung wurde mit diesem Tool der Zugang zum Forschungsfeld erschlossen.\n\n\nSPSS\nHochschullizenz\nAuswertung Daten zur Gesundheitsversorgung\nHypothesentest mittels xy\nDatenauswertung siehe S. 15 und Anhang S. 77\n\n\nVisual Studio C++\nHochschullizenz\nProgrammierung einer NavigationslÃ¶sung\nEntspricht Verwendungszweck\nProgrammierung des zentralen Programms der Arbeit, siehe Kap. 4\n\n\nWhisper (openAI)\nhttps://openai.com/index/whisper/\nTranskribieren von Interviews\nTranskribieren ohne Ãœbersetzung\nTranskribieren der Interviews, wurden korrigierend Ã¼berarbeitet. Siehe Anhang B\n\n\n\n\n\n\n\n\n\nTabelleÂ 5.3: Tabelle 10: Beispiel Reflexionstagebuch zur LLM Nutzung. Quelle: (Baresel et al. (2024), S. 16)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDatum\nWoran habe ich gearbeitet? (Stichpunkte)\nWelche digitalen Tools habe ich verwendet?\nNotizen zum Einsatz digitaler Tools\nReflexion\nBeleg/Beispiel\nGrad der Nutzung\n\n\n\n\n1.9.24\nThemenfindung\nChatGPT 3.5 Ã¼ber Academic Cloud\nVersuch, einige Begriffe zu schÃ¤rfenFragestellungen vorschlagen lassen\nHilfreich, um Fachbegriffe zu identifizierenAus den Begriffen mal Fragestellungen machen lassen. Das traf es aber nicht wirklich. Ich muss noch weitermachen.\n\n12\n\n\n2.9.24\nTexte lesen\nChatPDF\n2 Texte hochgeladen, geprÃ¼ft, ob relevant\nToll, dass ich deutsch fragen kann, auch wenn der Text englisch/italienisch ist. Entlastet! Macht das Lesen gezielter. Merke aber auch, dass ich dann den Text nicht mehr ganz lese.\n\n2\n\n\n5.9.24\nBild generieren\nbing.com/create\nIllustration fÃ¼r die PrÃ¤sentation zum Projekt\nMacht SpaÃŸ! Ist aber auch aufwÃ¤ndig, genau das zu prompten, was man haben will. Zeitfresser.\nDenken findet in der Auseinandersetzung von Mensch mit Maschine statt; KÃ¼nstliche Intelligenz ist ein Partner des Menschen beim Denken. Helle, motivierende Farben = 07_Denken-externalisiert_Utopie_01.jpeg\n4\n\n\n10.9.24\nText bearbeiten\nChatGPT 4.0 Ã¼ber Academic Cloud\nFormulierungsalternativen gesucht\nUnentschieden. Manches klingt gut, aber irgendwie auch nicht. WeiÃŸ nicht so recht, was ich davon halten soll.\n24-09-10_Chat-Verlauf.docx\n3",
    "crumbs": [
      "<span class='chapter-number'>5</span>Â  <span class='chapter-title'>Empfehlungen zur Umsetzung</span>"
    ]
  },
  {
    "objectID": "kapitel05.html#beispiele-fÃ¼r-die-kurs-integration-von-ki",
    "href": "kapitel05.html#beispiele-fÃ¼r-die-kurs-integration-von-ki",
    "title": "5Â  Empfehlungen zur Umsetzung",
    "section": "5.7 Beispiele fÃ¼r die Kurs-Integration von KI",
    "text": "5.7 Beispiele fÃ¼r die Kurs-Integration von KI\nAbschlieÃŸend wollen wir uns Beispiele ansehen, wie ein Kurs aussehen kÃ¶nnte, der mit LLM in der Vorbereitung arbeitet und sie in Ãœbungsaufgaben und die PrÃ¼fungsvorbereitung einbindet. Anmerkung: Hier wird nur die KI-ErgÃ¤nzung beschrieben, natÃ¼rlich werden auÃŸerdem LehrbÃ¼cher und Fachartikel als Input genutzt.\nZeitliche Struktur und Inhalte (Fokus auf den Einsatz von KI-Tools)\nWoche 1â€“4: Vorbereitung und KI-gestÃ¼tzte Materialerstellung (KI als â€Hiwiâ€œ) * Kursvorbereitung mit LLM: Erstellung und Anpassung vielfÃ¤ltiger Programmieraufgaben an unterschiedliche Lernniveaus mithilfe von Large Language Models. * DeepResearch: UnterstÃ¼tzung bei der Recherche aktueller Trends in der Programmierdidaktik und relevanter Beispiele, um realitÃ¤tsnahe Aufgabenstellungen zu entwickeln. * NotebookLM fÃ¼r Podcast-Episoden: Aus den erstellten Materialien werden mithilfe von NotebookLM kurze Podcast-Folgen generiert, die Studierende zur EinfÃ¼hrung in die Kursstruktur, grundlegende Programmierkonzepte und organisatorische Aspekte anhÃ¶ren kÃ¶nnen. Dies dient als motivierende, niederschwellige Form der Wissensvermittlung.\nWoche 5â€“8: Vertiefung und individuelle Lernwege (KI als â€Copilotâ€œ) * Individuelle Programmieraufgaben: Die Studierenden nutzen Google Colab oder ein Ã¤hnliches Tool, das KI-unterstÃ¼tzte Programmierung erlaubt (z.B. DeepNote). Sie lÃ¶sen damit gleich am Anfang Anwendungsaufgaben und mÃ¼ssen die Code-Bestandteile in der PrÃ¤senzzeit anderen Gruppen erklÃ¤ren. Die Ãœbungsaufgaben werden fortlaufend angepasst, indem die Lehrenden zusammen mit einem LLM bestehende Aufgaben je nach Lernfortschritt der Studierenden variieren (z.B. mehr Code-KomplexitÃ¤t oder zusÃ¤tzliche AnwendungsfÃ¤lle). * Voice Mode fÃ¼r Simulationen: Interaktive Rollenspiele bzw. Simulationen (z.B. â€Debugging-Dialogâ€œ) mit einem KI-Avatar in Voice Mode. Die Studierenden kÃ¶nnen live Fragen stellen, sich LÃ¶sungswege erklÃ¤ren lassen oder sich ein Code-Review im GesprÃ¤chsformat geben lassen. * DeepResearch: Zur Vertiefung konkreter Themen (z.B. Algorithmendesign, Datenstrukturen) recherchieren die Studierenden mithilfe von DeepResearch in Fachartikeln, Blogposts und Dokumentationen. Sie lernen, verschiedene Quellen kritisch zu bewerten und fÃ¼r ihr Projekt nutzbar zu machen.\nWoche 9â€“12: Konsolidierung und PrÃ¼fungsvorbereitung (KI als â€Lernhilfeâ€œ) * NotebookLM zur Zusammenfassung: Aus den im Kurs genutzten Lernmaterialien (Skripte, Forumsdiskussionen, Beispielcode) generiert NotebookLM automatisiert Zusammenfassungen und kurze Podcasts zu SchlÃ¼sselkonzepten. Studierende kÃ¶nnen diese unterwegs anhÃ¶ren oder gezielt zur PrÃ¼fungsvorbereitung nutzen. * LLM fÃ¼r Ãœbungsfragen: Auf Grundlage der bisherigen Lernfortschritte generiert das LLM individuelle Ãœbungsfragen sowie Quizformate zur SelbstÃ¼berprÃ¼fung. * Voice Mode fÃ¼r PrÃ¼fungssimulation: Studierende simulieren mÃ¼ndliche PrÃ¼fungssituationen oder Code-ErklÃ¤rungen Ã¼ber Voice Mode. Dies fÃ¶rdert die FÃ¤higkeit, Inhalte klar und strukturiert zu prÃ¤sentieren.\n\n5.7.1 Beispielkurs 2: ErgÃ¤nzung eines Kurses Interkulturelles Management durch KI-UnterstÃ¼tzung\nWoche 1â€“4: KI als â€Hiwiâ€œ * Ziel: Erstellung vielfÃ¤ltiger, kulturell spezifischer Fallstudien und Szenarien, die als Diskussions- und Analysegrundlage dienen. * LLM fÃ¼r Fallstudien & Szenarien: Die Lehrenden nutzen LLM (z.B. ChatGPT oder andere) zur Generierung von Fallstudien, die spezifische interkulturelle Kontexte beleuchten (z.B. Verhandlungen in ostasiatischen vs.Â europÃ¤ischen Kulturen, FÃ¼hrungsstile in verschiedenen Regionen etc.). * GegenmaÃŸnahme zur QualitÃ¤tssicherung: Die Ergebnisse werden stichprobenartig auf Richtigkeit, kulturelle SensibilitÃ¤t und Relevanz Ã¼berprÃ¼ft. * DeepResearch zur Materialrecherche: Lehrende recherchieren mithilfe von DeepResearch nach relevanter Literatur, neuesten Studien und Praxisberichten im Bereich interkulturelles Management. Die gefundenen Quellen flieÃŸen ein in vorbereitende Leselisten und Hintergrundinformationen fÃ¼r die Studierenden. * NotebookLM fÃ¼r Podcast-Folgen: FÃ¼r einen motivierenden Einstieg ins Thema werden kurze Podcasts (ca. 5â€“10 Minuten) mithilfe von NotebookLM erstellt. Themen kÃ¶nnten sein: â€EinfÃ¼hrung in kulturelle Dimensionenâ€œ (bspw. nach Hofstede), â€Erfolgsbeispiele im interkulturellen Managementâ€œ, â€Warum interkulturelle Kompetenz immer wichtiger wirdâ€œ. Studierende kÃ¶nnen diese Podcasts vor oder nach den PrÃ¤senz- bzw. Online-Sitzungen anhÃ¶ren, um zentrale Konzepte zu festigen.\nWoche 5â€“8: KI als â€Copilotâ€œ fÃ¼r Anwendungsaufgaben * Ziel: Entwicklung praxisnaher Simulationen, Rollenspiele und FallÃ¼bungen, um die Studierenden fÃ¼r reale interkulturelle Managementkonflikte zu sensibilisieren. * LLMs fÃ¼r Rollenspiel- und Simulationsszenarien: Studierende entwickeln in Kleingruppen Szenarien (z.B. Konflikte in multikulturellen Teams, Verhandlungen in internationalen Projekten), wobei sie LLM nutzen, um die Settings, Dialoge oder Konfliktpunkte zu konkretisieren. Lehrende moderieren den Prozess und Ã¼berprÃ¼fen die PlausibilitÃ¤t, sodass sichergestellt wird, dass kulturelle Nuancen realitÃ¤tsnah abgebildet werden. * ZusÃ¤tzlicher Einsatz: Chinesische OpenSource-Sprachmodelle wie â€DeepSeekâ€œ und japanische Sprachmodelle wie â€Sakanaâ€œ werden gezielt eingesetzt, um denselben Input zu unterschiedlichen interkulturellen Situationen zu liefern. Ziel: Die Lehrenden vergleichen die Outputs in Bezug auf die verwendeten Beispiele, die Fokussierung auf kulturelle Werte (z.B. Kollektivismus, Hierarchie, Entscheidungsfindung) und die TonalitÃ¤t der Texte. Daraus entstehen potenziell Fallstudien mit Abweichungen, die im Kurs aktiv diskutiert werden. * Voice Mode fÃ¼r interaktive Simulationen: Mithilfe von Voice Mode kÃ¶nnen die Studierenden verschiedene â€Akteureâ€œ in einem simulierten interkulturellen GesprÃ¤ch Ã¼bernehmen. Beispielsweise kÃ¶nnte ein Studierender die Rolle eines japanischen Managers Ã¼bernehmen, der mit einem franzÃ¶sischen CEO verhandelt â€“ unterstÃ¼tzt und angeleitet durch das KI-gestÃ¼tzte Voice Mode. Diese Live-Simulationen fÃ¶rdern besonders die Aussprache, interkulturelle Kommunikation und nonverbale Signale (sofern Video/Audio-Komponenten integriert sind). * DeepResearch fÃ¼r ProblemlÃ¶sungsvorschlÃ¤ge: Nach durchgefÃ¼hrten Simulationen nutzen die Studierenden DeepResearch, um Best Practices, wissenschaftliche Artikel und Fallbeispiele zu finden, die Ã¤hnliche interkulturelle Herausforderungen beschreiben. Auf dieser Basis erstellen sie Handlungsempfehlungen fÃ¼r die KonfliktlÃ¶sung. Die Lehrenden geben Feedback, um die studierendenzentrierte Reflexion zu stÃ¤rken.\nWoche 9â€“12: KI als â€Lernhilfeâ€œ * Ziel: Effektive PrÃ¼fungsvorbereitung, Vertiefung und Wiederholung zentraler Inhalte im interkulturellen Management. * LLMs fÃ¼r Zusammenfassungen und Wiederholungsfragen: Studierende lassen sich von Sprachmodellen kurze Zusammenfassungen zentraler Konzepte erstellen (z.B. kulturelle Dimensionen nach Hofstede, Schein, Trompenaars). Die LLMs generieren auf Basis des bisherigen Kursverlaufs zusÃ¤tzlich Quiz-Fragen oder Kurzantwortaufgaben, um das VerstÃ¤ndnis zu Ã¼berprÃ¼fen. * GegenmaÃŸnahme zur QualitÃ¤tssicherung: Die Lehrenden behalten die Kontrolle Ã¼ber die Endversion der Fragen, um unsinnige oder unpassende Aufgaben zu erkennen und zu eliminieren. * NotebookLM fÃ¼r Audio-Lerninhalte: Aus bereits vorhandenen Materialien (Skripte, Diskussionsergebnisse, Fallstudien) generiert NotebookLM weitere Podcast-Folgen, in denen SchlÃ¼sselkonzepte erlÃ¤utert oder wiederholt werden. Studierende kÃ¶nnen diese Folgen gezielt zur PrÃ¼fungsvorbereitung nutzen und dadurch Zeit- und OrtsunabhÃ¤ngigkeit beim Lernen erlangen. * Voice Mode fÃ¼r PrÃ¼fungssimulationen: Studierende Ã¼ben z.B. mÃ¼ndliche PrÃ¼fungen oder PrÃ¤sentationen im interkulturellen Kontext. Sie kÃ¶nnen sich von Voice Mode Fragen stellen lassen (â€Wie wÃ¼rden Sie in Situation X reagieren?â€œ) und ihre Antwort direkt in einer realistischen Simulation Ã¼ben. Dies fÃ¶rdert die rhetorische Sicherheit sowie das spontane Reagieren auf unvorhergesehene Fragen.\n\n\n5.7.2 Vorteile und Chancen der ErgÃ¤nzung der Lehrmaterialien durch KI\n\nRealitÃ¤tsnahe Lernsituationen: Durch Voice Mode-Simulationen und DeepResearch-gestÃ¼tzte Recherche wirken die Szenarien authentisch und praxisrelevant. Studierende lernen, ihre kulturelle SensibilitÃ¤t in unterschiedlichen Rollen aktiv zu trainieren.\nZeit- und Ressourcenersparnis: Lehrende profitieren von teilautomatisierten Prozessen (z.B. Erstellung von Fallstudien, Zusammenfassungen, Podcasts). Studierende haben jederzeit Zugriff auf zusÃ¤tzliche Lernressourcen wie Podcasts oder interaktive Ãœbungen.\nAdaptives Lernen und DiversitÃ¤t: LLMs und DeepResearch ermÃ¶glichen personalisierte Aufgabenstellungen und themenspezifische Vertiefungen. Kulturelle DiversitÃ¤t kann in den generierten Szenarien leichter abgebildet werden, indem verschiedene Regionen und Blickwinkel integriert werden.\n\n\n\n5.7.3 Risiken und GegenmaÃŸnahmen\n\nQualitÃ¤t und kulturelle SensibilitÃ¤t: GegenmaÃŸnahme: Lehrende prÃ¼fen alle generierten Inhalte (Text, Podcasts, Simulationen) auf kulturelle Stereotype und potenzielle Fehlinformationen. Durch Peer-Review unter Studierenden werden Vorurteile oder unangemessene Darstellung frÃ¼h erkannt.\nVertrauenswÃ¼rdigkeit und akademische Redlichkeit: GegenmaÃŸnahme: Studierende werden darin geschult, die KI-generierten Inhalte kritisch zu hinterfragen und zu validieren. Sie mÃ¼ssen Quellen nennen und sachlich begrÃ¼nden, wie und warum sie bestimmte KI-Ausgaben nutzen.\nDatenschutz und ethische Aspekte: GegenmaÃŸnahme: Sensible Informationen werden anonymisiert, Zugriffsrechte klar geregelt. Studierende erhalten eine EinfÃ¼hrung, wie sie KI-Tools sicher und verantwortungsbewusst einsetzen.\nTechnische AbhÃ¤ngigkeit: GegenmaÃŸnahme: Lehrmaterialien sind zusÃ¤tzlich offline verfÃ¼gbar (Skripte, Reader). Auch ohne KI-Tools kann der Kurs fortgesetzt werden.",
    "crumbs": [
      "<span class='chapter-number'>5</span>Â  <span class='chapter-title'>Empfehlungen zur Umsetzung</span>"
    ]
  },
  {
    "objectID": "kapitel05.html#wie-bleiben-sie-informiert",
    "href": "kapitel05.html#wie-bleiben-sie-informiert",
    "title": "5Â  Empfehlungen zur Umsetzung",
    "section": "5.8 Wie bleiben Sie informiert?",
    "text": "5.8 Wie bleiben Sie informiert?\nBei einem solch aktuellen Thema helfen gute Sammelstellen fÃ¼r Information, um auf dem Laufenden zu bleiben. AbschlieÃŸend einige Empfehlungen fÃ¼r gute Informationsquellen zum Thema Generative KI:\n\nNewsletter / Substack von Ethan Mollick der Wharton Business School mit sehr praktischen Ãœbersichten und Empfehlungen: https://www.oneusefulthing.org/. Abonnieren Sie ihn, es lohnt sich.\nHochschulforum Digitalisierung: Themendossier Generative KI: https://hochschulforumdigitalisierung.de/dossier/generative-ki/\nE-Teaching.org: KI in Studium und Lehre: https://www.e-teaching.org/praxis/themenseiten/ki-in-studium-und-lehre\nEine groÃŸe Anzahl an sehr guten didaktischen Prompts vom Team der Wharton Business School findet sich hier: https://www.moreusefulthings.com/prompts. Hervorzuheben sind v.a. die â€Blueprintsâ€œ, also Vorlagen, die fÃ¼r die eigene Lehre angepasst werden kÃ¶nnen (s.u. fÃ¼r zwei Beispiele).\nDie UniversitÃ¤t Harvard gibt hier eine Reihe von Beispielen, wie GenAI in der Lehre genutzt wird, u.a. mit Beispielen fÃ¼r Simulationen, Sprachdidaktik u.v.m.: https://bokcenter.harvard.edu/examples-and-ideas-for-using-AI-for-your-teaching.\nEtwas breiter â€“ wie nutzen 76.000 Lehrende KI an Hochschulen? Die KI-Firma Anthropic hat gerade einen Bericht herausgebracht, der anonymisiert basierend auf echten Interaktionen betrachtet, wie KI in der Lehre genutzt wird: https://www.anthropic.com/news/anthropic-education-report-how-educators-use-claude (Bent et al., 2025-08-26, 2025). Im Kontext von Rollenspielen ist hier interessant, wie die Online-Interaktion des GPT-Konkurrenten genutzt werden (â€Claude Artifactsâ€œ), speziell fÃ¼r â€Interactive Educational Gamesâ€œ.\nFortbildungen und Ãœbersichten mit Anwendungsfokus: Sowohl Google als auch Claude und OpenAI bieten Kurse fÃ¼r die technischen Aspekte der Nutzung von KI in der Lehre an: https://grow.google/ai-for-educators/, https://anthropic.skilljar.com/ai-fluency-framework-foundations.",
    "crumbs": [
      "<span class='chapter-number'>5</span>Â  <span class='chapter-title'>Empfehlungen zur Umsetzung</span>"
    ]
  }
]