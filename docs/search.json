[
  {
    "objectID": "kapitel01.html",
    "href": "kapitel01.html",
    "title": "1  Einleitung",
    "section": "",
    "text": "1.1 KI als Hilfe für die Lehre\nWie kann uns generative künstliche Intelligenz (KI) in der Lehre helfen? Hoffnung besteht hier für zwei typische Probleme: Erstens haben Studierende individuelle Bedürfnisse, aber wir haben nur begrenzte Zeit, auf diese einzugehen. Wie können wir Einzelne möglichst intensiv fördern, ohne vor Arbeit unterzugehen? Zweitens ist der Aufwand gerade für effektive Lehrmethoden oft sehr hoch, so etwa für häufige niedrigschwellige Tests, oder individuelles Feedback zu Studienarbeiten (Brown, Roediger, et al., 2014; s. etwa Hattie, 2023, Kap.13). Wer lehrt, fühlt sich aus Zeit- und Stoffdruck oft gezwungen, Abstriche von idealen Lehrsetups zu machen (Henderson & Dancy, 2007; Schmidt & Tippelt, 2005, S.104–105). Gerade Lehrmethoden, die didaktisch sinnvoll, aber mit hohem Aufwand verbunden sind, drohen dabei auf der Strecke zu bleiben (Brown, Roediger III, et al., 2014).\nFür die Lehre erschließen sich durch die großen KI-Sprachmodelle (LLM = Large Language Models) neue Möglichkeiten. Sie sind, wie es eine Analyse des MIT Professors Andrew McAfee auf den Punkt bringt „generally faster” (McAfee, 2024). Lehrende können mit KI-Unterstützung etwa deutlich schneller ein Set von Übungsaufgaben erstellen, mehrere Anwendungsbeispiele pro Konzept hinzufügen, Quizfragen zur schnellen Lernüberprüfung generieren, oder mit den Studierenden Rollenspiele durchführen (Meincke et al., 2024; E. Mollick & Mollick, 2023). Der Berg ist noch da, aber mit dem E-Bike kommt man weiter.\nImmer mehr Aspekte von typischen Forschungstätigkeiten – ein zentraler Ausbildungsinhalt der Hochschulen – können von der KI übernommen werden und zwar auf hohem Niveau. Vorbei sind die Zeiten, in denen wir die banalen Schreibprodukte der KI nur belächeln konnten. Ein Überblicksartikel des Forschers Anton Korinek im renommierten Journal of Economic Literature vom Dezember 2024 fasst das deutlich höhere Niveau zusammen: „die derzeitige Generation von LLMs ist in hohem Maße in der Lage, die wichtigsten Erkenntnisse von Forschungsarbeiten zu verarbeiten” (Korinek, 2024-12 (update), S.3, Übersetzung RB mit DeepL). Die professionelle Nutzung ist hier noch weiter: So demonstrierte etwa Google 2025 ein mehrstufiges Modell für die Pharma-Forschung („AI co-scientist”), das den Forschenden zeitintensive Zwischenschritte abnimmt (Gottweis et al., 2025). Auch im Peer-Review werden zunehmend Sprachmodelle eingesetzt – mit allen Vor- und Nachteilen, die das mit sich bringt (Naddaf, 2025a). Wie wir in den späteren Kapiteln sehen, experimentieren Hochschulen weltweit intensiv mit den neuen Möglichkeiten für Lehre und Forschung.\nWie ein Laie im Cockpit eines Verkehrsflugzeugs fällt es Lehrenden teils schwer zu entscheiden, welche der neuen Möglichkeiten sinnvoll für die eigene Lehre sind. Zunächst gibt es immer wieder Hype-Zyklen: Virtuelle Realität, Blockchain, Roboter, Internet der Dinge… (Allen & Edelson, 2024), viel wurde schon ins Rampenlicht gestellt und dann wieder vergessen. Es werden gerade für die Lehre regelmäßig neue Technologien beworben und gehyped, so dass Lehrende schon aus Selbstschutz eine gewisse Grundskepsis mitbringen (sollten), ob ein neuer technischer Zugang wirklich auch didaktischen Nutzen bringt (für eine wirkungsbasierte Übersicht s. etwa Hattie, 2023, Kap.14). Lehrende sind außderdem paradoxen Spannung zwischen den Identitäten als Experten und Innovatoren/Faszilitatoren ausgesetzt (fischer2025?): Ausgestrahlte Kompetenz ist einerseits Teil ihres Wertversprechens, was zur Abwehr ungewohnter Technologien einlädt. Andererseits sollen Lehrende auch zu Neugier und Innovation anleiten und insofern den Umgang mit neuen, auch für die Lehrenden selbst ungewohnten Technologien erleichtern.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Einleitung</span>"
    ]
  },
  {
    "objectID": "kapitel01.html#aktuelle-weiterentwicklungen-der-sprachmodelle",
    "href": "kapitel01.html#aktuelle-weiterentwicklungen-der-sprachmodelle",
    "title": "1  Einleitung",
    "section": "1.2 Aktuelle Weiterentwicklungen der Sprachmodelle",
    "text": "1.2 Aktuelle Weiterentwicklungen der Sprachmodelle\nEnde 2025 sehen wir im Rückblick, dass die Sprachbots immer selbstständiger werden, man spricht vom “Agentic Turn”Ethan Mollick (2025a): Wir verbringen jetzt weniger Zeit damit, über die ‘Zaubersprüche’ einzelner Prompts nachzudenken und mehr Zeit in ‘Mitarbeitergesprächen’ - Anleitung und Kritik der digitalen “Agenten” - Sprachmodelle, die selbstständig und auf hohem Niveau mehrere Arbeitsschritte durchführen. Die wichtigsten technologischen Durchbrüche sind die massive Steigerung der Kontextfenster (bis zu mehreren Millionen Token) und die Fähigkeit der Modelle, digitale “Werkzeuge” wie Browser und Dateisysteme autonom zu bedienen. Ein zentrales Thema für die praktische Nutzung ist die Parallelisierung und Beschleunigung: Experten arbeiten nicht mehr mit einer KI, sondern orchestrieren mehrere von Agenten, die etwa parallel an Recherche, Schreibarbeit oder Code arbeiten Willison (2025).\nWas hat sich in den letzten 2 Jahren praktisch in der Bedienung solcher Chatbots geändert? Drei zentrale Weiterentwicklungen zwischen 2024 und 2025 sind laut Korinek für den deutlichen Sprung in forschungsrelevanten Fähigkeiten der Sprachmodelle verantwortlich (Korinek, 2024-12 (update), S.2–3): Erstens neue Interaktionsmöglichkeiten – während die typische Nutzung früher auf Texteingabe im Eingabefenster beschränkt war, bieten die großen Sprachmodelle mittlerweile die Möglichkeit an, in einem Workspace gemeinsam an Text oder Code zu arbeiten (z.B. ChatGPT Canvas, Claude Artifacts). Zweitens sehen wir eine deutliche Verbesserung der Problemlösefähigkeit der Modelle (‘reasoning’) . Den stärksten Modellen (Chat GPT-5, Gemini 2.5, Claude Opus 4.1) kann man mittlerweile dabei zusehen, wie sie mehrstufiges Problemlösen und logisches Schlussfolgern etwa bei Rechercheaufgaben durchführen. Die Bedeutung von präzisen Prompt-„Zaubersprüchen” nimmt ab, da die neueren (Reasoning) Modelle ohnehin selbst Schritt für Schritt vorgehen und nachfragen (Meincke et al., 2025). Insgesamt steigt seit 2023 die Qualität der Aufgaben, die Sprachmodelle erledigen können, rasant. Empirische Untersuchungen zeigen, dass die Sprachmodelle immer längere Aufgaben auf hohem Niveau erledigen können (Kwa et al., 2025).\nDie neuen Modelle sind außderdem günstiger und effizienter geworden: die Kosten pro Interaktion sind stark gesunken. Illustratives Beispiel: Eine Millionen Token kosteten mit GPT-4 noch 50 Dollar, jetzt nur noch 14 Cent (InvertedStone, 2025; Ethan Mollick, 2025b). Das Modell halluziniert (weiterhin, also Vorsicht, aber) deutlich seltener als seine Vorgänger: OpenAI gibt hier ca. 1% Halluzinationen der Antworten statt ca. 5% bei Vorgängermodellen (o3, 4o) an, je nach Komplexität der Frage und erlaubter „Bedenkzeit” (OpenAI, 2025).\nDrittens hat sich die Internetsuche mit LLMs deutlich verbessert. Während man früher noch oft über sinnlose oder erfundene Ergebnisse lachte, stellt die Suche von ChatGPT, Google/Gemini, oder speziellen Suchanbietern wie Perplexity mittlerweile eine große Zeitersparnis dar: „a useful tool to provide up-to-date answers to questions that are grounded in facts found on the internet, together with the requisite citations—a crucial capability for researchers” (Korinek, 2024-12 (update), S.3). Das gilt zunehmend für die stärksten allgemeinen Modelle und erst recht für Anbieter, die auf Forschungsrecherche (und Studierende) spezialisiert sind, wie Elicit oder Paperpal. Auch breite Internet-Recherchen und Textproduktionen sind zunehmend komplett delegierbar („deep research”), mit deutlichen Auswirkungen auf den Arbeitsprozess in der Wissensarbeit Liang et al. (2025).",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Einleitung</span>"
    ]
  },
  {
    "objectID": "kapitel01.html#wie-nutzen-studierende-und-lehrende-genai",
    "href": "kapitel01.html#wie-nutzen-studierende-und-lehrende-genai",
    "title": "1  Einleitung",
    "section": "1.3 Wie nutzen Studierende und Lehrende GenAI?",
    "text": "1.3 Wie nutzen Studierende und Lehrende GenAI?\nAuch Studierende nutzen bereits umfangreich Sprachmodelle für einen breiten Strauß an Zielen (s. Abbildung 1.1). Eine Auswertung der KI-Forscher des KI-Unternehmens Anthropic von 1 Millionen anonymisierten Chats zwischen Usern mit Universitätskonto und dem KI Bot zeigt typische Muster der Nutzung (Handa et al., 2025): Studierende setzen das Sprachmodell vor allem für anspruchsvolle Tätigkeiten ein, wie das Erstellen neuer Inhalte und das Analysieren komplexer Themen, was höheren Ebenen der Bloomschen Taxonomie entspricht. Daraus ergibt sich die Herausforderung sicherzustellen, dass Studierende wesentliche kognitive Aufgaben nicht vollständig an KI delegieren: Aufgaben müssen angepasst und der verantwortungsvolle Umgang mit der Technik muss eingeübt werden.\n\n\n\n\n\n\nAbbildung 1.1: Wofür Studierende LLMs nutzen Quelle: Handa et al. (2025)\n\n\n\n\n\n\n\n\n\nAbbildung 1.2: Schwerpunkte der Nutzung von LLMs (Claude) durch Studierende nach der Bloom’schen Taxonomie. Quelle: Handa et al. (2025)\n\n\n\nAuch außerhalb der Hochschule steigt die Nutzung. Eine Reihe von Studien zeigen erhöhte Produktivität von Büroarbeitenden mit LLM-Unterstützung: der Kundensupport arbeitet 15% schneller, wenn das Sprachmodell Antwortoptionen vorschlägt und Verweise auf interne technische Dokumentation anbietet (Brynjolfsson et al., 2025), Programmierer programmieren schneller (Peng et al., 2023), Consultants sind produktiver bei komplexen Beratungsprojekten (Dell’Acqua et al., 2023) und Sprachmodelle wie ChatGPT können eine Vielzahl kleiner Aufgaben beschleunigen (Handa et al., 2025) und werden insofern gerade zur Texterstellung schon millionenfach als Hilfsmittel im Beruf genutzt: Von Kundenbewertungen über Pressemitteilungen und Stellenanzeigen (Liang et al., 2025).\nDie zunehmende Verwendung von KI in der Lehre hat gute Gründe. Wie oft eine neue Technologie genutzt wird, hängt nach dem Technology Acceptance Model (TAM) von der wahrgenommenen Benutzerfreundlichkeit (perceived ease of use) und der wahrgenommenen Nützlichkeit (perceived usefulness) ab (Marangunić & Granić, 2015). Generative KI wie ChatGPT decken sichtlich beide Aspekte ab: Sie sind einfach zu nutzen (Kestin et al., 2025; Lee et al., 2025; Monib et al., 2025; Naddaf, 2025b) und erzeugen einen deutlichen Mehrwert, wie Studierende und Lehrende in einer Vielzahl von Umfragen der letzten zwei Jahren berichten (Heidt, 2025; Morgan, 2024; Ou et al., 2024). Lehrende ziehen nach: Meta-Untersuchungen zeigen ein extremes Wachstum an Publikationen zur Nutzung von LLM im Hochschulalltag (Ma, 2025; Ogunleye et al., 2024).",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Einleitung</span>"
    ]
  },
  {
    "objectID": "kapitel01.html#risiken-und-nebenwirkungen",
    "href": "kapitel01.html#risiken-und-nebenwirkungen",
    "title": "1  Einleitung",
    "section": "1.4 Risiken und Nebenwirkungen",
    "text": "1.4 Risiken und Nebenwirkungen\nDie Metapher mit dem E-Bike trägt allerdings auch, was die Risiken und Nebenwirkungen angeht: Ab wann lässt die maschinelle Unterstützung wichtige Muskeln verkümmern? Solche Gefahren bestehen – wie empirische Studien zeigen, erfordern die neuen Workflows der Wissensarbeit durch KI-Unterstützung auch neue Formen der kritischen Auseinandersetzung mit den Inhalten. Die Analyse von 1 Millionen anonymisierten Studierenden-Chats durch Anthropic (Handa et al., 2025) zeigt einerseits, dass Studierende das LLM vor allem für kognitiv anspruchsvollere Aufgaben einsetzen, vor allem in den Kategorien „Creating” und „Analyzing” (s. Abbildung 1.2). Dies steht im deutlichen Gegensatz zur Nutzung von einfachen Internetsuchen, die einen Schwerpunkt auf dem Finden einzelner Fakten haben.\nWie kann man verhindern, dass die Studierenden kritische kognitive Aufgaben allein den KI-Systemen übergeben? Eine Studie von 319 Wissensarbeitern zeigt, dass sich das Gewicht zwischen den Einzelaufgaben der Wissensarbeit mit LLMs verschiebt: Der Aufwand für die Recherchen selbst sinkt, es steigt anderseits der Aufwand für Management-ähnliche Aufgaben: Koordination der Einzelaufgaben für Mensch und Maschine, kritische Prüfung der berichteten Ergebnisse und die Integration von Ergebnissen in den Gesamtprozess (etwa zur Erstellung eines Gesamtberichtes, einer Test-Spezifikation oder eines Protokolls) (Lee et al., 2025). Werden solche neuen Vorgehensweisen nicht geübt, droht ein Rückgang des kritischen Denkens. Lehre heißt in diesem Kontext auch, empfohlene Arbeitsweisen mit der neuen Technik zu üben.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Einleitung</span>"
    ]
  },
  {
    "objectID": "kapitel01.html#kapitelübersicht",
    "href": "kapitel01.html#kapitelübersicht",
    "title": "1  Einleitung",
    "section": "1.5 Kapitelübersicht",
    "text": "1.5 Kapitelübersicht\nIm Folgenden werden wir zunächst einige Grundbegriffe klären: Was sind große Sprachmodelle und was ist mit Begriffen wie Token, Prompt und RAG gemeint? Welche Modelle können Lehrende aktuell nutzen und welche Empfehlungen für Prompts sind belastbar (Abschnitt 2.5)? Dann fragen wir nach Zielen: Welche Art von Wissen und Methoden unterscheidet und empfiehlt die Lernforschung? Welche didaktischen Wirkmechanismen können durch KI genutzt werden, um typische Probleme der Hochschullehre anzugehen (Abschnitt 3)? Im Abschnitt 4 schauen wir auf Praxisbeispiele für vier Anwendungsfelder von Sprachmodellen an Hochschulen: KI als Hiwi (direkte Arbeitserleichterung), KI als Copilot (Unterstützung beim Schreiben und Coden) und KI als Tutor (Feedback und Lernunterstützung) sowie KI als Simulator (Role Play und Goal Play). Abschließend zeigen wir verschiedene Anwendungen von KI in verschiedenen Kurstypen und gehen auf neue Herausforderungen für Prüfungen ein (Abschnitt 5). Im Appendix finden Sie eine breite Sammlung von didaktischen Prompts und auf GenAI ausgerichteten Aufgabenstellungen von führenden Hochschulen.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Einleitung</span>"
    ]
  }
]