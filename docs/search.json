[
  {
    "objectID": "kapitel01.html",
    "href": "kapitel01.html",
    "title": "1Â  Einleitung",
    "section": "",
    "text": "1.1 KI als Hilfe fÃ¼r die Lehre\nWie kann uns generative kÃ¼nstliche Intelligenz (KI) in der Lehre helfen? Hoffnung besteht hier fÃ¼r zwei typische Probleme: Erstens haben Studierende individuelle BedÃ¼rfnisse, aber wir haben nur begrenzte Zeit, auf diese einzugehen. Wie kÃ¶nnen wir Einzelne mÃ¶glichst intensiv fÃ¶rdern, ohne vor Arbeit unterzugehen? Zweitens ist der Aufwand gerade fÃ¼r effektive Lehrmethoden oft sehr hoch, so etwa fÃ¼r hÃ¤ufige niedrigschwellige Tests, oder individuelles Feedback zu Studienarbeiten (Brown et al., 2014; s. etwa Hattie, 2023, Kap.13). Wer lehrt, fÃ¼hlt sich aus Zeit- und Stoffdruck oft gezwungen, Abstriche von idealen Lehrsetups zu machen (Henderson & Dancy, 2007; Schmidt & Tippelt, 2005, S.104â€“105). Gerade Lehrmethoden, die didaktisch sinnvoll, aber mit hÃ¶herem Aufwand verbunden sind, drohen dabei auf der Strecke zu bleiben (s. etwa Dunlosky et al., 2013; Roediger & Pyc, 2012).\nFÃ¼r die Lehre erschlieÃŸen sich durch die groÃŸen KI-Sprachmodelle (LLM = Large Language Models) neue MÃ¶glichkeiten. Sie sind, wie es eine Analyse des MIT Professors Andrew McAfee auf den Punkt bringt â€generally fasterâ€ (McAfee, 2024). Lehrende kÃ¶nnen mit KI-UnterstÃ¼tzung etwa deutlich schneller eine Recherche durchfÃ¼hren, ein Set von Ãœbungsaufgaben erstellen, mehrere Anwendungsbeispiele pro Konzept hinzufÃ¼gen, Quizfragen zur schnellen LernÃ¼berprÃ¼fung generieren, oder mit den Studierenden Rollenspiele durchfÃ¼hren (Meincke et al., 2024; Mollick & Mollick, 2023). Der Berg ist noch da, aber mit dem E-Bike kommt man weiter.",
    "crumbs": [
      "<span class='chapter-number'>1</span>Â  <span class='chapter-title'>Einleitung</span>"
    ]
  },
  {
    "objectID": "kapitel01.html#ki-als-hilfe-fÃ¼r-die-lehre",
    "href": "kapitel01.html#ki-als-hilfe-fÃ¼r-die-lehre",
    "title": "1Â  Einleitung",
    "section": "",
    "text": "Schnelles Brainstorming mit der KI\n\n\n\n\n  \n    \n      ğŸ’¡\n      Wie kann ich GenAI in meiner Lehre nutzen?\n      KI\n    \n    \n    \n      Geben Sie Ihren Fachbereich ein. Das Sprachmodell hilft beim Brainstormen.\n    \n    \n    \n      \n      \n        Los\n      \n    \n    \n    \n      \n      \n        âš¡ Antworten von GPT-4o-mini - ein effizientes, aber nicht das schlauste Modell Â· Kann Fehler enthalten\n      \n    \n  \n\n\n\n\n\n\n\n\n\n\n\n\nAbbildungÂ 1.1: GenAI als KraftverstÃ¤rker",
    "crumbs": [
      "<span class='chapter-number'>1</span>Â  <span class='chapter-title'>Einleitung</span>"
    ]
  },
  {
    "objectID": "kapitel01.html#was-2025-mÃ¶glich-ist-praktische-beispiele-fÃ¼r-recherche-Ã¼bungsaufgaben-erklÃ¤rungen",
    "href": "kapitel01.html#was-2025-mÃ¶glich-ist-praktische-beispiele-fÃ¼r-recherche-Ã¼bungsaufgaben-erklÃ¤rungen",
    "title": "1Â  Einleitung",
    "section": "1.2 Was 2025 mÃ¶glich ist: Praktische Beispiele fÃ¼r Recherche, Ãœbungsaufgaben, ErklÃ¤rungen",
    "text": "1.2 Was 2025 mÃ¶glich ist: Praktische Beispiele fÃ¼r Recherche, Ãœbungsaufgaben, ErklÃ¤rungen\nSchauen wir uns einige praktische Beispiele an. Wir wollen wissen, was es fÃ¼r aktuelle Fallstudien zu Lieferketten-Problemen gibt. Als Recherche-Hiwi lassen wir das Sprachmodell auf akademischen Blogs und Fachzeitschriften nach aktuellen Beispielen suchen.\n\n\n\n\n\n\nAbbildungÂ 1.2: Recherche-Hiwi-Vorgehen\n\n\n\nSolche Suchen fÃ¼hren Sprachmodelle mittlerweile in mehreren Schritten durch. Hier sehen wir den â€œDenkprozessâ€.\n\n\n\n\n\n\nAbbildungÂ 1.3: Recherche-Hiwi-Denkprozess\n\n\n\nHier das Ergebnis: Ein erster ausformulierter Bericht von 13 Seiten nach ca. 5 Minuten Recherche. Die Abbildung zeigt den Auszug mit der tabellarischen Zusammenfassung der Forschungsartikel.\n\n\n\n\n\n\nAbbildungÂ 1.4: Recherche-Hiwi-Ergebnis\n\n\n\nWie kann man Konzepte einfach und mit Beispielen erklÃ¤ren? Wir bitten ChatGPT um VorschlÃ¤ge zu zwei Konzepten aus der Wissenschaftstheorie: Der Duham-Quines-These, die beschreibt, warum Wissenschaft nur graduell, mosaik-bauend zu Erkenntnissen kommen kann und Mayoâ€™s Konzept der â€œStrengen Testsâ€ (severe testing), nach denen man wissenschaftliche Aussagen graduell auf ihre Belastbarkeit bewerten kann.\n Wie kÃ¶nnte man das in einem Test abfragen? Auch hierzu bitten wir ChatGPT (5.2) um VorschlÃ¤ge.\n Ende 2025 kann GenAI professionelle Folien-PrÃ¤sentationen sehr schnell erstellen. Sprachmodelle wie Googleâ€™s Gemini kÃ¶nnen mittlerweile auch Text erstellen (Willison, 2025b) und damit auch komplexe Infografiken (und Folien). Das Sprachmodell Claude liefert eine Beschreibung (â€˜Skillâ€™) von 3500 WÃ¶rtern mit, die dem Sprachmodell genau erklÃ¤rt, wie es Schritt fÃ¼r Schritt eine PowerPoint PrÃ¤sentation erstellt und testet (Anthropic, 2025).\nEine grafisch ansprechende PrÃ¤sentation zu erstellen ist recht zeitaufwÃ¤ndig - und Brillianz als Grafiker gehÃ¶rt vielleicht auch nicht zu den Kernkompetenzen von Lehrenden. Wir bitten daher Gemini (NotebookLM) und Claude, uns basierend auf Ãœberblicksartikeln zwei PrÃ¤sentationen zu erstellen: Eine zur Frage, welche Lerntechniken fÃ¼r Studierende besonders gut funktionieren (s. Kapitel 2) und die zweite zur Frage, welche Best-Practices es gibt, Aufgabenstellungen mit der intensiven Nutzung von GenAI zu verbinden (s. Anhang B).\nZu integrierten Aufgaben mit GenAI liefert uns das Sprachmodell nach wenigen Minuten 15 sehr schicke Folien (NotebookLM, basierend auf 13 Quellen-PDFs).\n\n\n\n\n\n\nAbbildungÂ 1.5: Recherche-Hiwi-Ergebnis\n\n\n\nZu Lerntechniken erhielten wir nach etwa 5 Minuten basierend auf einem Fachartikel, 8 professionelle Folien (mit kleineren Formatierungsfehlern, etwa ZeilenumbrÃ¼chen).\n\n\n\n\n\n\nAbbildungÂ 1.6: Recherche-Hiwi-Ergebnis",
    "crumbs": [
      "<span class='chapter-number'>1</span>Â  <span class='chapter-title'>Einleitung</span>"
    ]
  },
  {
    "objectID": "kapitel01.html#nutzung-von-genai-in-der-forschung",
    "href": "kapitel01.html#nutzung-von-genai-in-der-forschung",
    "title": "1Â  Einleitung",
    "section": "1.3 Nutzung von GenAI in der Forschung",
    "text": "1.3 Nutzung von GenAI in der Forschung\nImmer mehr Aspekte von typischen ForschungstÃ¤tigkeiten â€“ ein zentraler Ausbildungsinhalt der Hochschulen â€“ kÃ¶nnen von der KI Ã¼bernommen werden und zwar auf hohem Niveau. Vorbei sind die Zeiten, in denen wir die banalen Schreibprodukte der KI nur belÃ¤cheln konnten. Ein Ãœberblicksartikel des Forschers Anton Korinek im renommierten Journal of Economic Literature vom Dezember 2024 fasst die deutlich hÃ¶here QualitÃ¤t des Outputs zusammen: â€die derzeitige Generation von LLMs ist in hohem MaÃŸe in der Lage, die wichtigsten Erkenntnisse von Forschungsarbeiten zu verarbeitenâ€ (Korinek, 2024, S.3, Ãœbersetzung RB mit DeepL).\nDie professionelle Nutzung durch Forscher etwa in Laborumgebungen oder der Mathematik ist hier teils noch weiter. Eine schÃ¶ne visuelle Verdeutlichung davon, was jetzt mÃ¶glich ist, findet sich hier: Eine Visualisierung von Ã¼ber 6000 KonferenzbeitrÃ¤gen, die jeweils zusammengefasst werden und denen durch ein Sprachmodell eine ErklÃ¤rung in einfacher Sprache beigefÃ¼gt wurde (â€œexplain-it-like-Iâ€™m-5â€): Hier kann man das interaktiv ausprobieren: https://jalammar.github.io/assets/neurips_2025.html.\n\n\n\n\n\n\nAbbildungÂ 1.7: Visualisierung und ErlÃ¤uterung in einfacher Sprache von 6000+ KonferenzbeitrÃ¤gen\n\n\n\nWie kann GenAI uns bei der Forschung direkt unterstÃ¼tzen? Google demonstrierte 2025 ein mehrstufiges Modell fÃ¼r die Pharma-Forschung (â€˜AI co-scientistâ€™), das den Forschenden zeitintensive Zwischenschritte abnimmt (Gottweis et al., 2025) (s. AbbildungÂ 1.8). OpenAI zeigte Ende 2023 schon in einem ausfÃ¼hrlichen Bericht eine Vielzahl mÃ¶glicher Hilfsanwendungen im Wissenschaftsbereich. Mit deutlichen Warnhinweisen (speziell wegen selbstbewusst vertretenen Halluzinationen) aber auch teils erstaunlich hoher QualitÃ¤t (Bubeck et al., 2023). Auch im Peer-Review werden zunehmend Sprachmodelle eingesetzt â€“ mit allen Vor- und Nachteilen, die das mit sich bringt (Naddaf, 2025). Wie wir in den spÃ¤teren Kapiteln sehen, experimentieren Hochschulen weltweit intensiv mit den neuen MÃ¶glichkeiten fÃ¼r Lehre und Forschung.\n\n\n\n\n\n\nAbbildungÂ 1.8: Googleâ€™s Co-Scientist Ansatz an einem Beispiel aus der Pharmaforschung\n\n\n\nEnde 2025, hat sich der potenzielle Mehrwert (und speziell Zeitgewinn) bei fachgemÃ¤ÃŸer Nutzung  noch einmal erweitert. Ein aktueller Bericht (November 2025) von OpenAI stellt eine Reihe von Fallstudien dar, wie Forschende starke Sprachmodelle nutzen (Bubeck et al., 2025). Die Quelle der Ergebnisse ist natÃ¼rlich nicht neutral (OpenAI), die Ergebnisse sind aber m.E. mit Blick auf die eigene Nutzungserfahrung sehr plausibel: Als Mehrwert wird hÃ¤ufig eine auÃŸerordentliche Zeitersparnis bei RoutinetÃ¤tigkeiten genannt, speziell bei der Nutzung von Verfahren und Wissensquellen, die die Forscher zwar bewerten kÃ¶nnen, deren Aneignung aber ohne die Hilfe der Sprachmodelle deutlich lÃ¤nger dauern wÃ¼rde. Dies ist sehr wertvoll und wird die Verbreitung solcher Tools treiben. Wir sehen in den Einzelberichten aber auch klare Warnsignale: Wenn man die Zwischenergebnisse mangels Fachkenntnis nicht kritisch hinterfragen kann, ist die Wahrscheinlichkeit hoch, Fehler zu Ã¼bernehmen. Auch starke Sprachmodelle vertreten sehr Ã¼berzeugend falsche Ergebnisse und AnsÃ¤tze. Nur durch Fachwissen haben Nutzer die erforderlichen Bewertungsmuster. Erst durch eigenes Fachwissen und der Erfahrung im kritischen Umgang mit dem Tool entsteht der Mehrwert. Man muss insofern das Terrain kennen und lernen, wie man den Sportwagen Sprachmodell fahren muss, kÃ¶nnen UnfÃ¤lle vermieden werden.\nAm Ende dieses Kapitels kÃ¶nnen Sie Details der Bewertungen aus den verschiedenen Disziplinen sehen (Bubeck et al., 2025). Kapitel 1.8\nWie ein Laie im Cockpit eines Verkehrsflugzeugs fÃ¤llt es Lehrenden teils schwer zu entscheiden, welche der neuen MÃ¶glichkeiten sinnvoll fÃ¼r die eigene Lehre sind. ZunÃ¤chst gibt es immer wieder Hype-Zyklen: Virtuelle RealitÃ¤t, Blockchain, Roboter, Internet der Dingeâ€¦ (Allen & Edelson, 2024), viel wurde schon ins Rampenlicht gestellt und dann wieder vergessen. Es werden gerade fÃ¼r die Lehre regelmÃ¤ÃŸig neue Technologien beworben und gehyped, so dass Lehrende schon aus Selbstschutz eine gewisse Grundskepsis mitbringen (sollten), ob ein neuer technischer Zugang wirklich auch didaktischen Nutzen bringt (fÃ¼r eine wirkungsbasierte Ãœbersicht von Technologien s. etwa Hattie, 2023, Kap.14). Lehrende sind auÃŸderdem paradoxen Spannung zwischen den IdentitÃ¤ten als Experten und Innovatoren/Faszilitatoren ausgesetzt (Fischer & Dobbins, 2024): Ausgestrahlte Kompetenz ist einerseits Teil ihres Wertversprechens, was zur Abwehr ungewohnter Technologien einlÃ¤dt. Andererseits sollen Lehrende auch zu Neugier und Innovation anleiten und insofern den Umgang mit neuen, auch fÃ¼r die Lehrenden selbst ungewohnten Technologien erleichtern.\n\n\n\n\n\n\nAbbildungÂ 1.9: Neue technologische Chancen und Herausforderungen mit GenAI. Quelle: Mit Gemini generiert.",
    "crumbs": [
      "<span class='chapter-number'>1</span>Â  <span class='chapter-title'>Einleitung</span>"
    ]
  },
  {
    "objectID": "kapitel01.html#aktuelle-weiterentwicklungen-der-sprachmodelle",
    "href": "kapitel01.html#aktuelle-weiterentwicklungen-der-sprachmodelle",
    "title": "1Â  Einleitung",
    "section": "1.4 Aktuelle Weiterentwicklungen der Sprachmodelle",
    "text": "1.4 Aktuelle Weiterentwicklungen der Sprachmodelle\n2025 lernen die groÃŸen Sprachmodelle noch besser â€œnachzudenkenâ€ - sogenannte â€œReasoningâ€-Modelle werden breit verfÃ¼gbar. Aus didaktischer Sicht ist das auch deshalb interessant, weil man Lernenden jetzt Denkstrategien vorfÃ¼hren kann, speziell Hypothesenbildung und PrÃ¼fung (etwa (Brown et al., 2014), S.90-94, â€œgenerative learningâ€, oder die Studien von Willemain zur Modellierung von Problemen durch Experten (Willemain, 1994, 1995)). Ein neuer Ansatzpunkt zur Verbesserung der Ergebnisse wird hier genutzt (Grootendorst, 2025) : Statt (nur) mehr Ressourcen in das Training immer komplexerer Modelle zu investieren (train-time compute), werden die Modelle jetzt dazu angehalten, lÃ¤nger â€œnachzudenkenâ€, bevor sie ein Ergebnis anbieten (test-time compute). Hinter diesem â€œbesseren Nachdenkenâ€ stehen zwei Prinzipien (Grootendorst, 2025; Snell et al., 2024): Die Sprachmodelle werden einerseits instruiert, schrittweise vorzugehen (Input-Verbesserung der Vorschlagsverteilung) und andererseits dazu angehalten, die eigenen Antworten zu prÃ¼fen (Output-Verbesserung, Verifizierer). Die Sprachmodelle fÃ¼hren insofern jetzt teils selbststÃ¤ndig PrÃ¼fschritte durch, die man frÃ¼her durch komplexe Prompts induziert hÃ¤tte. Ende 2025 sehen wir in der Konsequenz, dass die Sprachbots immer selbststÃ¤ndiger werden, man spricht vom â€œAgentic Turnâ€(Mollick, 2025a; Steinberger, 2025; Willison, 2025a): Als Nutzer solcher Reasoning Modelle verbringen wir jetzt weniger Zeit damit, Ã¼ber die â€˜ZaubersprÃ¼cheâ€™ einzelner Prompts nachzudenken und mehr Zeit in â€˜MitarbeitergesprÃ¤chenâ€™ - Anleitung und Kritik der digitalen â€œAgentenâ€ - Sprachmodelle, die selbststÃ¤ndig und auf hohem Niveau mehrere Arbeitsschritte durchfÃ¼hren. Insgesamt steigt seit 2023 die QualitÃ¤t der Aufgaben, die Sprachmodelle erledigen kÃ¶nnen, rasant. Empirische Untersuchungen zeigen, dass die Sprachmodelle immer lÃ¤ngere Aufgaben auf hohem Niveau erledigen kÃ¶nnen (Kwa et al., 2025).\nDie neuen Modelle sind auÃŸderdem gÃ¼nstiger und effizienter geworden: die Kosten pro Interaktion sind stark gesunken. Illustratives Beispiel: Eine Millionen Token kosteten mit GPT-4 noch 50 Dollar, jetzt nur noch 14 Cent (InvertedStone, 2025; Mollick, 2025b). Das Modell halluziniert (weiterhin, also Vorsicht, aber) deutlich seltener als seine VorgÃ¤nger: OpenAI gibt hier ca. 1% Halluzinationen der Antworten statt ca. 5% bei VorgÃ¤ngermodellen (o3, 4o) an, je nach KomplexitÃ¤t der Frage und erlaubter â€Bedenkzeitâ€ (OpenAI, 2025).\nWeiterhin hat sich die Internetsuche mit LLMs deutlich verbessert. WÃ¤hrend man frÃ¼her noch oft Ã¼ber sinnlose oder erfundene Ergebnisse lachte, stellt die Suche von ChatGPT, Google/Gemini, oder speziellen Suchanbietern wie Perplexity mittlerweile eine groÃŸe Zeitersparnis dar: â€a useful tool to provide up-to-date answers to questions that are grounded in facts found on the internet, together with the requisite citationsâ€”a crucial capability for researchersâ€ (Korinek, 2024, S.3). Das gilt zunehmend fÃ¼r die stÃ¤rksten allgemeinen Modelle und erst recht fÃ¼r Anbieter, die auf Forschungsrecherche (und Studierende) spezialisiert sind, wie Elicit oder Paperpal. Auch breite Internet-Recherchen und Textproduktionen sind zunehmend komplett delegierbar (â€deep researchâ€), mit deutlichen Auswirkungen auf den Arbeitsprozess in der Wissensarbeit (s. etwa Schwarcz et al. (2025) fÃ¼r juristische Recherchen, Korinek (2024) fÃ¼r Ã–konomie und Liang et al. (2025) fÃ¼r PR-TÃ¤tigkeiten).",
    "crumbs": [
      "<span class='chapter-number'>1</span>Â  <span class='chapter-title'>Einleitung</span>"
    ]
  },
  {
    "objectID": "kapitel01.html#wie-nutzen-studierende-und-lehrende-genai",
    "href": "kapitel01.html#wie-nutzen-studierende-und-lehrende-genai",
    "title": "1Â  Einleitung",
    "section": "1.5 Wie nutzen Studierende und Lehrende GenAI?",
    "text": "1.5 Wie nutzen Studierende und Lehrende GenAI?\nFÃ¼r Studierende sind GenAI Chatbots zum Standard fÃ¼r Informationssuche und Schreibaufgaben geworden: So berichten 92 % der befragten britischen Vollzeitstudierenden (n=1.041, Erhebung im Dezember 2024), dass sie KI-Tools wie ChatGPT regelmÃ¤ÃŸig verwenden, und 88 % geben an, solche Tools fÃ¼r PrÃ¼fungsleistungen (â€œfor assessmentsâ€) zu nutzen (Freeman, 2025). Deutsche Daten des CHE-Centrum fÃ¼r Hochschulentwicklung bestÃ¤tigen dies: etwa zwei Drittel der Studierenden gaben Ende 2024 an, KI-Tools mindestens wÃ¶chentlich zu nutzen (HÃ¼sch, Marc et al., 2025) (65%, n=23.288 von 171 Hochschulen).\nWofÃ¼r genau nutzen Studierende GenAI? Studierende geben an, dass sie sich am hÃ¤ufigsten Konzepte erklÃ¤ren lassen, Artikel zusammenfassen oder Ideen fÃ¼r Schreib- und Forschungsprojekte sammeln (Freeman, 2025). Nutzungsstudien zeigen sogar noch stÃ¤rkeren Einsatz speziell fÃ¼r Schreibprojekte (s. AbbildungÂ 1.10): Wie eine Auswertung von 1 Millionen anonymisierten Chats zwischen Usern mit UniversitÃ¤tskonto und dem Sprachmodell zeigt nutzen Studierende die KI-Bots vor allem zum Erstellen neuer Inhalte und das Analysieren komplexer Themen, was hÃ¶heren Ebenen der Bloomschen Taxonomie entspricht (s. AbbildungÂ 1.11). Ein GroÃŸteil der befragten britischen Studierenden gibt an, PrÃ¼fungsleistungen durch GenAI zu unterstÃ¼tzen. Dieser Anteil sprang zwischen den ErhebungszeitrÃ¤umen Ende 2023 und 2024 von der HÃ¤lfte auf fast 90% (53% auf 88%, Freeman, 2025).\n\n\n\n\n\n\nAbbildungÂ 1.10: WofÃ¼r Studierende LLMs nutzen. Quelle: Handa et al. (2025-04-08, 2025)\n\n\n\nHochschulen mÃ¼ssen insofern sicherstellen, dass PrÃ¼fungsleistungen nicht entwertet und Studierende die produktive Nutzung solcher Tools erlernen. Studierende dÃ¼rfen einerseits wesentliche kognitive Aufgaben nicht vollstÃ¤ndig an GenAI delegieren: Aufgaben und PrÃ¼fungsleistungen mÃ¼ssen angepasst werden. Weiterhin entsteht ein neuer Bedarf an Kompetenzschulung, den Studierende wie Unternehmen Ã¤uÃŸern: der produktive Umgang mit den neuen GenAI Tools muss eingeÃ¼bt werden. Deutsche Studierende fÃ¼hlen sich hierauf nicht gut vorbereitet: In der CHE-Studie bewerten sie das bestehende Angebot zum Erwerb von KI-Kompetenzen mit nur 2,7 von 5 Sternen (HÃ¼sch, Marc et al., 2025).\n\n\n\n\n\n\nAbbildungÂ 1.11: Schwerpunkte der Nutzung von LLMs (Claude) durch Studierende nach der Bloomâ€™schen Taxonomie. Quelle: Handa et al. (2025-04-08, 2025)\n\n\n\nDie zunehmende Verwendung von KI in der Lehre hat gute GrÃ¼nde. Wie oft eine neue Technologie genutzt wird, hÃ¤ngt nach dem Technology Acceptance Model (TAM, s. AbbildungÂ 1.12) von der wahrgenommenen Benutzerfreundlichkeit (perceived ease of use) und der wahrgenommenen NÃ¼tzlichkeit (perceived usefulness) ab (MaranguniÄ‡ & GraniÄ‡, 2015). Generative KI wie ChatGPT decken sichtlich beide Aspekte ab: Sie sind einfach zu nutzen (Kestin et al., 2025; Lee et al., 2025; Monib et al., 2025; Naddaf, 2025) und erzeugen einen deutlichen Mehrwert, wie Studierende und Lehrende in einer Vielzahl von Umfragen der letzten zwei Jahren berichten (Heidt, 2025; Morgan, 2024; Ou et al., 2024). Lehrende ziehen nach: Meta-Untersuchungen zeigen ein extremes Wachstum an Publikationen zur Nutzung von LLM im Hochschulalltag (Ma, 2025; Ogunleye et al., 2024).\n\n\n\n\n\n\nAbbildungÂ 1.12: GrÃ¼nde fÃ¼r die Verbreitung von GenAI nach dem Technologie-Akzeptanz-Modell\n\n\n\nAuch auÃŸerhalb der Hochschule steigt die Nutzung. Eine Reihe von Studien zeigen erhÃ¶hte ProduktivitÃ¤t von BÃ¼roarbeitenden mit LLM-UnterstÃ¼tzung: der Kundensupport arbeitet 15% schneller, wenn das Sprachmodell Antwortoptionen vorschlÃ¤gt und Verweise auf interne technische Dokumentation anbietet (Brynjolfsson et al., 2025), Programmierer programmieren schneller (Peng et al., 2023), Consultants sind produktiver bei komplexen Beratungsprojekten (Dellâ€™Acqua et al., 2023) und Sprachmodelle wie ChatGPT kÃ¶nnen eine Vielzahl kleiner Aufgaben beschleunigen (Handa et al., 2025-04-08, 2025) und werden insofern gerade zur Texterstellung schon millionenfach als Hilfsmittel im Beruf genutzt: Von Kundenbewertungen Ã¼ber Pressemitteilungen und Stellenanzeigen (Liang et al., 2025).\nSchauen wir auf die Abnehmern unserer Graduierten: Wie nutzen die Unternehmen Mitte 2025 solche Sprachmodelle? Eine aktuelle Studie (2025/12) zur Nutzung von GenAI in Unternehmen stellt ein extremes Wachstum fest sowie einen deutlichen Unterschied in der Nutzung von erfahrenen und weniger routinierten Usern (Chatterji, 2025). Der OpenAI-Report zeigt, dass die Nutzung von Sprachmodellen in Unternehmen 2025 deutlich breiter und tiefer wird: ChatGPT-Enterprise-Nachrichten stiegen im Jahresvergleich etwa um das Achtfache, gleichzeitig wachsen wiederholbare ArbeitsablÃ¤ufe stark (Nutzung von Projects/Custom GPTs ~19-fach seit Jahresbeginn; rund 20 % der Enterprise-Nachrichten laufen bereits Ã¼ber solche strukturierten Workflows). Gleichzeitig bleibt bei fortgeschritteneren Funktionen noch viel ungenutztes Potenzial. Vor allem der Mehrwert von neueren Funktionen wie DeepSearch (Delegation ausfÃ¼hrlicher Recherchen), Reasoning (schrittweises, sorgfÃ¤ltiges Antworten mit deutlich hÃ¶herer QualitÃ¤t) und Datenanalyse mit Coding Tools wie Codex werden von Praktikern mit Firmen-Lizenz noch sehr selten genutzt. Selbst unter monatlich aktiven Enterprise-Nutzern haben 19 % noch nie Datenanalyse, 14 % noch nie Reasoning und 12 % noch nie (Deep) Search genutzt (bei tÃ¤glich Aktiven sinkt das auf 3 %, 1 % und 1 %).",
    "crumbs": [
      "<span class='chapter-number'>1</span>Â  <span class='chapter-title'>Einleitung</span>"
    ]
  },
  {
    "objectID": "kapitel01.html#risiken-und-nebenwirkungen",
    "href": "kapitel01.html#risiken-und-nebenwirkungen",
    "title": "1Â  Einleitung",
    "section": "1.6 Risiken und Nebenwirkungen",
    "text": "1.6 Risiken und Nebenwirkungen\nDie Metapher mit dem E-Bike trÃ¤gt allerdings auch, was die Risiken und Nebenwirkungen angeht: Ab wann lÃ¤sst die maschinelle UnterstÃ¼tzung wichtige Muskeln verkÃ¼mmern? Solche Gefahren bestehen â€“ wie empirische Studien zeigen, erfordern die neuen Workflows der Wissensarbeit durch KI-UnterstÃ¼tzung auch neue Formen der kritischen Auseinandersetzung mit den Inhalten.\nIm Gegensatz zur einfachen Faktensuche im Internet werden hier nicht nur ein paar dornige Zweige im AufgabenbÃ¼ndel mechanisch â€˜geerntetâ€™, sondern gleich das gesamte BÃ¼ndel fertig verschnÃ¼rt bereitgestellt. Schlimmstenfalls droht das, was ein Artikel von Walsh (2025) prÃ¤gnant betitelt: â€œEverybody is cheating their way through collegeâ€. Wenn klassische Projektaufgaben quasi auf Knopfdruck erstellt werden kÃ¶nnen, droht diese Form von Leistung sinnlos zu werden. Mit etwas Lust an Dramatik kÃ¶nnen wir uns Endzeit-Szenarien vorstellen, in denen Lehrende klagend durch die TrÃ¼mmer ihrer schÃ¶nen Portfolio-PrÃ¼fungen stolpern: Die Homework-Apocalypse (Mollick, 2023).\nAber so schlimm muss es nicht werden. Es gibt schon eine Reihe plausibler AnsÃ¤tze, Lehrformate so umzugestalten, dass erwÃ¼nschte Schwierigkeiten nach Bjork & Bjork (2011) beibehalten oder sogar verstÃ¤rkt werden, trotz der (wohl praktisch unvermeidbaren) breiten allgemeinen Nutung von GenAI durch Studierende.\nWird der Umgang mit GenAI nicht geÃ¼bt, droht ein RÃ¼ckgang des kritischen Denkens. Eine Studie von 319 Wissensarbeitern zeigt, dass sich das Gewicht zwischen den Einzelaufgaben der Wissensarbeit mit LLMs verschiebt: Der Aufwand fÃ¼r die Recherchen selbst sinkt, es steigt anderseits der Aufwand fÃ¼r Management-Ã¤hnliche Aufgaben: Koordination der Einzelaufgaben fÃ¼r Mensch und Maschine, kritische PrÃ¼fung der berichteten Ergebnisse und die Integration von Ergebnissen in den Gesamtprozess (etwa zur Erstellung eines Gesamtberichtes, einer Test-Spezifikation oder eines Protokolls) (Lee et al., 2025).\nWie kann man also verhindern, dass die Studierenden kritische kognitive Aufgaben allein den KI-Systemen Ã¼bergeben? Lehre heiÃŸt in diesem Kontext auch, empfohlene Arbeitsweisen mit der neuen Technik zu Ã¼ben. Wie das gehen kann, sehen wir in den folgenden Kapiteln.",
    "crumbs": [
      "<span class='chapter-number'>1</span>Â  <span class='chapter-title'>Einleitung</span>"
    ]
  },
  {
    "objectID": "kapitel01.html#kapitelÃ¼bersicht",
    "href": "kapitel01.html#kapitelÃ¼bersicht",
    "title": "1Â  Einleitung",
    "section": "1.7 KapitelÃ¼bersicht",
    "text": "1.7 KapitelÃ¼bersicht\nIm Folgenden werden wir zunÃ¤chst einige Grundbegriffe klÃ¤ren {Kapitel 2}: Was sind groÃŸe Sprachmodelle und was ist mit Begriffen wie Token, Prompt und RAG gemeint? Welche Modelle kÃ¶nnen Lehrende aktuell nutzen und welche Empfehlungen fÃ¼r Prompts sind belastbar {Kapitel 2.5.1}? Dann fragen wir nach Zielen: Welche Art von Wissen und Methoden unterscheidet und empfiehlt die Lernforschung? Welche didaktischen Wirkmechanismen kÃ¶nnen durch KI genutzt werden, um typische Probleme der Hochschullehre anzugehen {Kapitel 3}? Im Abschnitt 4 schauen wir auf Praxisbeispiele fÃ¼r vier Anwendungsfelder von Sprachmodellen an Hochschulen {Kapitel 4}: KI als Hiwi (direkte Arbeitserleichterung), KI als Copilot (UnterstÃ¼tzung beim Schreiben und Coden) und KI als Tutor (Feedback und LernunterstÃ¼tzung) sowie KI als Simulator (Role Play und Goal Play). AbschlieÃŸend zeigen wir verschiedene Anwendungen von KI in verschiedenen Kurstypen und gehen auf neue Herausforderungen fÃ¼r PrÃ¼fungen ein {Kapitel 5}. Im Appendix finden Sie eine breite Sammlung von didaktischen Prompts und auf GenAI ausgerichteten Aufgabenstellungen von fÃ¼hrenden Hochschulen {Anhang B}",
    "crumbs": [
      "<span class='chapter-number'>1</span>Â  <span class='chapter-title'>Einleitung</span>"
    ]
  },
  {
    "objectID": "kapitel01.html#sec-forschung-details",
    "href": "kapitel01.html#sec-forschung-details",
    "title": "1Â  Einleitung",
    "section": "1.8 Schlaglichter aus der Forschung mit GenAI: Erfahrungsberichte aus den Disziplinen (GPT-5 und 5-Pro)",
    "text": "1.8 Schlaglichter aus der Forschung mit GenAI: Erfahrungsberichte aus den Disziplinen (GPT-5 und 5-Pro)\nWie und wofÃ¼r lassen sich die stÃ¤rksten Sprachmodelle aktuell in der Forschung nutzen? Hier finden Sie Schlaglichter aus den verschiedenen Disziplinen (Bubeck et al., 2025). Es sei darauf hingewiesen, dass die Forschenden teils GPT-5 (die Version fÃ¼r ca. 20 EUR im Monat) und teils GPT-5 Pro (die stÃ¤rkste Version fÃ¼r ca. 200 EUR im Monat) verwendet haben.\n\n\n\n\n\n\nMathematik / Optimierung der Schrittweite\n\n\n\n\n\nForschender: SÃ©bastien Bubeck\nThema: Untersuchung, ob GPT-5 ein kÃ¼rzlich verÃ¶ffentlichtes Resultat zur KonvexitÃ¤t von Optimierungskurven verbessern oder reproduzieren kann.\nMehrwert:\nâ€â€¦one can see that GPT-5 claims to have improved the condition from Î·â‰¤1/L to Î·â‰¤1.5/L, thus approaching the optimal bound (but not quite getting there) of Î·â‰¤1.75/L. But is this claim substantiated? It is indeed, and the proof given by GPT-5 is shown in Figure I.2, which the present author has verified to be correct.â€œ\nâ€â€¦the proof given by GPT-5 is quite different from the one in v2. Indeed, the GPT-5 proof can be viewed as a more canonical variant of the v1 proofâ€¦â€œ\nProbleme:\nâ€GPT-5 did not manage to fully rederive the v2 result, but it basically went half-way between v1 and v2.â€œ\nSchlussfolgerungen:\nâ€To say it plainly, such a result (improving from 1/L to 1.5/L) could probably have been achieved by some experts in the field in a matter of hours, and likely for most experts it would have taken a few days. This is the type of science acceleration that we will see time and again in this report.â€œ\n\n\n\n\n\n\n\n\n\nMathematik / Literaturrecherche zu ErdÅ‘s-Problemen\n\n\n\n\n\nForschende: Mehtaab Sawhney und Mark Sellke\nThema: Nutzung von GPT-5 zur Identifizierung bereits verÃ¶ffentlichter LÃ¶sungen fÃ¼r Probleme aus der ErdÅ‘s-Datenbank, die dort als â€offenâ€œ gelistet waren.\nMehrwert:\nâ€GPT-5 located references solving the above problemsâ€¦ Identifying these decades-old papers required GPT-5 to go far beyond the functionality of a search engine, and indeed to read each of these papers in detail and apply a genuine understanding of mathematics.â€œ\nâ€GPT-5 translated and explained the proofs from [Pom59] to us so that we could verify them ourselves.â€œ\nâ€GPT-5 assisted us in pointing out parts of the paper that made the intended definition clear.â€œ\nProbleme:\nâ€â€¦in some cases it was overly enthusiastic about partial progress it had found.â€œ\nSchlussfolgerungen:\nâ€GPT-5 therefore provides the practicing mathematician a new mechanism to access the collective breadth of the mathematical literature.â€œ\nâ€This provides a convenient, crowd-sourceable â€˜soft certificateâ€™ that the solution is unlikely to appear in the published literature.â€œ\n\n\n\n\n\n\n\n\n\nMathematik / LLMs als Forschungspartner\n\n\n\n\n\nForschender: Timothy Gowers\nThema: Erfahrungen bei der Nutzung von LLMs fÃ¼r mathematische Probleme im FrÃ¼hstadium.\nMehrwert:\nâ€â€¦with GPT-5 my experience has been that the references are rarely hallucinated, and even the hallucinations can turn out to be pointers to references that exist and are useful.â€œ\nâ€â€¦GPT-5 has solved them [well-defined subproblems] for me in a matter of seconds.â€œ\nâ€â€¦I have had reasonably precise ideas for solving problems that I have run past GPT-5 Pro, which has explained to me why them cannot work.â€œ\nâ€â€¦even the less good ideas of an LLM can sometimes stimulate me to make progress. (I think of this as the â€˜That clearly doesnâ€™t work â€¦ but wait a minute!â€™ phenomenon.)â€œ\nProbleme:\nâ€â€¦on the negative side, if I ask more open-ended questions, or offer more sketchy ideas for proof attempts, then that seems to encourage the more annoying characteristics of LLMs to come to the fore: they will tell me that my ideas do indeed work, and will write something that supposedly fleshes out the details but that does not withstand close scrutiny.â€œ\nâ€â€¦it gave me a hallucinated reference but by an author who had written on closely related topics.â€œ\nSchlussfolgerungen:\nâ€â€¦my current assessment of LLMs is that they are just beginning to be useful as research collaboratorsâ€¦â€œ\nâ€â€¦LLMs can speed up the process of thinking about a problem, especially if that problem is a little outside oneâ€™s primary domain of expertiseâ€¦â€œ\nâ€â€¦they are capable of playing this knowledgeable-research-supervisor role with meâ€¦ but that they are not yet at the levelâ€¦ at which a human mathematicianâ€¦ would ask for joint authorship.â€œ\n\n\n\n\n\n\n\n\n\nMathematik / Neue Resultate zum ErdÅ‘s-Problem #848\n\n\n\n\n\nForschende: Mehtaab Sawhney und Mark Sellke\nThema: LÃ¶sung eines offenen Problems Ã¼ber Teilmengen von {1, â€¦, N}, bei denen ab+1 nicht quadratfrei ist.\nMehrwert:\nâ€GPT-5 put forward the new idea that led to our solutionâ€¦â€œ\nâ€The idea suggested by GPT-5â€™s replyâ€¦ gives a method to use any single number b âˆˆ A to obtain similarly harsh constraints on all other a âˆˆ A.â€œ\nProbleme:\nâ€GPT-5 made attempts in this direction but had numerous errors in its implementation (as can be seen in the transcript).â€œ\nâ€â€¦current models remain limited in perceiving the â€˜negative spaceâ€™ of mathematics. While models are able to suggest plausible proof strategies, they often do not realize certain â€˜obviousâ€™ examples which block progress, and are overly confident in the power of existing methods.â€œ\nSchlussfolgerungen:\nâ€â€¦GPT-5 has the ability to serve as an effective mathematical assistant, capable of recalling relevant lemmas, identifying analogies and locating relevant results from vague, ill-specified prompts.â€œ\n\n\n\n\n\n\n\n\n\nMathematik / Graphentheorie: Teilgraphen-ZÃ¤hlungen\n\n\n\n\n\nForschende: SÃ©bastien Bubeck, Mark Sellke und Steven Yin\nThema: Beweis von Ungleichungen fÃ¼r die Anzahl bestimmter induzierter Teilgraphen in BÃ¤umen.\nMehrwert:\nâ€Both of GPT-5â€™s proofs are quite different from any of the arguments in [BL16; Bub+16].â€œ\nâ€â€¦GPT-5â€™s proof is short and elegant, and based on a somewhat miraculous identity.â€œ\nProbleme:\nâ€A few incorrect proofs were also generated and rejected by human checking.â€œ\nSchlussfolgerungen:\nâ€â€¦GPT-5 was able to reprove the first inequality, and then build on this to also prove the second (open) inequality.â€œ\n\n\n\n\n\n\n\n\n\nMathematik / Lerntheorie: Dynamische Netzwerke\n\n\n\n\n\nForschende: SÃ©bastien Bubeck, Mark Sellke und Steven Yin\nThema: Identifizierbarkeit des Parameters w in einem modifizierten prÃ¤ferenziellen Bindungsprozess.\nMehrwert:\nâ€GPT-5 was able to prove that w is indeed identifiableâ€¦â€œ\nâ€â€¦this illustrates that GPT-5â€™s decision to focus on the quantity L(t) is already non-obvious.â€œ\nProbleme:\nâ€â€¦when we asked (an unscaffolded) GPT-5 to provide more detail for these latter arguments, it made several false startsâ€¦ After some human pushback, GPT-5 eventually came up with a correct but unnecessarily complicated proofâ€¦â€œ\nSchlussfolgerungen:\nâ€While all major proof ideas below are due to GPT-5, a few details of proof writing are human-supplied.â€œ\n\n\n\n\n\n\n\n\n\nPhysik / Symmetrien Schwarzer LÃ¶cher\n\n\n\n\n\nForschender: Alex Lupsasca\nThema: (Re-)Derivation nichttrivialer Lie-Punkt-Symmetrien der Wellengleichung in einer Kerr-Raumzeit.\nMehrwert:\nâ€Within 18 minutes, the model produced the correct curved-space generators closing into SL(2, R)â€¦â€œ\nâ€The final generators are too structured to be a lucky guess. The model likely executed (implicitly) a mix of: recognizing conformal invariance in the flat equation, hypothesizing a curved analogue, and/or exploiting a coordinate mapâ€¦â€œ\nProbleme:\nâ€The model initially failed on the curved-space problem, but then succeeded after a flat-space warm-upâ€¦â€œ\nâ€What GPT-5 got wrong (along the way). The cold start on Eq. (I.1) incorrectly concluded â€˜no symmetries.â€™â€œ\nSchlussfolgerungen:\nâ€AI as a symmetry engine. With minimal domain scaffolding, current models can carry out nontrivial Lie-symmetry discovery for PDEs with non-constant coefficients.â€œ\nâ€Research velocity. Given such capabilities, the time from idea to publishable result can compress from months to days once the right prompts and scaffolds are in place.â€œ\nâ€â€¦contemporary LLMs can act as practical assistants for symmetry discovery and analytic structure mining in theoretical physics.â€œ\n\n\n\n\n\n\n\n\n\nPhysik / Fusionsforschung: Thermonukleare Brandwellen\n\n\n\n\n\nForschender: Brian Keith Spears\nThema: Entwicklung eines reduzierten physikalischen Modells fÃ¼r thermonuklearer Brandwellen in ICF-Kapseln.\nMehrwert:\nâ€GPT-5 is quite good at this kind of model development and setup. It required little intervention on my part to make this plausible and complete.â€œ\nâ€The point is that I can now deliver in minutes as if I were at the highest level I have ever been at for this kind of work. â€¦ to have it in minutes is remarkable.â€œ\nâ€However, when re-prompted to examine a pathological result or null signal, GPT-5 offered quite sophisticated solutions, including different implementations of FFTs to prevent aliasing, improved resolutions to track burn frontsâ€¦â€œ\nProbleme:\nâ€GPT-5 was a bad designer, offering results that were null, noisy, or invalid (NaNs), while claiming that glory had been achieved.â€œ\nâ€The model, in its eagerness to please, often introduces numerical duct tape to smooth over a thorny issue, silently swaps out detailed numerical solves for approximations with trends it knows I want, and confidently declares victory when numerical signals are still obviously noise.â€œ\nSchlussfolgerungen:\nâ€â€¦executing this workflow from concept, to numerical exploration, to theoretical supporting statement in hours is rather amazing.â€œ\nâ€I feel like my 6 hours of work here yielded something I could have done over a month or two with a very good pair of postdocsâ€¦ That is a compression of about a factor of 1000.â€œ\nâ€â€¦users must be expert enough to catch the oversimplifications, must persist to get the model to reconsider, and must be vigilantâ€¦â€œ\n\n\n\n\n\n\n\n\n\nPhysik / Astrophysik: Gravitationsstrahlung\n\n\n\n\n\nForschender: Robert Scherrer\nThema: Analytische Integration des Leistungsspektrums von Garfinkle-Vachaspati-Strings.\nMehrwert:\nâ€After reasoning for 40 minutes, GPT-5 Pro produced a result for large odd n identical to the asymptotic result I had previously derivedâ€¦ It used a completely different method of solution from my own.â€œ\nâ€GPT-5 Pro also gave the leading order correction term to this formulaâ€¦ I was not aware of this correction termâ€¦â€œ\nProbleme:\nâ€The program hung up for quite a long time, giving me no details about its thought process. After several hours I became frustrated and killed it.â€œ\nSchlussfolgerungen:\nâ€GPT-5 Pro is capable of solving complex analytic integrations that are beyond the reach of symbolic manipulation programs such as Mathematica.â€œ\n\n\n\n\n\n\n\n\n\nBiologie / Immunologische In-vitro-Experimente\n\n\n\n\n\nForschender: Derya Unutmaz\nThema: Mechanistische Analyse der Wirkung von 2-DG auf die Differenzierung von T-Zellen und Vorhersage der ZytotoxizitÃ¤t von CAR-T-Zellen.\nMehrwert:\nâ€GPT-5 Pro provided the key mechanism that could explain these findings and, in addition, made highly relevant experimental suggestions.â€œ\nâ€The mechanistic insight and further hypothesis to dissect these findings were highly valuable and not immediately obvious, despite our deep expertise in this field.â€œ\nâ€GPT-5 Pro perfectly analyzed and described the data in the figureâ€¦â€œ\nâ€â€¦GPT-5 Pro made sufficient contributions to this work to the extent that it would warrant its inclusion as a co-author in this new study.â€œ\nProbleme:\nâ€â€¦a caveat for this suggestion is that GPT-5 Pro may have known about this finding and made the connection with this result.â€œ\nSchlussfolgerungen:\nâ€GPT-5 Pro can function as a true mechanistic co-investigator in biomedical research, compressing months of reasoning into minutes, uncovering non-obvious hypotheses, and directly shaping experimentally testable strategies.â€œ\nâ€Precision interpretation of complex biology. GPT-5 Pro rapidly connected the observed phenotypes to a mechanistic hypothesisâ€¦â€œ\nâ€The net effect will be a much higher discovery rate per experiment and a shorter route from observation to discovery to intervention, thus profoundly accelerating the biomedical scientific process.â€œ\n\n\n\n\n\n\n\n\n\nInformatik / Geometrie: Literaturrecherche zur Optimierung\n\n\n\n\n\nForschender: Nikita Zhivotovskiy\nThema: Suche nach Anwendungen und verwandter Literatur fÃ¼r eine neue geometrische Aussage Ã¼ber â€Î±-ratio coversâ€œ.\nMehrwert:\nâ€â€¦given only a core mathematical statement, GPT-5 can rapidly surface nontrivial and technically aligned links across areasâ€¦ providing context for new applications.â€œ\nâ€At first sightâ€¦ this seems unrelated to Theorem II.1.1 and could be mistaken for a hallucination. However, unpacking their proof shows that their result can be phrased as a coordinatewise (1+Ïµ)-ratio coverâ€¦â€œ\nSchlussfolgerungen:\nâ€â€¦GPT-5 can rapidly surface nontrivial and technically aligned links across areasâ€¦ providing context for new applications.â€œ\n\n\n\n\n\n\n\n\n\nInformatik / Schranken fÃ¼r Online-Algorithmen\n\n\n\n\n\nForschender: Christian Coester\nThema: Verbesserung der unteren Schranken fÃ¼r das Problem des â€Convex Body Chasingâ€œ.\nMehrwert:\nâ€Given a single short prompt, GPT-5 produced a rather non-obvious counter-example against the algorithm.â€œ\nâ€GPT-5 suggested a much simpler and cleaner solution: trigger the switch once the algorithm is below the semicircle at distance â‰¥ Îµ from pt.Â This avoids the freezeâ€¦ The idea seems obvious in hindsight, yet far more elegantâ€¦â€œ\nâ€â€¦the inspiring appearance of the number Ï€/2 in its reasoning traceâ€¦â€œ\nProbleme:\nâ€The argument it gives for this [feasibility of the construction] is actually incorrect, but a correct argument is easy to seeâ€¦â€œ\nâ€â€¦it initially failed to understand how viewing the problem in continuous time could yield stronger bounds, and upon later attemptsâ€¦ it presented arguments containing serious flaws.â€œ\nâ€â€¦GPT-5â€™s responses also contained some errors, but these were easy to fix for a human, overall accelerating the research process.â€œ\nSchlussfolgerungen:\nâ€Perhaps the most impressive part is its proof refuting the follow-the-leader algorithm, produced from a single prompt without any guidance on how to approach the task.â€œ\n\n\n\n\n\n\n\n\n\nInformatik / Clique-avoiding Codes (Warnbeispiel)\n\n\n\n\n\nForschende: Venkatesan Guruswami und Parikshit Gopalan\nThema: Suche nach einer unteren Schranke fÃ¼r die Co-Dimension von Codes, die Clique-Indikatoren vermeiden.\nMehrwert:\nKein expliziter Mehrwert im Text auÃŸer der Reproduktion bekannter Beweise.\nProbleme:\nâ€Initially, it was convinced that this bound was tight (up to an additive constant), and tried to convince us of this using a sequence of buggy arguments, resorting to linear algebra and proof by authorityâ€¦â€œ\nâ€The most amusing was a hallucinated response to the effect that one of us had asked this question on TCS Stack Exchangeâ€¦ Both these claims are incorrect.â€œ\nâ€â€¦it appears that GPT-5 reproduced Alonâ€™s proof and passed it along to us without realizing its source.â€œ\nSchlussfolgerungen:\nâ€Our experience illustrates a pitfall in using AI: although GPT-5 possesses enormous internal knowledgeâ€¦ it may not always report the original information sources accurately. This has the potential to deceive even seasoned researchers into thinking their findings are novel.â€œ\n\n\n\nLink zurÃ¼ck zum FlieÃŸtext: {AbbildungÂ 1.9}",
    "crumbs": [
      "<span class='chapter-number'>1</span>Â  <span class='chapter-title'>Einleitung</span>"
    ]
  }
]