---
title: "Einleitung"
bibliography: references.json
csl: apa.csl
lang: de
reference-section-title: "Literaturverzeichnis"
format:
  html:
    toc: true
    toc-location: right
    number-sections: true
---

## KI als Hilfe für die Lehre
**Wie kann uns generative künstliche Intelligenz** (KI) **in der Lehre helfen**? Hoffnung besteht hier für zwei typische Probleme: Erstens haben Studierende **individuelle Bedürfnisse**, aber wir haben nur **begrenzte Zeit**, auf diese einzugehen. Wie können wir Einzelne möglichst intensiv fördern, ohne vor Arbeit unterzugehen? Zweitens ist der **Aufwand gerade für effektive Lehrmethoden** oft sehr hoch, so etwa für häufige niedrigschwellige Tests, oder individuelles Feedback zu Studienarbeiten [s. etwa @hattie2023, Kap. 13; @brown2014a]. Wer lehrt, fühlt sich aus Zeit- und Stoffdruck oft gezwungen, Abstriche von idealen Lehrsetups zu machen [@henderson2007a; @schmidt2005a, S. 104–105]. Gerade Lehrmethoden, die didaktisch sinnvoll, aber mit höherem Aufwand verbunden sind, drohen dabei auf der Strecke zu bleiben [s. etwa @dunlosky2013; @roediger2012b].


::: {.callout-tip title="Schnelles Brainstorming mit der KI"}

{{< include _relevance-widget.qmd >}}

:::


**Für die Lehre** erschließen sich durch die großen KI-Sprachmodelle (LLM = Large Language Models) neue Möglichkeiten. Sie sind, wie es eine Analyse des MIT Professors Andrew McAfee auf den Punkt bringt „**generally faster**" [@mcafee2024]. Lehrende können mit KI-Unterstützung etwa deutlich schneller eine Recherche durchführen, ein Set von Übungsaufgaben erstellen, mehrere Anwendungsbeispiele pro Konzept hinzufügen, Quizfragen zur schnellen Lernüberprüfung generieren, oder mit den Studierenden Rollenspiele durchführen [@meincke2024a; @mollick2023a]. Der Berg ist noch da, aber mit dem E-Bike kommt man weiter.



![GenAI als Kraftverstärker](images/ai-ebike-gemini.jpg){#fig-ai-ebike fig-align="center"}

## Was 2025 möglich ist: Praktische Beispiele für Recherche, Übungsaufgaben, Erklärungen
**Schauen wir uns einige praktische Beispiele an**. Wir wollen wissen, was es für aktuelle Fallstudien zu Lieferketten-Problemen gibt. Als Recherche-Hiwi lassen wir das Sprachmodell auf akademischen Blogs und Fachzeitschriften nach aktuellen Beispielen suchen. 

![Recherche-Hiwi-Denkprozess](images/script01-dr-plan.svg){#fig-deep-research2 fig-align="center"}


Solche Suchen führen Sprachmodelle mittlerweile in mehreren Schritten durch. Hier sehen wir den "Denkprozess".

![Recherche-Hiwi-Denkprozess](images/deep-research-recherche-aktuelle-lieferkettenprobleme-denkprozess-geminipro.svg){#fig-deep-research2 fig-align="center"}

Hier das Ergebnis: Ein erster ausformulierter Bericht von 13 Seiten nach ca. 5 Minuten Recherche. Die Abbildung zeigt den Auszug mit der tabellarischen Zusammenfassung der Forschungsartikel.

![Recherche-Hiwi-Ergebnis](images/deep-research-recherche-aktuelle-lieferkettenprobleme-ergebnis-auszug-geminipro.svg){#fig-deep-research3 fig-align="center"}

Wie kann man Konzepte einfach und mit Beispielen erklären? Wir bitten ChatGPT um Vorschläge zu zwei Konzepten aus der Wissenschaftstheorie: Der Duham-Quines-These, die beschreibt, warum Wissenschaft nur graduell, mosaik-bauend zu Erkenntnissen kommen kann und Mayo's Konzept der "Strengen Tests" (severe testing), nach denen man wissenschaftliche Aussagen graduell auf ihre Belastbarkeit bewerten kann.

![Recherche-Hiwi-Ergebnis](images/konzepterklaerungen-beispiele-gpt5-2.svg){#fig-deep-research3 fig-align="center"}
Wie könnte man das in einem Test abfragen? Auch hierzu bitten wir ChatGPT (5.2) um Vorschläge.

![Recherche-Hiwi-Ergebnis](images/multiple-choice-test-beispiele-gen-chatgpt.svg){#fig-deep-research3 fig-align="center"}
Ende 2025 kann GenAI **professionelle Folien-Präsentationen sehr schnell erstellen.** Sprachmodelle wie Google's *Gemini* können mittlerweile auch Text erstellen [@willison2025a] und damit auch komplexe Infografiken (und Folien). Das Sprachmodell *Claude* liefert eine Beschreibung ('Skill') von 3500 Wörtern mit, die dem Sprachmodell genau erklärt, wie es Schritt für Schritt eine PowerPoint Präsentation erstellt und testet [@anthropic2025a]. 

Eine grafisch ansprechende Präsentation zu erstellen ist recht zeitaufwändig - und Brillianz als Grafiker gehört vielleicht auch nicht zu den Kernkompetenzen von Lehrenden. Wir bitten daher Gemini (NotebookLM) und Claude, uns basierend auf Überblicksartikeln zwei Präsentationen zu erstellen: Eine zur Frage, welche Lerntechniken für Studierende besonders gut funktionieren (s. @kapitel03) und die zweite zur Frage, welche Best-Practices es gibt, Aufgabenstellungen mit der intensiven Nutzung von GenAI zu verbinden (s. @kapitel06).

Zu integrierten Aufgaben mit GenAI liefert uns das Sprachmodell nach etwa 5 Minuten 15 sehr schicke Folien (NotebookLM, basierend auf 13 Quellen-PDFs).

![Recherche-Hiwi-Ergebnis](images/genai-integrierte-aufgaben-gen-notebooklm.svg){#fig-deep-research3 fig-align="center"}


Zu Lerntechniken erhielten wir nach etwa 5 Minuten basierend auf einem Fachartikel, 8 professionelle Folien (mit kleineren Formatierungsfehlern, etwa Zeilenumbrüchen).

![Recherche-Hiwi-Ergebnis](images/lerntechniken-ppt-gen-claude-2025-12.svg){#fig-deep-research3 fig-align="center"}


## Nutzung von GenAI in der Forschung

**Immer mehr Aspekte von typischen Forschungstätigkeiten** – ein zentraler Ausbildungsinhalt der Hochschulen – können **von der KI übernommen** werden und zwar auf hohem Niveau. Vorbei sind die Zeiten, in denen wir die banalen Schreibprodukte der KI nur belächeln konnten. Ein Überblicksartikel des Forschers Anton Korinek im renommierten Journal of Economic Literature vom Dezember 2024 fasst die deutlich höhere Qualität des Outputs zusammen: „die derzeitige Generation von LLMs ist in hohem Maße in der Lage, die wichtigsten Erkenntnisse von Forschungsarbeiten zu verarbeiten" [@korinek2024b, S. 3, Übersetzung RB mit DeepL]. Die professionelle Nutzung ist hier teils noch weiter: So demonstrierte etwa Google 2025 ein mehrstufiges Modell für die Pharma-Forschung („**AI co-scientist**"), das den Forschenden zeitintensive Zwischenschritte abnimmt [@gottweis2025a]. Auch im Peer-Review werden zunehmend Sprachmodelle eingesetzt – mit allen Vor- und Nachteilen, die das mit sich bringt [@naddaf2025]. Wie wir in den späteren Kapiteln sehen, experimentieren Hochschulen weltweit intensiv mit den neuen Möglichkeiten für Lehre und Forschung.

**Wie ein Laie im Cockpit eines Verkehrsflugzeugs** fällt es Lehrenden teils schwer zu entscheiden, welche der neuen Möglichkeiten sinnvoll für die eigene Lehre sind. Zunächst gibt es immer wieder Hype-Zyklen: Virtuelle Realität, Blockchain, Roboter, Internet der Dinge... [@allen2024], viel wurde schon ins Rampenlicht gestellt und dann wieder vergessen. Es werden gerade für die Lehre regelmäßig neue Technologien beworben und gehyped, so dass Lehrende schon aus Selbstschutz eine gewisse Grundskepsis mitbringen (sollten), ob ein neuer technischer Zugang wirklich auch didaktischen Nutzen bringt [für eine wirkungsbasierte Übersicht von Technologien s. etwa @hattie2023, Kap.14].  Lehrende sind außderdem paradoxen Spannung zwischen den Identitäten als Experten und Innovatoren/Faszilitatoren ausgesetzt [@fischer2024]: Ausgestrahlte Kompetenz ist einerseits Teil ihres Wertversprechens, was zur Abwehr ungewohnter Technologien einlädt. Andererseits sollen Lehrende auch zu Neugier und Innovation anleiten und insofern den Umgang mit neuen, auch für die Lehrenden selbst ungewohnten Technologien erleichtern.


![Neue technologische Chancen und Herausforderungen mit GenAI. *Quelle:* Mit Gemini generiert.](images/ai-as-new-tech-gemini.jpg){#fig-ki-herausforderung fig-align="center"} 


## Aktuelle Weiterentwicklungen der Sprachmodelle
2025 lernen die großen Sprachmodelle noch besser "nachzudenken" - sogenannte "Reasoning"-Modelle werden breit verfügbar. Aus didaktischer Sicht ist das auch deshalb interessant, weil man Lernenden jetzt Denkstrategien vorführen kann, speziell Hypothesenbildung und Prüfung (etwa [@brown2014a], S.90-94, "generative learning", oder die Studien von Willemain zur Modellierung von Problemen durch Experten [@willemain1994; @willemain1995b]). Ein neuer Ansatzpunkt zur Verbesserung der Ergebnisse wird hier genutzt [@grootendorst2025] : Statt (nur) mehr Ressourcen in das Training immer komplexerer Modelle zu investieren (train-time compute), werden die Modelle jetzt dazu angehalten, länger "nachzudenken", bevor sie ein Ergebnis anbieten (test-time compute). Hinter diesem "besseren Nachdenken" stehen zwei Prinzipien [@snell2024; @grootendorst2025]: Die Sprachmodelle werden einerseits instruiert, schrittweise vorzugehen (Input-Verbesserung der Vorschlagsverteilung) und andererseits dazu angehalten, die eigenen Antworten zu prüfen (Output-Verbesserung, Verifizierer). Die Sprachmodelle führen insofern jetzt teils selbstständig Prüfschritte durch, die man früher durch komplexe Prompts induziert hätte. Ende 2025 sehen wir in der Konsequenz, dass die Sprachbots immer selbstständiger werden, man spricht vom "Agentic Turn"[@willison2025; @steinberger2025; @mollick2025]: Als Nutzer solcher Reasoning Modelle verbringen wir jetzt weniger Zeit damit, über die 'Zaubersprüche' einzelner Prompts nachzudenken und mehr Zeit in 'Mitarbeitergesprächen' - Anleitung und Kritik der digitalen "Agenten" - Sprachmodelle, die selbstständig und auf hohem Niveau mehrere Arbeitsschritte durchführen. Insgesamt steigt seit 2023 die Qualität der Aufgaben, die Sprachmodelle erledigen können, rasant. Empirische Untersuchungen zeigen, dass die Sprachmodelle immer längere Aufgaben auf hohem Niveau erledigen können [@kwa2025a].

Die neuen Modelle sind außderdem günstiger und effizienter geworden: die Kosten pro Interaktion sind stark gesunken. Illustratives Beispiel: Eine Millionen Token kosteten mit GPT-4 noch 50 Dollar, jetzt nur noch 14 Cent [@invertedstone2025; @mollick2025a]. Das Modell halluziniert (weiterhin, also Vorsicht, aber) deutlich seltener als seine Vorgänger: OpenAI gibt hier ca. 1% Halluzinationen der Antworten statt ca. 5% bei Vorgängermodellen (o3, 4o) an, je nach Komplexität der Frage und erlaubter „Bedenkzeit" [@openai2025b].

Weiterhin hat sich die **Internetsuche mit LLMs deutlich verbessert**. Während man früher noch oft über sinnlose oder erfundene Ergebnisse lachte, stellt die Suche von ChatGPT, Google/Gemini, oder speziellen Suchanbietern wie Perplexity mittlerweile eine große Zeitersparnis dar: „a useful tool to provide up-to-date answers to questions that are grounded in facts found on the internet, together with the requisite citations—a crucial capability for researchers" [@korinek2024b, S. 3]. Das gilt zunehmend für die stärksten allgemeinen Modelle und erst recht für Anbieter, die auf Forschungsrecherche (und Studierende) spezialisiert sind, wie Elicit oder Paperpal. Auch breite Internet-Recherchen und Textproduktionen sind zunehmend komplett delegierbar („deep research"), mit deutlichen Auswirkungen auf den Arbeitsprozess in der Wissensarbeit (s. etwa @schwarcz2025a für juristische Recherchen, @korinek2024b für Ökonomie und @liang2025a für PR-Tätigkeiten).

## Wie nutzen Studierende und Lehrende GenAI?

Auch **Studierende nutzen bereits umfangreich Sprachmodelle** für einen breiten Strauß an Zielen (s. @fig-llm-nutzung). Eine Auswertung der KI-Forscher des KI-Unternehmens *Anthropic* von 1 Millionen anonymisierten Chats zwischen Usern mit Universitätskonto und dem KI Bot zeigt typische Muster der Nutzung [@handa2025c]: Studierende setzen das Sprachmodell **vor allem für anspruchsvolle Tätigkeiten** ein, wie das **Erstellen neuer Inhalte und das Analysieren komplexer Themen**, was höheren Ebenen der Bloomschen Taxonomie entspricht (s. @fig-llm-nutzung-bloom). Daraus ergibt sich die Herausforderung sicherzustellen, dass Studierende wesentliche kognitive Aufgaben nicht vollständig an GenAI delegieren: Aufgaben müssen angepasst und der verantwortungsvolle Umgang mit der Technik muss eingeübt werden.

![Wofür Studierende LLMs nutzen. *Quelle:* @handa2025c](images/script01-01.svg){#fig-llm-nutzung fig-align="center"}

**Auch außerhalb der Hochschule steigt die Nutzung**. Eine Reihe von Studien zeigen **erhöhte Produktivität von Büroarbeitenden mit LLM-Unterstützung**: der Kundensupport arbeitet 15% schneller, wenn das Sprachmodell Antwortoptionen vorschlägt und Verweise auf interne technische Dokumentation anbietet [@brynjolfsson2025], Programmierer programmieren schneller [@peng2023a], Consultants sind produktiver bei komplexen Beratungsprojekten [@dellacqua2023a] und Sprachmodelle wie ChatGPT können eine Vielzahl kleiner Aufgaben beschleunigen [@handa2025c] und werden insofern gerade zur Texterstellung schon millionenfach als Hilfsmittel im Beruf genutzt: Von Kundenbewertungen über Pressemitteilungen und Stellenanzeigen [@liang2025a].


![Schwerpunkte der Nutzung von LLMs (Claude) durch Studierende nach der Bloom'schen Taxonomie. Quelle: @handa2025c](images/script01-02.svg){#fig-llm-nutzung-bloom}

Die zunehmende Verwendung von KI in der Lehre hat gute Gründe. Wie oft eine neue Technologie genutzt wird, hängt nach dem **Technology Acceptance Model** (TAM, s. @fig-tam) von der **wahrgenommenen Benutzerfreundlichkeit** (perceived ease of use) und der **wahrgenommenen Nützlichkeit** (perceived usefulness) ab [@marangunic2015b]. Generative KI wie ChatGPT decken sichtlich beide Aspekte ab: Sie sind einfach zu nutzen [@kestin2025; @lee2025a; @monib2025a; @naddaf2025c] und erzeugen einen deutlichen Mehrwert, wie Studierende und Lehrende in einer Vielzahl von Umfragen der letzten zwei Jahren berichten [@heidt2025a; @morgan2024a; @ou2024a]. Lehrende ziehen nach: Meta-Untersuchungen zeigen ein extremes Wachstum an Publikationen zur Nutzung von LLM im Hochschulalltag [@ma2025a; @ogunleye2024a].


![Gründe für die Verbreitung von GenAI nach dem Technologie-Akzeptanz-Modell](images/tam-diagram-mermaid.svg){#fig-tam fig-align="center"}


## Risiken und Nebenwirkungen

Die Metapher mit dem E-Bike trägt allerdings auch, was die **Risiken und Nebenwirkungen** angeht: Ab wann lässt die maschinelle Unterstützung wichtige Muskeln verkümmern? Solche Gefahren bestehen – wie empirische Studien zeigen, erfordern die neuen Workflows der Wissensarbeit durch KI-Unterstützung auch neue Formen der kritischen Auseinandersetzung mit den Inhalten. 

**Studierende nutzen GenAI bereits umfangreich für anspruchsvolle Aufgaben.** Die Analyse von 1 Millionen anonymisierten Studierenden-Chats durch Anthropic [@handa2025c] zeigt einerseits, dass **Studierende das LLM vor allem für kognitiv anspruchsvollere Aufgaben einsetzen**, vor allem in den Kategorien „Creating" und „Analyzing" (s. @fig-bloom-taxonomie). 

Im Gegensatz zur einfachen Faktensuche im Internet werden hier nicht nur ein paar dornige Zweige im Aufgabenbündel mechanisch 'geerntet', sondern gleich das gesamte Bündel fertig verschnürt bereitgestellt. Schlimmstenfalls droht das, was ein Artikel von Walsh @walsh2025a prägnant betitelt: "Everybody is cheating their way through college". Wenn klassische Projektaufgaben quasi auf Knopfdruck erstellt werden können, droht diese Form von Leistung sinnlos zu werden. Mit etwas Lust an Dramatik können wir uns Endzeit-Szenarien vorstellen, in denen Lehrende klagend durch die Trümmer ihrer schönen Portfolio-Prüfungen stolpern: Die Homework-Apocalypse [@mollick2023d].

**Aber so schlimm muss es nicht werden.** Es gibt schon eine Reihe plausibler Ansätze, Lehrformate so umzugestalten, dass erwünschte Schwierigkeiten nach @bjork2011 beibehalten oder sogar verstärkt werden, trotz der (wohl praktisch unvermeidbaren) breiten allgemeinen Nutung von GenAI durch Studierende. 

**Wird der Umgang mit GenAI nicht geübt, droht ein Rückgang des kritischen Denkens.** Eine Studie von 319 Wissensarbeitern zeigt, dass sich das **Gewicht zwischen den Einzelaufgaben der Wissensarbeit mit LLMs verschiebt**: Der Aufwand für die Recherchen selbst sinkt, es steigt anderseits der Aufwand für Management-ähnliche Aufgaben: Koordination der Einzelaufgaben für Mensch und Maschine, kritische Prüfung der berichteten Ergebnisse und die Integration von Ergebnissen in den Gesamtprozess (etwa zur Erstellung eines Gesamtberichtes, einer Test-Spezifikation oder eines Protokolls) [@lee2025a]. 

Wie kann man also verhindern, dass die Studierenden kritische kognitive Aufgaben allein den KI-Systemen übergeben? Lehre heißt in diesem Kontext auch, empfohlene Arbeitsweisen mit der neuen Technik zu üben. Wie das gehen kann, sehen wir in den folgenden Kapiteln.

## Kapitelübersicht

Im Folgenden werden wir zunächst einige **Grundbegriffe** klären: Was sind große Sprachmodelle und was ist mit Begriffen wie Token, Prompt und RAG gemeint? **Welche Modelle** können Lehrende aktuell nutzen und welche **Empfehlungen für Prompts** sind belastbar (Abschnitt 2.5)? Dann fragen wir nach **Zielen**: Welche Art von Wissen und Methoden unterscheidet und empfiehlt die Lernforschung? Welche **didaktischen Wirkmechanismen** können durch KI genutzt werden, um typische Probleme der Hochschullehre anzugehen (Abschnitt 3)? Im Abschnitt 4 schauen wir auf **Praxisbeispiele** für vier Anwendungsfelder von Sprachmodellen an Hochschulen: **KI als Hiwi** (direkte Arbeitserleichterung), **KI als Copilot** (Unterstützung beim Schreiben und Coden) und **KI als Tutor** (Feedback und Lernunterstützung) sowie **KI als Simulator** (Role Play und Goal Play). Abschließend zeigen wir verschiedene Anwendungen von KI in verschiedenen Kurstypen und gehen auf neue **Herausforderungen für Prüfungen** ein (Abschnitt 5). Im Appendix finden Sie eine breite Sammlung von didaktischen Prompts und auf GenAI ausgerichteten Aufgabenstellungen von führenden Hochschulen.

