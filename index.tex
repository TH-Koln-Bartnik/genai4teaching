% Options for packages loaded elsewhere
% Options for packages loaded elsewhere
\PassOptionsToPackage{unicode}{hyperref}
\PassOptionsToPackage{hyphens}{url}
\PassOptionsToPackage{dvipsnames,svgnames,x11names}{xcolor}
%
\documentclass[
  ngerman,
  letterpaper,
  DIV=11]{scrreprt}
\usepackage{xcolor}
\usepackage{amsmath,amssymb}
\setcounter{secnumdepth}{4}
\usepackage{iftex}
\ifPDFTeX
  \usepackage[T1]{fontenc}
  \usepackage[utf8]{inputenc}
  \usepackage{textcomp} % provide euro and other symbols
\else % if luatex or xetex
  \usepackage{unicode-math} % this also loads fontspec
  \defaultfontfeatures{Scale=MatchLowercase}
  \defaultfontfeatures[\rmfamily]{Ligatures=TeX,Scale=1}
\fi
\usepackage{lmodern}
\ifPDFTeX\else
  % xetex/luatex font selection
\fi
% Use upquote if available, for straight quotes in verbatim environments
\IfFileExists{upquote.sty}{\usepackage{upquote}}{}
\IfFileExists{microtype.sty}{% use microtype if available
  \usepackage[]{microtype}
  \UseMicrotypeSet[protrusion]{basicmath} % disable protrusion for tt fonts
}{}
\makeatletter
\@ifundefined{KOMAClassName}{% if non-KOMA class
  \IfFileExists{parskip.sty}{%
    \usepackage{parskip}
  }{% else
    \setlength{\parindent}{0pt}
    \setlength{\parskip}{6pt plus 2pt minus 1pt}}
}{% if KOMA class
  \KOMAoptions{parskip=half}}
\makeatother
% Make \paragraph and \subparagraph free-standing
\makeatletter
\ifx\paragraph\undefined\else
  \let\oldparagraph\paragraph
  \renewcommand{\paragraph}{
    \@ifstar
      \xxxParagraphStar
      \xxxParagraphNoStar
  }
  \newcommand{\xxxParagraphStar}[1]{\oldparagraph*{#1}\mbox{}}
  \newcommand{\xxxParagraphNoStar}[1]{\oldparagraph{#1}\mbox{}}
\fi
\ifx\subparagraph\undefined\else
  \let\oldsubparagraph\subparagraph
  \renewcommand{\subparagraph}{
    \@ifstar
      \xxxSubParagraphStar
      \xxxSubParagraphNoStar
  }
  \newcommand{\xxxSubParagraphStar}[1]{\oldsubparagraph*{#1}\mbox{}}
  \newcommand{\xxxSubParagraphNoStar}[1]{\oldsubparagraph{#1}\mbox{}}
\fi
\makeatother

\usepackage{color}
\usepackage{fancyvrb}
\newcommand{\VerbBar}{|}
\newcommand{\VERB}{\Verb[commandchars=\\\{\}]}
\DefineVerbatimEnvironment{Highlighting}{Verbatim}{commandchars=\\\{\}}
% Add ',fontsize=\small' for more characters per line
\usepackage{framed}
\definecolor{shadecolor}{RGB}{241,243,245}
\newenvironment{Shaded}{\begin{snugshade}}{\end{snugshade}}
\newcommand{\AlertTok}[1]{\textcolor[rgb]{0.68,0.00,0.00}{#1}}
\newcommand{\AnnotationTok}[1]{\textcolor[rgb]{0.37,0.37,0.37}{#1}}
\newcommand{\AttributeTok}[1]{\textcolor[rgb]{0.40,0.45,0.13}{#1}}
\newcommand{\BaseNTok}[1]{\textcolor[rgb]{0.68,0.00,0.00}{#1}}
\newcommand{\BuiltInTok}[1]{\textcolor[rgb]{0.00,0.23,0.31}{#1}}
\newcommand{\CharTok}[1]{\textcolor[rgb]{0.13,0.47,0.30}{#1}}
\newcommand{\CommentTok}[1]{\textcolor[rgb]{0.37,0.37,0.37}{#1}}
\newcommand{\CommentVarTok}[1]{\textcolor[rgb]{0.37,0.37,0.37}{\textit{#1}}}
\newcommand{\ConstantTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{#1}}
\newcommand{\ControlFlowTok}[1]{\textcolor[rgb]{0.00,0.23,0.31}{\textbf{#1}}}
\newcommand{\DataTypeTok}[1]{\textcolor[rgb]{0.68,0.00,0.00}{#1}}
\newcommand{\DecValTok}[1]{\textcolor[rgb]{0.68,0.00,0.00}{#1}}
\newcommand{\DocumentationTok}[1]{\textcolor[rgb]{0.37,0.37,0.37}{\textit{#1}}}
\newcommand{\ErrorTok}[1]{\textcolor[rgb]{0.68,0.00,0.00}{#1}}
\newcommand{\ExtensionTok}[1]{\textcolor[rgb]{0.00,0.23,0.31}{#1}}
\newcommand{\FloatTok}[1]{\textcolor[rgb]{0.68,0.00,0.00}{#1}}
\newcommand{\FunctionTok}[1]{\textcolor[rgb]{0.28,0.35,0.67}{#1}}
\newcommand{\ImportTok}[1]{\textcolor[rgb]{0.00,0.46,0.62}{#1}}
\newcommand{\InformationTok}[1]{\textcolor[rgb]{0.37,0.37,0.37}{#1}}
\newcommand{\KeywordTok}[1]{\textcolor[rgb]{0.00,0.23,0.31}{\textbf{#1}}}
\newcommand{\NormalTok}[1]{\textcolor[rgb]{0.00,0.23,0.31}{#1}}
\newcommand{\OperatorTok}[1]{\textcolor[rgb]{0.37,0.37,0.37}{#1}}
\newcommand{\OtherTok}[1]{\textcolor[rgb]{0.00,0.23,0.31}{#1}}
\newcommand{\PreprocessorTok}[1]{\textcolor[rgb]{0.68,0.00,0.00}{#1}}
\newcommand{\RegionMarkerTok}[1]{\textcolor[rgb]{0.00,0.23,0.31}{#1}}
\newcommand{\SpecialCharTok}[1]{\textcolor[rgb]{0.37,0.37,0.37}{#1}}
\newcommand{\SpecialStringTok}[1]{\textcolor[rgb]{0.13,0.47,0.30}{#1}}
\newcommand{\StringTok}[1]{\textcolor[rgb]{0.13,0.47,0.30}{#1}}
\newcommand{\VariableTok}[1]{\textcolor[rgb]{0.07,0.07,0.07}{#1}}
\newcommand{\VerbatimStringTok}[1]{\textcolor[rgb]{0.13,0.47,0.30}{#1}}
\newcommand{\WarningTok}[1]{\textcolor[rgb]{0.37,0.37,0.37}{\textit{#1}}}

\usepackage{longtable,booktabs,array}
\usepackage{calc} % for calculating minipage widths
% Correct order of tables after \paragraph or \subparagraph
\usepackage{etoolbox}
\makeatletter
\patchcmd\longtable{\par}{\if@noskipsec\mbox{}\fi\par}{}{}
\makeatother
% Allow footnotes in longtable head/foot
\IfFileExists{footnotehyper.sty}{\usepackage{footnotehyper}}{\usepackage{footnote}}
\makesavenoteenv{longtable}
\usepackage{graphicx}
\makeatletter
\newsavebox\pandoc@box
\newcommand*\pandocbounded[1]{% scales image to fit in text height/width
  \sbox\pandoc@box{#1}%
  \Gscale@div\@tempa{\textheight}{\dimexpr\ht\pandoc@box+\dp\pandoc@box\relax}%
  \Gscale@div\@tempb{\linewidth}{\wd\pandoc@box}%
  \ifdim\@tempb\p@<\@tempa\p@\let\@tempa\@tempb\fi% select the smaller of both
  \ifdim\@tempa\p@<\p@\scalebox{\@tempa}{\usebox\pandoc@box}%
  \else\usebox{\pandoc@box}%
  \fi%
}
% Set default figure placement to htbp
\def\fps@figure{htbp}
\makeatother

\ifLuaTeX
  \usepackage{luacolor}
  \usepackage[soul]{lua-ul}
\else
  \usepackage{soul}
\fi

% definitions for citeproc citations
\NewDocumentCommand\citeproctext{}{}
\NewDocumentCommand\citeproc{mm}{%
  \begingroup\def\citeproctext{#2}\cite{#1}\endgroup}
\makeatletter
 % allow citations to break across lines
 \let\@cite@ofmt\@firstofone
 % avoid brackets around text for \cite:
 \def\@biblabel#1{}
 \def\@cite#1#2{{#1\if@tempswa , #2\fi}}
\makeatother
\newlength{\cslhangindent}
\setlength{\cslhangindent}{1.5em}
\newlength{\csllabelwidth}
\setlength{\csllabelwidth}{3em}
\newenvironment{CSLReferences}[2] % #1 hanging-indent, #2 entry-spacing
 {\begin{list}{}{%
  \setlength{\itemindent}{0pt}
  \setlength{\leftmargin}{0pt}
  \setlength{\parsep}{0pt}
  % turn on hanging indent if param 1 is 1
  \ifodd #1
   \setlength{\leftmargin}{\cslhangindent}
   \setlength{\itemindent}{-1\cslhangindent}
  \fi
  % set entry spacing
  \setlength{\itemsep}{#2\baselineskip}}}
 {\end{list}}
\usepackage{calc}
\newcommand{\CSLBlock}[1]{\hfill\break\parbox[t]{\linewidth}{\strut\ignorespaces#1\strut}}
\newcommand{\CSLLeftMargin}[1]{\parbox[t]{\csllabelwidth}{\strut#1\strut}}
\newcommand{\CSLRightInline}[1]{\parbox[t]{\linewidth - \csllabelwidth}{\strut#1\strut}}
\newcommand{\CSLIndent}[1]{\hspace{\cslhangindent}#1}

\ifLuaTeX
\usepackage[bidi=basic]{babel}
\else
\usepackage[bidi=default]{babel}
\fi
% get rid of language-specific shorthands (see #6817):
\let\LanguageShortHands\languageshorthands
\def\languageshorthands#1{}
\ifLuaTeX
  \usepackage[german]{selnolig} % disable illegal ligatures
\fi


\setlength{\emergencystretch}{3em} % prevent overfull lines

\providecommand{\tightlist}{%
  \setlength{\itemsep}{0pt}\setlength{\parskip}{0pt}}



 


\KOMAoption{captions}{tableheading}
\makeatletter
\@ifpackageloaded{tcolorbox}{}{\usepackage[skins,breakable]{tcolorbox}}
\@ifpackageloaded{fontawesome5}{}{\usepackage{fontawesome5}}
\definecolor{quarto-callout-color}{HTML}{909090}
\definecolor{quarto-callout-note-color}{HTML}{0758E5}
\definecolor{quarto-callout-important-color}{HTML}{CC1914}
\definecolor{quarto-callout-warning-color}{HTML}{EB9113}
\definecolor{quarto-callout-tip-color}{HTML}{00A047}
\definecolor{quarto-callout-caution-color}{HTML}{FC5300}
\definecolor{quarto-callout-color-frame}{HTML}{acacac}
\definecolor{quarto-callout-note-color-frame}{HTML}{4582ec}
\definecolor{quarto-callout-important-color-frame}{HTML}{d9534f}
\definecolor{quarto-callout-warning-color-frame}{HTML}{f0ad4e}
\definecolor{quarto-callout-tip-color-frame}{HTML}{02b875}
\definecolor{quarto-callout-caution-color-frame}{HTML}{fd7e14}
\makeatother
\makeatletter
\@ifpackageloaded{bookmark}{}{\usepackage{bookmark}}
\makeatother
\makeatletter
\@ifpackageloaded{caption}{}{\usepackage{caption}}
\AtBeginDocument{%
\ifdefined\contentsname
  \renewcommand*\contentsname{Inhaltsverzeichnis}
\else
  \newcommand\contentsname{Inhaltsverzeichnis}
\fi
\ifdefined\listfigurename
  \renewcommand*\listfigurename{Abbildungsverzeichnis}
\else
  \newcommand\listfigurename{Abbildungsverzeichnis}
\fi
\ifdefined\listtablename
  \renewcommand*\listtablename{Tabellenverzeichnis}
\else
  \newcommand\listtablename{Tabellenverzeichnis}
\fi
\ifdefined\figurename
  \renewcommand*\figurename{Abbildung}
\else
  \newcommand\figurename{Abbildung}
\fi
\ifdefined\tablename
  \renewcommand*\tablename{Tabelle}
\else
  \newcommand\tablename{Tabelle}
\fi
}
\@ifpackageloaded{float}{}{\usepackage{float}}
\floatstyle{ruled}
\@ifundefined{c@chapter}{\newfloat{codelisting}{h}{lop}}{\newfloat{codelisting}{h}{lop}[chapter]}
\floatname{codelisting}{Listing}
\newcommand*\listoflistings{\listof{codelisting}{Listingverzeichnis}}
\makeatother
\makeatletter
\makeatother
\makeatletter
\@ifpackageloaded{caption}{}{\usepackage{caption}}
\@ifpackageloaded{subcaption}{}{\usepackage{subcaption}}
\makeatother
\usepackage{bookmark}
\IfFileExists{xurl.sty}{\usepackage{xurl}}{} % add URL line breaks if available
\urlstyle{same}
\hypersetup{
  pdftitle={KI als Hilfe zum Lehren und Lernen (Beta-Version! Format wird noch optimiert)},
  pdfauthor={Roman Bartnik},
  pdflang={de},
  colorlinks=true,
  linkcolor={blue},
  filecolor={Maroon},
  citecolor={Blue},
  urlcolor={Blue},
  pdfcreator={LaTeX via pandoc}}


\title{KI als Hilfe zum Lehren und Lernen (Beta-Version! Format wird
noch optimiert)}
\author{Roman Bartnik}
\date{2025-12-31}
\begin{document}
\maketitle

\renewcommand*\contentsname{Inhaltsverzeichnis}
{
\hypersetup{linkcolor=}
\setcounter{tocdepth}{2}
\tableofcontents
}

\bookmarksetup{startatroot}

\chapter*{Übersicht}\label{uxfcbersicht}
\addcontentsline{toc}{chapter}{Übersicht}

\markboth{Übersicht}{Übersicht}

Dieses Buch untersucht, wie generative künstliche Intelligenz (GenAI)
Lehre, Lernen und Forschung verändern kann. Es richtet sich an Lehrende,
Forschende und Studierende, die verstehen möchten, \textbf{wie KI als
Werkzeug der Hochschuldidaktik} eingesetzt werden kann.

Das Buch besteht aus den folgenden Kapiteln:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Überblick: KI als Hilfe zum Lehren und Lernen\\
\item
  Grundbegriffe und technische Grundlagen\\
\item
  Didaktische Prinzipien und Cognitive Science\\
\item
  Praxisbeispiele: KI als Hiwi, Copilot, Tutor, Simulator\\
\item
  Empfehlungen zur Umsetzung\\
\item
  Appendix 01: Strukturierung der didaktischen Prompts\\
\item
  Appendix 02: Best-Practice Sammlung didaktischer Prompts und
  Aufgabenstellungen\\
\end{enumerate}

Im ersten Teil fassen wir die aktuelle Forschungslage zusammen.

\bookmarksetup{startatroot}

\chapter{Einleitung}\label{sec-einleitung}

\section{KI als Hilfe für die
Lehre}\label{ki-als-hilfe-fuxfcr-die-lehre}

\textbf{Wie kann uns generative künstliche Intelligenz} (KI) \textbf{in
der Lehre helfen}? Hoffnung besteht hier für zwei typische Probleme:
Erstens haben Studierende \textbf{individuelle Bedürfnisse}, aber wir
haben nur \textbf{begrenzte Zeit}, auf diese einzugehen. Wie können wir
Einzelne möglichst intensiv fördern, ohne vor Arbeit unterzugehen?
Zweitens ist der \textbf{Aufwand gerade für effektive Lehrmethoden} oft
sehr hoch, so etwa für häufige niedrigschwellige Tests, oder
individuelles Feedback zu Studienarbeiten (Brown et al., 2014; s. etwa
Hattie, 2023, Kap.13). Wer lehrt, fühlt sich aus Zeit- und Stoffdruck
oft gezwungen, Abstriche von idealen Lehrsetups zu machen (Henderson \&
Dancy, 2007; Schmidt \& Tippelt, 2005, S.104--105). Gerade Lehrmethoden,
die didaktisch sinnvoll, aber mit höherem Aufwand verbunden sind, drohen
dabei auf der Strecke zu bleiben (s. etwa Dunlosky et al., 2013;
Roediger \& Pyc, 2012).

\begin{tcolorbox}[enhanced jigsaw, breakable, titlerule=0mm, leftrule=.75mm, opacitybacktitle=0.6, rightrule=.15mm, arc=.35mm, left=2mm, colframe=quarto-callout-tip-color-frame, opacityback=0, coltitle=black, bottomtitle=1mm, colback=white, toptitle=1mm, title=\textcolor{quarto-callout-tip-color}{\faLightbulb}\hspace{0.5em}{Schnelles Brainstorming mit der KI}, bottomrule=.15mm, colbacktitle=quarto-callout-tip-color!10!white, toprule=.15mm]

\end{tcolorbox}

\textbf{Für die Lehre} erschließen sich durch die großen
KI-Sprachmodelle (LLM = Large Language Models) neue Möglichkeiten. Sie
sind, wie es eine Analyse des MIT Professors Andrew McAfee auf den Punkt
bringt „\textbf{generally faster}'' (McAfee, 2024). Lehrende können mit
KI-Unterstützung etwa deutlich schneller eine Recherche durchführen, ein
Set von Übungsaufgaben erstellen, mehrere Anwendungsbeispiele pro
Konzept hinzufügen, Quizfragen zur schnellen Lernüberprüfung generieren,
oder mit den Studierenden Rollenspiele durchführen (Meincke et al.,
2024; Mollick \& Mollick, 2023c). Der Berg ist noch da, aber mit dem
E-Bike kommt man weiter.

\begin{figure}

\centering{

\pandocbounded{\includegraphics[keepaspectratio]{images/ai-ebike-gemini.jpg}}

}

\caption{\label{fig-ai-ebike}GenAI als Kraftverstärker}

\end{figure}%

\section{Was 2025 möglich ist: Praktische Beispiele für Recherche,
Übungsaufgaben,
Erklärungen}\label{was-2025-muxf6glich-ist-praktische-beispiele-fuxfcr-recherche-uxfcbungsaufgaben-erkluxe4rungen}

\textbf{Schauen wir uns einige praktische Beispiele an}. Wir wollen
wissen, was es für aktuelle Fallstudien zu Lieferketten-Problemen gibt.
Als Recherche-Hiwi lassen wir das Sprachmodell auf akademischen Blogs
und Fachzeitschriften nach aktuellen Beispielen suchen.

\begin{figure}

\centering{

\pandocbounded{\includegraphics[keepaspectratio]{index_files/mediabag/images/script01-dr-plan.pdf}}

}

\caption{\label{fig-deep-research2}Recherche-Hiwi-Vorgehen}

\end{figure}%

Solche Suchen führen Sprachmodelle mittlerweile in mehreren Schritten
durch. Hier sehen wir den ``Denkprozess''.

\begin{figure}

\centering{

\pandocbounded{\includegraphics[keepaspectratio]{index_files/mediabag/images/deep-research-recherche-aktuelle-lieferkettenprobleme-denkprozess-geminipro.pdf}}

}

\caption{\label{fig-deep-research2}Recherche-Hiwi-Denkprozess}

\end{figure}%

Hier das Ergebnis: Ein erster ausformulierter Bericht von 13 Seiten nach
ca. 5 Minuten Recherche. Die Abbildung zeigt den Auszug mit der
tabellarischen Zusammenfassung der Forschungsartikel.

\begin{figure}

\centering{

\pandocbounded{\includegraphics[keepaspectratio]{index_files/mediabag/images/deep-research-recherche-aktuelle-lieferkettenprobleme-ergebnis-auszug-geminipro.pdf}}

}

\caption{\label{fig-deep-research3}Recherche-Hiwi-Ergebnis}

\end{figure}%

Wie kann man Konzepte einfach und mit Beispielen erklären? Wir bitten
ChatGPT um Vorschläge zu zwei Konzepten aus der Wissenschaftstheorie:
Der Duham-Quines-These, die beschreibt, warum Wissenschaft nur graduell,
mosaik-bauend zu Erkenntnissen kommen kann und Mayo's Konzept der
``Strengen Tests'' (severe testing), nach denen man wissenschaftliche
Aussagen graduell auf ihre Belastbarkeit bewerten kann.

\begin{center}
\pandocbounded{\includegraphics[keepaspectratio]{index_files/mediabag/images/konzepterklaerungen-beispiele-gpt5-2.pdf}}
\end{center}
Wie könnte man das in einem Test abfragen? Auch hierzu bitten wir
ChatGPT (5.2) um Vorschläge.

\begin{center}
\pandocbounded{\includegraphics[keepaspectratio]{index_files/mediabag/images/multiple-choice-test-beispiele-gen-chatgpt.pdf}}
\end{center}
Ende 2025 kann GenAI \textbf{professionelle Folien-Präsentationen sehr
schnell erstellen.} Sprachmodelle wie Google's \emph{Gemini} können
mittlerweile auch Text erstellen (Willison, 2025b) und damit auch
komplexe Infografiken (und Folien). Das Sprachmodell \emph{Claude}
liefert eine Beschreibung (`Skill') von 3500 Wörtern mit, die dem
Sprachmodell genau erklärt, wie es Schritt für Schritt eine PowerPoint
Präsentation erstellt und testet (Anthropic, 2025b).

Eine grafisch ansprechende Präsentation zu erstellen ist recht
zeitaufwändig - und Brillianz als Grafiker gehört vielleicht auch nicht
zu den Kernkompetenzen von Lehrenden. Wir bitten daher Gemini
(NotebookLM) und Claude, uns basierend auf Überblicksartikeln zwei
Präsentationen zu erstellen: Eine zur Frage, welche Lerntechniken für
Studierende besonders gut funktionieren (s.
Kapitel~\ref{sec-grundbegriffe}) und die zweite zur Frage, welche
Best-Practices es gibt, Aufgabenstellungen mit der intensiven Nutzung
von GenAI zu verbinden (s. Anhang~\ref{sec-prompts}).

Zu integrierten Aufgaben mit GenAI liefert uns das Sprachmodell nach
wenigen Minuten 15 sehr schicke Folien (NotebookLM, basierend auf 13
Quellen-PDFs).

\begin{figure}

\centering{

\pandocbounded{\includegraphics[keepaspectratio]{index_files/mediabag/images/genai-integrierte-aufgaben-gen-notebooklm.pdf}}

}

\caption{\label{fig-deep-research3}Recherche-Hiwi-Ergebnis}

\end{figure}%

Zu Lerntechniken erhielten wir nach etwa 5 Minuten basierend auf einem
Fachartikel, 8 professionelle Folien (mit kleineren
Formatierungsfehlern, etwa Zeilenumbrüchen).

\begin{figure}

\centering{

\pandocbounded{\includegraphics[keepaspectratio]{index_files/mediabag/images/lerntechniken-ppt-gen-claude-2025-12.pdf}}

}

\caption{\label{fig-deep-research3}Recherche-Hiwi-Ergebnis}

\end{figure}%

\section{Nutzung von GenAI in der
Forschung}\label{nutzung-von-genai-in-der-forschung}

\textbf{Immer mehr Aspekte von typischen Forschungstätigkeiten} -- ein
zentraler Ausbildungsinhalt der Hochschulen -- können \textbf{von der KI
übernommen} werden und zwar auf hohem Niveau. Vorbei sind die Zeiten, in
denen wir die banalen Schreibprodukte der KI nur belächeln konnten. Ein
Überblicksartikel des Forschers Anton Korinek im renommierten Journal of
Economic Literature vom Dezember 2024 fasst die deutlich höhere Qualität
des Outputs zusammen: „die derzeitige Generation von LLMs ist in hohem
Maße in der Lage, die wichtigsten Erkenntnisse von Forschungsarbeiten zu
verarbeiten'' (Korinek, 2024, S.3, Übersetzung RB mit DeepL).

\textbf{Die professionelle Nutzung durch Forscher etwa in
Laborumgebungen oder der Mathematik ist hier teils noch weiter.} Eine
schöne visuelle Verdeutlichung davon, was jetzt möglich ist, findet sich
hier: Eine Visualisierung von über 6000 Konferenzbeiträgen, die jeweils
zusammengefasst werden und denen durch ein Sprachmodell eine Erklärung
in einfacher Sprache beigefügt wurde (``explain-it-like-I'm-5''):
\textbf{Hier kann man das interaktiv ausprobieren:}
https://jalammar.github.io/assets/neurips\_2025.html.

\begin{figure}

\centering{

\pandocbounded{\includegraphics[keepaspectratio]{images/neuips-papers-visualization-eli5.jpg}}

}

\caption{\label{fig-conference-papers}Visualisierung und Erläuterung in
einfacher Sprache von 6000+ Konferenzbeiträgen}

\end{figure}%

\textbf{Wie kann GenAI uns bei der Forschung direkt unterstützen?}
Google demonstrierte 2025 ein mehrstufiges Modell für die
Pharma-Forschung (\emph{`AI co-scientist'}), das den Forschenden
zeitintensive Zwischenschritte abnimmt (Gottweis et al., 2025) (s.
Abbildung~\ref{fig-coscientist}). OpenAI zeigte Ende 2023 schon in einem
ausführlichen Bericht eine Vielzahl möglicher Hilfsanwendungen im
Wissenschaftsbereich. Mit deutlichen Warnhinweisen (speziell wegen
selbstbewusst vertretenen Halluzinationen) aber auch teils erstaunlich
hoher Qualität (Bubeck et al., 2023). Auch im Peer-Review werden
zunehmend Sprachmodelle eingesetzt -- mit allen Vor- und Nachteilen, die
das mit sich bringt (Naddaf, 2025). Wie wir in den späteren Kapiteln
sehen, experimentieren Hochschulen weltweit intensiv mit den neuen
Möglichkeiten für Lehre und Forschung.

\begin{figure}

\centering{

\pandocbounded{\includegraphics[keepaspectratio]{images/co-scientist-design.jpg}}

}

\caption{\label{fig-coscientist}Google's Co-Scientist Ansatz an einem
Beispiel aus der Pharmaforschung}

\end{figure}%

Ende 2025, hat sich \textbf{der potenzielle Mehrwert (und speziell
Zeitgewinn) \emph{bei fachgemäßer Nutzung} } noch einmal erweitert. Ein
aktueller Bericht (November 2025) von OpenAI stellt eine Reihe von
Fallstudien dar, wie Forschende starke Sprachmodelle nutzen (Bubeck et
al., 2025). Die Quelle der Ergebnisse ist natürlich nicht neutral
(OpenAI), die Ergebnisse sind aber m.E. mit Blick auf die eigene
Nutzungserfahrung sehr plausibel: Als Mehrwert wird häufig eine
\textbf{außerordentliche Zeitersparnis bei Routinetätigkeiten} genannt,
speziell bei der Nutzung von Verfahren und Wissensquellen, die die
Forscher zwar bewerten können, deren Aneignung aber ohne die Hilfe der
Sprachmodelle deutlich länger dauern würde. Dies ist sehr wertvoll und
wird die Verbreitung solcher Tools treiben. Wir sehen in den
Einzelberichten aber auch \textbf{klare Warnsignale}: Wenn man die
Zwischenergebnisse mangels Fachkenntnis nicht kritisch hinterfragen
kann, ist die Wahrscheinlichkeit hoch, Fehler zu übernehmen. Auch starke
Sprachmodelle vertreten sehr überzeugend falsche Ergebnisse und Ansätze.
Nur durch Fachwissen haben Nutzer die erforderlichen Bewertungsmuster.
\textbf{Erst durch eigenes Fachwissen \emph{und} der Erfahrung im
kritischen Umgang mit dem Tool entsteht der Mehrwert}. Man muss insofern
das Terrain kennen \emph{und} lernen, wie man den Sportwagen
Sprachmodell fahren muss, können Unfälle vermieden werden.

Am Ende dieses Kapitels können Sie Details der Bewertungen aus den
verschiedenen Disziplinen sehen (Bubeck et al., 2025).
Kapitel~\ref{sec-forschung-details}

\textbf{Wie ein Laie im Cockpit eines Verkehrsflugzeugs} fällt es
Lehrenden teils schwer zu entscheiden, welche der neuen Möglichkeiten
sinnvoll für die eigene Lehre sind. Zunächst gibt es immer wieder
Hype-Zyklen: Virtuelle Realität, Blockchain, Roboter, Internet der
Dinge\ldots{} (Allen \& Edelson, 2024), viel wurde schon ins Rampenlicht
gestellt und dann wieder vergessen. Es werden gerade für die Lehre
regelmäßig neue Technologien beworben und gehyped, so dass Lehrende
schon aus Selbstschutz eine gewisse Grundskepsis mitbringen (sollten),
ob ein neuer technischer Zugang wirklich auch didaktischen Nutzen bringt
(für eine wirkungsbasierte Übersicht von Technologien s. etwa Hattie,
2023, Kap.14). Lehrende sind außderdem paradoxen Spannung zwischen den
Identitäten als Experten und Innovatoren/Faszilitatoren ausgesetzt
(Fischer \& Dobbins, 2024): Ausgestrahlte Kompetenz ist einerseits Teil
ihres Wertversprechens, was zur Abwehr ungewohnter Technologien einlädt.
Andererseits sollen Lehrende auch zu Neugier und Innovation anleiten und
insofern den Umgang mit neuen, auch für die Lehrenden selbst ungewohnten
Technologien erleichtern.

\begin{figure}

\centering{

\pandocbounded{\includegraphics[keepaspectratio]{images/ai-as-new-tech-gemini.jpg}}

}

\caption{\label{fig-ki-herausforderung}Neue technologische Chancen und
Herausforderungen mit GenAI. \emph{Quelle:} Mit Gemini generiert.}

\end{figure}%

\section{Aktuelle Weiterentwicklungen der
Sprachmodelle}\label{aktuelle-weiterentwicklungen-der-sprachmodelle}

2025 lernen die großen Sprachmodelle noch besser ``nachzudenken'' -
sogenannte ``Reasoning''-Modelle werden breit verfügbar. Aus
didaktischer Sicht ist das auch deshalb interessant, weil man Lernenden
jetzt Denkstrategien vorführen kann, speziell Hypothesenbildung und
Prüfung (etwa (Brown et al., 2014), S.90-94, ``generative learning'',
oder die Studien von Willemain zur Modellierung von Problemen durch
Experten (Willemain, 1994, 1995)). Ein neuer Ansatzpunkt zur
Verbesserung der Ergebnisse wird hier genutzt (Grootendorst, 2025) :
Statt (nur) mehr Ressourcen in das Training immer komplexerer Modelle zu
investieren (train-time compute), werden die Modelle jetzt dazu
angehalten, länger ``nachzudenken'', bevor sie ein Ergebnis anbieten
(test-time compute). Hinter diesem ``besseren Nachdenken'' stehen zwei
Prinzipien (Grootendorst, 2025; Snell et al., 2024): Die Sprachmodelle
werden einerseits instruiert, schrittweise vorzugehen
(Input-Verbesserung der Vorschlagsverteilung) und andererseits dazu
angehalten, die eigenen Antworten zu prüfen (Output-Verbesserung,
Verifizierer). Die Sprachmodelle führen insofern jetzt teils
selbstständig Prüfschritte durch, die man früher durch komplexe Prompts
induziert hätte. Ende 2025 sehen wir in der Konsequenz, dass die
Sprachbots immer selbstständiger werden, man spricht vom
\textbf{``Agentic Turn''}(Mollick, 2025a; Steinberger, 2025; Willison,
2025a): Als Nutzer solcher Reasoning Modelle verbringen wir jetzt
weniger Zeit damit, über die `Zaubersprüche' einzelner Prompts
nachzudenken und mehr Zeit in `Mitarbeitergesprächen' - Anleitung und
Kritik der digitalen ``Agenten'' - Sprachmodelle, die selbstständig und
auf hohem Niveau mehrere Arbeitsschritte durchführen. Insgesamt steigt
seit 2023 die Qualität der Aufgaben, die Sprachmodelle erledigen können,
rasant. Empirische Untersuchungen zeigen, dass die Sprachmodelle immer
längere Aufgaben auf hohem Niveau erledigen können (Kwa et al., 2025).

Die neuen Modelle sind außderdem günstiger und effizienter geworden: die
Kosten pro Interaktion sind stark gesunken. Illustratives Beispiel: Eine
Millionen Token kosteten mit GPT-4 noch 50 Dollar, jetzt nur noch 14
Cent (InvertedStone, 2025; Mollick, 2025b). Das Modell halluziniert
(weiterhin, also Vorsicht, aber) deutlich seltener als seine Vorgänger:
OpenAI gibt hier ca. 1\% Halluzinationen der Antworten statt ca. 5\% bei
Vorgängermodellen (o3, 4o) an, je nach Komplexität der Frage und
erlaubter „Bedenkzeit'' (OpenAI, 2025).

Weiterhin hat sich die \textbf{Internetsuche mit LLMs deutlich
verbessert}. Während man früher noch oft über sinnlose oder erfundene
Ergebnisse lachte, stellt die Suche von ChatGPT, Google/Gemini, oder
speziellen Suchanbietern wie Perplexity mittlerweile eine große
Zeitersparnis dar: „a useful tool to provide up-to-date answers to
questions that are grounded in facts found on the internet, together
with the requisite citations---a crucial capability for researchers''
(Korinek, 2024, S.3). Das gilt zunehmend für die stärksten allgemeinen
Modelle und erst recht für Anbieter, die auf Forschungsrecherche (und
Studierende) spezialisiert sind, wie Elicit oder Paperpal. Auch breite
Internet-Recherchen und Textproduktionen sind zunehmend komplett
delegierbar („deep research''), mit deutlichen Auswirkungen auf den
Arbeitsprozess in der Wissensarbeit (s. etwa Schwarcz et al. (2025) für
juristische Recherchen, Korinek (2024) für Ökonomie und W. Liang et al.
(2025) für PR-Tätigkeiten).

\section{Wie nutzen Studierende und Lehrende
GenAI?}\label{wie-nutzen-studierende-und-lehrende-genai}

\textbf{Für Studierende sind GenAI Chatbots zum Standard für
Informationssuche und Schreibaufgaben geworden}: So berichten 92 \% der
befragten britischen Vollzeitstudierenden (n=1.041, Erhebung im Dezember
2024), dass sie KI-Tools wie ChatGPT regelmäßig verwenden, und 88 \%
geben an, solche Tools für Prüfungsleistungen (``for assessments'') zu
nutzen (Freeman, 2025). Deutsche Daten des CHE-Centrum für
Hochschulentwicklung bestätigen dies: etwa zwei Drittel der Studierenden
gaben Ende 2024 an, KI-Tools mindestens wöchentlich zu nutzen (Hüsch,
Marc et al., 2025) (65\%, n=23.288 von 171 Hochschulen).

\textbf{Wofür genau nutzen Studierende GenAI?} Studierende geben an,
dass sie sich am häufigsten Konzepte erklären lassen, Artikel
zusammenfassen oder Ideen für Schreib- und Forschungsprojekte sammeln
(Freeman, 2025). Nutzungsstudien zeigen sogar noch stärkeren Einsatz
speziell für Schreibprojekte (s. Abbildung~\ref{fig-llm-nutzung}): Wie
eine Auswertung von 1 Millionen anonymisierten Chats zwischen Usern mit
Universitätskonto und dem Sprachmodell zeigt nutzen Studierende die
KI-Bots vor allem zum \textbf{Erstellen neuer Inhalte und das
Analysieren komplexer Themen}, was höheren Ebenen der Bloomschen
Taxonomie entspricht (s. Abbildung~\ref{fig-llm-nutzung-bloom}). Ein
Großteil der befragten britischen Studierenden gibt an,
Prüfungsleistungen durch GenAI zu unterstützen. Dieser Anteil sprang
zwischen den Erhebungszeiträumen Ende 2023 und 2024 von der Hälfte auf
fast 90\% (53\% auf 88\%, Freeman, 2025).

\begin{figure}

\centering{

\pandocbounded{\includegraphics[keepaspectratio]{index_files/mediabag/images/script01-01.pdf}}

}

\caption{\label{fig-llm-nutzung}Wofür Studierende LLMs nutzen.
\emph{Quelle:} Handa et al. (2025-04-08, 2025)}

\end{figure}%

\textbf{Hochschulen müssen insofern sicherstellen, dass
Prüfungsleistungen nicht entwertet und Studierende die produktive
Nutzung solcher Tools erlernen}. Studierende dürfen einerseits
wesentliche kognitive Aufgaben nicht vollständig an GenAI delegieren:
Aufgaben und Prüfungsleistungen müssen angepasst werden. Weiterhin
entsteht ein \textbf{neuer Bedarf an Kompetenzschulung}, den Studierende
wie Unternehmen äußern: der produktive Umgang mit den neuen GenAI Tools
muss eingeübt werden. \textbf{Deutsche Studierende fühlen sich hierauf
nicht gut vorbereitet}: In der CHE-Studie bewerten sie das bestehende
Angebot zum Erwerb von KI-Kompetenzen mit nur 2,7 von 5 Sternen (Hüsch,
Marc et al., 2025).

\begin{figure}

\centering{

\pandocbounded{\includegraphics[keepaspectratio]{index_files/mediabag/images/script01-02.pdf}}

}

\caption{\label{fig-llm-nutzung-bloom}Schwerpunkte der Nutzung von LLMs
(Claude) durch Studierende nach der Bloom'schen Taxonomie. Quelle: Handa
et al. (2025-04-08, 2025)}

\end{figure}%

Die zunehmende Verwendung von KI in der Lehre hat gute Gründe. Wie oft
eine neue Technologie genutzt wird, hängt nach dem \textbf{Technology
Acceptance Model} (TAM, s. Abbildung~\ref{fig-tam}) von der
\textbf{wahrgenommenen Benutzerfreundlichkeit} (perceived ease of use)
und der \textbf{wahrgenommenen Nützlichkeit} (perceived usefulness) ab
(Marangunić \& Granić, 2015). Generative KI wie ChatGPT decken sichtlich
beide Aspekte ab: Sie sind einfach zu nutzen (Greg Kestin et al., 2025;
Lee et al., 2025; Monib et al., 2025; Naddaf, 2025) und erzeugen einen
deutlichen Mehrwert, wie Studierende und Lehrende in einer Vielzahl von
Umfragen der letzten zwei Jahren berichten (Heidt, 2025; Morgan, 2024;
Ou et al., 2024). Lehrende ziehen nach: Meta-Untersuchungen zeigen ein
extremes Wachstum an Publikationen zur Nutzung von LLM im
Hochschulalltag (Ma, 2025; Ogunleye et al., 2024).

\begin{figure}

\centering{

\pandocbounded{\includegraphics[keepaspectratio]{index_files/mediabag/images/tam-diagram-mermaid.pdf}}

}

\caption{\label{fig-tam}Gründe für die Verbreitung von GenAI nach dem
Technologie-Akzeptanz-Modell}

\end{figure}%

\textbf{Auch außerhalb der Hochschule steigt die Nutzung}. Eine Reihe
von Studien zeigen \textbf{erhöhte Produktivität von Büroarbeitenden mit
LLM-Unterstützung}: der Kundensupport arbeitet 15\% schneller, wenn das
Sprachmodell Antwortoptionen vorschlägt und Verweise auf interne
technische Dokumentation anbietet (Brynjolfsson et al., 2025),
Programmierer programmieren schneller (Peng et al., 2023), Consultants
sind produktiver bei komplexen Beratungsprojekten (Dell'Acqua et al.,
2023) und Sprachmodelle wie ChatGPT können eine Vielzahl kleiner
Aufgaben beschleunigen (Handa et al., 2025-04-08, 2025) und werden
insofern gerade zur Texterstellung schon millionenfach als Hilfsmittel
im Beruf genutzt: Von Kundenbewertungen über Pressemitteilungen und
Stellenanzeigen (W. Liang et al., 2025).

Schauen wir auf die Abnehmern unserer Graduierten: \textbf{Wie nutzen
die Unternehmen Mitte 2025 solche Sprachmodelle?} Eine aktuelle Studie
(2025/12) zur Nutzung von GenAI in Unternehmen stellt ein extremes
Wachstum fest sowie einen deutlichen Unterschied in der Nutzung von
erfahrenen und weniger routinierten Usern (Chatterji, 2025). Der
OpenAI-Report zeigt, dass die Nutzung von Sprachmodellen in Unternehmen
2025 deutlich \emph{breiter und tiefer} wird:
ChatGPT-Enterprise-Nachrichten stiegen im Jahresvergleich etwa um das
Achtfache, gleichzeitig wachsen wiederholbare Arbeitsabläufe stark
(Nutzung von Projects/Custom GPTs \textasciitilde19-fach seit
Jahresbeginn; rund 20 \% der Enterprise-Nachrichten laufen bereits über
solche strukturierten Workflows). Gleichzeitig bleibt bei
fortgeschritteneren Funktionen noch viel ungenutztes Potenzial. Vor
allem der Mehrwert von neueren Funktionen wie \emph{DeepSearch}
(Delegation ausführlicher Recherchen), \emph{Reasoning} (schrittweises,
sorgfältiges Antworten mit deutlich höherer Qualität) und
\emph{Datenanalyse} mit Coding Tools wie Codex werden von Praktikern mit
Firmen-Lizenz noch sehr selten genutzt. Selbst unter monatlich aktiven
Enterprise-Nutzern haben 19 \% noch nie Datenanalyse, 14 \% noch nie
Reasoning und 12 \% noch nie (Deep) Search genutzt (bei täglich Aktiven
sinkt das auf 3 \%, 1 \% und 1 \%).

\section{Risiken und Nebenwirkungen}\label{risiken-und-nebenwirkungen}

Die Metapher mit dem E-Bike trägt allerdings auch, was die
\textbf{Risiken und Nebenwirkungen} angeht: Ab wann lässt die
maschinelle Unterstützung wichtige Muskeln verkümmern? Solche Gefahren
bestehen -- wie empirische Studien zeigen, erfordern die neuen Workflows
der Wissensarbeit durch KI-Unterstützung auch neue Formen der kritischen
Auseinandersetzung mit den Inhalten.

Im Gegensatz zur einfachen Faktensuche im Internet werden hier nicht nur
ein paar dornige Zweige im Aufgabenbündel mechanisch `geerntet', sondern
\textbf{gleich das gesamte Bündel fertig verschnürt bereitgestellt.}
Schlimmstenfalls droht das, was ein Artikel von Walsh (2025) prägnant
betitelt: \textbf{``Everybody is cheating their way through college''.}
Wenn klassische Projektaufgaben quasi auf Knopfdruck erstellt werden
können, droht diese Form von Leistung sinnlos zu werden. Mit etwas Lust
an Dramatik können wir uns Endzeit-Szenarien vorstellen, in denen
\textbf{Lehrende klagend durch die Trümmer ihrer schönen
Portfolio-Prüfungen stolpern:} Die Homework-Apocalypse (Mollick, 2023).

\textbf{Aber so schlimm muss es nicht werden.} Es gibt schon eine Reihe
plausibler Ansätze, Lehrformate so umzugestalten, dass erwünschte
Schwierigkeiten nach Bjork \& Bjork (2011) beibehalten oder sogar
verstärkt werden, trotz der (wohl praktisch unvermeidbaren) breiten
allgemeinen Nutung von GenAI durch Studierende.

\textbf{Wird der Umgang mit GenAI nicht geübt, droht ein Rückgang des
kritischen Denkens.} Eine Studie von 319 Wissensarbeitern zeigt, dass
sich das \textbf{Gewicht zwischen den Einzelaufgaben der Wissensarbeit
mit LLMs verschiebt}: Der Aufwand für die Recherchen selbst sinkt, es
steigt anderseits der Aufwand für Management-ähnliche Aufgaben:
Koordination der Einzelaufgaben für Mensch und Maschine, kritische
Prüfung der berichteten Ergebnisse und die Integration von Ergebnissen
in den Gesamtprozess (etwa zur Erstellung eines Gesamtberichtes, einer
Test-Spezifikation oder eines Protokolls) (Lee et al., 2025).

Wie kann man also verhindern, dass die Studierenden kritische kognitive
Aufgaben allein den KI-Systemen übergeben? Lehre heißt in diesem Kontext
auch, empfohlene Arbeitsweisen mit der neuen Technik zu üben. Wie das
gehen kann, sehen wir in den folgenden Kapiteln.

\section{Kapitelübersicht}\label{kapiteluxfcbersicht}

Im Folgenden werden wir zunächst einige \textbf{Grundbegriffe} klären
\{Kapitel~\ref{sec-grundbegriffe}\}: Was sind große Sprachmodelle und
was ist mit Begriffen wie Token, Prompt und RAG gemeint? \textbf{Welche
Modelle} können Lehrende aktuell nutzen und welche \textbf{Empfehlungen
für Prompts} sind belastbar \{Kapitel~\ref{sec-prompt-vorgehen}\}? Dann
fragen wir nach \textbf{Zielen}: Welche Art von Wissen und Methoden
unterscheidet und empfiehlt die Lernforschung? Welche
\textbf{didaktischen Wirkmechanismen} können durch KI genutzt werden, um
typische Probleme der Hochschullehre anzugehen
\{Kapitel~\ref{sec-didaktik}\}? Im Abschnitt 4 schauen wir auf
\textbf{Praxisbeispiele} für vier Anwendungsfelder von Sprachmodellen an
Hochschulen \{Kapitel~\ref{sec-szenarien}\}: \textbf{KI als Hiwi}
(direkte Arbeitserleichterung), \textbf{KI als Copilot} (Unterstützung
beim Schreiben und Coden) und \textbf{KI als Tutor} (Feedback und
Lernunterstützung) sowie \textbf{KI als Simulator} (Role Play und Goal
Play). Abschließend zeigen wir verschiedene Anwendungen von KI in
verschiedenen Kurstypen und gehen auf neue \textbf{Herausforderungen für
Prüfungen} ein \{Kapitel~\ref{sec-umsetzung}\}. Im Appendix finden Sie
eine breite Sammlung von didaktischen Prompts und auf GenAI
ausgerichteten Aufgabenstellungen von führenden Hochschulen
\{Anhang~\ref{sec-prompts}\}

\section{Schlaglichter aus der Forschung mit GenAI: Erfahrungsberichte
aus den Disziplinen (GPT-5 und 5-Pro)}\label{sec-forschung-details}

Wie und wofür lassen sich die stärksten Sprachmodelle aktuell in der
Forschung nutzen? Hier finden Sie Schlaglichter aus den verschiedenen
Disziplinen (Bubeck et al., 2025). Es sei darauf hingewiesen, dass die
Forschenden teils GPT-5 (die Version für ca. 20 EUR im Monat) und teils
GPT-5 Pro (die stärkste Version für ca. 200 EUR im Monat) verwendet
haben.

\begin{tcolorbox}[enhanced jigsaw, breakable, titlerule=0mm, leftrule=.75mm, opacitybacktitle=0.6, rightrule=.15mm, arc=.35mm, left=2mm, colframe=quarto-callout-note-color-frame, opacityback=0, coltitle=black, bottomtitle=1mm, colback=white, toptitle=1mm, title=\textcolor{quarto-callout-note-color}{\faInfo}\hspace{0.5em}{Mathematik / Optimierung der Schrittweite}, bottomrule=.15mm, colbacktitle=quarto-callout-note-color!10!white, toprule=.15mm]

\textbf{Forschender:} Sébastien Bubeck

\textbf{Thema:} Untersuchung, ob GPT-5 ein kürzlich veröffentlichtes
Resultat zur Konvexität von Optimierungskurven verbessern oder
reproduzieren kann.

\textbf{Mehrwert:}

„\ldots one can see that GPT-5 claims to have improved the condition
from η≤1/L to η≤1.5/L, thus approaching the optimal bound (but not quite
getting there) of η≤1.75/L. But is this claim substantiated? It is
indeed, and the proof given by GPT-5 is shown in Figure I.2, which the
present author has verified to be correct.``

„\ldots the proof given by GPT-5 is quite different from the one in v2.
Indeed, the GPT-5 proof can be viewed as a more canonical variant of the
v1 proof\ldots``

\textbf{Probleme:}

„GPT-5 did not manage to fully rederive the v2 result, but it basically
went half-way between v1 and v2.``

\textbf{Schlussfolgerungen:}

„To say it plainly, such a result (improving from 1/L to 1.5/L) could
probably have been achieved by some experts in the field in a matter of
hours, and likely for most experts it would have taken a few days. This
is the type of science acceleration that we will see time and again in
this report.``

\end{tcolorbox}

\begin{tcolorbox}[enhanced jigsaw, breakable, titlerule=0mm, leftrule=.75mm, opacitybacktitle=0.6, rightrule=.15mm, arc=.35mm, left=2mm, colframe=quarto-callout-note-color-frame, opacityback=0, coltitle=black, bottomtitle=1mm, colback=white, toptitle=1mm, title=\textcolor{quarto-callout-note-color}{\faInfo}\hspace{0.5em}{Mathematik / Literaturrecherche zu Erdős-Problemen}, bottomrule=.15mm, colbacktitle=quarto-callout-note-color!10!white, toprule=.15mm]

\textbf{Forschende:} Mehtaab Sawhney und Mark Sellke

\textbf{Thema:} Nutzung von GPT-5 zur Identifizierung bereits
veröffentlichter Lösungen für Probleme aus der Erdős-Datenbank, die dort
als „offen`` gelistet waren.

\textbf{Mehrwert:}

„GPT-5 located references solving the above problems\ldots{} Identifying
these decades-old papers required GPT-5 to go far beyond the
functionality of a search engine, and indeed to read each of these
papers in detail and apply a genuine understanding of mathematics.``

„GPT-5 translated and explained the proofs from {[}Pom59{]} to us so
that we could verify them ourselves.``

„GPT-5 assisted us in pointing out parts of the paper that made the
intended definition clear.``

\textbf{Probleme:}

„\ldots in some cases it was overly enthusiastic about partial progress
it had found.``

\textbf{Schlussfolgerungen:}

„GPT-5 therefore provides the practicing mathematician a new mechanism
to access the collective breadth of the mathematical literature.``

„This provides a convenient, crowd-sourceable `soft certificate' that
the solution is unlikely to appear in the published literature.``

\end{tcolorbox}

\begin{tcolorbox}[enhanced jigsaw, breakable, titlerule=0mm, leftrule=.75mm, opacitybacktitle=0.6, rightrule=.15mm, arc=.35mm, left=2mm, colframe=quarto-callout-note-color-frame, opacityback=0, coltitle=black, bottomtitle=1mm, colback=white, toptitle=1mm, title=\textcolor{quarto-callout-note-color}{\faInfo}\hspace{0.5em}{Mathematik / LLMs als Forschungspartner}, bottomrule=.15mm, colbacktitle=quarto-callout-note-color!10!white, toprule=.15mm]

\textbf{Forschender:} Timothy Gowers

\textbf{Thema:} Erfahrungen bei der Nutzung von LLMs für mathematische
Probleme im Frühstadium.

\textbf{Mehrwert:}

„\ldots with GPT-5 my experience has been that the references are rarely
hallucinated, and even the hallucinations can turn out to be pointers to
references that exist and are useful.``

„\ldots GPT-5 has solved them {[}well-defined subproblems{]} for me in a
matter of seconds.``

„\ldots I have had reasonably precise ideas for solving problems that I
have run past GPT-5 Pro, which has explained to me why them cannot
work.``

„\ldots even the less good ideas of an LLM can sometimes stimulate me to
make progress. (I think of this as the `That clearly doesn't work
\ldots{} but wait a minute!' phenomenon.)``

\textbf{Probleme:}

„\ldots on the negative side, if I ask more open-ended questions, or
offer more sketchy ideas for proof attempts, then that seems to
encourage the more annoying characteristics of LLMs to come to the fore:
they will tell me that my ideas do indeed work, and will write something
that supposedly fleshes out the details but that does not withstand
close scrutiny.``

„\ldots it gave me a hallucinated reference but by an author who had
written on closely related topics.``

\textbf{Schlussfolgerungen:}

„\ldots my current assessment of LLMs is that they are just beginning to
be useful as research collaborators\ldots``

„\ldots LLMs can speed up the process of thinking about a problem,
especially if that problem is a little outside one's primary domain of
expertise\ldots``

„\ldots they are capable of playing this
knowledgeable-research-supervisor role with me\ldots{} but that they are
not yet at the level\ldots{} at which a human mathematician\ldots{}
would ask for joint authorship.``

\end{tcolorbox}

\begin{tcolorbox}[enhanced jigsaw, breakable, titlerule=0mm, leftrule=.75mm, opacitybacktitle=0.6, rightrule=.15mm, arc=.35mm, left=2mm, colframe=quarto-callout-note-color-frame, opacityback=0, coltitle=black, bottomtitle=1mm, colback=white, toptitle=1mm, title=\textcolor{quarto-callout-note-color}{\faInfo}\hspace{0.5em}{Mathematik / Neue Resultate zum Erdős-Problem \#848}, bottomrule=.15mm, colbacktitle=quarto-callout-note-color!10!white, toprule=.15mm]

\textbf{Forschende:} Mehtaab Sawhney und Mark Sellke

\textbf{Thema:} Lösung eines offenen Problems über Teilmengen von \{1,
\ldots, N\}, bei denen ab+1 nicht quadratfrei ist.

\textbf{Mehrwert:}

„GPT-5 put forward the new idea that led to our solution\ldots``

„The idea suggested by GPT-5's reply\ldots{} gives a method to use any
single number b ∈ A to obtain similarly harsh constraints on all other a
∈ A.``

\textbf{Probleme:}

„GPT-5 made attempts in this direction but had numerous errors in its
implementation (as can be seen in the transcript).``

„\ldots current models remain limited in perceiving the `negative space'
of mathematics. While models are able to suggest plausible proof
strategies, they often do not realize certain `obvious' examples which
block progress, and are overly confident in the power of existing
methods.``

\textbf{Schlussfolgerungen:}

„\ldots GPT-5 has the ability to serve as an effective mathematical
assistant, capable of recalling relevant lemmas, identifying analogies
and locating relevant results from vague, ill-specified prompts.``

\end{tcolorbox}

\begin{tcolorbox}[enhanced jigsaw, breakable, titlerule=0mm, leftrule=.75mm, opacitybacktitle=0.6, rightrule=.15mm, arc=.35mm, left=2mm, colframe=quarto-callout-note-color-frame, opacityback=0, coltitle=black, bottomtitle=1mm, colback=white, toptitle=1mm, title=\textcolor{quarto-callout-note-color}{\faInfo}\hspace{0.5em}{Mathematik / Graphentheorie: Teilgraphen-Zählungen}, bottomrule=.15mm, colbacktitle=quarto-callout-note-color!10!white, toprule=.15mm]

\textbf{Forschende:} Sébastien Bubeck, Mark Sellke und Steven Yin

\textbf{Thema:} Beweis von Ungleichungen für die Anzahl bestimmter
induzierter Teilgraphen in Bäumen.

\textbf{Mehrwert:}

„Both of GPT-5's proofs are quite different from any of the arguments in
{[}BL16; Bub+16{]}.``

„\ldots GPT-5's proof is short and elegant, and based on a somewhat
miraculous identity.``

\textbf{Probleme:}

„A few incorrect proofs were also generated and rejected by human
checking.``

\textbf{Schlussfolgerungen:}

„\ldots GPT-5 was able to reprove the first inequality, and then build
on this to also prove the second (open) inequality.``

\end{tcolorbox}

\begin{tcolorbox}[enhanced jigsaw, breakable, titlerule=0mm, leftrule=.75mm, opacitybacktitle=0.6, rightrule=.15mm, arc=.35mm, left=2mm, colframe=quarto-callout-note-color-frame, opacityback=0, coltitle=black, bottomtitle=1mm, colback=white, toptitle=1mm, title=\textcolor{quarto-callout-note-color}{\faInfo}\hspace{0.5em}{Mathematik / Lerntheorie: Dynamische Netzwerke}, bottomrule=.15mm, colbacktitle=quarto-callout-note-color!10!white, toprule=.15mm]

\textbf{Forschende:} Sébastien Bubeck, Mark Sellke und Steven Yin

\textbf{Thema:} Identifizierbarkeit des Parameters w in einem
modifizierten präferenziellen Bindungsprozess.

\textbf{Mehrwert:}

„GPT-5 was able to prove that w is indeed identifiable\ldots``

„\ldots this illustrates that GPT-5's decision to focus on the quantity
L(t) is already non-obvious.``

\textbf{Probleme:}

„\ldots when we asked (an unscaffolded) GPT-5 to provide more detail for
these latter arguments, it made several false starts\ldots{} After some
human pushback, GPT-5 eventually came up with a correct but
unnecessarily complicated proof\ldots``

\textbf{Schlussfolgerungen:}

„While all major proof ideas below are due to GPT-5, a few details of
proof writing are human-supplied.``

\end{tcolorbox}

\begin{tcolorbox}[enhanced jigsaw, breakable, titlerule=0mm, leftrule=.75mm, opacitybacktitle=0.6, rightrule=.15mm, arc=.35mm, left=2mm, colframe=quarto-callout-note-color-frame, opacityback=0, coltitle=black, bottomtitle=1mm, colback=white, toptitle=1mm, title=\textcolor{quarto-callout-note-color}{\faInfo}\hspace{0.5em}{Physik / Symmetrien Schwarzer Löcher}, bottomrule=.15mm, colbacktitle=quarto-callout-note-color!10!white, toprule=.15mm]

\textbf{Forschender:} Alex Lupsasca

\textbf{Thema:} (Re-)Derivation nichttrivialer Lie-Punkt-Symmetrien der
Wellengleichung in einer Kerr-Raumzeit.

\textbf{Mehrwert:}

„Within 18 minutes, the model produced the correct curved-space
generators closing into SL(2, R)\ldots``

„The final generators are too structured to be a lucky guess. The model
likely executed (implicitly) a mix of: recognizing conformal invariance
in the flat equation, hypothesizing a curved analogue, and/or exploiting
a coordinate map\ldots``

\textbf{Probleme:}

„The model initially failed on the curved-space problem, but then
succeeded after a flat-space warm-up\ldots``

„What GPT-5 got wrong (along the way). The cold start on Eq. (I.1)
incorrectly concluded `no symmetries.'\,``

\textbf{Schlussfolgerungen:}

„AI as a symmetry engine. With minimal domain scaffolding, current
models can carry out nontrivial Lie-symmetry discovery for PDEs with
non-constant coefficients.``

„Research velocity. Given such capabilities, the time from idea to
publishable result can compress from months to days once the right
prompts and scaffolds are in place.``

„\ldots contemporary LLMs can act as practical assistants for symmetry
discovery and analytic structure mining in theoretical physics.``

\end{tcolorbox}

\begin{tcolorbox}[enhanced jigsaw, breakable, titlerule=0mm, leftrule=.75mm, opacitybacktitle=0.6, rightrule=.15mm, arc=.35mm, left=2mm, colframe=quarto-callout-note-color-frame, opacityback=0, coltitle=black, bottomtitle=1mm, colback=white, toptitle=1mm, title=\textcolor{quarto-callout-note-color}{\faInfo}\hspace{0.5em}{Physik / Fusionsforschung: Thermonukleare Brandwellen}, bottomrule=.15mm, colbacktitle=quarto-callout-note-color!10!white, toprule=.15mm]

\textbf{Forschender:} Brian Keith Spears

\textbf{Thema:} Entwicklung eines reduzierten physikalischen Modells für
thermonuklearer Brandwellen in ICF-Kapseln.

\textbf{Mehrwert:}

„GPT-5 is quite good at this kind of model development and setup. It
required little intervention on my part to make this plausible and
complete.``

„The point is that I can now deliver in minutes as if I were at the
highest level I have ever been at for this kind of work. \ldots{} to
have it in minutes is remarkable.``

„However, when re-prompted to examine a pathological result or null
signal, GPT-5 offered quite sophisticated solutions, including different
implementations of FFTs to prevent aliasing, improved resolutions to
track burn fronts\ldots``

\textbf{Probleme:}

„GPT-5 was a bad designer, offering results that were null, noisy, or
invalid (NaNs), while claiming that glory had been achieved.``

„The model, in its eagerness to please, often introduces numerical duct
tape to smooth over a thorny issue, silently swaps out detailed
numerical solves for approximations with trends it knows I want, and
confidently declares victory when numerical signals are still obviously
noise.``

\textbf{Schlussfolgerungen:}

„\ldots executing this workflow from concept, to numerical exploration,
to theoretical supporting statement in hours is rather amazing.``

„I feel like my 6 hours of work here yielded something I could have done
over a month or two with a very good pair of postdocs\ldots{} That is a
compression of about a factor of 1000.``

„\ldots users must be expert enough to catch the oversimplifications,
must persist to get the model to reconsider, and must be
vigilant\ldots``

\end{tcolorbox}

\begin{tcolorbox}[enhanced jigsaw, breakable, titlerule=0mm, leftrule=.75mm, opacitybacktitle=0.6, rightrule=.15mm, arc=.35mm, left=2mm, colframe=quarto-callout-note-color-frame, opacityback=0, coltitle=black, bottomtitle=1mm, colback=white, toptitle=1mm, title=\textcolor{quarto-callout-note-color}{\faInfo}\hspace{0.5em}{Physik / Astrophysik: Gravitationsstrahlung}, bottomrule=.15mm, colbacktitle=quarto-callout-note-color!10!white, toprule=.15mm]

\textbf{Forschender:} Robert Scherrer

\textbf{Thema:} Analytische Integration des Leistungsspektrums von
Garfinkle-Vachaspati-Strings.

\textbf{Mehrwert:}

„After reasoning for 40 minutes, GPT-5 Pro produced a result for large
odd n identical to the asymptotic result I had previously
derived\ldots{} It used a completely different method of solution from
my own.``

„GPT-5 Pro also gave the leading order correction term to this
formula\ldots{} I was not aware of this correction term\ldots``

\textbf{Probleme:}

„The program hung up for quite a long time, giving me no details about
its thought process. After several hours I became frustrated and killed
it.``

\textbf{Schlussfolgerungen:}

„GPT-5 Pro is capable of solving complex analytic integrations that are
beyond the reach of symbolic manipulation programs such as
Mathematica.``

\end{tcolorbox}

\begin{tcolorbox}[enhanced jigsaw, breakable, titlerule=0mm, leftrule=.75mm, opacitybacktitle=0.6, rightrule=.15mm, arc=.35mm, left=2mm, colframe=quarto-callout-note-color-frame, opacityback=0, coltitle=black, bottomtitle=1mm, colback=white, toptitle=1mm, title=\textcolor{quarto-callout-note-color}{\faInfo}\hspace{0.5em}{Biologie / Immunologische In-vitro-Experimente}, bottomrule=.15mm, colbacktitle=quarto-callout-note-color!10!white, toprule=.15mm]

\textbf{Forschender:} Derya Unutmaz

\textbf{Thema:} Mechanistische Analyse der Wirkung von 2-DG auf die
Differenzierung von T-Zellen und Vorhersage der Zytotoxizität von
CAR-T-Zellen.

\textbf{Mehrwert:}

„GPT-5 Pro provided the key mechanism that could explain these findings
and, in addition, made highly relevant experimental suggestions.``

„The mechanistic insight and further hypothesis to dissect these
findings were highly valuable and not immediately obvious, despite our
deep expertise in this field.``

„GPT-5 Pro perfectly analyzed and described the data in the
figure\ldots``

„\ldots GPT-5 Pro made sufficient contributions to this work to the
extent that it would warrant its inclusion as a co-author in this new
study.``

\textbf{Probleme:}

„\ldots a caveat for this suggestion is that GPT-5 Pro may have known
about this finding and made the connection with this result.``

\textbf{Schlussfolgerungen:}

„GPT-5 Pro can function as a true mechanistic co-investigator in
biomedical research, compressing months of reasoning into minutes,
uncovering non-obvious hypotheses, and directly shaping experimentally
testable strategies.``

„Precision interpretation of complex biology. GPT-5 Pro rapidly
connected the observed phenotypes to a mechanistic hypothesis\ldots``

„The net effect will be a much higher discovery rate per experiment and
a shorter route from observation to discovery to intervention, thus
profoundly accelerating the biomedical scientific process.``

\end{tcolorbox}

\begin{tcolorbox}[enhanced jigsaw, breakable, titlerule=0mm, leftrule=.75mm, opacitybacktitle=0.6, rightrule=.15mm, arc=.35mm, left=2mm, colframe=quarto-callout-note-color-frame, opacityback=0, coltitle=black, bottomtitle=1mm, colback=white, toptitle=1mm, title=\textcolor{quarto-callout-note-color}{\faInfo}\hspace{0.5em}{Informatik / Geometrie: Literaturrecherche zur Optimierung}, bottomrule=.15mm, colbacktitle=quarto-callout-note-color!10!white, toprule=.15mm]

\textbf{Forschender:} Nikita Zhivotovskiy

\textbf{Thema:} Suche nach Anwendungen und verwandter Literatur für eine
neue geometrische Aussage über „α-ratio covers``.

\textbf{Mehrwert:}

„\ldots given only a core mathematical statement, GPT-5 can rapidly
surface nontrivial and technically aligned links across areas\ldots{}
providing context for new applications.``

„At first sight\ldots{} this seems unrelated to Theorem II.1.1 and could
be mistaken for a hallucination. However, unpacking their proof shows
that their result can be phrased as a coordinatewise (1+ϵ)-ratio
cover\ldots``

\textbf{Schlussfolgerungen:}

„\ldots GPT-5 can rapidly surface nontrivial and technically aligned
links across areas\ldots{} providing context for new applications.``

\end{tcolorbox}

\begin{tcolorbox}[enhanced jigsaw, breakable, titlerule=0mm, leftrule=.75mm, opacitybacktitle=0.6, rightrule=.15mm, arc=.35mm, left=2mm, colframe=quarto-callout-note-color-frame, opacityback=0, coltitle=black, bottomtitle=1mm, colback=white, toptitle=1mm, title=\textcolor{quarto-callout-note-color}{\faInfo}\hspace{0.5em}{Informatik / Schranken für Online-Algorithmen}, bottomrule=.15mm, colbacktitle=quarto-callout-note-color!10!white, toprule=.15mm]

\textbf{Forschender:} Christian Coester

\textbf{Thema:} Verbesserung der unteren Schranken für das Problem des
„Convex Body Chasing``.

\textbf{Mehrwert:}

„Given a single short prompt, GPT-5 produced a rather non-obvious
counter-example against the algorithm.``

„GPT-5 suggested a much simpler and cleaner solution: trigger the switch
once the algorithm is below the semicircle at distance ≥ ε from pt.~This
avoids the freeze\ldots{} The idea seems obvious in hindsight, yet far
more elegant\ldots``

„\ldots the inspiring appearance of the number π/2 in its reasoning
trace\ldots``

\textbf{Probleme:}

„The argument it gives for this {[}feasibility of the construction{]} is
actually incorrect, but a correct argument is easy to see\ldots``

„\ldots it initially failed to understand how viewing the problem in
continuous time could yield stronger bounds, and upon later
attempts\ldots{} it presented arguments containing serious flaws.``

„\ldots GPT-5's responses also contained some errors, but these were
easy to fix for a human, overall accelerating the research process.``

\textbf{Schlussfolgerungen:}

„Perhaps the most impressive part is its proof refuting the
follow-the-leader algorithm, produced from a single prompt without any
guidance on how to approach the task.``

\end{tcolorbox}

\begin{tcolorbox}[enhanced jigsaw, breakable, titlerule=0mm, leftrule=.75mm, opacitybacktitle=0.6, rightrule=.15mm, arc=.35mm, left=2mm, colframe=quarto-callout-note-color-frame, opacityback=0, coltitle=black, bottomtitle=1mm, colback=white, toptitle=1mm, title=\textcolor{quarto-callout-note-color}{\faInfo}\hspace{0.5em}{Informatik / Clique-avoiding Codes (Warnbeispiel)}, bottomrule=.15mm, colbacktitle=quarto-callout-note-color!10!white, toprule=.15mm]

\textbf{Forschende:} Venkatesan Guruswami und Parikshit Gopalan

\textbf{Thema:} Suche nach einer unteren Schranke für die Co-Dimension
von Codes, die Clique-Indikatoren vermeiden.

\textbf{Mehrwert:}

\emph{Kein expliziter Mehrwert im Text außer der Reproduktion bekannter
Beweise.}

\textbf{Probleme:}

„Initially, it was convinced that this bound was tight (up to an
additive constant), and tried to convince us of this using a sequence of
buggy arguments, resorting to linear algebra and proof by
authority\ldots``

„The most amusing was a hallucinated response to the effect that one of
us had asked this question on TCS Stack Exchange\ldots{} Both these
claims are incorrect.``

„\ldots it appears that GPT-5 reproduced Alon's proof and passed it
along to us without realizing its source.``

\textbf{Schlussfolgerungen:}

„Our experience illustrates a pitfall in using AI: although GPT-5
possesses enormous internal knowledge\ldots{} it may not always report
the original information sources accurately. This has the potential to
deceive even seasoned researchers into thinking their findings are
novel.``

\end{tcolorbox}

\textbf{Link zurück zum Fließtext:}
\{Abbildung~\ref{fig-ki-herausforderung}\}

\bookmarksetup{startatroot}

\chapter{Grundbegriffe}\label{sec-grundbegriffe}

\section{Definition einiger
Grundbegriffe}\label{definition-einiger-grundbegriffe}

In diesem Abschnitt wollen wir einigen Definitionen und Bedeutungen
klären. Dabei nutzen wir immer wieder kleine Interaktionen und
Lernspiele, auch um so zu zeigen, wie wir einfacher ``fragend'' und
aktivierend lehren können.

Wo finden Sie zusätzliches oder vertiefendes Material? Als visuelle
Begleitung empfehle ich das sehr schöne Einführungsvideo des
Mathematik-Didaktikers Grant Sanderson (7 Minuten,
\url{https://youtu.be/LPZh9BOjkQs}). Tiefer in die mathematischen
Details geht die grafische und interaktive Einführung als Animation von
Brendan Bycroft (\url{https://bbycroft.net/llm}). Wer sich auch die
technischen Hintergründe genauer erschließen will, kann das
Lehrbuch-Standardwerk von Jurafsky \& Martin (2025) nutzen, das online
frei verfügbar ist.

Von Prompt bis Token, über Temperatur und RAG: Was ist Ihnen schon an
Grundbegriffen in diesem Kontext vertraut? Testen Sie sich selbst mit
dem folgenden kleinen Spiel. Bei voller Punktzahl winkt Ihnen ein Preis!

\begin{tcolorbox}[enhanced jigsaw, breakable, titlerule=0mm, leftrule=.75mm, opacitybacktitle=0.6, rightrule=.15mm, arc=.35mm, left=2mm, colframe=quarto-callout-tip-color-frame, opacityback=0, coltitle=black, bottomtitle=1mm, colback=white, toptitle=1mm, title=\textcolor{quarto-callout-tip-color}{\faLightbulb}\hspace{0.5em}{Lernspiel: Welche Grundbegriffe kennen Sie schon?}, bottomrule=.15mm, colbacktitle=quarto-callout-tip-color!10!white, toprule=.15mm]

\emph{Ordnen Sie die Begriffe den korrekten Definitionen zu!}

(am besten auf dem Computer spielen). Hier auch Online abrufbar (so
etwas nennt sich ``Artifact'' beim Sprachmodell ``Claude'')
\href{https://claude.site/artifacts/d8e3cee4-ea47-48e3-a84c-a774d408aac8}{\ul{https://claude.site/artifacts/d8e3cee4-ea47-48e3-a84c-a774d408aac8}}

\end{tcolorbox}

Ein Sprachmodell ist ein Rechensystem, das das nächste Wort in einer
Wortkette vorhersagt, basierend auf den vorher genannten Wörtern in
dieser Kette Jurafsky \& Martin (2025), Kap.7, S.2). Ein großes
Sprachmodell Ein \textbf{Large Language Model (LLM)} ist ein
fortschrittliches maschinelles Lernmodell, das speziell darauf trainiert
ist, menschliche Sprache zu verstehen und Texte zu erzeugen, die
natürlich erscheinen. Die Modelle können erstaunliche Mengen von
Textdaten verarbeiten, um vielseitige Sprachanwendungen zu ermöglichen.

Die \textbf{generative Künstliche Intelligenz} (GenAI) bezieht sich auf
Systeme, die fähig sind, neue Inhalte zu erzeugen, wie etwa Texte, die
noch nicht existierten. LLMs sind ein zentraler Teil dieser generativen
KI und können eigenständig Texte zu einem breiten Spektrum von Themen
generieren.

\begin{tcolorbox}[enhanced jigsaw, breakable, titlerule=0mm, leftrule=.75mm, opacitybacktitle=0.6, rightrule=.15mm, arc=.35mm, left=2mm, colframe=quarto-callout-tip-color-frame, opacityback=0, coltitle=black, bottomtitle=1mm, colback=white, toptitle=1mm, title=\textcolor{quarto-callout-tip-color}{\faLightbulb}\hspace{0.5em}{Tipp: Mini-Interaktionen einfach als HTML erstellen}, bottomrule=.15mm, colbacktitle=quarto-callout-tip-color!10!white, toprule=.15mm]

Können Sie in HTML programmieren? Jetzt schon. Die \emph{Lernspiele in
diesem Abschnitt} wurden mit Hilfe von Sprachmodellen erstellt (Gemini,
ChatGPT, Claude). Meist mit einer Variation des einfachen Prompts:
\textbf{Erstelle mir ein browser-basiertes Lernspiel zum Thema / zur
Illustration von \ldots``}. Oft hat man nach 5-10 Minuten eine gute
erste Version. In der Lehre mache ich das oft auch als Übung mit
Studierenden. Sie sollen dann erst mit Hilfe der KI ein Lernspiel
erstellen und dann begründet bewerten, welcher Spiel-Prototyp das
Konzept am besten darstellt. Bei etwas mehr Zeit kann man sie
gegenseitig bewerten lassen, selbst Kriterien erstellen oder stärkere
Gamification hinzufügen. Im Ergebnis beschäftigen sich idealerweise die
Teilnehmer intensiv mit einem theoretischen Konzept (Bei komplexeren
Themen hilft es, einen Fachtext als Hintergrund zum Konzept
hochzuladen.)

\end{tcolorbox}

Das \textbf{Sprachmodell} (s. Abbildung 3) zerlegt dazu grob gesagt
Inputs wie Texte in kleine Bausteine (Tokens), verwandelt diese in
Zahlen (Embeddings), erkennt mithilfe komplexer Muster (Transformer und
Attention) deren Zusammenhänge, und erzeugt auf diese Weise
selbstständig basierend auf kontextbezogen berechneten
Wahrscheinlichkeiten neue Texte (generative Sprachproduktion).

Damit Sprachmodelle wie ChatGPT Sprache verstehen und erzeugen kann,
zerlegen sie Text in sogenannte \textbf{Tokens} -- kleine Bausteine wie
Wörter, Wortteile oder Satzzeichen (s. etwa Jurafsky \& Martin, 2025,
Kap.2). Jedes dieser Tokens wird in einen \textbf{Vektor} umgewandelt --
eine Zahlenreihe, die das Wort mathematisch beschreibt. Dieser Vorgang
nennt sich \textbf{Embedding}. Dabei wird darauf geachtet, dass ähnliche
Wörter ähnliche Vektoren erhalten, beispielsweise „Hund`` und „Katze``.

Hier kann man das selbst einfach ausprobieren: Das interaktive Widget
simuliert eine GPT-2-ähnliche Tokenisierung.

\begin{tcolorbox}[enhanced jigsaw, breakable, titlerule=0mm, leftrule=.75mm, opacitybacktitle=0.6, rightrule=.15mm, arc=.35mm, left=2mm, colframe=quarto-callout-tip-color-frame, opacityback=0, coltitle=black, bottomtitle=1mm, colback=white, toptitle=1mm, title=\textcolor{quarto-callout-tip-color}{\faLightbulb}\hspace{0.5em}{Geben Sie eigenen Text ein, unten wird er dann in Tokens und Zahlen
umgewandelt}, bottomrule=.15mm, colbacktitle=quarto-callout-tip-color!10!white, toprule=.15mm]

\end{tcolorbox}

Die kleine Simulation hier soll nur ein Gefühl für den Prozess geben.
Wie die Umwandlung eines bestimmten Textes genau in verschiedenen
Sprachmodellen aussieht, können Sie interaktiv auf Webseiten wie
Tiktokenizer ausprobieren: https://tiktokenizer.vercel.app/.

Ein \textbf{Prompt} ist eine Eingabeaufforderung, die an ein LLM
gesendet wird, um eine spezifische Antwort zu erhalten. Die Gestaltung
dieser Prompts ist entscheidend für die Qualität der generierten
Antworten und wird als \textbf{Prompt Engineering} bezeichnet.

\subsection{Was heißt hier GPT?}\label{was-heiuxdft-hier-gpt}

GPT steht für \textbf{Generative Pre-trained Transformer}. Wir schauen
zunächst, was diese drei Begriffe bedeuten.

\emph{`Generative'}: Der Begriff „\textbf{generativ}`` bedeutet in
diesem Zusammenhang, dass GPT eigenständig neue, sinnvolle Texte
erzeugen kann, indem es gelernte Muster neu kombiniert, anstatt fertige
Texte zu übernehmen.

\emph{`Pretrained'}: GPT wurde mit riesigen Textmengen
\textbf{vortrainiert} (\textbf{Pretraining}), ohne konkrete Aufgaben
lösen zu müssen -- dieser Vorgang erfolgt unüberwacht
(\emph{unsupervised learning}). Sprachmodelle nutzen häufig die Methode
\textbf{„Reinforcement Learning with Human Feedback`` (RLHF)}, um noch
bessere Texte zu generieren. Dabei erzeugt das LLM zunächst verschiedene
Textversionen, die von menschlichen Bewertern nach Qualität beurteilt
werden.Diese Bewertungen dienen dazu, das Modell zusätzlich zu
trainieren und zu steuern, indem Texte belohnt werden, die von Menschen
als besonders gut, klar oder hilfreich eingeschätzt wurden. Durch diesen
Prozess „lernt`` das LLM, Texte zu bevorzugen, die nicht nur sprachlich
richtig, sondern für Menschen besonders verständlich und nützlich sind.
Das macht es möglich, dass GPT später aus wenigen Stichworten neue Texte
generieren kann -- also kreativ Sprache produziert, ohne bloß zu
kopieren (generativ).

\emph{`Transformer'}: Das Herzstück des GPT ist der sogenannte
\textbf{Transformer} -- ein Rechenmodell, das durch ein spezielles
Aufmerksamkeitsverfahren (\textbf{Attention}) erkennt, welche Wörter im
Zusammenhang wichtig sind. Dadurch kann GPT die Bedeutung von Wörtern im
Kontext richtig einschätzen.

Im Transformer bedeutet „Attention``: Jedes Wort (genauer: jedes Token)
entscheidet dynamisch, auf welche anderen Tokens es beim Verstehen oder
Generieren am stärksten „hören`` sollte. Technisch ist das eine
gewichtete Mischung von Informationen: Das Modell bildet eine Art
Relevanzscore zwischen einem „aktuellen Interesse`` und möglichen
„Informationsquellen`` und erstellt daraus Gewichte, die sich zu 1
aufsummieren. Die Ausgabe ist dann eine gewichtete Summe der
Informationsinhalte. Das ist wie bei einer Literaturrecherche: Eine
Fragestellung (Query) wird mit Titeln/Abstracts als „Hinweis-Schilder``
(Keys) abgeglichen; die eigentlichen Inhalte (Values) aus den passenden
Quellen fließen dann stärker in das Gesamtverständnis ein.

Beispielsweise erkennt GPT so in einem Satz wie „Die Bank steht unter
einem Baum`` anhand des Kontextes, ob „Bank`` ein Möbelstück oder eine
Institution meint (s. Abbildung \_). (Der zentrale Fachartikel von 2017,
ein zentraler Auslöser der aktuellen KI-Welle, hatte den knackigen Titel
``Attention is all you need'' Vaswani et al. (2017) - der Artikel wurde
mittlerweile mehr als 200.000 fach zitiert.)

\textbf{Was behält das Sprachmodell von unserer Unterhaltung? Wie viel
Text kann ich -- auch als PDF -- hochladen?} Neuere LLMs können schon
ganze Bücher schnell aufsaugen und dann zusammenfassen (z.B. Claude,
ChatGPT oder Gemini). Das \textbf{Kontext-Fenster} eines LLM beschreibt
die Menge an vorherigem Text, die das Modell bei der Verarbeitung neuer
Informationen berücksichtigt, um den Kontext und die Zusammenhänge zu
verstehen.

Ein \textbf{Agent} im Kontext von Automation und künstlicher Intelligenz
meint zunächst allgemein etwas, das seine Umwelt wahrnimmt (durch
Sensoren) und auf sie einwirkt (durch Aktoren) (Russell \& Norvig, 2021,
S.54). Agenten bestehen aus einer Architektur, die bestimmt, was möglich
ist und einem Programm, das vorgibt, wie der Agent handeln soll (Russell
\& Norvig, 2021, S.65ff.). Ersteres meint bildlich gesprochen die Augen
und Hände des Agenten: Die \emph{Agenten-Architektur} beschreibt den
spezifischen Setup von Sensoren und Aktoren, die bestimmen, was für den
Agenten wahrnehmbar und handelbar ist. Für GenAI Agenten fragt das etwa:
Hat er Web-Anbindung? Kann er programmieren? Das \emph{Agenten-Programm}
ist das Regelbuch: es bestimmt, wie der Agent reagiert. Von einfachen
Wenn-Dann-Regeln bis hin zu komplexen Weltmodellen (z.B. Physik-Modelle,
die die Schwerkraft berücksichtigen oder Kosten-Gewinn Rechnungen für
eine Wirtschaftssimulation).

GPT-basierte Agenten können Text analysieren, generieren und
verschiedene Aufgaben automatisieren, indem sie vorab definierte Muster
und Regeln befolgen. Durch die Erstellung solcher Agenten können
Lehrende interaktive und personalisierte Lerninhalte einfacher
gestalten.

\textbf{RAG (Retrieval-Augmented Generation)} beschreibt die
Möglichkeit, zusätzliche Daten wie Fachtexte, Statistiken oder
Gesetzesbücher in Kombination mit einem KI Modell zu nutzen. Die KI ist
das Gehirn, die zusätzliche Wissensdatenbank quasi das Bücherregal, das
zu Rate gezogen werden kann. Je nach Kontextfenster stehen dort mehr
oder weniger Bücher. Insofern umschreibt RAG ein KI-Modell, das die
Fähigkeiten von Textgenerierungsmodellen (wie GPT) mit einer
Wissensdatenbank kombiniert. So wird etwa der Prompt-Agent (s.u.) mit
einer Reihe von Fachtexten „gefüttert``, in denen Best Practices des
Prompting erklärt werden.

Einige Unterschiede zwischen einem einfachen Sprachmodell (LLM) und dem
Setup mit Zusatzmaterial (RAG) und erlaubter Werkzeugnutzung (Tool Use,
Agenten) sehen wir an der folgenden Interaktion. Wählen Sie hier jeweils
die passende Antwort (einfach, aber so bleiben Sie dran!).

\begin{tcolorbox}[enhanced jigsaw, breakable, titlerule=0mm, leftrule=.75mm, opacitybacktitle=0.6, rightrule=.15mm, arc=.35mm, left=2mm, colframe=quarto-callout-tip-color-frame, opacityback=0, coltitle=black, bottomtitle=1mm, colback=white, toptitle=1mm, title=\textcolor{quarto-callout-tip-color}{\faLightbulb}\hspace{0.5em}{Lernspiel: LLM, RAG oder Agent, was sind mögliche Probleme und
Anwendungsfelder?}, bottomrule=.15mm, colbacktitle=quarto-callout-tip-color!10!white, toprule=.15mm]

Runter scrollen und ``Los gehts!'' auswählen, dann nacheinander die
Interaktionen für LLM, RAG und Agent auswählen und die Fragen
beantworten.

\end{tcolorbox}

Das Modell sucht nach relevanten Daten und integriert diese in die
generierte Antwort. In der Lehre kann RAG verwendet werden, um den
Studierenden Fachtexte oder besonders aktuelle Informationen zur
Verfügung zu stellen. Beispielsweise könnten Studierende in einem
Geschichtsseminar eine KI befragen, die externe Quellen durchforstet, um
aktuelle Erkenntnisse zu historischen Ereignissen zu präsentieren.
Unternehmen nutzen diese Technik, um etwa 1000-seitige
Gebrauchsanweisungen mit KI durchsuchbar zu machen, oder Chatbots zu
trainieren, die typische, repetitive Kundenanfragen beantworten.
Insofern ermöglicht RAG eine dynamische und zeitgemäße
Wissensvermittlung, die nicht auf das festgelegte Wissen des KI-Modells
beschränkt ist.

\subsection{Was nutzen - LLM, RAG oder
Agent?}\label{was-nutzen---llm-rag-oder-agent}

Wie unterscheiden sich die verschiedenen \emph{Nutzungs-Muster}, die wir
bis jetzt kennengelernt haben? Frage ich nur das Sprachmodell? Oder
lieber das Sprachmodell mit Zusatz-Material (RAG)? Oder vielleicht das
Sprachmodell mit Tools (Agenten)? Prüfen Sie Ihr Verständnis: Welche der
links gezeigten Antworten passen zu welchem der rechts gezeigten Muster?
Nutzt das Sprachmodell nur sein ``Standard-Wissen'' (LLM only), oder
werden ``Werkzeuge'' wie Internet-Nutzung erlaubt?

\begin{tcolorbox}[enhanced jigsaw, breakable, titlerule=0mm, leftrule=.75mm, opacitybacktitle=0.6, rightrule=.15mm, arc=.35mm, left=2mm, colframe=quarto-callout-tip-color-frame, opacityback=0, coltitle=black, bottomtitle=1mm, colback=white, toptitle=1mm, title=\textcolor{quarto-callout-tip-color}{\faLightbulb}\hspace{0.5em}{Lernspiel: Welche Art des LLM-Setups passt zu den links gezeigten
Antworten oder Denkprozessen?}, bottomrule=.15mm, colbacktitle=quarto-callout-tip-color!10!white, toprule=.15mm]

\end{tcolorbox}

Das beendet unsere kurze Begriffsbestimmung. Ein etwas breiteres Glossar
für Anwender finden Sie etwa bei der populärwissenschaftlichen
Zeitschrift CIO (Chief Intelligence Officer):
\url{https://www.cio.de/article/3700849/die-wichtigsten-begriffe-im-genai-umfeld.html}.

\section{Wie denken Sprachmodelle und warum halluzinieren
sie?}\label{wie-denken-sprachmodelle-und-warum-halluzinieren-sie}

Eine Studie des KI-Labors Anthropic hat mit neuen Methoden den
\textbf{Denkprozess eines Sprachmodells im Detail nachgezeichnet}
(Lindsey et al., 2025), was uns erstmals etwas genauer verstehen lässt,
wie Sprachmodelle mit verschiedenen Sprachen umgehen, wie sie den
Schreibprozess „planen``, wie sie bei Kalkulationen vorgehen, wie weit
ihre Selbsterkenntnis reicht und warum sie manchmal Antworten erfinden
(„halluzinieren``).

\begin{figure}

\centering{

\pandocbounded{\includegraphics[keepaspectratio]{index_files/mediabag/images/script02-03.pdf}}

}

\caption{\label{fig-thoughtprocess}Visualisierte Gedanken eines
Sprachmodells {[}@lindsey2025{]}}

\end{figure}%

\begin{itemize}
\tightlist
\item
  \textbf{Sprachübergreifend gleich:} Das Modell nutzt einen gemeinsamen
  sprachübergreifenden Bedeutungsraum.
\item
  \textbf{Textplanung:} Bei der Texterstellung plant das Modell mehrere
  Wörter im Voraus.
\item
  \textbf{Paralleles Rechnen:} Für Kalkulationen nutzt das Modell
  parallele Rechenpfade, die am Ende verbunden werden.
\item
  \textbf{Man traue nicht der Selbstkenntnis:} Das Modell erfindet
  manchmal Argumentationsketten (\emph{motivated reasoning}).
\item
  \textbf{Bekanntheit führt zu Halluzinationen:} Wenn das Modell eine
  genannte Entität „kennt`` (hier: den Namen des Forschers, Karpathy),
  aber nicht die Antwort auf die Frage (Titel des Fachartikels) führt
  das zu erfundenen Antworten (die „can't answer``-Funktion wird
  unterdrückt).
\end{itemize}

Claude nutzt einen \textbf{gemeinsamen Bedeutungsraum für verschiedene
Sprachen} -- ein Hinweis auf eine Art „universelle Denksprache``. Claude
verarbeitet Informationen in einem sprachunabhängigen, abstrakten
Bedeutungsraum. Bei der Frage nach dem „Gegenteil von klein`` in
verschiedenen Sprachen (z.\,B. Englisch, Französisch, Chinesisch)
aktivieren sich im Modell dieselben internen Merkmale für „Kleinheit``
und „Gegenteil``, unabhängig von der Eingabesprache. Erst in einem
späteren Schritt wird die Antwort in die jeweilige Zielsprache
übersetzt. Diese Erkenntnis legt nahe, dass Claude Wissen und Konzepte
sprachübergreifend anwenden kann.

\textbf{Plant das Sprachmodell die Textgeneration?} Entgegen der
Annahme, dass Sprachmodelle Texte strikt Wort für Wort basierend auf dem
unmittelbaren Kontext generieren, zeigt Claude die Fähigkeit, mehrere
Wörter im Voraus zu planen. In Aufgaben zur Gedichtgenerierung
identifiziert Claude beispielsweise Reimwörter, bevor es die
vorhergehenden Zeilen formuliert. Ein Beispiel: Soll ein Gedicht mit dem
Wort „Kaninchen`` enden, wählt Claude dieses Zielwort frühzeitig aus und
gestaltet die Zeile so, dass sie darauf hinführt. \hspace{0pt}Diese
Fähigkeit zur Vorausplanung deutet darauf hin, dass Claude in der Lage
ist, komplexe Textstrukturen zu erstellen, die über einfache
Wortassoziationen hinausgehen.

\textbf{Wie kalkulieren Sprachmodelle?} Anthropic hat in seiner Studie
zu Claude 3.5 Haiku detailliert untersucht, wie das Modell mathematische
Berechnungen intern verarbeitet. Dabei wurde festgestellt, dass Claude
bei Aufgaben wie der Addition von Zahlen parallele Rechenpfade nutzt, um
zu einem Ergebnis zu gelangen.\hspace{0pt} Claude verwendet zwei
Hauptpfade, um Additionen durchzuführen: 1. \textbf{Grobabschätzung:}
Ein Pfad schätzt das Ergebnis basierend auf den Größenordnungen der
Zahlen. 2. \textbf{Präzise Berechnung:} Ein anderer Pfad fokussiert sich
auf die genaue Berechnung, insbesondere auf die Bestimmung der letzten
Ziffer der Summe.

Diese beiden Pfade arbeiten zusammen, um das finale Ergebnis zu
erzeugen. Wenn beispielsweise der Pfad für die letzte Ziffer deaktiviert
wird, liefert Claude nur eine grobe Schätzung, ohne die genaue Endziffer
korrekt zu bestimmen.

\textbf{Können wir das Modell fragen, wie es zu einem Ergebnis gekommen
ist?} Eher nicht. Anthropics Studie zeigt, dass das Modell bei komplexen
Aufgaben manchmal überzeugende, aber erfundene Argumentationsketten
präsentiert. Bei einfachen Berechnungen, wie der Quadratwurzel von 0,64,
lassen sich klare interne Rechenschritte nachweisen. Bei schwierigeren
Aufgaben, etwa der Berechnung des Kosinus einer großen Zahl, gibt Claude
jedoch vor, Berechnungen durchgeführt zu haben, obwohl keine
entsprechenden internen Prozesse erkennbar sind. In solchen Fällen
konstruiert das Modell plausible, aber unbegründete Erklärungen -- ein
Verhalten, das als „motiviertes Denken`` bezeichnet wird. Diese
Fähigkeit, überzeugend zu argumentieren, ohne tatsächlich die zugrunde
liegende Logik zu befolgen, kann für Nutzer irreführend sein. Die von
Anthropic entwickelten Interpretationswerkzeuge ermöglichen es, solche
untreuen Denkprozesse zu identifizieren, indem sie die tatsächlichen
internen Abläufe des Modells sichtbar machen. Dies ist ein wichtiger
Schritt, um die Zuverlässigkeit und Transparenz von KI-Systemen zu
verbessern.

\textbf{Was kann zu Halluzinationen führen?} Wie wir im oben gezeigten
Beispiel sehen, ist den Antworten des Sprachmodells nicht immer zu
trauen. Das LLM verfügt über einen standardmäßig aktiven „Refusal
Circuit``, der das Modell dazu bringt, keine Antwort zu geben, wenn es
keine ausreichenden Informationen hat. Wenn eine bekannte Entität
erfasst wird, aktiviert sich ein konkurrierender „Known
Entity``-Mechanismus, der den Refusal Circuit hemmt und eine Antwort
ermöglicht. Problematisch wird es, wenn Claude einen Namen erkennt, aber
keine spezifischen Informationen dazu hat. In solchen Fällen kann der
„Known Entity``-Mechanismus fälschlicherweise den Refusal Circuit
unterdrücken, was zu einer Halluzination führt. Ein Beispiel: Bei der
Frage nach einem Fachartikel des bekannten Forschers Karpathy gibt
Claude einen erfundenen Titel an, da das Modell zwar den Namen kennt, in
diesem Fall aber keine Informationen über den Artikel hat. Bei weniger
bekannten Namen gibt das Modell an, die Antwort nicht zu kennen (Lindsey
et al., 2025).

\section{Welches Modell wählen?}\label{welches-modell-wuxe4hlen}

\textbf{Was für LLMs gibt es aktuell?} Die großen Anbieter mit den
jeweils stärksten Modellen (s. @fig-leaderboard) sind OpenAI (Chat
GPT-5), Google (Gemini 2.5) und Anthropic (Claude Opus 4.1 / Sonnet 4).
Je nach Anwendung werden günstigere Modelle angeboten, die weniger
Rechenaufwand benötigen, meist mit dem Zusatz „Mini``. Starke Reasoning
Modelle (die komplexe Fragestellungen bearbeiten können) von OpenAI sind
GPT 5 oder Gemini 2.5 Flash (Stand 08/2025). Kostenfrei nutzbare Open
Source Alternativen sind z.B. Mistral (eines der wenigen europäischen
Modelle) und Llama4 (von Meta/Facebook) sowie die chinesische Konkurrenz
DeepSeek V3.1 (Mollick, 2025a; sowie Vellum, 2024).

\textbf{Welches Sprachmodell sollte man aktuell nutzen?} Die kurze
Antwort ist, dass aktuell \textbf{GPT-5 eine gute Wahl} ist. \textbf{Für
Lehrende kostenfrei nutzbar} gibt es aktuell (August 2025) den zentralen
Dienst „Chat-AI`` / Academic Cloud der Gesellschaft für
wissenschaftliche Datenverarbeitung Göttingen (GWDG)
(https://chat-ai.academiccloud.de/), über den neben einer Reihe von
quelloffenen Modellen mittlerweile auch Chat GPT-5 nutzbar ist. Hier
kann man sich einfach mit einer Hochschuladresse registrieren und den
Dienst nutzen. Hochschulen bieten teils einen eigenen KI-Zugang an, die
TH-Köln etwa einen begrenzten Zugang zu ChatGPT und einzelnen
quelloffenen Modellen über das THKI-Lab
(https://ki.th-koeln.de/login.php). \textbf{Im September 2025 wurde} an
der TH Köln und weiteren NRW-Hochschulen die Lösung KI:connect
ausgerollt, die ähnliche Funktionalitäten bereitstellt
(https://kiconnect.pages.rwth-aachen.de/pages/).

Außerdem können Lehrende über die Hochschullizenz Microsoft 365 Copilot
herunterladen und dann einen KI-Chat als Desktop-Anwendung nutzen, eine
Anwendung, unter deren Haube auch wieder verschiedene Versionen von
ChatGPT stecken (hier einloggen und einfach herunterladen:
https://www.office.com/). Hier kann man auch GPT 5 nutzen, Chats
speichern und komplexere Anweisungen als „Agenten`` entwerfen und
teilen.

Diese kostenfreien Lösungen sind in den letzten Monaten stark ausgebaut
worden und mittlerweile schon sehr nützlich geworden. Sie stellen
allerdings i.d.R. nicht den aktuellen Stand der Performanz der
KI-Modelle dar. Lehrende sollten daher unbedingt 1 bis 2 Monate die 20
Euro investieren und auch die stärksten Bezahlmodelle ausprobieren (also
ChatGPT oder Gemini in der Bezahlversion). Nur so erhält man ein Gefühl
dafür, was aktuell technisch möglich ist und wie „sicher`` die eigenen
Prüfungsleistungen sind (z.B. „im Gespräch`` mit der KI, über das Voice
Modell, was bei den kostenfreien Zugängen aktuell meist abgeklemmt ist).

\pandocbounded{\includegraphics[keepaspectratio]{index_files/mediabag/images/script02-10.pdf}}
\pandocbounded{\includegraphics[keepaspectratio]{index_files/mediabag/images/script02-11.pdf}}

Quelle: (Vellum, 2024), Stand 08/2025.

\textbf{Hier kann man vergleichen:} In der LM-Arena kann man
verschiedene Modelle ausprobieren und ihre Antwort auf eine bestimmte
Frage gegenüberstellen: https://lmarena.ai/ (Untermenü: „Arena
(side-by-side)``).

\section{Was können die Modelle -- und was
nicht?}\label{was-kuxf6nnen-die-modelle-und-was-nicht}

Was für Aufgaben LLMs beherrschen ist sehr uneinheitlich und
\textbf{verändert sich dynamisch}. Es gibt Bereiche, in denen heutige KI
auf menschlichem Niveau oder besser agiert, und andere, oft nur
geringfügig andersartige Aufgaben, an denen die KI (noch) scheitert
(Dell'Acqua et al., 2023). Mollick und Kollegen prägen hierfür den
Begriff einer „\textbf{Jagged Technological Frontier}`` (zerklüftete
Technik-Grenze) (Dell'Acqua et al., 2023). Zwei Aufgaben von ähnlicher
Schwierigkeit für Menschen können mit sehr unterschiedlicher Qualität
durch ein LLM gelöst werden -- eine liegt innerhalb der KI-Frontier
(d.~h. die KI kann sie lösen), die andere außerhalb (KI liefert
unbrauchbare oder falsche Resultate) (Dell'Acqua et al., 2023).

In einem Experiment mit Consultants wurden 18 verschiedene
Beratungsaufgaben gestellt. Für die meisten („inside the frontier``)
brachte KI enorme Vorteile, doch bei einer gezielt außerhalb der
Frontier gewählten Aufgabe schnitt die KI-Gruppe deutlich schlechter ab:
Hier waren die Consultants in der Gruppe mit KI 19 Prozentpunkte weniger
häufig korrekt als die ohne KI (Dell'Acqua et al., 2023). Dieses
Ergebnis unterstreicht die \textbf{Gefahr, LLMs unkritisch auf Probleme
anzuwenden, die ihre aktuellen Fähigkeiten übersteigen} -- die Leistung
fällt dann hinter menschliches Niveau zurück. Praktisch bedeutet die
Jagged Frontier, dass Organisationen und Individuen lernen müssen, die
Grenze der KI-Fähigkeiten zu erkennen und entsprechend zu navigieren
(Dell'Acqua et al., 2023).

Für folgende Anwendungsfälle sind LLMs mittlerweile gut nutzbar (Handa
et al., 2025-04-08, 2025; Korinek, 2024; Schwarcz et al., 2025):

\begin{itemize}
\tightlist
\item
  Zusammenfassung von Fachartikeln
\item
  Fortgeschrittene mathematische Ableitungen
\item
  Anspruchsvolle Codierungsaufgaben
\item
  Erstellen eines Podcasts zu einer Forschungsarbeit
\item
  Erstellen von Präsentationsfolien
\item
  Verfassen von Blogbeiträgen
\item
  Simulieren von Interviews mit der Sprachausgabe von ChatGPT oder
  Gemini
\item
  KI-gestützte Suche (mit kritischer Prüfung natürlich)
\end{itemize}

Die Fähigkeiten der Modelle wuchsen in den letzten Monaten rasant und
damit werden die Aufgaben, die man an sie delegieren kann komplexer. Die
Länge der Aufgaben, die KI Sprachmodelle relativ genau erledigen können,
verdoppelt sich seit 2019 etwa alle 7 Monate (Kwa et al., 2025). Auch
die Bewertung von Forschungsarbeiten im Rahmen des Peer-Reviews wird
zunehmend teil-automatisiert, etwa durch die automatische Prüfung von
Quellen oder Code und Teilbewertungen durch Dienste wie Veracity oder
Paper Wizard (Lovely, 2025; Naddaf, 2025).

\textbf{Ist das ein Mensch, oder ein Bot?} Eine neuere Studie zeigt,
dass neue Sprachmodelle uns bei dieser Frage mittlerweile
\textbf{erfolgreich täuschen können} und so den Turing Test bestehen, da
sie in einer sozialen Interaktion Menschen erfolgreich imitieren können
(Jones \& Bergen, 2025). In einem randomisierten
Drei-Parteien-Turing-Test mit über 1.000 Spielen wurde ein mit
speziellen Eingabe-Anweisungen (Persona-Prompt) versehenes Sprachmodell
(GPT-4.5) von den Respondenten zu 73 \% für den Menschen gehalten,
häufiger als echte Menschen in der Vergleichsgruppe. Weniger komplexe
Modelle (wie Llama 3.1) schritten schlechter ab. Die Autoren diskutieren
daraus resultierende Risiken von sozialer Manipulation oder
Arbeitsplatzsubstitution, sowie die Notwendigkeit robusterer
menschlicher Erkennungsstrategien.

Auch durch diesen Fähigkeitsschub ist der \textbf{Einsatz von
Sprachmodellen in Support-Funktionen wie Call Centern stark gestiegen},
empirische Studien belegen hier einen starken Produktivitätszuwachs
(Brynjolfsson et al., 2025).

Die Gründe für die Produktivitätssteigerung von KI-Modellen lassen sich
durch \textbf{Scaling Laws} (Training Scaling Law, Inference Scaling
Law, (Mollick, 2025a) beschreiben: KI-Modelle werden einerseits
exponentiell besser, je mehr Daten, Rechenleistung und Parameter genutzt
werden und andererseits, wenn sie mehr Zeit zum „nachdenken`` erhalten.
(FÜr eine schöne visuelle Beschreibung, s. Grootendorst (2025))

Der erste Zusammenhang (\textbf{Training Scaling Law}) besagt, dass
größere KI-Modelle mit mehr Parametern und Trainingsdaten systematisch
leistungsfähiger werden. Allerdings sind solche Ertragszuwächse mit
hohen Kosten verbunden: Eine 10-fache Steigerung an Rechenaufwand führt
etwa zu einer Erhöhung der Leistungsmetriken um einen festen Betrag, was
abnehmende Grenzerträge andeutet.

Neben dem positiven Effekt der Modellgröße wurde in den letzten Monaten
ein zweiter Scaling-Effekt (\textbf{Inference Scaling Law}) auf der
Anwenderseite deutlich: LLMs liefern bessere Lösungen, wenn man ihnen
mehr „\textbf{Denkzeit}`` gibt. OpenAI fand heraus, dass ein Modell mit
längerer Schritt-für-Schritt-Reasoning-Phase merklich bessere Ergebnisse
erzielt, analog zu einem Menschen, dem man mehr Zeit für eine schwierige
Aufgabe gibt. Dieser Inference Scaling Law führte zur Entwicklung von
\textbf{Reasonern} -- KI-Systemen, die bei Bedarf intern zusätzliche
Rechenschritte durchführen, um schwierige Probleme genauer zu lösen
(Gottweis et al., 2025; OpenAI, 2024; Schwarcz et al., 2025).

Zusammengenommen bedeuten diese Skalierungsgesetze, dass KI-Systeme
\textbf{durch höheren Ressourceneinsatz (beim Training und bei der
Nutzung) immer leistungsfähiger} und vielseitiger werden, wenn auch zu
steigenden Kosten. Ökonomisch relevant ist hier vor allem, dass die
\textbf{Grenzkosten der KI-Nutzung sehr niedrig} bleiben, sobald ein
großes Modell einmal trainiert ist: Ist das Modell erstellt, kann es
millionenfach eingesetzt werden, was \textbf{Skaleneffekte in der
Verbreitung} ermöglicht. Somit schafft das Scaling Law die Grundlage
dafür, dass \textbf{hochleistungsfähige KI als allgemein verfügbares
Gut} in Wirtschaft und Bildung eingesetzt werden kann. Durch diese
Eigenschaft ermöglicht KI eine schnelle und kosteneffiziente Skalierung
personalisierter und adaptiver Lernangebote (Mollick, 2025a). Dieses
exponentielle Wachstum unterscheidet KI grundlegend von bisherigen
technologischen Entwicklungen, bei denen Verbesserungen oft linear
verliefen.

OpenAI hat allein in den ersten Monaten von \textbf{2025 mehrere neue
Funktionen} eingeführt, die den Einsatz von KI in der Hochschullehre
deutlich erweitern könnten: Mit der Bildgenerierungsfunktion in GPT4o
lassen sich nun auch fotorealistische Visualisierungen erstellen, was
z.B. in der technischen Bildung oder bei Designprojekten didaktisch
genutzt werden kann (März 2025). Die neuen Audio-Modelle ermöglichen
eine präzise Steuerung von Sprachstil und Tonfall -- hilfreich etwa für
simulierte Rollenspiele, interaktive Lernbegleiter oder barrierefreie
Lerninhalte (März 2025). Das im Februar eingeführte \textbf{deep
research}-Modul erlaubt KI-gestützte Rechercheprozesse, die Studierende
bei komplexen Projektarbeiten oder der Literatursichtung unterstützen
könnten (Februar 2025). Zusätzlich wurde mit \textbf{o3-mini} ein
kostengünstigeres Modell vorgestellt, das den Zugang zu leistungsfähigen
KI-Anwendungen auch in Bildungseinrichtungen erleichtert (Januar 2025).

\pandocbounded{\includegraphics[keepaspectratio]{index_files/mediabag/images/script02-05.pdf}}.
Quelle: Kwa et al. (2025)

Es lassen sich nach dieser Studie \textbf{zwei Kooperationsmodelle
zwischen Mensch und LLM} unterscheiden, um die Technologiegrenze optimal
auszunutzen (Dell'Acqua et al., 2023): Der \textbf{Centaur-Ansatz} teilt
die Aufgabe, indem der Mensch der KI die Teilprobleme überlässt, die
innerhalb der Frontier liegen, und sich selbst auf den Rest
konzentriert. Der \textbf{Cyborg-Ansatz} integriert die KI tiefer, indem
der Mensch kontinuierlich mit der KI interagiert und Feedback-Schleifen
nutzt. Beide setzen implizit voraus, dass der Nutzer um die Stärken und
Schwächen des LLM weiß.

Eine spätere Studie des weitgehend selben Teams mit 776 Praktikern bei
Procter \& Gamble zeigt, dass Individuen mit LLM Unterstützung deutlich
produktiver Probleme lösen oder neue Ideen generieren konnten. Das
Sprachmodell scheint einen deutlichen Mehrwert als „\textbf{Cybernetic
Teammate}`` zu bringen und Einzelne teils auf das Leistungsniveau von
ganzen Teams zu bringen (Dell'Acqua et al., 2025).

Wenn man \textbf{ältere oder weniger starke (offene) Modelle nutzt,
fährt man mit dem Fahrrad auf der Autobahn}. Vergleiche zeigen starke
Performanzunterschiede zwischen GPT-3.5 und den folgenden Updates zu
GPT-4 und GPT-4o. Auch die frei verfügbaren Modelle wie Llama sind teils
deutlich weniger „schlau``! Hier muss man insofern aufpassen, dass die
einfache Verfügbarkeit solcher Modelle über Plattformen wie Academic
Cloud nicht zu einem falschen Bild führt.

\section{Wo und wie spreche ich mit der
KI?}\label{wo-und-wie-spreche-ich-mit-der-ki}

\subsection{Wo sprechen? Verschiedene Zugänge zu
Sprachmodellen}\label{sec-prompt-vorgehen}

\textbf{Wo} sprechen wir mit dem Sprachmodell? Welche Zugänge zur KI
gibt es? Es gibt \textbf{grob gesagt drei Ansätze}:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  Die einfache Eingabe in das Chat-Interface (z.B. bei Chat GPT oder
  Claude), ist am leichtesten umzusetzen. Um verschiedene Modelle zu
  nutzen, muss man sich aber neu einloggen und evtl. ein weiteres
  Abonnement bezahlen. Die meisten Modelle erlauben aber auch recht
  umfangreiche kostenlose Nutzung, was meist zum Kennenlernen ausreicht.
  Für Hochschulen werden zentral nach und nach verschiedene Dienste mit
  solchen Oberflächen aufgesetzt, die meist aber aus Gründen des
  Datenschutzes einige Funktionen abklemmen (z.B. meist die direkte
  Sprachinteraktion und das Speichern von Benutzerprofilen).
\item
  Nutzung einer Bedienoberfläche wie Witsy oder Typingmind, die Prompts
  speichert und Agenten erstellen lässt, die mit verschiedenen Modellen
  funktionieren (Schwarze, 2025). Hier muss man einmalig das System
  aufsetzen (Witsy) und für den höheren Komfort teils eine eine Lizenz
  kaufen (TypingMind, ca. 40 \$ für Hochschulangehörige), dafür kann man
  dann einfacher Modelle wechseln und über einen sogenannten API Key nur
  die tatsächliche Nutzung abrechnen (was sich bei einfacher Nutzung auf
  ein paar Cent beläuft, siehe die oben gezeigte Übersicht der Preise
  pro Millionen Token).
\item
  Wenn man sich nicht vor etwas Code scheut, kann man auch einfach
  selbst programmieren (mit KI-Unterstützung in Tools wie Google Colab)
  und kleine Sprachagenten aufsetzen. (Evtl. dann in Verbindung mit
  \textbf{Replit} für die Online-Bereitstellung und Diensten wie
  \textbf{Voiceflow} für die Oberfläche.) Auch hierfür braucht man
  eigentlich nur API Keys zur Identifizierung. Fragen Sie Chat GPT, wie
  das geht und lassen sich den Code schreiben, es ist überraschend
  einfach! Es gibt bei Youtube auch eine Vielzahl von kurzen
  Erläuterungen.
\end{enumerate}

\subsection{Wie sprechen?
Prompt-Befehle}\label{wie-sprechen-prompt-befehle}

\textbf{Wie} spreche ich mit dem LLM? Vorab die vielleicht wichtigste,
wenn auch banale Empfehlung: Es hilft, \textbf{genau zu sagen, was man
eigentlich will}. Man sollte nicht auf den Hiwi schimpfen, wenn man sich
nicht die Zeit genommen hat, zu sagen, was eigentlich die Aufgabe ist!

Wie beschreibe ich genau, was ich will? Einfache \textbf{Daumenregeln
für Prompts} gliedern das in vier Schritte: dem Sprachmodell eine
\textbf{Rolle} zuzuweisen („Du bist Verhandlungsexpertin``), ein klares
\textbf{Ziel} zu definieren („Du hilfst mir dabei, mich auf
Geschäftsverhandlungen vorzubereiten``), es zu bitten, sein
\textbf{Vorgehen} (den Gedankengang / „chain of thought``) offenzulegen
und Schritt-für-Schritt vorzugehen („Erstelle zunächst einen Plan und
frag mich nach Feedback. Warte meine Antwort ab und passe den Plan
eventuell an. Wenn ich zufrieden bin, beginne mit dem ersten Schritt in
deinem Plan.``) sowie \textbf{Beispiele} („few shot``) für eine
gewünschte Struktur oder Analyse mitzuliefern („Formatiere die
Dateinamen in dieser Form {[}Autor{]}-{[}Jahr{]}-{[}Kurztitel{]}``, oder
„Gib mir 5 Handlungsoptionen und nenne jeweils Vor- und Nachteile``).

Dabei veranlasst die Chain of Thought-Methode das LLM, seine
Gedankengänge offen zu legen. Das Modell zeigt seine Überlegungen
Schritt für Schritt, was die Nachvollziehbarkeit seiner Antworten
verbessert. So können wir auch besser nachsteuern und das Ergebnis an
unsere Ziele anpassen.

\begin{tcolorbox}[enhanced jigsaw, breakable, titlerule=0mm, leftrule=.75mm, opacitybacktitle=0.6, rightrule=.15mm, arc=.35mm, left=2mm, colframe=quarto-callout-note-color-frame, opacityback=0, coltitle=black, bottomtitle=1mm, colback=white, toptitle=1mm, title=\textcolor{quarto-callout-note-color}{\faInfo}\hspace{0.5em}{Hinweis}, bottomrule=.15mm, colbacktitle=quarto-callout-note-color!10!white, toprule=.15mm]

Wollen Sie sich interaktiv einen ausführlichen Prompt erstellen lassen?
Nutzen Sie diesen \textbf{Prompt-Bot}, den wir für Sie auf Basis der
Best-Practice Empfehlungen von OpenAI, Anthropic und wissenschaftlichen
Studien zu Prompt-Strategien erstellt haben:
\url{https://chatgpt.com/g/g-sF6vTgq2U-prompt-bot}

\end{tcolorbox}

Neuere empirische Untersuchungen haben eine Reihe von
\textbf{anekdotischen Hausrezepten des Promptings systematisch geprüft
und meist widerlegt}. Prompts funktionieren nicht immer gleich und so
kommt es schnell zu anektodischer Evidenz, dass eine Formulierung
„besser geklappt`` hätte. Die wenigsten der Empfehlungen helfen
zuverlässig (Meincke et al., 2025b, 2025b, 2025a). Hilft es,
\textbf{höflich} zu sein (nein), zu \textbf{drohen} (nein),
\textbf{Geld} anzubieten (nein), oder den Hiwi-Bot \textbf{Schritt für
Schritt} vorgehen zu lassen (ja, aber das machen die neueren
Reasoning-Sprachmodelle auch selbst)?

Für die Lehre wollen wir \textbf{den Prompts speziell didaktische
Elemente hinzufügen}, also etwa verhindern, dass den Studierenden sofort
eine Lösung ausgegeben wird, da das eigene Nachdenken in Form von Fragen
und sokratischem Dialog ihnen dabei hilft, die Ergebnisse auch zu
behalten (Roediger \& Pyc, 2012). Konkrete und sehr detaillierte
\textbf{Prompt-Beispiele speziell für die Lehre} finden Sie im Appendix
3: Ausgewählte Prompts zur Lehr- und Lernunterstützung. Weitere
Beispiele dafür finden sich in der Prompt-Bibliothek von Ethan Mollick
(https://www.moreusefulthings.com/prompts).

Gerade \textbf{für „Agenten``}, die einigermaßen zuverlässig bestimmte
Aufgaben erfüllen sollen, lohnt es sich aber im Sinne der o.g.
Empfehlung (sag, was Du willst), sehr detaillierte Prompts mit
Beispielen zu formulieren. Wer hier tiefer einsteigen will, kann hier
die \textbf{detaillierten Empfehlungen der KI-Labore zum Prompt-Design
lesen:} von Anthropic/Claude, alternativ hier die Details von OpenAI.

\section{Wie steht es mit dem Energieverbrauch der
Modelle?}\label{wie-steht-es-mit-dem-energieverbrauch-der-modelle}

Durch das starke Wachstum der neuen Technologie, werden wir verstärkt
mit den möglichen Effekten von KI auf Ressourcenverbrauch und
Umweltbelastung konfrontiert Spencer \& Singh (2025). Auch bei der
Nutzung in der Lehre wird dies regelmäßig von Studierenden angesprochen.
In diesem Bereich gibt es viel Hype und Desinformation in beide
Richtungen (von „Weltuntergang durch KI-Energiehunger!{}`` zu „keinerlei
Problem``), so dass hier ein kurzer Überblick seriöser Studien nützlich
erscheint. Dieser sehr knappe Abriss soll vor allem eine kurze
Orientierung und den Verweis auf weiterführende Literatur zur vertieften
Beschäftigung bieten.

\textbf{Wie schmutzig ist es also, KI zu nutzen? Die kurze Antwort} ist,
dass ein typischer Prompt aktuell etwa soviel Energie verbraucht wie ca.
10 Sekunden Netflix-Streaming oder eine typische Google Suche im Jahre
2008 (Elsworth et al., 2025; Mollick, 2025c). Die gute Nachricht ist,
dass die Modelle effizienter werden und der Energieverbrauch pro
Output-Token rasant sinkt und dass die Anreize für die großen Anbieter
stark darauf ausgerichtet sind, den Energieverbrauch weiter zu senken.
Gegenläufig und problematisch ist die stark steigende Nutzung, die z.B.
zur Ausweitung gerade umweltbelastender Energieformen wie Gasturbinen
führt (Wittenberg, 2025).

\textbf{Solche Vergleiche sind nicht trivial}, da etwa bei der Nutzung
in Unternehmen auch die Umweltfolgen der aktuellen Alternativen
„bepreist`` werden müssen, um einen sinnvollen Vergleich zu erzielen.
Wie belastet die Lieferkette eines physischen Buchs die Umwelt im
Vergleich zu einem E-Book? Ein aktueller Mitarbeiter im physischen
Callcenter mit seinem Arbeitsweg, Schreibtisch und Heizbedarf im
Vergleich zum KI-Chatbot? Unabhängig davon, wie diese Rechnungen
ausgehen, sind sie sichtlich komplex.

Im Folgenden sollen dazu einige Kernaussagen aus Untersuchungen der
International Energy Agency (IEA), dem World Economic Forum und des MIT
Technology Reviews zusammengefasst werden. Basierend auf die aktuelle
Untersuchung des MIT Technology Survey (O'Donnell \& Crownhart, 2025)
gliedere ich diesen kurzen Abriss zum Energieverbrauch in vier Teile:
Die Modellbildung, die Anfrage (query), die Emissionen und Prognosen für
das weitere Wachstum.

\textbf{Modellbildung.} Daten-Zentren und KI-Nutzung machen aktuell nur
wenige Prozent der globalen Energienutzung aus. Schätzungen der
Energieagentur IEA liegen etwa bei 3-5\%. Deutlich höhere Anteile liegen
in den Bereichen Gebäude, Industrie und Fahrzeuge (Ritchie, 2024a;
Spencer \& Singh, 2024). Mit Blick auf die Zukunft ist der rasant
wachsende Energiebedarf durch Bevölkerungswachstum und wachsenden
Wohlstand ärmerer Bevölkerungsgruppen bei weitem ein stärkerer Treiber
für Emissionswachstum und Klimawandel (Spencer \& Singh, 2024). Einige
Klimaaktivisten warnen sogar vor „distraction`` - davor, sich durch
solche Ablenkungen und Modethemen wie KI Energieverbrauch von dem Fokus
auf die großen Hebel der Emissionsvermeidung ablenken zu lassen (Masley,
2025; Ritchie, 2024b). Während die Einmalaufwände für das Training der
Modelle erheblich sind, hat das schnelle Wachsen der Nutzerzahlen sie
mittlerweile in den Schatten gestellt. Die Energieaufwände für Anfragen
(Inferenz) bedingen nunmehr einen größeren Energieverbrauch als das
Training der Modelle (O'Donnell \& Crownhart, 2025; Spencer \& Singh,
2025).

\textbf{Anfrage.} Der Energieverbrauch einer einzelnen KI-Textanfrage
ist relativ gering. Er liegt unter dem Energieverbrauch von wenigen
Minuten für eine kleine LED-Lampe. Konkret liegen die Schätzungen hier
aktuell zwischen 0.3 Wattstunden (Wh) für GPT-4o und 0.03 Wh für kleine
Modelle (O'Donnell \& Crownhart, 2025; You, 2025).

\textbf{Im Vergleich zu anderen Energieverbrauchen ist das nicht viel.}
Vergleicht man den höheren Wert von 0.3 Wh mit den 12.000 Wattstunden,
die ein durchschnittlicher britischen Haushalt pro Tag verbraucht (für
US-Haushalte wird die deutlich höhere Zahl von 28.000 Wattstunden pro
Tag genannt!), wird schnell klar, dass weniger KI-Nutzung zumindest
aktuell kein großer Hebel für Energiesparen oder Klimaschutz ist. Die
oft zitierte Statistik, nach der eine Anfrage bei ChatGPT 10x mehr
verbraucht als eine Google Suche vergisst meist zu erwähnen, dass die
Basisrate dieser Internetnutzung im Vergleich zu anderen Dingen, in die
unser Energieverbrauch fließt, extrem niedrig ist (Ritchie, 2024b).

\textbf{Modellgröße ist allerdings ein zentraler Faktor für den
Energiebedarf} pro Anfrage und hieraus speisen sich plausiblere Sorgen.
Zwar ist Bildgenerierung i.d.R. weniger energieintensiv als
Textgenerierung, da Modelle zur Bildgenerierung oft mit weniger
Parametern arbeiten als Textmodelle. Aber komplexere Anfragen (etwa
mehrstufige lange Reasoning Aufträge) und speziell Video-Generierung
benötigen deutlich mehr Energie: Ein hochqualitatives Video von 5
Sekunden kann bis zu 1.000 Wattstunden verbrauchen (0.94 kWh), was etwas
mehr als einer Stunde Mikrowellennutzung entspricht -- ein deutlicher
Unterschied (O'Donnell \& Crownhart, 2025).

\textbf{Der Anteil größerer Modelle und komplexerer Anfragen wird
voraussichtlich deutlich zunehmen}, wenn die Modellgrößen weiter
ansteigen und komplexere Anfragen, wie Video-Generierung zunehmen.
Gegenläufig wirkt der starke Anreiz für die Anbieter (und speziell für
die kleineren Konkurrenten von OpenAI, die über geringere finanzielle
Mittel verfügen), den Energieverbrauch pro Inferenz durch effizientere
Chip-Konstruktionen und neue Trainingsansätze zu senken. Wie die
Analysten der IEA zusammenfassen: „The efficiency of AI-related computer
chips has doubled roughly every two-and-a-half to three years, and a
modern AI-related computer chip uses 99\% less power to perform the same
calculations as a model from 2008'' (Spencer \& Singh, 2024).

Insgesamt wird perspektivisch die punktuelle Einzelnutzung durch
\textbf{einzelne Anfragen weniger wichtig werden, als die strukturell
bedingte Integration der KI-Technologien} in immer mehr digitale
Anwendungen, die als Folge des rasanten technologischen Wandels und der
hohen Investitionen absehbar ist (O'Donnell \& Crownhart, 2025).

\textbf{Emissionen.} In diesem Zusammenhang wird der ungünstige
Energiemix der aktuell entstehenden Datenzentren kritisiert: Da
KI-Rechenzentren rund um die Uhr laufen und meist in Regionen mit
fossilen Energieträgern stehen, ist der durchschnittliche CO₂-Ausstoß
ihrer Stromversorgung etwa 48\% höher als der US-Durchschnitt (O'Donnell
\& Crownhart, 2025). Dem gegenüber stehen \textbf{gegenläufige Effekte
wie höhere Effizienz der Steuerung}, etwa von Energienetzen
(Greene-Dewasmes \& Tladi, 2025) und dem \textbf{Ersatz von manuellen
menschlichen Aufwänden durch Digitalisierung}, etwa durch Reisen für
einen Film-Dreh (ohne KI) oder dem Energiebedarf eines menschlichen
Call-Centers. Das starke Wachstum der Nutzung muss insofern mit
politischer Anreizsetzung für emissionslose Energiegewinnung verbunden
sein, wenn eine starke Zunahme an Emissionen vermieden werden soll.
Hierfür gibt etwa die IEA klare Empfehlungen und technische Lösungen
sind bekannt. Besorgt stimmt die Analysten die Prognose eines starken
Wachstums von Datencentern im asiatischen Raum, die meist nicht mit
emissionsfreier Energie betrieben werden (Spencer \& Singh, 2025).

\textbf{Prognose.} In der Summe sehen viele der Untersuchungen
\textbf{Probleme eher in der prognostizierten zukünftigen Entwicklung
als in den aktuellen Energieaufwänden}. Das starke prognostizierte
Wachstum könnte etwa dazu führen, dass KI-Anwendungen bis 2028 mehr als
12\% des US-Strombedarfs ausmachen (O'Donnell \& Crownhart, 2025).

\section{Energieverbrauch und politische
Steuerung}\label{energieverbrauch-und-politische-steuerung}

Die \textbf{IEA} prognostiziert ebenfalls eine \textbf{Verdreifachung
des Energieverbrauchs von Rechenzentren bis 2030}, getrieben durch KI.
Maßnahmen wie \textbf{Effizienzgewinne} und \textbf{nachhaltige
Architektur} können diese Entwicklung abbremsen (Spencer \& Singh,
2025).

Wie der \textbf{MIT-Bericht} hervorhebt, sollte vor diesem Hintergrund
der starke und kurzfristig induzierte Ausbau der Infrastruktur
\textbf{politisch durch Anreize zur Emissionsvermeidung gesteuert}
werden, sodass ein starkes Wachstum der Emissionen durch diesen --
wahrscheinlich im Kern unvermeidlichen -- technologischen Wandel
vermieden wird (O'Donnell \& Crownhart, 2025).

So besteht die Hoffnung, dass \textbf{positive Effekte auf Emissionen}
in den Hauptbereichen von CO₂-Emissionen (Gebäude, Industrie, Transport
sowie die verbundenen Energienetze) durch \textbf{höhere Effizienz in
Planung und Nutzung} genutzt werden können, ohne dass sie durch die
wachsenden Kosten von immer komplexeren Inferenz-Anfragen überlagert
werden (Greene-Dewasmes \& Tladi, 2025; Spencer \& Singh, 2025).

Politisch gesehen ergibt sich insofern ein \textbf{Bedarf an Steuerung
dieses strukturellen technologischen Wandels}, damit die Ziele denen der
Gesellschaft entsprechen. Dazu müssen die \textbf{Fakten klar sein}: Um
Kosten und Effekte abschätzen, abfedern und verteilen zu können, fordern
die Forscher eine \textbf{deutlich höhere Transparenz der Energiebedarfe
durch die Modellanbieter} (O'Donnell \& Crownhart, 2025).

\bookmarksetup{startatroot}

\chapter{Didaktische Ziele und Mechanismen}\label{sec-didaktik}

\section{Was für Ziele verfolgen wir mit dem Einsatz von GenAI in der
Lehre?}\label{was-fuxfcr-ziele-verfolgen-wir-mit-dem-einsatz-von-genai-in-der-lehre}

Bevor wir uns der konkreten Umsetzung zuwenden, müssen wir uns zunächst
fragen, was wir überhaupt bezwecken: Was sind unsere Ziele für die
konkrete Umsetzung in Lehrsituationen?

Mollick \& Mollick (2023b) argumentieren, dass KI als
``Kraftverstärker'' für Lehrkräfte dienen kann, indem sie die
Implementierung evidenzbasierter Lehransätze erleichtert, die sonst
aufgrund von Zeit- und Arbeitsaufwand oft schwer umzusetzen sind. Aber
wie wirkt das? Was begründet die erhoffte Wirkung?

Zur Orientierung sollen hier kurz Kategorien von Wissen und Lernmethoden
eingeführt werden. Dann können wir im Detail diskutieren, für welche
Ziele und Methodenwahl welche Art der Unterstützung geeignet ist. Ziele?
Was für Wissen? Fakten, Prozesse, Übertrag.

\section{Wissenstypen}\label{wissenstypen}

Hattie (2023, S.358, 340ff.) unterscheidet drei Stufen des Lernens (s.
Abbildung~\ref{fig-wissenstypen}).

Zunächst geht es um \textbf{„knowing that``}, also das reine
\textbf{Fakten- und Begriffswissen}, das erworben und dann gefestigt
werden muss: Hier soll eine belastbare Wissensbasis entstehen, weshalb
Lehrkräfte häufig Vorwissensaktivierung oder Drill-and-Practice
einsetzen und durch unmittelbares Feedback die korrekte Erinnerung
verankern.

Darauf baut \textbf{„knowing how``} auf, das \textbf{prozedurale und
strategische Können}. Auch hier müssen Abläufe zunächst erworben und
dann gefestigt werden. Lernende erwerben Prozesswissen, indem sie
modellierte Beispiele studieren, in gelenkten Übungen selbst anwenden
und mithilfe von „worked examples`` sowie Fehleranalysen Schritt für
Schritt ihre Vorgehensweisen optimieren. Festigen können Lernende dieses
Prozesswissen besonders gut durch Interaktion oder Wettbewerb mit
anderen Lernenden, da diese Auseinandersetzung ihnen dabei hilft,
verschiedene Nutzungskontexte zu vergleichen (Chi et al., 2018).

Die höchste Stufe nennt Hattie \textbf{„knowing with``}: Wissen wird
flexibel \textbf{auf neue Situationen übertragen}. Problembasiertes
Lernen, authentische Fallstudien, bewusste Reflexionsphasen und
kooperativ angelegte Projekte fördern dabei, Konzepte in unbekannten
Kontexten sicher anzuwenden und weiterzuentwickeln.

Mit welchen \textbf{Methoden} werden diese \textbf{Wissenstypen in der
Lehre} vertieft?

\begin{figure}

\centering{

\pandocbounded{\includegraphics[keepaspectratio]{images/abbildung8_placeholder.png}}

}

\caption{\label{fig-wissenstypen}Abbildung 8: Methoden nach Wissenstyp:
Fakten, Prozess und Transfer. Quelle: Basierend auf Hattie (2023), S.
358, 340ff.}

\end{figure}%

Wo können wir neue technische Hilfsmittel wie LLMs zur Unterstützung
dieser Methoden besonders effektiv einsetzen?

\section{Anwendungsbeispiele nach
Wissenskategorien}\label{anwendungsbeispiele-nach-wissenskategorien}

Zur Unterstützung des \textbf{Aufbaus von Faktenwissen („knowing
that``)} können neuere LLMs inzwischen gut grundlegende Konzepte
erklären (Korinek, 2024, S.48) und zum Selbststudium komplette
Abruf-Übungen erzeugen: Sie formulieren Multiple-Choice- und
Kurzantwortfragen, bewerten die Eingaben sofort und erklären fehlerhafte
Distraktoren -- ein Verfahren, das in einer STEM-Untersuchung zur
automatischen Item-Generierung überzeugende Validitätswerte zeigte
(Säuberli \& Clematide, 2024).

Ebenso lassen sich sehr schnell Definitionen, Paraphrasen oder
Mini-Zusammenfassungen erzeugen, was personalisierte Glossare ermöglicht
(Chen et al., 2024). Wang et al. (2024) sprechen von KI als „Confusion
Helper``. Um Halluzinationen zu vermeiden, wird das Modell häufig per
Retrieval-Augmentation an externe Wissensbasen gekoppelt (also z.B.
durch Beigabe von Skripten oder Fachartikeln als PDF. Siehe auch das
Harvard-Tutor-Bot Beispiel in Abschnitt 4.3, wo Musterlösungen
beigegeben werden.).

Zur \textbf{Festigung von Prozessen und Strategien („knowing how``)}
dient das LLM als dialogischer Coach: Feingranulierte Prompts („Erkläre
den Beschaffungsprozess in 5 Schritten und stelle nach jeder Stufe eine
Kontrollfrage``) steigern die Lösungswahrscheinlichkeit in
Tutorendialogen (Scarlatos et al., 2025). Sprachmodelle können Lehrenden
dabei helfen, komplette „worked examples`` mitsamt Zwischenschritten zu
generieren (Hassany et al., 2024).

Angepasste Sprachmodelle können Lernende zur Selbstkorrektur anleiten,
vor allem, wenn sie Zugriff auf die individuelle Lernhistorie haben und
theoriegeleitetes Verständnis Gründen für Fehler zugrunde liegt. Zhang
et al. (2025) demonstrieren dies am Beispiel eines selbst entwickelten
multimodalen \textbf{Mathematik-Tutor-Bots} (MathCCS, Mathematical
Classification and Constructive Suggestions).

Der \textbf{Teachable-Agent-Ansatz} nutzt umgekehrt das
Lernen-durch-Lehren-Prinzip: Studierende bringen dem LLM eine Methode
bei und reflektieren dabei ihre eigene Strategie. Dies basiert auf der
Annahme, dass Interaktionen besonders effektiv zum Lernen beitragen (Chi
et al., 2018; Hayashi et al., 2025). Wie auch in der persönlichen
Interaktion scheint hierbei wichtig zu sein, welche „Persönlichkeit``
der KI-Bot hat, dem Studierende etwas beibringen sollen (Lyu et al.,
2025) und mehr Anstrengung in der Interaktion (etwa durch
ausführlicheres Formulieren beim Erklären) führt zu mehr Lernerfolg
(Love et al., 2025).

Sprachmodelle können genutzt werden, um komplexe (mathematische)
Anwendungsprobleme mit einem simulierten User
\textbf{„durchzuspielen``,} so dass \textbf{logische Fehler im
Lösungsprozess sichtbar werden,} wie der Prototyp „MathChat`` von Y. Wu
et al. (2023) zeigt. Meta-Analysen zeigen starke positive Lerneffekte,
deuten aber auch auf mögliche Einschränkungen hin. So gibt es Anzeichen
dafür, dass die Effekte höher für Studierende sind als für Schüler und
möglicherweise schwinden Motivationsschübe durch \textbf{abnehmende
`novelty effects'} einfacher Chat-Interfaces über die Zeit der Nutzung.
Die Autoren der Metastudie empfehlen, hier mit stärkerer
\textbf{Gamifizierung und Personalisierung} der Chatbots gegenzusteuern
(R. Wu \& Yu, 2024), was sich mit praktischen Ansätzen etwa von Duolingo
deckt (Kazu \& Kuvvetli, 2025) (z.B.: Gamifizierung durch Streaks und
Leaderboards, Challenges, Video-Chats mit dem Emo-Teen Lili usw.).
Solche aufwändigen Setups sind im Hochschulkontext natürlich schwieriger
abzudecken, ließen sich aber vielleicht graduell als Studierendenprojekt
entwickeln?

Für \textbf{Transfer und Anwendung („knowing with``)} entwirft das LLM
realitätsnahe Szenarien -- etwa Rollenspiele zu Lieferantenausfällen --
und übernimmt Stakeholder-Rollen, wobei Analysen des Brookings-Instituts
das Potenzial für kollaboratives Reasoning hervorheben (Korinek, 2024).
Cross-Domain-Prompts fördern Analogiebildung („Welche Parallelen
bestehen zwischen agilem Projektmanagement und Lean-Procurement?{}``)
(Mollick \& Mollick, 2023b).

In Gruppenarbeiten funktioniert das Modell als Co-Autor: KI-unterstützte
Schreibprozesse können die Menge und Vielfalt der Ideen steigern
(Meincke et al., 2024; Shaer et al., 2024). Auch hier ist jedoch die
sorgfältige Gestaltung des Lernprozesses wichtig, so dass nicht
erwünschte Schwierigkeiten an die KI delegiert und so kritische
Denkprozesse nicht eingeübt werden (Lee et al., 2025).

\section{Effektive Lerntechniken und Unterstützung mit
KI}\label{effektive-lerntechniken-und-unterstuxfctzung-mit-ki}

\textbf{Wie lernen wir besonders effektiv?} In diesem Abschnitt
verdeutlichen wir kurz die angestrebten Wirkmechanismen mit Fokus auf
drei Lehrtechniken, die die Kognitionswissenschaft als besonders
effektiv heraushebt (siehe Mörth et al. (2021) für eine gute
deutschsprachige Übersicht).

Die moderne Lernforschung der Kognitionspsychologie stellt drei Gruppen
von Techniken als besonders gute Kombination zwischen Effektivität und
einfacher Anwendung heraus: \textbf{Verteiltes und gemischtes Lernen},
\textbf{testgestütztes Lernen} und \textbf{fragebasierte Ausarbeitung}
(Dunlosky, Rawson, Marsh, Nathan \& Willingham, 2013; Mörth et al.
(2021); Roediger \& Pyc (2012)). Diese Wirkung gibt es allerdings nicht
umsonst: Den positiven Effekten der Techniken steht oft ein deutlich
höherer Vorbereitungsaufwand gegenüber. Wie im Folgenden kurz skizziert
wird, lassen sich KI-Tools nutzen, um den Aufwand dieser drei
Mechanismen zu verringern, was die Lernwirkung im Vergleich zu
traditionellen Ansätzen deutlich erhöhen kann.

\textbf{Zeitliche Verteilung und inhaltliche Mischung von Lerninhalten
(Spacing \& interleaving)}: Diese Technik basiert auf dem Prinzip, dass
Informationen besser behalten werden, wenn das Lernen über die Zeit
verteilt und in verschiedenen Kontexten stattfindet, anstatt in einer
einzigen, intensiven Sitzung (Brown et al., 2014; Murre \& Dros, 2015;
Roediger \& Pyc, 2012). \textbf{Abstände} zwischen Lerneinheiten und die
wiederholte Aktivierung von Wissensstrukturen stärken die Verbindung
zwischen Hinweisreizen und Gedächtnis und geben dem Gehirn Zeit,
Erinnerungen effektiv zu speichern. Dies fördert die Langzeiterinnerung,
denn der wiederholte Abruf verstärkt die gespeicherten Muster und
vertieft sie so.

Weiterhin hilft es, zu „mischen``: \textbf{inhaltlich gemischtes Üben}
(\emph{interleaving}) ist effektiver als die isolierte Behandlung von
Themenblöcken, die linear im Semesterverlauf abgehandelt werden (Mörth
et al., 2021). Das liegt daran, dass das gemischte Üben die
Unterscheidung zwischen verschiedenen Aufgabentypen fördert, was
entscheidend für die spätere Anwendungskompetenz ist. Nur durch den
geübten Vergleich verschiedener Kombinationen von Anwendungskontexten
und Lösungsansätzen kann ein Gefühl dafür ausgebildet werden, welches
Werkzeug zu welchem Problem passt. Fallstudien und Simulationen bieten
sich hier an, wenn diese ausreichend komplex sind, um bekannte Analysen
in neuen Kontexten anzuwenden und neue einzuführen.

\textbf{Testgestütztes Lernen (Test-enhanced learning)}: Das Abrufen von
Informationen durch Tests fördert das Langzeitgedächtnis deutlich
stärker als das erneute Lesen des Stoffes. Für Studierende ist das
anstrengender, es bringt aber deutlich mehr (Brown et al., 2014). Ein
‚Test` kann dabei auch die Bearbeitung von Lerninhalten im Rahmen einer
Fallstudie, die kritische Bewertung potenziell falscher Aussagen eines
LLMs oder die Beantwortung von Verständnisfragen im Dialog mit einem
Tutor-Bot sein.

Häufige Aktivierung von Lerninhalten durch Fragen verbessert den
Lernerfolg durch mehrere Mechanismen (Roediger \& Karpicke, 2006).
Erstens fördert solches Testen das transfergerechte Verarbeiten, da die
mentalen Prozesse beim Testen und beim späteren Abrufen ähnlich sind,
was die Erinnerungsfähigkeit verbessert. Zweitens stärkt die
Wiederholung durch Tests einerseits den erinnerten Inhalt und fügt
andererseits neue ‚Haken` hinzu, mit denen wir den Inhalt aus dem
Gedächtnis ziehen: die Beziehungen zwischen Hinweisreizen (\emph{cues})
und dem Inhalt im Gedächtnis, indem zusätzliche Abrufwege zu
gespeicherten Wissensmustern geschaffen werden, was den Abruf
verbessert. Praktisch kann man diesen tollen Effekt auch recht einfach
durch regelmäßige kurze Fragerunden nutzen: Wie die Lernforscher
herausstellen: „frequent low-stakes quizzes (last only 5 or 10 min) can
produce a large boost in performance`` (Roediger \& Pyc, 2012, S.246).

\textbf{Fragebasierte Ausarbeitung (Explanatory questioning)}: Bei
dieser Technik wird das tiefergehende Verständnis von Material durch das
Stellen und Beantworten von „Warum``-Fragen gefördert. In
\textbf{Rollenspielen und Simulationen} können Teilnehmer durch bewusste
Praxis aktiv Szenarien durchspielen, während sie gleichzeitig durch
gezielte Fragen angeleitet werden, die zum tieferen Nachdenken und zur
Reflexion anregen. Diese Fragen können dazu dienen, die Teilnehmer dazu
zu bringen, ihre Entscheidungen und Handlungen im Kontext des
Rollenspiels zu erklären, wodurch das Verständnis für die Anwendung von
Konzepten in realen oder simulierten Situationen vertieft wird.

Indem Lernende über die Gründe hinter den Fakten nachdenken, werden
Verbindungen zu bereits bekanntem Wissen hergestellt, was zu einem
tieferen Verständnis und besserer Erinnerung führt. Dies deckt sich mit
dem Postulat der ICAP-Theorie des kognitiven Engagements (Chi et al.,
2018): Interaktion (I) ist effektiver als individuelle Konstruktion, was
wiederum effektiver ist als aktive (aber nicht konstruktive)
Beteiligung, was wiederum die passive Lernteilnahme schlägt (I
\textgreater{} C \textgreater{} A \textgreater{} P).

\textbf{Wie können LLMs genutzt werden, um diese Lerntechniken zu
unterstützen?}

Wir skizzieren das hier kurz an einem Seminar zum interkulturellen
Management. Um \textbf{zeitliche Verteilung und Mischung} zu fördern,
kann mit LLMs eine Serie von kurzen, thematisch variierenden Aufgaben
und Fallstudien über das Semester verteilt erstellt werden. Diese
könnten reale Szenarien abbilden, in denen Studierende ihre Fähigkeiten
im interkulturellen Management anwenden müssen. Beispielsweise könnte
das Sprachmodell Aufgaben generieren, bei denen Studierende Strategien
für die Überwindung kultureller Barrieren in internationalen Teams
entwickeln.

Was sind Beispiele für \textbf{testgestütztes Lernen}? Regelmäßige,
durch LLMs generierte Quizze bringen Studierende dazu, ihr Wissen
häufiger aktiv abzurufen. Durch LLMs können Multiple-Choice-Fragen,
Fallstudienanalysen und Szenariobeschreibungen zu interkulturellen
Missverständnissen erzeugt werden, welche die Studierenden lösen müssen.

Zur Unterstützung von \textbf{fragebasierter Ausarbeitung} können LLMs
die Erstellung von Fallstudien, Simulationen und Rollenspielen
unterstützen, damit Studierende über interkulturelle Dynamiken und
Managementstrategien nachdenken. Diese könnten als Ausgangspunkt für
Diskussionen im Kurs oder als Teil von Hausaufgaben dienen, wobei die
Studierenden angehalten werden, über die Verbindungen zwischen dem
Kursmaterial und den simulierten interkulturellen Interaktionen zu
reflektieren. Viele weitere Beispiele hierfür besprechen wir im
folgenden Kapitel, wo wir Anwendungsfälle von KI in der Lehre nach der
didaktischen Rolle des Werkzeugs darstellen: Hilfskraft, Copilot, Tutor
oder Simulator.

\bookmarksetup{startatroot}

\chapter{Vier Szenarien der Nutzung von GenAI: Hiwi, Tutor, Copilot,
Simulator}\label{sec-szenarien}

Wie nutzen Lehrende aktuell generative KI? Zur ersten Orientierung
stellen wir in Tabelle 1 eine Reihe von exemplarischen aktuellen
Anwendungsfällen aus deutschen und internationalen Hochschulen zusammen
(Stand April 2025). Die Abgrenzung der verschiedenen Kategorien und
Details der Umsetzung erklären wir im Folgenden.

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 8\tabcolsep) * \real{0.2000}}
  >{\raggedright\arraybackslash}p{(\linewidth - 8\tabcolsep) * \real{0.2000}}
  >{\raggedright\arraybackslash}p{(\linewidth - 8\tabcolsep) * \real{0.2000}}
  >{\raggedright\arraybackslash}p{(\linewidth - 8\tabcolsep) * \real{0.2000}}
  >{\raggedright\arraybackslash}p{(\linewidth - 8\tabcolsep) * \real{0.2000}}@{}}
\caption{Tabelle 1: Anwendungsfälle zur Nutzung von KI als Hilfskraft,
Copilot, Tutor oder Simulator aus deutschen und internationalen
Hochschulen}\label{tbl-usecases}\tabularnewline
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
Kategorie
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Use Case \& KI-Bot-Funktion
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Lernbereich \& Mehrwert
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Hochschule/Institution
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Quelle
\end{minipage} \\
\midrule\noalign{}
\endfirsthead
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
Kategorie
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Use Case \& KI-Bot-Funktion
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Lernbereich \& Mehrwert
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Hochschule/Institution
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Quelle
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
\textbf{KI als Hilfskraft} & KI-generierte Übungsaufgaben und Skripte
(``Instructors as Innovators'') & Entlastung der Lehrenden, Effizienz
bei Materialerstellung & Wharton School (UPenn) & Mollick \& Mollick
(2024) \\
& Automatisierte Transkription qualitativer Interviews (``Mit KI über KI
qualitativ forschen'') & Zeitersparnis, Unterstützung in qualitativer
Forschung & LMU München & Wannemacher et al. (2025), Fall Nr. 040 \\
& Erstellung multimedialer Lernmaterialien (``KI-gestützte Entwicklung
von Lernmedien'') & Höhere Flexibilität im Selbststudium, vielfältige
Lernwege & Hochschule Ruhr West & Wannemacher et al. (2025), Fall Nr.
137 \\
& Entwicklung KI-basierter Audioerklärungen (``HAnS --
Hochschul-Assistenzsystem'') & Orts- und zeitunabhängiges Lernen &
Universität Münster & Wannemacher et al. (2025), Fall Nr. 162 \\
& Analyse offener Antworten aus Befragungen (``Analyse offener
Antworten'') & Verbesserte Auswertung und Feedbackqualität & Hochschule
München & Wannemacher et al. (2025), Fall Nr. 189 \\
\textbf{KI als Co-Pilot} & Unterstützung beim Schreiben von Texten \&
Coding & Kreativitätsförderung, individuelle Hilfestellung & Wharton
School (UPenn) & Mollick \& Mollick (2024) \\
& Analyse von Geschäftsberichten mit KI (``TEAM with AI'') & Vertieftes
Verständnis von Geschäftsmodellen & DHBW Heilbronn & Wannemacher et al.
(2025), Fall Nr. 172 \\
& Erstellung von Präsentationen \& Podcasts (``TEAM with AI'') &
Innovative Lehrmedien, Förderung digitaler Kompetenz & DHBW Heilbronn &
Wannemacher et al. (2025), Fall Nr. 172 \\
& Coding-Unterstützung für Data-Science-Kurse (``Generative AI for Data
Science 101'') & Niedrigschwelliger Zugang zum Programmieren, Fokus auf
Fachinhalte & University of Southern California (USC) & Bien \&
Mukherjee (2025) \\
\textbf{KI als Tutor} & KI-Tutoren für Physikvorlesungen & Signifikante
Leistungssteigerung, höheres Engagement & Harvard University & Gregory
Kestin et al. (2024) \\
& KI-basierte Tutoren für Geschäftsverhandlungen & Verbesserte
Kommunikationsfähigkeiten & Wharton School (UPenn) & Mollick \& Mollick
(2024) \\
& Digitaler Assistent zur Prüfungsvorbereitung & Sofortiges Feedback,
individualisierte Vorbereitung & Hochschule Hof & Wannemacher et al.
(2025), Fall Nr. 208 \\
& Individuelles formatives Feedback, personalisierte Lernunterstützung
(``COFFEE \& MIND'') & Bessere Lernergebnisse, passgenaue Betreuung &
FernUniversität Hagen & Wannemacher et al. (2025), Fall Nr. 061 \\
\textbf{KI als Simulator} & ``PitchQuest'' Entrepreneurship-Simulation
(``Simulated Practice at Scale'') & Praxisnahe Übung für
Unternehmenspitches & Wharton School (UPenn) & Mollick et al. (2024) \\
& Fortgeschrittene Voice-Mode-Simulation (``ChatGPT's Advanced Voice
Mode'') & Dynamische Patienten- / Szenariensimulation, z.B. für
medizinische Trainings & Verschiedene Simulationseinrichtungen & Barra
et al. (2024) \\
& Generative KI für Sprachlern-Simulationen (``Reconceptualizing the
Role of the University Language Teacher'') & Interaktive Übung,
realitätsnahe Konversation in der Fremdsprache & University of
Technology, Sydney \& Manchester & Tutton \& Cohen (2025) \\
& Dokumentenbasierte KI-Simulation (``Enhancing History Education with
Google NotebookLM'') & Umwandlung historischer Quellen in dynamische
Lernformate, Audio-Podcasts & Lindenwood University & Huffman \& Hutson
(2024) \\
& ``Talk2Transform'' -- Gesprächssimulation für Managementtrainings &
Realitätsnahe Management-/Führungstrainings & TH Brandenburg &
Wannemacher et al. (2025), Fall Nr. 132 \\
& ``TEAM with AI'' -- Verhandlungstrainings in der BWL-Grundlagenlehre &
Praktische Anwendung \& tieferes Verständnis & DHBW Heilbronn &
Wannemacher et al. (2025), Fall Nr. 172 \\
& KI-basierte Gesprächssimulation in der Personalpsychologie
(``Gesprächssimulationen für Personalpsychologie'') & Training sozialer
Kompetenzen, Deeskalation & HAW Hamburg & Wannemacher et al. (2025),
Fall Nr. 177 \\
\end{longtable}

\section{KI als Hiwi}\label{ki-als-hiwi}

\subsection{Wobei soll die Hilfskraft
unterstützen?}\label{wobei-soll-die-hilfskraft-unterstuxfctzen}

Beschäftigte in Forschung und Lehre erfüllen eine Vielzahl sehr
heterogener Aufgaben, mit einem wachsenden Teil an „Verwaltung``. Wer
lehrt, merkt schnell, dass die Präsenzveranstaltung nur die Spitze eines
ganzen Eisbergs an Aufgaben darstellt. Eine Umfrage unter Lehrenden in
Österreich zeigt, dass sie etwa ein Drittel ihrer Zeit mit
Lehraktivitäten verbringen (32\%) und etwa ein Fünftel mit
Verwaltungstätigkeiten in der Hochschule (20\%) sowie ein weiteres
Fünftel mit externen Verpflichtungen wie Gutachten oder Tätigkeiten in
wissenschaftlichen Gesellschaften (9\%, 10\%) (Österreichischer
Universitätsprofessor/innenverband, 2018). Wie Unkraut im Garten, wächst
der Anteil, den Lehrende mit „sonstigem`` verbringen: Vor allem der
Zeitaufwand für Verwaltung stieg an (Schomburg et al., 2012).

Woraus besteht das im Detail und wo könnten LLMs helfen? Vor- und
Nachbereitung, Evaluation, Beratung, Planung und vieles mehr lassen die
Stunden eines Tages schnell vergehen. Abbildung 9 zeigt die 25
Hauptaufgaben, die Lehrende nach Umfragen des US Arbeitsministeriums
verrichten (https://www.onetonline.org/link/summary/25-1011.00). Welche
Auswirkungen können wir von LLM auf diese konkreten Aufgaben erwarten?

\begin{figure}

\centering{

\pandocbounded{\includegraphics[keepaspectratio]{images/script04-01.png}}

}

\caption{\label{fig-onet-tasks}Abbildung 9: Was für Aufgaben erledigen
Lehrende? 25 Einzelaufgaben am Beispiel „Business Teachers,
Postsecondary`` nach Umfragen des US Arbeitsministeriums auf O\emph{Net.
Quelle: O}Net, 2025}

\end{figure}%

Historische Studien zeigen, dass Technologie typischerweise
\textbf{Tätigkeiten} (tasks) beeinflusst und eher selten ganze Jobs
ersetzt. Führend sind dazu Untersuchungen von David Autor und dem
Nobelpreisträger Daron Acemoglu (Acemoglu \& Restrepo, 2019; Autor,
2015). Eine nützliche Kategorisierung unterscheidet \textbf{drei
Effekte} neuer Technologien auf den Faktor Arbeit: Technologische
Veränderungen können menschliche Arbeit ersetzen
(\textbf{Verdrängungseffekt} / displacement effect), spezifische
Arbeitskräfte produktiver machen (\textbf{Produktivitätseffekt} /
productivity effect / augmentation), oder neue Aufgaben (und Jobs)
schaffen (\textbf{Wiedereinsetzungseffekt} / reinstatement effect)
(Acemoglu \& Restrepo, 2019).

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.3333}}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.3333}}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.3333}}@{}}
\caption{Tabelle 2: Für welche Aufgaben in der Lehre erwarten wir
Verdrängung und Erhöhung der Produktivität und welche Aufgaben kommen
hinzu? Legende: x = klarer Effekt, ? = gemischter Effekt. Quelle:
Theorierahmen nach Acemoglu \& Restrepo
(2019)}\label{tbl-acemoglu}\tabularnewline
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
Effekt
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Beschreibung
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Aufgaben in der Lehre (Beispiele)
\end{minipage} \\
\midrule\noalign{}
\endfirsthead
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
Effekt
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Beschreibung
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Aufgaben in der Lehre (Beispiele)
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
\textbf{Verdrängung} & Technologie übernimmt Aufgaben & • Erstellung,
Durchführung und Bewertung von Prüfungen (x)• Verwaltung von Noten und
Anwesenheit (x)• Vorbereitung standardisierter Lehrmaterialien (x)•
Zusammenstellung von Bibliographien (x) \\
\textbf{Produktivität} & Technologie macht Arbeit effizienter & •
Vorbereitung und Durchführung von Vorlesungen (x)• Durchführung von
Seminaren und Diskussionen (x)• Akademische und berufliche Beratung
(?/x)• Forschung und Publikation (x)• Pflege von Webseiten und digitalen
Ressourcen (?/x) \\
\textbf{Wiedereinsetzung} & Technologie schafft neue Aufgaben & •
Entwicklung KI-gestützter Lehrkonzepte (x)• Qualitätskontrolle von
KI-Materialien (x)• Gestaltung individueller Lernpfade (x)• Ethische und
rechtliche Begleitung (x)• Weiterbildung des Personals (x) \\
\end{longtable}

In Tabelle~\ref{tbl-acemoglu} übertragen wir die genannten drei Effekte
auf konkrete Aufgaben in der Hochschullehre.

Der \textbf{Verdrängungseffekt} betrifft hauptsächlich administrative
und stark standardisierte Tätigkeiten. Aufgaben wie das Erstellen,
Durchführen und Bewerten von Prüfungen, die Verwaltung von Noten und
Anwesenheiten sowie die Vorbereitung standardisierter Lehrmaterialien
oder Literaturzusammenstellungen werden voraussichtlich vollständig oder
überwiegend von KI übernommen. Anwendungsstudien und Umfragen der
letzten zwei Jahre geben hierzu deutliche Hinweise (Morgan, 2024;
Naddaf, 2025; Ogunleye et al., 2024; Ou et al., 2024; Tutton \& Cohen,
2025).

Der \textbf{Produktivitätseffekt} bezieht sich auf zentrale Lehr-,
Forschungs- und Betreuungstätigkeiten, die durch KI effizienter werden.
Dazu zählen die Vorbereitung und Durchführung von Vorlesungen, Seminaren
und Diskussionen, akademische und berufliche Beratung der Studierenden
sowie Forschung und Publikationen. KI unterstützt hier durch
automatische Literaturauswertungen, personalisierte Lerninhalte oder
Pflege digitaler Ressourcen, sodass Lehrende ihre Kernaufgaben besser
und effektiver erfüllen können (Gottweis et al., 2025; Meincke et al.,
2024; Mollick \& Mollick, 2023b, 2024; Schwarcz et al., 2025).

\textbf{Gemischte Effekte} treten bei einigen Aufgaben wie der
Entwicklung und Pflege von Kurswebseiten, dem digitalen Aufzeichnen von
Vorträgen und der Auswahl von Lehrmaterialien auf, bei denen KI sowohl
Teile der Aufgaben ersetzt als auch deren Durchführung produktiver
macht.

Der \textbf{Wiedereinsetzungseffekt} zeigt, dass durch den Einsatz von
generativer KI gänzlich neue Aufgaben entstehen. Dazu gehören
beispielsweise die Entwicklung neuer KI-gestützter Lehrkonzepte und
-methoden, Qualitätskontrollen von KI-generierten Lehrmaterialien,
Gestaltung individueller Lernpfade, ethische und rechtliche Begleitung
des KI-Einsatzes sowie die Weiterbildung des Lehrpersonals im Umgang mit
KI-Technologien (Dihan et al., 2025; Mollick et al., 2024; Mollick \&
Mollick, 2024).

Durch diese differenziertere Analyse der drei Effekte wird klar, dass
die Einführung von KI in die Lehre zwar mit hoher Sicherheit
\textbf{deutliche Änderungen im Aufgaben-Mix} und der Zeitanteile
bedeutet, die wir mit verschiedenen Aufgaben verbringen. Das ist nicht
neu: Wer bestellt heute noch regelmäßig per Fernleihe, schickt Briefe
oder kopiert in großem Umfang? Wir sehen, dass generative KI
wahrscheinlich mittelfristig einen Teil der aktuellen Tätigkeiten
verdrängen, zentrale Kernaufgaben produktiver gestalten und zugleich
neue, spezialisierte Aufgaben in der Lehre schaffen wird.

Ob das \textbf{insgesamt zu einer Zeitersparnis führt, ist keineswegs
sicher}, denn die neuen Aufgaben um die Einrichtung und Betreuung der
KI-Unterstützung können sehr zeitintensiv sein, als Beispiel sei hier
etwa die Einrichtung eines Physik-Tutor-Bots (Gregory Kestin et al.,
2024) oder einer Startup-Simulation, in der KI in verschiedenen Rollen
beim Aufsetzen und Verbessern von Geschäftsplänen hilft (Mollick et al.,
2024). Beide Konzepte führen sichtlich zu einer Verbesserung der Lehre,
aber die gibt es auch hier nicht umsonst.

\subsection{Wobei unterstützt KI besonders
gut?}\label{wobei-unterstuxfctzt-ki-besonders-gut}

Was sind typische Anwendungsfelder für Lehrende und Studierende? KI
unterstützt Lehrende \textbf{ähnlich einer Hilfskraft} beim Erstellen
von Lehrmaterialien, indem sie Beispiele generiert, die abstrakte
Konzepte in realen Kontexten veranschaulichen (Mollick \& Mollick,
2023b). Dies fördert ein tieferes Verständnis und eine breitere
Anwendbarkeit der Inhalte. Ebenso kann KI den Verwaltungsaufwand für
Kurse verringern, indem sie dabei hilft, Übersichten, Dokumente und
Präsentationen zu erstellen. Idealerweise verschiebt sich dann die
Energie der Lehrenden auf Kernkompetenzen wie individuelle Erläuterung,
Motivation und Coaching von Arbeitsgruppen.

\textbf{KI kann dabei helfen}: Von der Analyse der Lernenden über die
Erstellung, Anpassung und Verknüpfung von Inhalten bis hin zur
Unterstützung bei Recherche und Literaturarbeit. Während die
Sprachmodelle noch vor drei Jahren vor allem einfache Fragen beantworten
konnten, können die stärksten Modelle mittlerweile ganze Aufgabenbündel
abarbeiten, (s. Abbildung 7), wie etwa komplexe Recherchen, Datenanalyse
oder Code-Generierung (Naddaf, 2025, 2025). KI als „Co-Scientist``
(Gottweis et al., 2025) -- positiv gesehen \textbf{werden die Hiwis
immer schlauer}.

\textbf{Erste Untersuchungen zeigen positive Effekte auf Lehrende} --
weniger Stress, mehr Energie - wenn sie ChatGPT zur Unterstützung
einsetzen. Wie auch bei anderen neuen Technologien hängen die positiven
Effekte mit der Einfachheit der Nutzung und der empfundenen Nützlichkeit
zusammen, wie etwa eine neuere Umfrage unter 401 Dozierenden zeigt
(Cambra-Fierro et al., 2025).

Die folgende Tabelle fasst eine Reihe von Anwendungsfeldern zusammen.

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.3333}}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.3333}}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.3333}}@{}}
\caption{Tabelle 3: Detaillierte Anwendungsfelder von KI zur
Kursvorbereitung. Quelle: Basierend auf Gimpel et al. (2023); Mollick \&
Mollick (2023b); Mollick \& Mollick
(2022)}\label{tbl-prep-apps}\tabularnewline
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
Kategorie
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Empfehlung
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Beispiele
\end{minipage} \\
\midrule\noalign{}
\endfirsthead
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
Kategorie
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Empfehlung
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Beispiele
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
\textbf{Analyse der Lernenden} & Vorkenntnisse und Lerntypen analysieren
& Auswertung von Fragebögen, Lernstandserhebungen \\
& Rückmeldungen zusammenfassen und auswerten & Analyse von
Feedbackformularen, Forenbeiträgen \\
\textbf{Generierung von Inhalten} & Vielfältige Beispiele und
Erklärungen & Anwendungsbeispiele, Analogien, Visualisierungen \\
& Übungsaufgaben, Quizfragen und Tests & Aufgaben verschiedener
Schwierigkeitsgrate und Formate \\
& Zusammenfassungen und Analysen von Materialien & Kernaussagen von
Texten, Vergleich von Konzepten \\
\textbf{Anpassung von Materialien} & Automatische Anpassung an Niveaus
und Formate & Vereinfachung von Texten, Ergänzung von Erklärungen \\
& Optimierung basierend auf Rückmeldungen & Überarbeitung von
Beispielen, Aufgaben, Erklärungen \\
\textbf{Verknüpfung und Wiederholung} & Bezüge zwischen Themen
herstellen & Querverweise, Analogien, Anwendung in neuen Kontexten \\
& Integration in Aufgaben und Tests zum verteilten Üben &
Wiederholungsfragen zu Vorwissen in späteren Einheiten \\
\textbf{Recherche und Literatur} & Suche und Vorschläge relevanter
Quellen & Literaturempfehlungen passend zum Thema \\
& Zusammenfassungen und Vergleiche von Literatur & Synopsen,
Gegenüberstellungen, Forschungsüberblicke \\
\end{longtable}

KI kann bei \textbf{Schreib- und Formatierarbeiten} viel Zeit sparen.
Textbausteine in eine Tabelle zusammenfassen, Tabellen umformatieren
oder Tabelleninhalte in Fließtext verwandeln, Hauptpunkte mit
anschaulichen Beispielen für verschiedene Adressatenkreise illustrieren,
Literaturangaben in ein bestimmtes Format wie BibTeX verwandeln, das
sich mit einem Klick in Zotero einlesen lässt, Übersetzungen in
verschiedene Sprachen, Erstellung von Übersichtsdokumenten oder
Websites\ldots{} Viele Fleißarbeiten lassen sich bei sorgfältiger
Aufsicht sehr gut an den digitalen Hiwi delegieren. Nutzungsberichte und
Experimente zeigen einen deutlichen Mehrwert etwa bei Recherche,
Texterstellung und Zusammenfassung (Brynjolfsson et al., 2025; Handa et
al., 2025; Schwarcz et al., 2025).

Für die \textbf{Recherche und Textgenerierung} lässt sich der Hiwi gut
nutzen (McKnight, 2022): Machen Sie die KI zu Recherche-Assistenten, um
Themen umfassend zu recherchieren und Texte zur Überprüfung sowie
Referenzen für nachfolgende Untersuchungen der Studierenden zu
kompilieren (z.B. mit Complexity.ai oder dem Consensus GPT (Add-on zu
ChatGPT) sowie neueren Lösungen wie Deep Research (Schwarcz et al.,
2025) und spezialisierte Lösungen wie Elicit, die auf akademische
Datenbanken zurückgreifen (jedoch oft nur auf Abstracts, keine
Volltexte). Diese Materialien können als Grundlage für originale und
sorgfältig referenzierte Schreibarbeiten dienen. Nutzen Sie KI-Tools für
routinemäßige Texte, wie Blog-Inhalte, und bewerten Sie kritisch, wo und
warum KI-Texte, menschliche Texte oder Hybridtexte angebracht sind.
Erforschen Sie die spezifischen Möglichkeiten von KI-basierten
Inhalts-Generatoren für Ihr Fachgebiet, beispielsweise die Produktion
von Texten in mehreren Sprachen innerhalb von Sekunden oder die
Erstellung von für Suchmaschinen optimierten Texten.

Speziell zur \textbf{Kursvorbereitung} schlagen Experten eine Reihe von
Möglichkeiten vor, wie die KI Lehrende unterstützen kann (Gimpel et al.,
2023; Mollick \& Mollick, 2022, 2023b): KI kann die
\textbf{Vorkenntnisse der Studierenden analysieren}, um Materialien und
Methoden passgenau auszuwählen und anzupassen -- etwa um Startup Pitches
vorzubereiten (Mollick et al., 2024). Durch \textbf{Zusammenfassung und
Analyse von Rückmeldungen} der Studierenden können Verständnisprobleme
und Lernlücken identifiziert werden. KI kann weiterhin \textbf{Beispiele
und Erklärungen} zu Kursthemen generieren, um das Verständnis zu
fördern. Lehrende können \textbf{Zusammenfassungen und Analysen von
Kursmaterialien und Literatur} anfertigen, Lernmaterialien an
verschiedene Niveaus und Formate anpassen, Erklärungen und Materialien
basierend auf Rückmeldungen der Studierenden optimieren. So bieten etwa
Mollick und andere Teilnehmern \textbf{angepasste Feedbacks und Videos}
an, je nachdem was in einem anfänglichen Fragebogen berichtet wurde und
welches Level an Vorwissen die User zeigen (Mollick et al., 2024). KI
kann Bezüge zwischen aktuellen und zuvor gelernten Themen herstellen und
diese in Aufgaben und Tests zum verteilten Üben über den Kursverlauf
hinweg integrieren. Der effektive Einsatz erfordert aber stets die
Prüfung, Auswahl und Einbettung durch die Lehrenden auf Basis ihrer
didaktischen Expertise (Mollick \& Mollick, 2023b, 2024).

\textbf{Übungsaufgaben, Quizfragen und Tests} mit adaptivem Feedback
können in kurzer Zeit erstellt werden. Wie eine neuere Studie zeigt,
können auch „simulierte Studierende`` genutzt werden, um die
\textbf{Qualität neuer Multiple-Choice Fragen zu bewerten} (Lu \& Wang,
2024).

Was für \textbf{konkrete Nutzungsbeispiele} finden wir Anfang 2025 in
aktuellen Berichten? Ein Artikel der Fachzeitschrift \emph{Nature}
(Tabelle 4) fasst Anwendungen aus verschiedenen Bereichen zusammen, die
von Fehlersuche zur Erstellung von Simulationsübungen und Wochenplänen
reicht (Heidt, 2025).

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 2\tabcolsep) * \real{0.5000}}
  >{\raggedright\arraybackslash}p{(\linewidth - 2\tabcolsep) * \real{0.5000}}@{}}
\caption{Tabelle 4: Aktuelle Nutzungsbeispiele von KI zur
Lehrunterstützung. Quelle: Zusammengestellt nach Heidt
(2025)}\label{tbl-nature-examples}\tabularnewline
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
Fachgebiete
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
KI-Nutzung
\end{minipage} \\
\midrule\noalign{}
\endfirsthead
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
Fachgebiete
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
KI-Nutzung
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
\textbf{Informatik} & Selbstentwickelter KI-Chatbot „Class Primer``
analysiert mithilfe von ChatGPT-4 Kursinhalte und erstellt strukturierte
Zusammenfassungen sowie visuelle Lernhilfen, um komplexe Themen bereits
vor der Vorlesung zu verstehen. \\
\textbf{Wirtschaftswissenschaften} (Geschichte/Wirtschaftsgeschichte) &
Im Rahmen der Erstellung wissenschaftlicher Essays simulieren
Studierende mithilfe von ChatGPT historische Persönlichkeiten (z.B.
Henry Kissinger), um deren Perspektiven und Argumente bezüglich
historischer Ereignisse besser nachvollziehen und kritisch hinterfragen
zu können. \\
\textbf{Psychologie und Sprachbildung} & Nutzung von KI-basierten
Chatbots („Language Buddy``), um Fremdsprachenkenntnisse interaktiv und
dialektspezifisch zu trainieren und damit sprachliche Kompetenzen zu
verbessern. \\
\textbf{Neurowissenschaften} (Data Science) & Einsatz von Chatbots als
„technische Assistenten`` zur effizienteren Fehlersuche in
datenanalytischen Programmiercodes, was den Rechercheaufwand reduziert
und direkte, spezifische Lösungsvorschläge bietet. \\
\textbf{Literatur- und Wissenschaftskommunikation} & Nutzung von KI
(NotebookLM), um wissenschaftliche Literatur in Form von automatisch
generierten Podcasts aufzubereiten. Dabei entstehen fiktive Dialoge
zwischen Moderatoren, was einen kreativeren Zugang zu wissenschaftlichen
Inhalten ermöglicht. \\
\textbf{Luft- und Raumfahrttechnik} (Projektmanagement) & KI-Chatbots
unterstützen bei der Erstellung detaillierter Wochenpläne und der
rollenbasierten Aufgabenverteilung in studentischen Gruppenprojekten.
Dies verbessert die organisatorischen Abläufe und berücksichtigt
individuelle Stärken der Gruppenmitglieder. \\
\textbf{Allgemeine Studierendenberatung und persönliche Entwicklung} &
Hilfe für Studierende verschiedener Fachrichtungen durch KI-basierte
Tools, um individuelle Zeitpläne für Studium, Freizeitaktivitäten und
soziales Leben zu erstellen. KI unterstützt sie dabei, persönliche Ziele
(wie Sport, Musik oder zwischenmenschliche Beziehungen) effektiver und
bewusster zu gestalten. \\
\end{longtable}

Die \textbf{Aufgaben für Studierende} müssen unter diesen neuen
Rahmenbedingungen \textbf{angepasst werden}. Einfache Recherche-Übungen
werden stark entwertet, da der Arbeitsfluss mittlerweile weitgehend
automatisiert ist. Abbildung 10 zeigt den Unterschied für eine einfache
Recherche-Übung. Was für Einzelschritte müssen Studierende erledigen, um
einen Bericht zum Stand der Industrie 4.0 (etwa: sensorgestützte
Vernetzung von Maschinen) in Deutschland zu erstellen? Links sehen wir
einige typische Arbeitsschritte, die Studierende manuell durchführen
müssen: Begriffe klären, Quellen recherchieren und zusammenfassen,
Gliederung erstellen und Bericht formulieren und formatieren. Rechts
sehen wir, wie die selben Arbeitsschritte mit der Unterstützung von LLMs
durchgeführt werden. Grün markierte Aufgaben führt das LLM automatisch
durch, Gelb markiert Aufgaben, die Iterationen mit den Usern erfordern
(etwa: mehrere Prompts, Fine-Tuning, Anpassung). Das Beispiel setzt
sorgfältige Nutzung der technischen Hilfsmittel voraus -- wenn
Studierende nur den Aufwand minimieren wollen, kann ihnen das LLM auch
in einem einzigen Schritt einen (meist: weniger guten, aber zum Bestehen
dieser Aufgabe wahrscheinlich noch ausreichenden) Bericht erstellen.

\begin{figure}

\centering{

\pandocbounded{\includegraphics[keepaspectratio]{images/script04-02.png}}

}

\caption{\label{fig-report-workflow}Abbildung 10: Einfache Aufgaben
müssen angepasst werden: Die traditionelle Erstellung eines Berichts
durch Studierende (Szenario A) kann durch LLMs weitgehend automatisiert
werden (Szenario B). Blau = manuell, grün = automatisch, gelb = hybrid.
Quelle: Selbst erstellt mit GPT-o und Google Colab im Mermaid-Format.}

\end{figure}%

\textbf{Wie einfach das tatsächlich mittlerweile für Studierende geht},
verdeutlicht ein Beispiel (s. Abbildung 11): Wir nutzen die im
Hochschulnetz frei verfügbare Lizenz von Statista und die hier
angebotene LLM-Funktion „Research AI``, um einen Textausschnitt zum
Thema „Industrie 4.0 in Deutschland`` zu generieren und erhalten auf
einen sehr einfachen Prompt praktisch sofort einen korrekt formulierten
und formatierten Ausschnitt mit 5 von Statista kuratierten Quellen
zurück. Der hier angebotene Mehrwert zu breiteren Modellen wie GPT oder
Gemini besteht vor allem in der Auswahl und Zusammenstellung der Quellen
durch Statista. Ähnliche Angebote gibt es inzwischen aus verschiedenen
Bereichen, etwa vom juristischen Verlag Wolters Kluwer
(https://www.wolterskluwer.com/de-de/solutions/wolters-kluwer-online).

\begin{figure}

\centering{

\pandocbounded{\includegraphics[keepaspectratio]{images/script04-03.png}}

}

\caption{\label{fig-statista-researchai}Abbildung 11: Beispiel mit
ResearchAI von statista -- automatisierte Recherche, Zusammenfassung und
Zitation}

\end{figure}%

\section{KI als Copilot}\label{ki-als-copilot}

In dieser Kategorie hilft das Sprachmodell uns dabei, etwas zu tun, was
wir sonst nicht könnten. Mollick \& Mollick (2024) beschreiben mehrere
solcher Ansätze: Bei der \textbf{``Case Co-Creation''} (Mollick \&
Mollick, 2024, S.25--28) arbeiten Studierende mit der KI zusammen, um
ein Fallbeispiel für Kommilitonen zu erstellen. Dies fördert die
Artikulation von Ideen und die kritische Auseinandersetzung mit dem
KI-Output, da die initialen Entwürfe oft oberflächlich sind und durch
studentische Expertise verbessert werden müssen. Die Übung
\textbf{``Critique the AI''} lässt die KI ein Szenario zu einem Konzept
(z.B. Groupthink) erstellen, das die Studierenden dann kritisch bewerten
und ggf. verbessern müssen. Dies schult das Erkennen von
Konzeptmerkmalen und die Fähigkeit, Wissen durch Korrektur zu
artikulieren. Eine Herausforderung ist, dass die KI Konzepte manchmal
unvollständig oder fehlerhaft illustriert, was aber Teil des Lerneffekts
sein kann (Mollick \& Mollick, 2024).

Wie können \textbf{LLMs als Programmierassistenten} bei Coden und
Datenanalyse helfen? Bien \& Mukherjee (2025) beschreiben den Einsatz
von GitHub Copilot in einer \textbf{Einführung in die Datenanalyse für
MBA-Studierende} an der University of Southern California. Studierende
lernen, englische Prompts zu schreiben, die Copilot in R-Code übersetzt,
um Datenanalysen durchzuführen, ohne selbst R-Syntax lernen zu müssen
(Bien \& Mukherjee, 2025, S.129). Der Mehrwert ist, dass Studierende
direkt mit Daten interagieren und experimentieren können
(``translator-in-your-ear''), was das Verständnis fördert und die
Hemmschwelle senkt (Bien \& Mukherjee, 2025). Herausforderungen liegen
in der Inkonsistenz der KI (gleicher Prompt kann unterschiedlichen Code
erzeugen), der Notwendigkeit, spezifische Prompting-Fähigkeiten zu
lehren, und der Schwierigkeit für Studierende, die Korrektheit des
generierten Codes zu überprüfen, was durch häufiges Plotten und Prüfen
der Ergebnisse mitigiert werden muss (Bien \& Mukherjee, 2025, S.131,
133).

J. T. Liang et al. (2024) untersuchten in einer großangelegten Umfrage
die \textbf{Usability von KI-Programmierassistenten} wie GitHub Copilot.
Sie fanden heraus, dass Entwickler diese Tools vor allem nutzen, um
Tastenanschläge zu reduzieren, Aufgaben schneller zu erledigen und
Syntax abzurufen (J. T. Liang et al., 2024, S.2). Erfolgreiche
Anwendungen sind die Generierung von repetitivem Code oder Code mit
einfacher Logik sowie Unterstützung beim Lernen neuer Sprachen/APIs (J.
T. Liang et al., 2024, S.5--6). Als zentrale Herausforderungen wurden
genannt, dass der generierte Code oft funktionale oder nicht-funktionale
Anforderungen nicht erfüllt, die Steuerung des Tools schwierig ist und
Nutzer oft nicht verstehen, welcher Input zum Output führte (J. T. Liang
et al., 2024, S.2, 7).

Weitere Anwendungsbeispiele nutzen \textbf{LLM als Hilfe für
Schreibprozesse}: Aus Deutschland wird das Projekt
\textbf{``DeepWrite''} (U Passau, FAU, HöD Bayern) beschrieben, das
KI-Assistenzsysteme zur Förderung der \textbf{Schreib- und
Argumentationskompetenz} in Jura und Wirtschaft entwickelt (Wannemacher
et al., 2025, Case 66). An der Universität Kiel erproben Studierende der
Mittelalterlichen Geschichte den Einsatz von KI zur Unterstützung des
\textbf{Hausarbeitenprozesses} (Recherche, Übersetzung, Gliederung) und
diskutieren den Mehrwert im Vergleich zu traditionellen Methoden
(Wannemacher et al., 2025, Case 193). An der Universität Marburg wird KI
testweise zur Hilfe beim \textbf{Verfassen von Laborprotokollen} in der
Pharmazie eingesetzt, um insbesondere sprachliche Hürden zu überwinden
(Wannemacher et al., 2025, Case 25).

An der LMU München nutzen Soziologie-Studierende im Projekt
\textbf{``Mit KI über KI qualitativ forschen''} verschiedene KI-Tools
(Qualia, MAXQDA AI assist) zur \textbf{Durchführung und Auswertung
qualitativer Interviews}, um deren Potenzial und Grenzen im
Forschungsprozess kritisch zu reflektieren (Wannemacher et al., 2025,
S.29--31, Case 040). Herausforderungen hierbei sind der hohe
Einarbeitungsaufwand für Lehrende, die dynamische Tool-Entwicklung und
offene datenschutzrechtliche und methodologische Fragen (Wannemacher et
al., 2025, S.30).

Im Projekt \textbf{``Held:innenreise mit KI''} an der Universität des
Saarlandes dient KI (ChatGPT, Transkribus) Studierenden der
Mittelalterlichen Geschichte als Werkzeug zur \textbf{Transkription,
Übersetzung und Interpretation handschriftlicher lateinischer Quellen},
was den Zugang erleichtert und digitale Kompetenzen fördert (Wannemacher
et al., 2025, Case 146). Als Hürde wird der Umgang mit unterschiedlichen
Vorkenntnissen der Studierenden und die Notwendigkeit genannt, die
KI-Nutzung eng zu begleiten, ohne bei Fehlern sofort einzugreifen
(Wannemacher et al., 2025, S.33). Im Lehrkonzept \textbf{``TEAM with
AI''} (DHBW Heilbronn) nutzt KI Geschäftsberichte, um \textbf{Analysen
durchzuführen} und Entwürfe für Geschäftsmodellanalysen zu erstellen,
was die Studierenden bei komplexen Aufgaben unterstützt (Wannemacher et
al., 2025, S.27, Case 172).

Generell besteht bei Co-Pilot-Anwendungen die Gefahr der
Überabhängigkeit (Mollick \& Mollick, 2024). Die Notwendigkeit einer
kritischen Prüfung der KI-Ergebnisse (``Human in the Loop'') durch die
Nutzer ist zentral (Mollick \& Mollick, 2024, S.7).

\subsection{Besser schreiben -- als
Cyborg}\label{besser-schreiben-als-cyborg}

Wer akademisch schreibt, lässt sich zunehmend von einer Vielzahl an
unterstützenden KI-Systemen über die Schultern schauen -- oder die Hand
führen - , die Vorschläge zur besseren Sprachverwendung machen, wie
DeepL, Grammarly, oder ChatGPT (Ou et al., 2024). Ou et al. (2024)
sprechen von AI-assisted language tools (AILT), die Studierenden dabei
helfen, ihre Sprachfähigkeiten etwa von einer in die andere Sprache zu
übertragen und das Sprachniveau ihrer Schreibprodukte generell zu
verbessern. In ihrer Studie analysieren sie die Kommentare von 1703
schwedischen Studierenden und stellen komplexe Muster der Nutzung fest:
„\ldots students align their own languages, writing skills and thinking
with the algorithm-based language processes (e.g., lexical, grammatical,
and textual corrections, word choice suggestions, language translation)
within AI chatbots, writing assistance, and machine language translation
to optimise the outcomes of their academic writing. \ldots{} students
have become `spatially extended cyborg{[}s{]}'\,''.

Studierende schreiben durch die zunehmend mächtigere technische
Unterstützung ihre Haus- und Abschlussarbeiten deutlich anders. Bedeutet
dies das Ende der Hausarbeit? Wohl eher einen starken Wandel, denn es
wird weiter wichtig sein, die saubere Argumentation zu üben (Friedrich,
2023; Klein, 2023).

\begin{tcolorbox}[enhanced jigsaw, breakable, titlerule=0mm, leftrule=.75mm, opacitybacktitle=0.6, rightrule=.15mm, arc=.35mm, left=2mm, colframe=quarto-callout-tip-color-frame, opacityback=0, coltitle=black, bottomtitle=1mm, colback=white, toptitle=1mm, title=\textcolor{quarto-callout-tip-color}{\faLightbulb}\hspace{0.5em}{Probieren Sie mal}, bottomrule=.15mm, colbacktitle=quarto-callout-tip-color!10!white, toprule=.15mm]

Hier haben wir einen kleinen \textbf{Schreib-Trainer-Bot für
Studierende} erstellt, der ihnen dabei helfen soll, eine
\textbf{Einleitung für die Abschlussarbeit} zu schreiben. Dabei werden
zunächst Beispiele gezeigt die nach richtig/falsch sortiert werden
müssen, dann kommen nach und nach komplexere Fragen:
\href{https://chatgpt.com/g/g-68767cb33afc8191b1cfb9da1ed5c15a-bot-1-einleitungstrainer}{Link
zum Einleitungstrainer}

Hier eine zweite Übung (erstellt von Julia Schmid), zum die
strukturiertes \textbf{Schreiben mit Einleitungssätzen
(Topic-Sentences)} beibringen soll:
\href{https://chatgpt.com/g/g-68768c3031c08191b752ef66df258979-topic-sentence-bot}{Link
zum Topic-Sentence-Bot}.

\end{tcolorbox}

Die Studienberatung der Universität Frankfurt hat eine Übersicht nach
Phasen des Prozesses erstellt (Lehre virtuell - Universität Frankfurt,
2023), s. Tabelle 5:

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.3333}}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.3333}}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.3333}}@{}}
\caption{Tabelle 5: Integration von KI in den Schreibprozess. Quelle:
Studienberatung der Universität Frankfurt (Lehre virtuell - Universität
Frankfurt, 2023), Stand
10.3.2024}\label{tbl-writing-process}\tabularnewline
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
Phase im Schreibprozess
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Unterstützung durch KI
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Eigenanteil
\end{minipage} \\
\midrule\noalign{}
\endfirsthead
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
Phase im Schreibprozess
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Unterstützung durch KI
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Eigenanteil
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
\textbf{Themenfindung und Literaturrecherche} & BrainstormingGrober
Themenüberblick & SchwerpunktsetzungWissenschaftliche Quellen finden \\
\textbf{Lesen und Exzerpieren} & Zusammenfassung/Gliederung für ersten
ÜberblickTextpassagen vereinfachen & Gründliches LesenKI-generierte
Texte überarbeiten \\
\textbf{Rohfassung} & Ausformulieren von StichpunktenKooperatives
Freewriting & Stichpunkte festhalten``Schreiben, um eigene Gedanken zu
klären''KI-generierte Texte überarbeiten \\
\textbf{Überarbeiten} & Verschiedene Textversionen
generierenStil/Perspektive anpassen & Passende Textversion aussuchen und
anpassenMenschliches Feedback einholen \\
\textbf{Sprachliche Korrektur} & Spezialisierte Tools wie DeepL, Write
und Duden Mentor & Prüfen, ob Bedeutung verändert wurde \\
\end{longtable}

Mit einer einfachen Skala lässt sich auch die Intensität der LLM-Nutzung
grob beschreiben. (s. Tabelle 6): Je nach Phase im Arbeitsprozess kann
LLM zur Ideenfindung, zur Ausarbeitung möglicher Fragestellungen oder
Inhalte dienen. Je nach Intensität sollte dann die Nutzung stärker
begründet und durch Prüfschritte abgesichert werden (Baresel et al.,
2024; Rowland, 2023).

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.3333}}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.3333}}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.3333}}@{}}
\caption{Tabelle 6: Erläuterungen zum Grad der LLM-Nutzung. Quelle:
Baresel et al. (2024), basierend auf Rowland
(2023)}\label{tbl-llm-scale}\tabularnewline
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
Grad der KI-Nutzung
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Charakterisierung
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Beispiele
\end{minipage} \\
\midrule\noalign{}
\endfirsthead
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
Grad der KI-Nutzung
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Charakterisierung
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Beispiele
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
\textbf{1} & \textbf{Zur Inspiration} & Sie haben sich Vorschläge für
Themen unterbreiten lassen; Tools eingesetzt, um sich aus eigenen
Notizen heraus Themenschwerpunkte zu bilden; sich Formulierungen
vorschlagen lassen; die Rechtschreibung-/Grammatikprüfung genutzt. \\
\textbf{2} & \textbf{Ergänzend} & Sie haben sich mögliche
Fragestellungen vorschlagen lassen, einzelne Begriffe der
Aufgabenstellung oder Stellen in der Literatur erklären lassen,
Gliederungen der eigenen Notizen vorschlagen oder eigene Texte
zusammenfassen lassen, Reverse Outline zum eigenen Text (eine basierend
auf dem Geschriebenen erzeugte Gliederung) generieren lassen. \\
\textbf{3} & \textbf{Unterstützend} & Sie haben sich Anforderungen der
Aufgabe (z.B. Aufbau einer HA) erklären, Literatur zusammenfassen,
mögliche Gliederungen zum Thema vorschlagen lassen; Sie haben die
Fragestellung dialogisch verfeinert bzw. Textteile dialogisch verfasst
und dabei LLM-Output iterativ ergänzt; Sie haben sich
Überarbeitungsvorschläge bzgl. Leserlichkeit und Stil generieren
lassen. \\
\textbf{4} & \textbf{Inhaltsgestaltend} & Sie haben sich
Hintergrundwissen zur Aufgabe bzw. Antworten auf Fragestellung
generieren, Gliederung zum Thema vorgeben, Kürzungen und Ergänzungen
vornehmen lassen oder KI-generierten Text direkt übernommen. \\
\end{longtable}

Wie können wir konstruktiv mit den neuen technischen Möglichkeiten
umgehen? Die folgende Tabelle fasst konkrete Beispiele für Hausarbeiten
unter Einbindung von KI zusammen, die Ethan und Lilach Mollick in
verschiedenen Beiträgen ausgeführt haben (Mollick \& Mollick, 2023a,
2023b). Der übergeordnete Gedanke ist, KI nicht nur zur Automatisierung
einzusetzen, sondern neue, interaktivere und individuellere
Lernerfahrungen zu ermöglichen - mit mehr Reflexion, verschiedenen
Perspektiven, Kreativität und Kollaboration. Die Rolle der Lehrenden
wandelt sich hin zur Begleitung und Moderation dieser KI-gestützten
Prozesse.

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 2\tabcolsep) * \real{0.5000}}
  >{\raggedright\arraybackslash}p{(\linewidth - 2\tabcolsep) * \real{0.5000}}@{}}
\caption{Tabelle 7: Neue Ansätze für Hausarbeiten mit KI. Quelle:
Mollick \& Mollick (2023b) sowie die verlinkten
Blogeinträge}\label{tbl-mollick-assignments}\tabularnewline
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
Ansatz
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Beschreibung
\end{minipage} \\
\midrule\noalign{}
\endfirsthead
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
Ansatz
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Beschreibung
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
\textbf{Copilot: Kollaboratives Schreiben mit KI} & Gruppen von
Studierenden schreiben gemeinsam einen Text und nutzen KI als
zusätzliches ``Teammitglied''. Sie dokumentieren die Interaktion mit KI
und reflektieren Vor- und Nachteile. \\
\textbf{Copilot: Multimediale Anreicherung mit KI} & Studierende nutzen
KI, um ihre Arbeiten mit Visualisierungen, Animationen oder Audio
anzureichern und reflektieren, wie dies Verständnis und Attraktivität
erhöht. \\
\textbf{Copilot: KI als Coach und Reflexionspartner} & KI stellt Fragen
bezogen auf die Teamarbeit, um Studierende zur Reflexion ihrer
Lernerfahrungen, Herausforderungen und Lehren anzuregen. \\
\textbf{Tutor: KI-generierte Beispiele zur Erklärung von Konzepten} & KI
erstellt schnell viele Beispiele, die ein abstraktes Konzept in
unterschiedlichen realen Kontexten illustrieren. Dies hilft
Studierenden, die Idee zu erfassen und breiter anzuwenden. \\
\textbf{Tutor: KI-Tutor, den Studierende kritisieren} & KI erstellt
einen Essay zu einem Thema, den Studierende dann kollaborativ
verbessern, indem sie Informationen ergänzen, Punkte klären, Belege
liefern etc. Fördert kritische Analyse. \\
\textbf{Tutor: Simulation von Anwendungsszenarien mit KI} & Besonders in
praxisorientierten Fächern erstellen Studierende mit KI Simulationen, in
denen sie ihre Erkenntnisse anwenden, z.B. Unterrichtsszenarien in der
Lehramtsausbildung. \\
\end{longtable}

Prompts für ausgewählte Anwendungen finden Sie im Appendix. Im
Anwendungsteil des Workshops wollen wir diese Ansätze intensiv üben und
diskutieren. Letztlich ist die Anpassung der didaktischen Ansätze und
technischen Möglichkeiten auf die konkrete Kombination von Lerninhalt
und Studierendengruppe entscheidend. Es besteht die Hoffnung, dass die
neuen Möglichkeiten der administrativen Entlastung, höheren Niveaus bei
Arbeitsaufgaben und schnellerer Individualisierung der Lernunterstützung
in der Summe zu einem höheren Niveau des Lehrens und Lernens führt.
Voraussetzung dafür ist sicherlich eine Anpassung der Lehrstrategie und
die nüchterne und proaktive Beschäftigung mit den unvermeidlichen
Risiken und Nebenwirkungen von neuen technischen Möglichkeiten. Wie kann
kritisches Denken in diesen neuen Recherche- und Schreibprozessen
erfolgen (Lee et al., 2025)? In diesem Fall darf man vermuten, dass die
negativen Effekte noch höher wären, wenn wir die Lehre nicht anpassen.

\subsection{Jeder kann jetzt
programmieren}\label{jeder-kann-jetzt-programmieren}

Mit KI als Copilot können wir \textbf{viel umfangreicher und schneller
mit Code arbeiten}. Ein Beispiel ist Programmieren: Professionelle
Programmierer werden mit KI Copiloten deutlich schneller (Peng et al.,
2023; Steinberger, 2025; zunehmend beaufsichtigen sie KI-Agenten, siehe
etwa Willison, 2025a) und Lehrbücher haben zunehmend Namen wie „Learn
AI-assisted Python Programming`` (Porter \& Zingaro, 2024). Studierende
können so zum Beispiel viel schneller ein funktionierendes Spiel oder
eine Simulation erstellen, was die Motivation erhöht. Der \textbf{Raum
der kreativen Möglichkeiten weitet sich deutlich aus}. Mit
KI-Unterstützung können Schüler/innen mit Sonic Pi Musikstücke
programmieren (Gieselmann, 2024) oder mit Tools wie Violentmonkey kleine
Skripte für die individuelle Anzeige von Lieblings-Websites erstellen
(Eikenberg, 2025).

Wie helfen solche Copiloten beim Coden? Aktuelle Studien untersuchen
etwa, wie man mit KI Copiloten auch Nicht-Informatiker an
fortgeschrittene statistische Auswertungen heranführen kann (Bien \&
Mukherjee, 2025). In einer Einführungsvorlesung für
\textbf{MBA-Studierende} wurde GitHub Copilot genutzt, wobei die
Studierenden natürliche Spracheingaben verwendeten, um \textbf{R-Code
automatisch} generieren zu lassen. Das Ziel war, komplexe Syntax zu
vermeiden und die Studierenden direkt mit Datenanalyse vertraut zu
machen. Im Ergebnis ermöglichte die Nutzung von GitHub Copilot es
Studierenden ohne Programmierkenntnisse, statistische Methoden effektiv
und eigenständig anzuwenden. Studierende bewerteten die Nutzung der
KI-Tools überwiegend positiv, da diese die Lernerfahrung verbesserten
und den Zugang zur Programmierung erleichterten. Die empirische
Untersuchung zeigte, dass ein Großteil der universitären
Programmieraufgaben teilweise oder vollständig durch die KI-Tools gelöst
werden konnte.

Eine weitere Studie sammelt qualitative Erfahrungen in einem
\textbf{Einführungskurs in Informatik}, wie sich die Nutzung von Copilot
auf das Lernen auswirkte (Puryear \& Sprint, 2022). Studierende
profitierten deutlich von Copilot, insbesondere bei der Entwicklung von
Programmierfähigkeiten und beim Lösen konkreter Programmierprobleme.
Allerdings zeigte sich, dass die Studierenden weiterhin ein fundiertes
Verständnis der Programmiersprache benötigen, um KI-generierte Lösungen
richtig beurteilen und gegebenenfalls korrigieren zu können. Die KI
unterstützte den Lernprozess effektiv, konnte aber die grundlegenden
Konzepte nicht vollständig ersetzen.

Mehrere Studien testen, \textbf{wie gut ein KI Assistent typische
Programmieraufgaben} aus einer Einführungsveranstaltung löst -- zunächst
allein durch KI und dann mit Anpassung der Eingaben durch Studierende
(GitHub Copilot) (Denny et al., 2023). Eine öffentliche Datenbank mit
166 typischen CS1-Problemen wurde genutzt, um Copilot zu testen. Wenn
Copilot anfangs scheiterte, versuchten Studierende, die Beschreibung der
Aufgaben in natürlicher Sprache anzupassen („Prompt Engineering``), um
das Ergebnis zu verbessern. Copilot löste etwa die Hälfte der
Programmieraufgaben auf Anhieb korrekt. Durch gezieltes Prompt
Engineering konnten weitere 60 \% der anfänglich nicht gelösten Aufgaben
erfolgreich bearbeitet werden. Dies deutet darauf hin, dass die bewusste
Formulierung von Aufgabenstellungen ein wichtiger Bestandteil der
Lernaktivitäten wird und das Erlernen von Programmierkompetenzen
verändert.

Eine weitere Studie an der niederländischen Universität Twente zeigt
basierend auf Interviews und Umfragen mit Studierenden, dass ein
Großteil der universitären Programmieraufgaben teilweise oder
vollständig durch die KI-Tools gelöst werden konnte. Dies erfordert,
dass Lehrende ihre Unterrichtsstrategien anpassen, um sicherzustellen,
dass Kernkompetenzen dennoch vermittelt werden (Nizamudeen et al.,
2024).

Wofür nutzen professionelle Programmierer*innen die Copiloten? Eine
Studie untersucht dies mit einer Umfrage unter 410 Entwicklern (J. T.
Liang et al., 2024). Die wichtigsten Gründe der Nutzung waren
Autovervollständigung, schnelleres Abschließen von Programmieraufgaben
sowie Unterstützung beim Erinnern von Syntax. Als besonders erfolgreich
erwiesen sich die Tools bei repetitiven und einfachen
Programmieraufgaben. Häufige Probleme waren jedoch, dass generierter
Code oft nicht die gewünschten funktionalen oder nicht-funktionalen
Anforderungen erfüllte, wodurch Entwickler diesen oft modifizieren
mussten oder ganz darauf verzichteten.

Alle fünf Studien zeigen, dass KI-Programmierassistenten, insbesondere
GitHub Copilot, effektiv dabei helfen, \textbf{Einstiegshürden beim
Programmieren zu reduzieren}, indem sie Entwicklern helfen, repetitive
und einfache Programmieraufgaben effizienter zu erledigen (Bien \&
Mukherjee, 2025; J. T. Liang et al., 2024; Nizamudeen et al., 2024;
Puryear \& Sprint, 2022). Ein wesentliches Potenzial dieser Tools liegt
in der \textbf{Steigerung der Motivation und der Verkürzung der
Lernkurve} bei Programmieranfängern. Besonders wichtige neue
Kompetenzbereiche sind „Prompt Engineering``, die gezielte Steuerung der
KI-Ausgaben (Denny et al., 2023), sowie das Verständnis dafür, wie Input
den generierten Output beeinflusst (J. T. Liang et al., 2024). Jedoch
treten auch \textbf{Herausforderungen} auf: Häufig erfüllen
KI-generierte Lösungen nicht alle funktionalen oder nicht-funktionalen
Anforderungen, weshalb Entwickler oft erhebliche Anpassungen vornehmen
müssen oder den KI-generierten Code ganz verwerfen (J. T. Liang et al.,
2024). Dies unterstreicht, dass trotz erheblicher Erleichterungen durch
KI grundlegende Programmierkenntnisse weiterhin notwendig sind, um
Lösungen kritisch zu bewerten und effektiv anzupassen (Puryear \&
Sprint, 2022).

\textbf{Praktisch alles, was Code ist, lässt sich mit Sprachmodellen
erstellen und anpassen}. Wir brauchen also nur Code-Schnittstellen. Das
klingt kompliziert, ist aber überall schon vorhanden. Im Schreibprozess
importieren wir Zitationen über das Bibtex-Format (.bib).
Kalendertermine werden im Kalenderstandard (.ics) geführt. Für
Flußdiagramme gibt es z.B. den Mermaid Standard. Wir können insofern mit
Sprachmodellen:

\begin{itemize}
\tightlist
\item
  Zitationen von einem Foto aus importieren („Scanne das Foto und gib
  mir die Quellen als Bibtex Code aus. Erkläre mir dann, wie ich ihn
  importiere``)
\item
  Kalendereinträge aus einer Liste in unser Terminprogramm überführen
  („Erstelle mir aus dieser Liste Einträge im ICS Standard. Erkläre mir
  dann, wie ich den Code in Google Calendar importiere.``)
\item
  Ablaufdiagramme in Mermaid visualisieren und als Grafik speichern
  („Erstelle mir einen typischen Kaufprozess in Mermaid. Erkläre mir
  dann, wie ich ihn visualisieren und als Grafik exportieren kann.``
\item
  Interaktive Simulationen mit den Claude Artifacts erstellen (s.o.)
\item
  Dialogbasiert Grafiken und statistische Analysen in Google Colab
  erstellen (s.u.)
\item
  (Für viele weitere Ideen für solche Hilfsmittel können wir einfach das
  Sprachmodell fragen.)
\end{itemize}

\begin{figure}

\centering{

\pandocbounded{\includegraphics[keepaspectratio]{images/script04-04.png}}

}

\caption{\label{fig-mermaid}Abbildung 12: Visualisierung von
Ablaufdiagrammen in Mermaid (Chat GPT -- https://mermaid.live/)}

\end{figure}%

Wichtig für Hochschulen: Mit verschiedenen browserbasierten Tools wie
\textbf{Google Colab oder Cursor} steht mittlerweile eine sehr mächtige
Programmierhilfe mit integriertem Sprachmodell (Gemini) zur kostenlosen
Verfügung. Visualisierungen und statistische Analysen können hier
komplett dialogbasiert begonnen werden. Auch ohne Grundkenntnisse in der
Programmiersprache Python sind Studierende hier gleich handlungsfähig
und können durch häufige Nutzung Wissen aufbauen. Dadurch wird es etwa
möglich, von Studierenden durchgängig die Nutzung von Programmiertools
zur Erstellung von Visualisierungen zu verlangen. Die Hilfestellung
durch die KI Assistenz lässt dies deutlich leichter werden, als das
händische Gefrickel in den Grafiken von Excel oder gar PowerPoint. Zur
Illustration hier ein Beispiel-Notebook. Rechts können die Prompts
eingegeben werden:
\href{https://colab.research.google.com/drive/1mFJWvghahGor87gwkNZAqPYoejD3KDwK?usp=sharing}{Beispiel-Notebook}

\textbf{Beispiel-Prompts:} * Erstelle mir eine einfache Visualisierung
von vertikalen und horizontalen \textbf{Balkendiagrammen} in Python. *
\textbf{Passe die Balken so an}, dass die Prozentwerte auf den Balken
sichtbar sind. * Füge Beispiele für \textbf{Violin Charts} mit einem
etwas komplexeren \textbf{Beispieldatensatz} hinzu. * Erstelle jetzt
einen Beispieldatensatz und führe eine einfache \textbf{Explorative
Datenanalyse} (EDA) mit Visualisierungen durch.

\begin{figure}

\centering{

\pandocbounded{\includegraphics[keepaspectratio]{images/script04-05.png}}

}

\caption{\label{fig-colab}Abbildung 13: Visualisierung im Dialog mit
Google Colab und KI}

\end{figure}%

Anmerkung: Rechts schreibt man den Prompt, links entsteht der Code und
die Grafik. Besondere Stärken sind die Nachvollziehbarkeit (da alles im
Code steht) und die einfachen Anpassungsmöglichkeiten (da die KI sich um
die Syntax kümmert). Code ist hier einsehbar:
\href{https://colab.research.google.com/drive/1mFJWvghahGor87gwkNZAqPYoejD3KDwK?usp=sharing}{Link
zum Code}.

Solche \textbf{Hilfestellungen sind mittlerweile Alltag} geworden: Alle
großen Anbieter von Code Editoren wie \textbf{Pycharm, VS Code
(Microsoft/GitHub) und neue Anbieter wie Cursor} und (noch extremer, als
Agent) \textbf{Devin} (https://preview.devin.ai/) bieten mittlerweile
Programmierung mit KI-Unterstützung an. Für Hochschulen stellt sich die
Frage, wie diese Fähigkeit am Besten trainiert werden kann. Ein extremes
Anwendungsbeispiel ist dieser Youtuber, der in Trainingsvideos mit einer
Vielzahl verschiedener KI-Tools programmiert, auch selbst beschrieben
eher in der Rolle eines Supervisors, der die verschiedenen KI Helfer
überwacht und koordiniert:
\href{https://www.youtube.com/watch?v=C59LC1WJIbE}{Build Anything with
Cursor, David Ondrej, 2024-09-1}.

\section{KI als Tutor}\label{ki-als-tutor}

Diese Kategorie umfasst KI-Systeme, die Studierende direkt beim Lernen
anleiten, beraten oder ihnen Feedback geben.

\subsection{Beispiele für einfache
Tutoren}\label{beispiele-fuxfcr-einfache-tutoren}

Mollick \& Mollick (2024) beschreiben eine Reihe allgemeiner
Tutorenkonzepte: Der \textbf{``Integration Agent''} (Mollick \& Mollick,
2024, S.31--33) fordert Studierende durch offene Fragen heraus,
Verbindungen zwischen verschiedenen Kurskonzepten herzustellen, was
vernetztes Denken fördert. Der \textbf{``Reflection Coach''} (Mollick \&
Mollick, 2024, S.30) regt zur Reflexion über Erfahrungen an, um das
Gelernte zu konsolidieren. Der \textbf{``AI Tutor Blueprint''} (Mollick
\& Mollick, 2024, S.38--40) ermöglicht es Lehrenden, eigene, auf ihre
spezifischen Themen zugeschnittene Tutoren-Prompts zu erstellen.

An deutschen Hochschulen gibt es ebenfalls vielfältige
Tutor-Anwendungen: Der Lern- und Informationsassistent \textbf{``LISA''}
an der Hochschule Hof unterstützt Studierende bei der
\textbf{Prüfungsvorbereitung} durch personalisierte Lernpläne,
Übungsaufgaben und Feedback basierend auf hochgeladenen Materialien
(Wannemacher et al., 2025, Case 208). Herausforderungen sind hier die
Bekanntmachung des Tools und die potenziell geringere Ergebnisqualität
im Vergleich zu großen kommerziellen Modellen. An der FernUniversität in
Hagen bietet \textbf{``COFFEE''} skalierbares, kriterienbasiertes
\textbf{Feedback zu Freitextaufgaben}, während \textbf{``MIND''}
Feedback zu Lernaktivitäten liefert, um die \textbf{Selbstreflexion} zu
fördern (Wannemacher et al., 2025, Case 61). Hier sind der hohe initiale
Implementierungsaufwand, Datenschutzanforderungen und die Notwendigkeit
interdisziplinärer Expertise einschränkende Faktoren (Wannemacher et
al., 2025).

\textbf{``KI-Folio''} (U Passau, LMU München) gibt als Chatbot
\textbf{Feedback zu E-Portfolio-Aufgaben} und Reflexionen, um begrenzte
Betreuungsressourcen zu kompensieren (Wannemacher et al., 2025, Case
36). \textbf{``THI Success AI''} (TH Ingolstadt) ermöglicht
\textbf{individualisierte Lernpfade} und bietet einen Chatbot für
Übungsaufgaben und Fragen (Wannemacher et al., 2025, S.17--18, Case
210). Der \textbf{``Mentor-Bot''} an der CBS Köln unterstützt bei der
Übungsvorbereitung und bietet \textbf{Trainingsmodi} (Wannemacher et
al., 2025, Case 98). An der HU Berlin wird KI für \textbf{formatives
Assessment-Feedback} in der Sprachbildung genutzt, wobei Lehrende als
``Human in the Loop'' die KI-Vorschläge prüfen (Wannemacher et al.,
2025, Case 222). An der Hochschule Kempten bewertet KI
\textbf{Freitextantworten} in Übungen automatisch und gibt direktes
Feedback (Wannemacher et al., 2025, S.18, Case 169). Die Wilhelm Büchner
Hochschule setzt \textbf{``WBH A{[}I{]}ssist''} als allgemeinen
\textbf{KI-Tutor im Fernstudium} ein (Wannemacher et al., 2025, Case
63).

Für all diese allgemeinen Tutoren gilt: Ihre Effektivität hängt von der
Qualität des Prompts und der Fähigkeit der KI ab, die Tutor-Rolle
konsistent und pädagogisch sinnvoll auszufüllen, was nicht immer gegeben
ist und von Modell zu Modell variieren kann (Mollick \& Mollick, 2024,
S.36). Die KI kann oberflächlich bleiben oder halluzinieren (Mollick \&
Mollick, 2024, S.36).

\textbf{Sprachen lernen und schwierige Situationen simulieren} kann man
jetzt sehr einfach und auf hohem Niveau mit KI-Modellen wie ChatGPT oder
Gemini (Jurran, 2025). Vorreiter war der „Voice Mode`` von OpenAI, den
man als App auf dem Handy ausprobieren kann (gut in der kostenfreien,
sehr gut in der kostenpflichtigen Version), inzwischen bietet
Google/Gemini ähnliche Funktionen an. Die KI spricht auf Wunsch über ein
beliebiges Thema in einer beliebigen Sprache. Im fortgeschrittenen Modus
(„\textbf{Advanced Voice Mode}``, für Abonnenten) ist die Stimme noch
realistischer und man kann unter anderem die Geschwindigkeit und andere
Stimmparameter anpassen. Im Standardmodus kann man Dokumente hinzufügen,
auf die sich die Unterhaltung beziehen soll (s. das zweite Beispiel für
Anwendungen). Damit lassen sich zum Beispiel im Hochschulunterricht
interaktive und unmittelbare Anwendungen realisieren: Studierende
könnten ihre Fragen in Seminar- oder Vorlesungsphasen mündlich stellen,
wobei die KI entsprechende Antworten gibt, visuelle Inhalte erklärt oder
sogar aktuelle Daten aus dem Internet integriert. Besonders gut eignet
es sich auch zum Lernen von Sprachen: Man kann die englische
Präsentation ausprobieren und sich Feedback geben lassen. Solche
Interaktionen kommen dem Ideal eines persönlichen Tutors schon sehr
nahe, ermöglicht eine enge, interaktive und sehr auf die eigenen
Bedürfnisse und Lernziele zugeschnittene Zusammenarbeit und kann so
Lernprozesse dynamischer gestalten.

\textbf{Wie passt man die Lehre an?} Ein aktueller Artikel bespricht,
wie sich diese neuen Möglichkeiten auf die Rolle des Sprachunterrichts
an Hochschulen auswirken (Tutton \& Cohen, 2025): Es werden eine breite
Reihe an Tools besprochen und konkrete Empfehlungen zur Umsetzung
angeboten: Lehrende sollen mit Studierenden die Stärken und Schwächen
der Tools erproben und sie so an die Nutzung heranführen.
Unterrichtskonzepte sollten so angepasst werden, dass sich die Stärken
der KI-Tools und des Präsenz-Unterrichts ergänzen.

\subsection{Komplexer Physik Tutor mit
Musterlösungen}\label{komplexer-physik-tutor-mit-musterluxf6sungen}

Als \textbf{Beispiel für einen ausführlich getesteten Tutor-Bot} wollen
wir hier exemplarisch einen \textbf{Physik-Tutor der Harvard
Universität} etwas ausführlicher darstellen (Gregory Kestin et al.,
2024). Der Physik-Tutor ``PS2 Pal'' betreut Studierende in
Physik-Einsteigerkursen interaktiv und mit adaptiven Fragestellungen,
was in der Evaluation zu einem deutlich verbesserten Lernerfolg führte.
Im Verbund mit kürzeren Input-Phasen erhalten die Studierenden Aufgaben
und Fragestellungen, die sie direkt in Interaktion mit dem KI-Tutor
bearbeiten können. Der Tutor stellt Fragen, gibt bei Bedarf Hinweise und
passt den Schwierigkeitsgrad an den Fortschritt der bzw. des Lernenden
an.

Studierenden loggen sich über eine Weboberfläche -- oder in manchen
Fällen eine in den Kurs integrierte Lernplattform -- ein und erhalten
dann Aufgabenpakete zu Teilthemen (z. B. Kinematik, Kräfte oder
Energieerhaltung). Die KI analysiert die eingegebenen Antworten und
entscheidet anhand vorab definierter Parameter und eines
Maschinenlern-Modells, ob und wie viel zusätzliche Hilfestellung nötig
ist. Bei korrekten oder fast korrekten Lösungen wird ein vertiefender
Schritt vorgeschlagen (etwa eine weiterführende Frage), während bei
fehlerhaften Lösungsschritten gezielt ein Tipp oder ein Hinweis auf das
entsprechende Lehrmaterial gegeben wird. Dadurch werden die Lernenden
kontinuierlich im Lernprozess unterstützt, ohne gleich eine komplette
Lösung zu sehen.

Aus didaktischer Sicht entfaltet der Tutor seinen Mehrwert vor allem in
vier Punkten: * \textbf{Individuelle Anpassung}: Das System erkennt
unterschiedliche Lernstände (etwa durch Analyse typischer Fehler oder
wiederkehrender Wissenslücken) und kann dadurch passgenauere Folgefragen
stellen. * \textbf{Unmittelbares Feedback}: Während in großen
Lehrveranstaltungen Lehrende nur sehr eingeschränkt auf einzelne Fragen
von Studierenden eingehen können, liefert das KI-Tool praktisch sofort
Rückmeldungen. * \textbf{Motivation und aktive Teilhabe}: Studierende
werden durch die permanenten Interaktionsmöglichkeiten stärker
einbezogen, was sich positiv auf die Lernergebnisse auswirkt. *
\textbf{Zeitersparnis für Lehrende}: Ein Teil der individuellen
Betreuung kann -- bei inhaltlich gut vorbereitetem KI-System -- durch
den Tutor übernommen werden. Allerdings behält die Lehrkraft jederzeit
die Oberaufsicht, indem sie zum Beispiel relevante KI-Antworten
stichprobenartig überprüft oder spezielle Fälle selbst übernimmt (z. B.
wenn die KI Auskünfte gibt, die nicht zur jeweiligen Kursstruktur
passen).

Generell ist bei KI-Tutoren die \textbf{Gefahr von Fehlinformationen und
Halluzinationen} zu beachten. Hierfür gibt es jedoch gute
Gegenmaßnahmen, vor allem durch Kontrolle des Inputs und systematische
Qualitätstests der LLM-Tools. Eine interessante Möglichkeit, die beim
Physik-Tutor der Harvard Studie besprochen wird (Gregory Kestin et al.,
2024), ist die \textbf{Bereitstellung von Musterlösungen als Input}
(nicht nur der Fragen), was die Gefahr von Ungenauigkeiten,
Halluzinationen und Inkonsistenzen in den Antworten des Sprachmodells
deutlich reduziert. Der Aufwand für die Erstaufsetzung steigt hier zwar,
aber im Gegenzug verspricht dieser Ansatz die Vorteile der individuellen
Anleitung ohne die Nachteile der Qualitätsunsicherheit. Insgesamt ist
eine solche Durchsicht und intensive Qualitätskontrolle klar zu
empfehlen (dieser Aspekt der intensiven Qualitätstests wird bei der
Kurzvorstellung einiger deutscher Fallstudien in Wannemacher et al.
(2025) vernachlässigt).

\section{KI als Simulator}\label{ki-als-simulator}

Hier erstellt die KI interaktive Umgebungen für praxisnahes Training. In
einfachen Rollenspielen simuliert das Sprachmodell ein Gegenüber, um
z.B. Analyse- oder Verhaltensmuster einzuüben. Mollick \& Mollick (2024)
unterscheiden dabei \textbf{Role Play} (Rollenspiele) und \textbf{Goal
Play} (zielgerichtete Spiele).

\subsection{Role Play}\label{role-play}

\textbf{Rollenspiel-Simulationen} z.B. für Verhandlungen lassen
Studierende eine neue Rolle einnehmen und dadurch risikofrei zu Üben,
etwa von Verhandlungssituationen. In Deutschland wird an der TH
Brandenburg das Format ``Talk2Transform'' eingesetzt, das
\textbf{Mitarbeitergespräche in Transformationsprozessen} simuliert,
wobei KI die Mitarbeiterrollen spielt (Wannemacher et al., 2025, Case
132). Der Mehrwert liegt im praxisnahen Training von Kommunikations- und
Führungskompetenz. Herausforderungen sind der hohe
Konfigurationsaufwand, die technische Stabilität und die Tatsache, dass
KI menschliche Interaktion nicht vollständig ersetzen kann und Rollen
nicht immer fehlerfrei spielt (Wannemacher et al., 2025). In der HAW
Hamburg werden \textbf{Gesprächssimulationen zur deeskalierenden
Kommunikation} genutzt (Wannemacher et al., 2025, Case 177). An der
Hochschule Kempten kommen \textbf{KI-Avatare} zur Simulation von
\textbf{Führungsgesprächen} zum Einsatz (Wannemacher et al., 2025, Case
95). An der Deutschen Hochschule der Polizei dient eine Simulation der
\textbf{Sensibilisierung für LLM-Missbrauchspotenziale}, indem
Studierende explorativ deren missbräuchliche Nutzung erproben
(Wannemacher et al., 2025, Case 031).

\textbf{Direkt mit der KI zu sprechen} kann die Situation dabei noch
realistischer machen: Barra et al. (2024) beschreiben den Einsatz von
\textbf{ChatGPT's Advanced Voice Mode (AVM) in medizinischen
Simulationen}, speziell für das CPR-Training (s. Abbildung 14). AVM
ermöglicht der Simulationspuppe, mit einer natürlichen, emotional
reagierenden Stimme zu ``sprechen'', was den Realismus steigert. Der
Mehrwert liegt in der verbesserten Immersion, Zugänglichkeit und
Entlastung der Trainer. Herausforderungen sind die Sicherstellung der
Konsistenz, die Abhängigkeit von den Prompting-Fähigkeiten des Trainers
und technische Limitierungen des AVM bezüglich vorab eingebetteten
Wissens.

\textbf{Auch Juristen simulieren}: Einen ähnlichen Ansatz verfolgt die
simulierte Zeugenbefragung von Heetkamp, der es so etwa
Rechtsreferendaren ermöglicht, diese Kompetenz im Rollenspiel mit
VR-Brillen einzuüben (Heetkamp, 2023).

\begin{figure}

\centering{

\pandocbounded{\includegraphics[keepaspectratio]{images/script04-06.png}}

}

\caption{\label{fig-voice-mode}Abbildung 14: Nutzung der Voice Modes von
ChatGPT für medizinische Simulationen. Quelle: Barra et al. (2024)}

\end{figure}%

Eine umfangreiche Simulation beschreiben Mollick et al. (2024):
\textbf{``Pitch Quest''} an der \textbf{Wharton School} ist ein
Simulator für \textbf{Venture-Capital-Pitches}, der mehrere KI-Agenten
(Mentor, Investor, Bewerter) nutzt, um personalisierte Übung und
Feedback zu ermöglichen (Mollick et al., 2024, S.5--10). Der Mehrwert
liegt in der skalierbaren Bereitstellung von Übungsmöglichkeiten für
komplexe Skills. Herausforderungen sind die Aufrechterhaltung der
Konsistenz, die Vermeidung von Bias und Halluzinationen sowie der hohe
Entwicklungsaufwand für solche Multi-Agenten-Systeme (Mollick et al.,
2024, S.2--3).

\subsection{Goal Play -- zielgerichtete
Spiele}\label{goal-play-zielgerichtete-spiele}

In \textbf{zielgerichteten Spielen} (``Goal Play'', Mollick \& Mollick
(2024)) bleiben Studierende in ihrer normalen Rolle und wenden in einer
Situation bestimmtes Wissen oder theoretische Konzepte an (z.B.
Zielsetzung, Selbst-Distanzierung oder Analyseraster wie
Transaktionskostenanalyse), indem sie einen KI-Charakter anleiten.
Wichtig dabei: Die Studierenden wissen etwas, das das KI-Gegenüber im
Spiel nicht weiß.

So nehmen etwa bei dem einfachen Rollenspiel \textbf{``Teach the AI''}
(Mollick \& Mollick, 2024, S.21--23) Studierende die Rolle des Lehrenden
ein und erklären der KI (die einen unwissenden Studenten spielt) ein
Konzept. Der Mehrwert liegt im vertieften Lernen durch Lehren
(Protégé-Effekt) und dem Aufdecken eigener Wissenslücken. Als
Herausforderung kann die KI manchmal vom Thema abweichen oder Fragen
stellen, die die Studierenden an ihre Grenzen bringen; zudem ist die
Simulation eines ``Novizen'' durch die KI nur begrenzt realistisch
(Mollick \& Mollick, 2024, S.24).

Für beide Typen gilt: Die KI kann von der Rolle abweichen oder
inkonsistent agieren, und die Qualität der Erfahrung kann variieren.
Eine sorgfältige Einbettung und Reflexion durch Lehrende ist
entscheidend (Mollick \& Mollick, 2024). Bei allen Simulatoren ist die
Notwendigkeit einer klaren didaktischen Rahmung und eines Debriefings
durch Lehrende (``Human in the Loop'') zentral, um den Lernerfolg zu
sichern und die Grenzen sowie potenzielle Fehler der KI zu reflektieren
(Mollick \& Mollick, 2024, S.16).

\bookmarksetup{startatroot}

\chapter{Empfehlungen zur Umsetzung}\label{sec-umsetzung}

\section{Typische Aufgaben und Fragestellungen mit der KI durchspielen,
Prompts anpassen,
experimentieren}\label{typische-aufgaben-und-fragestellungen-mit-der-ki-durchspielen-prompts-anpassen-experimentieren}

Lehrende sollten zunächst Informationen sammeln, um zu verstehen, was KI
mit den Aufgaben in ihrem Kurs bewirken kann (MIT Teaching + Learning
Lab, 2023). Melden Sie sich bei einem der professionellen KI-Dienste an
wie ChatGPT oder Claude an und spielen Sie mit exemplarischen Konzepten,
Fragen und Aufgabensets aus dem Kurs. Dabei ist es wichtig, nicht gleich
bei der ersten schlechten Antwort aufzugeben, sondern
Anpassungsmöglichkeiten durchzugehen: Lässt sich der \textbf{Input
beschränken}? (Fragen auf einen Text-Input, eine gute Internetquelle
oder eine hochgeladene PDF beschränken.) Lässt sich der \textbf{Prompt
anpassen}? (Bearbeitung schrittweise durchführen lassen, Optionen und
Szenarien durchgehen lassen usw., siehe den Abschnitt 2.5.2 zu Prompt
Engineering.)

Wichtig ist, sich zu überlegen, welches Lernziel jede Aufgabe hat und
wie die KI damit umgeht. Es sollte bewertet werden, bei welchen Arten
von Fragen die KI gut abschneidet und wo ihre Grenzen liegen (Mollick,
2025c). Diese Erkenntnisse können dann genutzt werden, um etwa
Aufgabensets und andere Aufgabenstellungen besser zu strukturieren.

\section{Ausrichtung der Anpassungen nach Empfehlungen der
Lernforschung}\label{ausrichtung-der-anpassungen-nach-empfehlungen-der-lernforschung}

Um die Empfehlungen der Lernforschung in das Vorgehen mit Künstlicher
Intelligenz (KI) und Aufgabensets zu integrieren, könnten folgende
Schritte unternommen werden (MIT Teaching + Learning Lab, 2023):

\begin{itemize}
\tightlist
\item
  \textbf{Zeitliche Verteilung und inhaltliche Mischung von Lerninhalten
  (Spacing \& interleaving)}: Die Aufgabensets sollten so gestaltet
  werden, dass sie über das Semester verteilt sind und eine Vielfalt an
  Themen abdecken. Dies fördert die Langzeiterinnerung und hilft den
  Studierenden, die Anwendung der Konzepte in verschiedenen Kontexten zu
  üben. KI kann genutzt werden, um personalisierte Lernpläne zu
  erstellen, die auf den individuellen Fortschritt der Studierenden
  abgestimmt sind und eine Mischung aus verschiedenen Aufgabentypen
  bieten.
\item
  \textbf{Testgestütztes Lernen (Test-enhanced learning)}: Regelmäßige,
  durch KI unterstützte Quizze und Tests können in den Lehrplan
  integriert werden, um das Abrufen von Informationen zu fördern. Diese
  Tests könnten auch die kritische Bewertung von KI-generierten
  Antworten beinhalten, um die kritische Denkfähigkeit der Studierenden
  zu schärfen.
\item
  \textbf{Fragebasierte Ausarbeitung (Explanatory questioning)}:
  KI-Tutor-Bots könnten entwickelt werden, um Studierende durch gezielte
  ``Warum''-Fragen zu leiten, die ein tieferes Verständnis des Materials
  fördern. Diese Bots könnten in Simulationen und Rollenspielen
  eingesetzt werden, um die Studierenden dazu zu bringen, ihre
  Entscheidungen zu erklären und zu reflektieren, wodurch die Anwendung
  von Konzepten in realen oder simulierten Situationen vertieft wird.
\end{itemize}

\section{Einführung der Studierenden planen: Besser praktisch, häufig
und
niedrigschwellig}\label{einfuxfchrung-der-studierenden-planen-besser-praktisch-huxe4ufig-und-niedrigschwellig}

Den Einsatz von KI lernen die Studierenden, wenn sie häufig und über das
Semester zeitversetzt damit experimentieren dürfen und müssen. Auch hier
führen wieder die Empfehlungen des \textbf{Spacing \& Interleaving} zu
höherer Effektivität. Unterstützend können \textbf{externe Lernvideos}
von seriösen Plattformen wie dem KI-Campus genutzt werden (z.B.
https://ki-campus.org/videos/generativeki) oder selbst erstellte
hochschulweite Angebote wie die Lehrpfade der TH Köln
(https://lehrpfade.th-koeln.de/kategorie/ki/).

Um ein gemeinsames Verständnis über Grundlagen herzustellen, ist es
hilfreich, \textbf{Zeit in einer der ersten Präsenzveranstaltungen
einzuräumen}, um das gemeinsam zu üben. Der Sprung ins kalte Wasser ist
dabei meist besser, als eine lange Theorieeinführung: \textbf{Gleich
anfangen}, dann problembasiert erläutern. Aspekte von
\textbf{testbasiertem Lernen} und \textbf{fragebasierte Ausarbeitung}
lassen sich gut über Anwendungsaufgaben in der Präsenzveranstaltung
einbauen.

\subsection{Beispiel: KI-Übung in Präsenzveranstaltung am Ende eines
Theorieblock zu Nachhaltigkeit in
Lieferketten}\label{beispiel-ki-uxfcbung-in-pruxe4senzveranstaltung-am-ende-eines-theorieblock-zu-nachhaltigkeit-in-lieferketten}

\textbf{Aufgabe:} Nicht lange schnacken, gleich anpacken! Mit der KI
einen Projektplan für erste konkrete Schritte einer
Nachhaltigkeitsstrategie erstellen (Edge Browser, Bing Copilot = GPT-4).
Prompts zum Einstieg werden den Studierenden vorgegeben. Anfang mit:

\begin{itemize}
\tightlist
\item
  \emph{Prompt \#1}: „KI als Tutor`` oder ähnlich (siehe Appendix:
  Beispiel KI als Tutor \#1/ Allgemeiner Tutor. Prompts im Folgenden
  immer \emph{kursiv}.)
\item
  \emph{Prompt \#2}: \emph{Ich will eine Cradle-to-cradle
  Nachhaltigkeitsstrategie für ein Unternehmen entwerfen. Helfen Sie
  mir, konkrete erste Schritte nach der Cradle-to-cradle Zertifizierung
  zu planen.}
\end{itemize}

Studierende sollen ein Unternehmen auswählen, bei dem sie schon einmal
gearbeitet haben, oder das sie gut kennen. Hier ein Beispiel.

\begin{itemize}
\tightlist
\item
  \emph{Prompt \#3}: \emph{Ich denke über Voss Automotive nach, die
  folgende Produkte herstellen: innovative Leitungs-und
  Verbindungssysteme, die überall auf der Welt in Pkw und Nutzfahrzeugen
  sowie Land- und Baumaschinen eingesetzt werden. Unser Produktportfolio
  umfasst dabei einbaufertige Leitungsmodule mit Rohren, Schläuchen,
  Verbindungselementen, Ventilen und Sensoren. Zur Verbindungstechnik
  gehören Stecksysteme, Verschraubungen, Mehrfachkupplungen und
  Verteiler.}
\item
  \emph{Prompt \#4}: \emph{Erstelle einen Zeitplan als Tabelle mit
  Aufwandsschätzungen für 3 Personen in 4 Wochen.}
\item
  \emph{Prompt \#5}: \emph{Mehr Details bitte: Erstelle Unteraufgaben
  für die jeweiligen Aufgabenpakete, jeweils auch wieder mit
  Aufwandsschätzungen.}
\end{itemize}

Die Studierenden sollen den Projektplan dann weiter verbessern und
diskutieren. Erweiternd können sie auch z.B. Projektrisiken, Indikatoren
und Gegenmaßnahmen und Szenarien erheben und diskutieren.

\section{Wie prüfen wir jetzt? Jenseits der Homework
Apocalypse}\label{wie-pruxfcfen-wir-jetzt-jenseits-der-homework-apocalypse}

Jenseits der vielen produktiven Anwendungen besteht die Gefahr, dass
Studierende wichtige Teile des Denkprozesses an Sprachmodelle delegieren
(Lee et al., 2025). Klassische „Hausaufgaben`` wie
\textbf{Seminararbeiten, Gruppenprojekte und Abschlussarbeiten drohen
entwertet zu werden}. Ohne Anpassung der Aufgabenstellung werden die
Aufgaben potenziell sinnlos, da Studierende etwa Aufsätze oder
Reflexionsaufgaben einfach von Chat GPT schreiben und einreichen.
Interviews mit Studierenden und Nutzungsstudien zeigen, dass diese
Gefahr akut ist. Wie wir in der umfassenden empirische Nutzungsstudie
von Handa et al. (2025-04-08, 2025) sehen, nutzen Studierende
Sprachmodelle gerade zur Schreibunterstützung intensiv und häufig. Das
New York Magazine betitelt eine aktuelle Recherche mit „\textbf{Everyone
is cheating their way through college}'', auf der Grundlage einer
Vielzahl von Interviews mit desillusionierten Studierenden und Lehrenden
(Walsh, 2025). Der o.g. Artikel der Fachzeitschrift Nature (s. Tabelle
4) skizziert ebenfalls basierend auf Interviews ein breites Spektrum an
aktiver Nutzung im höheren Bildungsbereich (Heidt, 2025).

Schon 2023 kündigte der Wharton Professor Mollick die „Homework
Apocalypse`` an (Mollick, 2023). Dabei geht es Mollick weniger um das
Tricksen mit den neuen technischen Möglichkeiten („Cheating was already
common in schools``), sondern mehr um die \textbf{empfundene
Sinnlosigkeit von klassischen Hausaufgaben}. „Students will want to
understand why they are doing assignments that seem obsolete thanks to
AI.``. Wer gibt noch reine Rechenübungen auf, wenn alle Taschenrechner
haben? Wie kann Eigen- und Fremdleistung unter diesen neuen technischen
Bedingungen getrennt werden? Wie können auch jetzt noch Anreize für
Studierende gesetzt werden, Texte noch selbst zu lesen und Sätze noch
selbst zu formulieren?

\begin{figure}

\centering{

\pandocbounded{\includegraphics[keepaspectratio]{images/script05-01.png}}

}

\caption{\label{fig-interaction-types}Abbildung 15: Etwa gleichverteilt:
Vier Arten der Interaktion von Studierenden mit Sprachmodellen. Quelle:
Handa et al. (2025-04-08, 2025)}

\end{figure}%

Eine Unterscheidung der empirischen Anthropic-Studie von Studierenden
Interaktionen mit Sprachmodellen ist dabei hilfreich, um das Problem
einzuordnen (Handa et al., 2025-04-08, 2025): Hier werden vier Arten von
LLM-Nutzung unterschieden, je nachdem, ob ein \textbf{Problem} gelöst,
oder ein \textbf{Ergebnis generiert} werden soll und je nachdem, ob dies
\textbf{direkt oder interaktiv} erfolgt. Kollaborative Nutzungsformen
(Typ 3 und 4) sind dabei für den Lernerfolg eher hilfreich, während das
direkte Bereitstellen von Problemlösungen oder Texten aufgrund
mangelnder Beschäftigung der Studierenden mit den Problemen und
Materialien für Hausarbeiten eher hinderlich sein könnte (anders als für
die Vorbereitung von kontrollierten Tests wie Klausuren). Studierende
werden so eher in eine passive Rolle gedrängt und es fehlen die
erwünschten Schwierigkeiten (desirable difficulties, (Roediger \&
Karpicke, 2006)), das fragebasierte Durchkauen und Hin- und
Herüberlegen, das die Lernforschung als Wichtig für langfristiges
Behalten ansieht (Roediger \& Pyc, 2012).

Grob gesagt wollen wir also \textbf{kollaborative Interaktion und
Hilfestellung fördern und einfaches Übernehmen bereitgestellter Lösungen
verhindern}. Wie können wir dafür die Hausarbeiten anpassen? Im
Folgenden werden einige Empfehlungen zusammengefasst. Der
Vier-Säulen-Ansatz nach Gmeiner bietet Orientierung. Er unterscheidet
vier Gegenmaßnahmen für das Prüfen unter KI-Bedingungen: Mündlichkeit,
Prozessorientierung, Kontextualisierung sowie Kollaboration (Gmeiner,
2025).

\begin{figure}

\centering{

\pandocbounded{\includegraphics[keepaspectratio]{images/script05-02.png}}

}

\caption{\label{fig-gmeiner-pillars}Abbildung 16: KI-resistente
Aufgabenstellungen -- 4 Säulen nach Gmeiner (2025)}

\end{figure}%

\subsection{Mündlichkeit}\label{muxfcndlichkeit}

\textbf{Mündlichkeit} stärkt Verständnis, Transfer und Autorschaft.
Disputation, Präsentationen mit strukturiertem Q\&A und gezielte
Kolloquien machen eigene Entscheidungen sichtbar. So verlieren
generische KI-Texte an Wert. Leitfäden empfehlen diese Formate
ausdrücklich als Ergänzung zu schriftlichen Arbeiten. Detektionsscores
dienen nicht als Beweis, sondern höchstens als Anlass zur Klärung (QAA,
n.~d.; Jisc, n.~d.). Die University of Melbourne verweist auf
skalierbare, mündliche Validierungen. Die folgende Übersicht zeigt
typische Formate der mündlichen Prüfung.

\begin{figure}

\centering{

\pandocbounded{\includegraphics[keepaspectratio]{images/script05-03.png}}

}

\caption{\label{fig-oral-exams}Abbildung 17: Vergleich mündlicher
Prüfungsformen (Ward et al. (2024))}

\end{figure}%

Hier sollen exemplarisch einzelne mündliche Prüfungsformate beschrieben
werden, die Lehrende nutzen können.

Das erste Format ist das \textbf{Kurzkolloquium} („Viva Voce Exam`` in
der Abbildung). Ziel ist der Nachweis von Verständnis und Autorschaft.
Hier wird die schriftliche Arbeit vom Leistungsnachweis getrennt
(Gmeiner, 2025) und die Lernenden müssen ihre Entscheidungen in der
schriftlichen Arbeit erläutern und verteidigen. Die Studierenden reichen
ihre schriftliche Arbeit ein, die auch mit KI-Unterstützung erstellt
werden darf und führen ein dann ein etwa zehnminütiges Gespräch über die
Arbeit. Die Prüfenden wählen zum Beispiel zwei Kernentscheidungen zur
weiteren Erläuterung aus: Datenaufbereitung und Argumentation. Die
Studierenden erklären Vorgehen, Alternativen und Grenzen. Es folgt ein
kurzes Transfer-Szenario: „Was würden Sie ändern, wenn\ldots?{}``
Bewertet werden Klarheit, Begründung, Umgang mit Unsicherheit und
Konsistenz zur Schriftfassung. KI-Regeln: KI-Nutzung wird offengelegt;
Antworten sind persönlich und ohne Hilfsmittel. Skalierung gelingt mit
standardisierten Leitfragen, Doppelprüfungen im Stichprobenprinzip und
Aufzeichnung für Zweitbewertungen. Dieses Format eignet sich besonders
für die Prüfung von Abschlussarbeiten und lässt sich leicht auch auf
Seminararbeiten übertragen. Ähnlich wie auch für das folgende Format
müssen hierfür initial Bewertungsmatrizen erstellt werden, potentielle
\textbf{Herausforderungen} sind situativer \textbf{Stress} und Aspekte
von \textbf{Validität} (Form vs.~Inhalt, einfache vs.~schwere Fragen,
mündliche vs.~schriftliche Ausdrucksfähigkeit), \textbf{Reliabilität}
(Rating-Unterschiede bei verschiedenen Nachfragen und Bewertenden,
verschiedenen Szenarien usw.) und \textbf{Fairness} (z.B.
Sprachfähigkeiten, Vorwissen). Vorteile sind die Reaktivität und die
Möglichkeit, durch vertiefende Nachfragen Hintergrundwissen und
Begründungen abzufragen (Akimov \& Malin, 2020, S.31; Kearney, 2019).

Ein ähnliches Format, aber mit anderem Fokus ist die \textbf{interaktive
mündliche Prüfung} (interactive oral assessment, IO). Hier erhalten die
Studierenden ein praxisnahes Szenario, das sie in Interaktion mit den
Prüfenden analysieren und bearbeiten müssen (Ward et al., 2024).
Gestaltet werden IOs als offene, nicht im Detailablauf vorgegebene
Gespräche in realitätsnahen Szenarien, geführt zwischen Studierenden und
Prüfenden (oder zwischen Studierenden). So wird etwa gefordert, eine
Situation oder eine Fallstudie mit Bezug auf das erlesene Vorwissen zu
analysieren. Bewertet wird die Interaktion durch unterlegt durch präzise
Rubriken (die auch gemeinsam mit den Studierenden entwickelt werden
können (Ní~Bheoláin et al., 2020)), Beispielaufnahmen zur Vorbereitung
und formative Einbettung über das Semester. Beispiele für die Einbettung
umfassen etwa, dass Studierende die Rolle von Interviewten in einer
Talkshow einnehmen, oder im Duo ihre Erkenntnisse von einer
Konferenzteilnahme erläutern müssen. International wird diese
Prüfungsform durchaus in sehr großen Kohorten eingesetzt, von
Erstsemester-Kursen mit ca. 200 bis zu 800 Studierenden, mit 4 bis 10
Prüfenden (https://sway.cloud.microsoft/yQ2s0Bm3ILkWtGll). Es gibt eine
Reihe detaillierter \textbf{Leitfäden zur Umsetzung solcher
Szenario-Prüfungen} mit Aufnahmen von Beispielprüfungen und den
Bewertungsrubriken
(https://www.dcu.ie/sites/default/files/inline-files/interactive-oral-io-user-guide\_0.pdf
, siehe speziell die Übersicht der Ressourcen auf S.11).

\begin{figure}

\centering{

\pandocbounded{\includegraphics[keepaspectratio]{images/script05-04.png}}

}

\caption{\label{fig-large-cohorts}Abbildung 18: Mündlich prüfen geht
auch in großen Kohorten -- Beispiele von verschiedenen Universitäten}

\end{figure}%

\begin{figure}

\centering{

\pandocbounded{\includegraphics[keepaspectratio]{images/script05-05.png}}

}

\caption{\label{fig-pedagogy-scenarios}Abbildung 19: Drei Szenarien für
eine mündliche Prüfung in Pädagogik}

\end{figure}%

Ein drittes Format ist die \textbf{Posterpräsentation} mit
strukturiertem Q\&A. Die Studierenden erstellen ein Forschungs- oder
Praxisposter und präsentieren für fünf Minuten. Danach folgen gezielte
Fragen zu Methode, Evidenz und Limitationen. Artefakte sind Poster, ein
einseitiges Handout und ein Frageprotokoll. Bewertet wird die
Evidenzführung, Passung von Methode und Frage sowie die Qualität der
Antworten. KI darf für Layout und Sprachpolitur helfen, nicht für
Inhalt. Offenlegung ist Pflicht. Große Gruppen lassen sich mit
parallelen „Poster-Sessions`` und festen Zeitslots prüfen.

Für \textbf{Abschlussarbeiten} kann diese Ausweitung der mündlichen
Prüfungskomponente so operationalisiert werden, dass die Gewichtung des
Kolloquiums erhöht wird, bzw. ein zweites Kolloquium hinzugefügt wird
(um die Belastung der mündlichen Prüfung zu verteilen), in dem die
Studierenden ca. 1 Monat nach dem Beginn der Abschlussarbeit mündlich
den Stand der Forschung zum Thema darstellen und die Forschungslücke
begründen müssen. Ein aktueller Entwurf an der TH Köln hierfür sieht so
aus: * Kolloquium 1: Stand der Forschung und resultierende
Forschungsfragen (3 ECTS) * Schriftliche Arbeit (8 ECTS) * Kolloquium 2:
Ergebnis der Abschlussarbeit (4 ECTS) (Früher: Schriftliche Arbeit = 12
ECTS, Kolloquium = 3 ECTS).

\subsection{Prozessorientierung}\label{prozessorientierung}

\textbf{Prozessorientierung} rückt den Weg zum Ergebnis in den
Mittelpunkt und liefert über die stärkere Teilhabe der Prüfenden am
Erstellungsprozess Evidenz für Autorschaft und verantwortliche
KI-Nutzung. Insofern empfehlen die meisten Ratgeber, das Gewicht vom
Produkt auf den Prozess zu verlagern. Ein Ratgeber der Melbourne
University empfiehlt ausdrücklich, „vom Produkt zum Prozess`` zu
wechseln, Prozess-Notizbücher und Reflexionen einzubauen und mit
Umgebungen wie Cadmus digitale Prozess-Spuren zu erfassen (Mulder et
al., 2023). Eine Studie von Hanover Research fordert gestaffelte Abgaben
über die Zeit mit intensiver, iterativer Rückmeldung und betont, dass
die Sichtbarmachung individueller und kollaborativer Arbeitsprozesse
KI-Nutzung unattraktiv macht (Hanover Research, 2024). Empfehlungen der
Monash University konkretisieren dies: Prozessbewertungen, verbundene
Aufgaben und Einbindung der Prüfenden in den Entstehungsprozess (Monash
University, 2025). Gmeiner operationalisiert Prozessfokus zudem durch
transparente KI-Nutzungsdokumentation mit Prompt-/Output-Belegen und
reflektierter Einbettung in die Eigenleistung (Gmeiner, 2025).

\begin{figure}

\centering{

\pandocbounded{\includegraphics[keepaspectratio]{images/script05-06.png}}

}

\caption{\label{fig-task-difficulty}Abbildung 20: Abhilfe durch
Interaktion oder engere Prozessbetreuung: Aufgabentypen nach der
Schwierigkeit, durch KI repliziert zu werden (Hanover Research (2024))}

\end{figure}%

Ein zentrales Format ist das \textbf{Prozessjournal mit Audit-Trail}:
Studierende dokumentieren Suche, Auswahl, Analyse, Entscheidungen und
Revisionen fortlaufend; ein Versionsverlauf in Overleaf oder Git macht
Änderungen nachvollziehbar. Abgegeben werden Journal, Query-Protokolle,
Daten-/Code-Paket und Endprodukt. Bewertet werden Nachvollziehbarkeit,
Qualität der Entscheidungen, Reproduzierbarkeit und eine reflektierte
Darstellung der KI-Nutzung (Tool, Version, Prompts, Zweck, Umfang,
Korrekturen). Detektoren entfallen; der dokumentierte Prozess bildet die
Hauptgrundlage der Beurteilung.

Als zweites Format bietet sich die \textbf{gestaffelte Hausarbeit} an:
Outline, Annotated Bibliography, Methoden-Memo, Rohanalyse, Draft und
Final werden über das Semester verteilt, jeweils mit Feedback und klar
getrennten Prozess- und Produktpunkten in der Rubrik. KI kann bei
Ideenfindung und Sprachpolitur helfen, nicht bei Theoriebildung oder
Ergebnissen; Nutzung und kritische Einordnung sind offenzulegen. In
großen Kohorten tragen Peer-Reviews nach Rubrik und stichprobenhafte
Dozierenden-Checks zur Skalierung bei.

\subsection{Kontextualisierung und empirischer
Bezug}\label{kontextualisierung-und-empirischer-bezug}

\textbf{Kontextualisierung und Empirie} binden Leistung an reale Daten,
Orte und Rollen und entwerten generische KI-Outputs. Die Leitfäden
empfehlen realweltliche, lokal verankerte, persönlich bezogene Aufgaben.
Melbourne CSHE listet explizit „authentische, kontextspezifische oder
persönliche`` Aufgaben -- etwa Analysen weniger bekannter lokaler
Objekte, Bezüge zu persönlicher Erfahrung oder Aufgaben, die genuine
Berufsprodukte erzeugen (Mulder et al., 2023). Monash rät, Essayaufgaben
so zu verändern, dass personalisierte Anwendung und Kontextualisierung
zwingend sind; außerdem werden multimodale Artefakte als KI-resistenter
eingestuft (Monash University, 2025). Gmeiner präzisiert diese Logik:
biografisches Lernen, Aufgaben an außerschulischen Lernorten oder
tagesaktuelle Kontexte machen die Aufgabe „un-promptbar``, weil sie
persönliche, physische oder nicht-öffentliche Informationen, sinnliche
Beobachtung und Gegenwartsbezug erfordern (Gmeiner, 2025).

\textbf{Selbst erhobene Empirie zählt}, reine Literaturstudien oder
theoretische Ausarbeitungen sind zu vermeiden. Interviews,
Prozessanalysen, der Bau eines Prototypen oder sonstige Erhebungen von
Primärdaten verlangen, dass Studierende einen passenden Fall auswählen,
Daten erheben oder kuratieren, diese methodengerecht analysieren und
eine Entscheidungsvorlage erstellen. Abzugeben sind Datensatz,
Methodenprotokoll, Analyse-Notebook und eine kurze Empfehlung; bewertet
werden Kontextpassung, Datenqualität, methodische Angemessenheit und die
Tragfähigkeit der Handlungsempfehlung. KI darf strukturieren, nicht aber
Evidenz ersetzen. Alternativ können Replikations- und
Verifikationsaufgaben genutzt werden: Studierende replizieren eine
veröffentlichte Analyse, dokumentieren Abweichungen und prüfen
Robustheit mit alternativen Spezifikationen. Artefakte sind ein
vollständiges Repro-Paket, ein Abweichungsprotokoll und ein Kurzbericht,
der klar ausweist, was trägt und was nicht. KI kann Code-Snippets
vorschlagen, doch jede Zeile wird verstanden, kommentiert und getestet.
Offenlegung der Tool-Nutzung bleibt Pflicht. Automatisierte Checks und
präzise Rubriken halten den Korrekturaufwand im Rahmen.

Für Abschlussarbeiten kann dies so operationalisiert werden, dass reine
Literatur- oder Theoriearbeiten ohne empirischen Bezug vom
Prüfungsausschuss zu genehmigen sind.

\subsection{Kollaboration und
Kreation}\label{kollaboration-und-kreation}

\textbf{Kollaboration und Kreation} prüfen die soziale, evaluative und
kreative Dimension des Lernens und machen Aushandlung und Revision
sichtbar. Die Leitfäden schlagen in diesem Kontext etwa In-Class- und
Gruppenaufgaben, Peer-/Selbstbeurteilung und gestufte Projekte vor.
Melbourne CSHE zeigt in mehreren Fallbeispielen, wie verschachtelte
Aufgaben mit Gruppen-Literaturarbeit, Projektplänen, Peer-Review und
Präsentationen kombiniert werden. Diese Designs stärken
Prozess-Transparenz, evaluative Urteilskraft und erschweren
KI-Missbrauch (Mulder et al., 2023). Hanover Research betont ähnlich
Gruppenarbeiten, In-Class-Aktivitäten und Aufgaben, die die Nutzung von
KI explizit erlauben, aber kritisch auswerten lassen -- also Kreation
plus Metareflexion (Hanover Research, 2024).

\textbf{Wie kann so etwas aussehen?} Ein peer-reviewtes
Multimedia-Projekt etwa verlangt, dass kleine Teams ein konkretes
Produkt -- Podcast, Video oder Infografik -- für ein definiertes
Publikum erstellen. Der Prozess umfasst Briefing, Drehbuch,
Quellenkurzprüfungen, Prototyp, Peer-Feedback und Finalisierung.
Bewertet werden Evidenzbasis, Storyline, Zielgruppenpassung,
Feedbackqualität und die Umsetzung der Rückmeldungen; neben dem Produkt
liefern Teams Quellenlisten, Peer-Feedback-Protokolle und individuelle
Reflexionen. Alternativ können Rollen- oder Planspiele erstellt oder
bearbeitet und reflektiert werden (Gmeiner, 2025). KI kann als
Ideengeber dienen, doch Entscheidungen und Quellenhoheit verbleiben beim
Team; kurze Nachgespräche sichern Autorschaft ab.

Als Abschlussformat eignet sich ein Team-Capstone mit getrennter Team-
und Individualnote: Das Team liefert ein belastbares Artefakt -- etwa
einen Prototyp, eine Konzeptstudie oder einen Policy-Brief mit Daten --,
während jede Person einen individuellen Methoden-Anhang und eine
Reflexion zum eigenen Beitrag und zur KI-Nutzung abgibt. Bewertet werden
Teamprodukt, individueller methodischer Beitrag und die Qualität der
Reflexion; klare KI-Regeln fordern Offenlegung, Bias-Prüfung und
Quellenverifikation. Milestone-Boards, strukturierte Peer-Assessments
und stichprobenhafte mündliche Abfrage pro Team sichern Skalierbarkeit
und Integrität.

Kombiniert man die vier Säulen, entsteht eine Vielzahl von Optionen für
ein konsistentes, skalierbares Prüfungsdesign, das auf Transparenz,
Prozessnähe und reale Anwendung setzt. Mündliche Elemente sichern
Autorschaft und Transfer, prozessorientierte Formate liefern
nachvollziehbare Evidenz, kontextgebundene Aufgaben prüfen Verständnis
unter realen Bedingungen, und kollaborative Produkte stärken
Urteilskraft, Feedbackkultur und Kreativität. Klare Richtlinien,
Offenlegung und belastbare Rubriken tragen das Konstrukt. KI-Detektoren
werden überflüssig, weil die Beweise im Prozess liegen und Prüfende
enger an diesem Prozess teilnehmen und in den vorgestellten
Prüfungsformen interaktiv nachfragen können. Dies alles aufzusetzen
bedeutet durchaus hohe Initialaufwände und die neuen Prüfungsformen
müssen evaluiert werden, um bekannte Probleme etwa des Prüfens in
direkter Interaktion (Validität, Reliabilität, Fairness, s.o.)
einzudämmen (Akimov \& Malin, 2020). Positiv dabei: \textbf{Es gibt
schon viele Vorlagen, auf die man aufbauen kann} und durch diese
Anstrengungen bleiben Integrität und Qualität der Prüfungen gewahrt --
die oben genannte \textbf{Furcht vor Betrug und Sinnlosigkeit der
Prüfungen wird eingedämmt}, ohne dass auf reines Klausurlernen
zurückgefallen werden muss, während Studierende lernen, KI
verantwortlich, nachvollziehbar und wirksam einzusetzen.

\section{Richtlinien zur KI-Nutzung - welche Handreichungen geben
Hochschulen und was wird
empfohlen?}\label{richtlinien-zur-ki-nutzung---welche-handreichungen-geben-hochschulen-und-was-wird-empfohlen}

\subsection{Übersicht: Was regeln aktuelle
Richtlinien?}\label{uxfcbersicht-was-regeln-aktuelle-richtlinien}

Wie reagieren Hochschulen auf die Chancen und Herausforderungen von LLM?
Eine Übersichtsstudie von An et al. (2025) untersucht die
\textbf{Richtlinien der Top 50 US Hochschulen zur Nutzung von LLM}.
Mittels Topic Modeling identifizieren sie vier zentrale Themenfelder:
die Integration von LLM in Lehre und Prüfungen, die Nutzung in visuellen
und interaktiven Medien, Fragen der Sicherheit und Ethik sowie die
Wahrung akademischer Integrität. Die Sentimentanalyse zeigt eine
insgesamt positive Haltung gegenüber LLM, insbesondere in Richtlinien
für Lehrende und Verwaltungspersonal. Studierendenrichtlinien sind
hingegen zurückhaltender und stärker auf Einschränkungen fokussiert. Die
Analyse differenziert die Inhalte nach Zielgruppen: Während Lehrende vor
allem Unterstützung für Kursdesign und Prüfungsformate erhalten, stehen
bei Studierenden Regelungen zur Integrität im Vordergrund. Forschende
und Verwaltungspersonal werden bislang weniger berücksichtigt, obwohl
sie ebenfalls spezifische Herausforderungen und Potenziale im Umgang mit
LLM aufweisen. Die Autor:innen empfehlen daher eine stärkere
Differenzierung und kontinuierliche Weiterentwicklung der Richtlinien,
den Verzicht auf unzuverlässige Detektionstools sowie eine
institutionenübergreifende Reflexion über ethische, rechtliche und
didaktische Implikationen.

\textbf{Speziell deutsche Leitlinien an 27 Hochschulen} untersuchte das
Hochschulforum Digitalisierung im Jahr 2024 (Tobor, 2024), ein Update im
Februar 2025 ergänzt neuere Entwicklungen (Tobor, 2025). Die Analyse
umfasst hochschulweiten Leitlinien deutscher Universitäten zum Umgang
mit generativer KI. Dabei hebt Tobor eine Reihe bewährter Praktiken
hervor, die sich in mehreren Leitfäden wiederfinden (Für konkrete
Beispiele siehe Appendix 2: Beispiele für KI-Richtlinien):

\begin{itemize}
\tightlist
\item
  Ein zentrales Element ist die \textbf{Anpassung der
  Eigenständigkeitserklärung} in schriftlichen Prüfungen ohne Aufsicht.
  Viele Hochschulen -- exemplarisch die Vorlage der Hochschule RheinMain
  -- fordern darin von Studierenden eine explizite Erklärung, ob und in
  welcher Weise KI-Tools verwendet wurden. Diese Erklärungen dienen der
  Transparenz und ermöglichen Lehrenden, KI-Nutzung regelkonform
  einzuordnen.
\item
  Im Umgang mit \textbf{Verdachtsfällen unzulässiger KI-Nutzung} betonen
  viele Leitlinien die Grenzen technischer Erkennung. Tools wie GPTZero
  gelten als unzuverlässig. Stattdessen wird -- wie im Leitfaden der
  Universität Vechta -- ein \textbf{multifaktorielles Vorgehen}
  empfohlen, das Indikatoren wie nicht reale Quellen oder auffällige
  Formulierungen einbezieht. Bestätigt sich der Verdacht, erfolgt ein
  \textbf{Klärungsgespräch}, um das Verständnis der Studierenden für
  ihre Arbeit zu überprüfen.
\item
  Im Bereich \textbf{Urheberrecht} wird festgehalten, dass KI-Systeme
  wie ChatGPT derzeit keine Urheber im juristischen Sinne sind. Ihre
  Inhalte stellen daher nicht automatisch ein Plagiat dar, können aber
  Rechte Dritter verletzen. Die Verantwortung für eine rechtskonforme
  Nutzung liegt bei den Studierenden -- klare gesetzliche Regelungen
  stehen noch aus.
\item
  Kritisch sehen viele Hochschulen die \textbf{Verwendung von KI zur
  automatisierten Bewertung} von Prüfungsleistungen. Diese widerspricht
  in der Regel Prüfungsordnungen, die eine begründete Bewertung durch
  eine prüfende Person verlangen. Zudem wird das Hochladen studentischer
  Arbeiten in KI-Systeme als urheberrechtlich bedenklich eingestuft.
\item
  Schließlich fordern zahlreiche Leitlinien eine \textbf{didaktische
  Weiterentwicklung von Prüfungsformaten}. Empfehlungen reichen von
  stärker reflexionsorientierten Aufgaben über Zwischenfeedback und
  methodische Transparenz bis hin zu ergänzenden mündlichen Prüfungen.
  Ziel ist es, den Kompetenznachweis trotz verfügbarer KI-Tools
  aussagekräftig zu gestalten. Dabei sollte auch der Umgang mit KI
  selbst -- inklusive Prompt-Gestaltung oder kritischer Reflexion -- zum
  Prüfungsgegenstand werden. Lehrende werden ermutigt, den Einsatz von
  KI gemeinsam mit den Studierenden zu reflektieren und klare Regeln im
  Kurs zu kommunizieren.
\end{itemize}

Im Update von 2025 stellt Tobor auch kritisch die \textbf{thematische
Zersplitterung} der verschiedenen Handreichungen fest: Die Richtlinien
versuchen, eine Vielzahl von Einzelthemen für eine Vielzahl von Gruppen
zu integrieren, speziell regulatorische und didaktische. Hinzu kommen
Anforderungen zur Risikoaufklärung über Themen wie Halluzinationen,
Vorurteile von LLM in den Ergebnissen und Ressourcenverbrauch. Die
europäische KI-Verordnung (KI-VO) verschärft die Anforderungen an
Hochschulen, insbesondere im Hinblick auf KI-Kompetenzen und
Risikoeinstufungen bei Prüfungen. Positiv werden \textbf{integrierende
Formate wie ``Landing Pages``} genannt, etwa der KI-Hub der Universität
Vechta (https://www.uni-vechta.de/ki-hub). Ein solcher zentraler
Startpunkt kann allgemeine und spezielle Themen verbinden und -- bei
guter Kuratierung -- helfen, Komplexität zu reduzieren.

\subsection{Allgemeine Empfehlungen zu
Richtlinien}\label{allgemeine-empfehlungen-zu-richtlinien}

An et al. (2025) plädieren für ausgewogenere, zielgruppenspezifische
Leitlinien, die sowohl regulatorische Klarheit als auch didaktische
Impulse bieten -- insbesondere für Studierende, deren Perspektive
bislang zu wenig berücksichtigt wird. Was für didaktische und
regulatorische Aspekte für Lehrende und Studierende werden hier
festgelegt?

Für \textbf{Lehrende} stehen didaktische Empfehlungen im Vordergrund,
die auf eine bewusste Integration generativer KI in die Hochschullehre
zielen. In 94\,\% der untersuchten Richtlinien werden konkrete Hinweise
gegeben, wie LLM in \textbf{Kursdesign, Aufgabenstellungen und
Prüfungsformate} eingebunden werden kann. Lehrende werden ermutigt, im
Syllabus klar zu definieren, ob und wie der Einsatz von KI erlaubt ist
-- etwa durch gestufte Erlaubnisformen (verboten, erlaubt mit
Dokumentation, ausdrücklich gewünscht). Zudem wird empfohlen,
Prüfungsformate so umzugestalten, dass sie weniger anfällig für
unreflektierte KI-Nutzung sind, z. B. durch individuelle Reflexionen,
Gruppenarbeit oder mündliche Komponenten. Regulatorisch wird betont,
dass die Verantwortung für die Formulierung und Durchsetzung dieser
Regeln bei den Lehrenden liegt, jedoch unterstützt durch hochschulweite
Orientierungshilfen. KI-Detektionstools wie Turnitin oder GPTZero werden
hingegen kritisch gesehen: Viele Hochschulen raten von deren Einsatz ab,
da ihre Ergebnisse unzuverlässig seien und leicht zu
Fehlinterpretationen führen können.

Für \textbf{Studierende} betonen die Richtlinien vor allem
regulatorische Aspekte im Sinne der \textbf{akademischen Integrität}.
Häufig wird darauf hingewiesen, dass LLM nicht uneingeschränkt
eingesetzt werden darf, und dass ein nicht genehmigter Einsatz als
Täuschungsversuch gewertet werden kann. Die Verantwortung zur Klärung,
ob LLM zulässig ist, wird den Studierenden zugeschrieben -- sie sollen
aktiv Rücksprache mit Lehrenden halten. Didaktisch werden Studierende
allerdings meist weniger unterstützt: Nur wenige Richtlinien bieten
Anleitungen zur kompetenten Nutzung von LLM oder reflektieren über
sinnvolle Lernstrategien im Umgang mit KI. Eine Ausnahme bilden
vereinzelte Hinweise zur Förderung von \textbf{AI Literacy}, etwa zur
kritischen Bewertung von KI-generierten Texten oder zur
Transparenzpflicht bei der Nutzung von LLM in Hausarbeiten. Insgesamt
dominiert jedoch eine \textbf{restriktive und kontrollierende
Perspektive}, die stärker auf Vermeidung von Fehlverhalten als auf
befähigende Lernangebote setzt.

Die deutsche Untersuchung von Tobor (2025) betont, dass die Wirksamkeit
solcher Leitlinien maßgeblich davon abhängt, ob sie \textbf{bekannt
gemacht, kontinuierlich diskutiert und weiterentwickelt} werden. Zentral
ist es, die Leitlinien User-adäquat zu gestalten und bekannt zu machen.
(Auch hier begegnen uns implizit wieder die zentralen Kategorien
Nutzerfreundlichkeit und wahrgenommene Nützlichkeit des Technology
Acceptance Models.) Tobor warnt davor, Leitlinien als bloße
Beruhigungsmittel zu betrachten, und fordert stattdessen eine
\textbf{dialogische, ko-kreative Weiterentwicklung} -- etwa durch
Beteiligung von Studierenden, verbundweite Zusammenarbeit und neue
Formate wie Prompt-Battles. Leitlinien sollten als lebendige Rahmenwerke
verstanden werden, die zur aktiven Gestaltung des KI-bedingten Wandels
in Studium und Lehre beitragen.

\textbf{Wie sehen solche Richtlinien aus?} Konkrete Formulierungen und
Links hierzu finden Sie im Appendix 2: Beispiele für KI-Richtlinien.

\section{Wie können Studierende die Nutzung von LLM dokumentieren?
Stichworte, nach Arbeitsphase, nach Werkzeug oder als
Reflexionstagebuch}\label{wie-kuxf6nnen-studierende-die-nutzung-von-llm-dokumentieren-stichworte-nach-arbeitsphase-nach-werkzeug-oder-als-reflexionstagebuch}

\textbf{Frühe Handreichungen} zur Dokumentation von LLM in
Studierendenarbeiten waren noch sehr allgemein formuliert und bestanden
etwa darauf, dass \textbf{jegliche Nutzung im Schreibprozess} genau
protokolliert würde. Bei täglicher und stark integrierter Nutzung ist
das etwa so sinnvoll, wie die Forderung, jegliche Internetnutzung in
einem Tagebuch zu erfassen. Sinnlose Forderungen führen schnell dazu,
dass die dahinter stehende Forderung nach prinzipieller
Nachvollziehbarkeit des Forschungsvorgehens entwertet und
Umgehungshandlungen normalisiert werden.

\textbf{Neuere Empfehlungen} der Hochschulen sind hier deutlich
realistischer: So bietet etwa eine Handreichung von niedersächsischen
Hochschulen eine gute \textbf{Reihe von Optionen}, die von einer
einfachen Stichpunktliste („elicit.com zur Literaturrecherche,
perplexity.ai zur Internetrecherche, gamma.app zur
Präsentationserstellung, stablediffusionweb.com zur Bildgeneration``)
bis zu detaillierten Tagebüchern mit Reflexionshilfen reicht (Baresel et
al., 2024).

Im Folgenden zeigen wir drei weitere Beispiele für Dokumentationen nach
Arbeitsphasen, nach Werkzeugen und in Form eines Reflexionstagebuches
(Baresel et al., 2024).

Die Dokumentation nach \textbf{Arbeitsphasen} (s. Tabelle 8) zielt auf
eine strukturierte Erfassung des KI-Einsatzes entlang typischer
wissenschaftlicher Arbeitsphasen (z.\,B. Themenfindung, Recherche,
Schreiben). Studierende bewerten selbst den Grad der KI-Nutzung (von
„inspirierend`` bis „inhaltsgestaltend``) und dokumentieren Tool,
Einsatzkontext und Wirkung. Ziel ist Transparenz über den konkreten
Einfluss auf das Ergebnis.

Bei der \textbf{werkzeugorientierten} Dokumentation (s. Tabelle 9)
werden in tabellarischer Form die verwendeten Tools (z.\,B. ChatGPT,
DeepL Write) samt Quelle, Zweck, Funktion und Einsatzbereich gelistet.
Diese Variante erleichtert die Nachvollziehbarkeit, gibt aber wenig
Einblick in den Kontext oder den Einfluss der Tools auf den
Arbeitsprozess.

Beim \textbf{Reflexionstagebuch} (s. Tabelle 10) steht die
kontinuierliche, persönliche Auseinandersetzung mit dem eigenen
KI-Einsatz im Vordergrund. Studierende führen während des
Arbeitsprozesses ein Tagebuch, das später in eine prüfungsrelevante
Dokumentation überführt wird. Diese Methode fördert den Aufbau von
\textbf{KI-Literacy} und metakognitiver Kompetenz, ist jedoch
zeitaufwändig und betreuungsintensiv.

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.3333}}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.3333}}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.3333}}@{}}
\caption{Tabelle 8: Beispiel arbeitsphasenorientierte Dokumentation der
LLM Nutzung. Quelle: (Baresel et al. (2024), S.
11)}\label{tbl-doc-phases}\tabularnewline
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
Phase im Arbeitsprozess
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Dokumentation: Eingesetzte Tools, Verwendungszweck, Funktionsweise,
Ergebnis
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Grad der KI-Nutzung
\end{minipage} \\
\midrule\noalign{}
\endfirsthead
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
Phase im Arbeitsprozess
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Dokumentation: Eingesetzte Tools, Verwendungszweck, Funktionsweise,
Ergebnis
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Grad der KI-Nutzung
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
\textbf{Ideenfindung/Strukturierung} & \textbf{Tools}: ChatGPT,
Perplexity\textbf{Zweck}: Brainstorming zu Forschungsfragen,
Gliederungsideen\textbf{Ergebnis}: 5 Themenvorschläge, davon 1
weiterverfolgt & 1 \\
\textbf{Recherche} & \textbf{Tools}: Elicit, Semantic
Scholar\textbf{Zweck}: Suche nach passender Literatur\textbf{Ergebnis}:
Liste mit 15 Quellen, 8 davon verwendet & 2 \\
\textbf{Schreiben/Formulieren} & \textbf{Tools}: DeepL
Write\textbf{Zweck}: Verbesserung des sprachlichen
Ausdrucks\textbf{Ergebnis}: Überarbeitete Einleitung & 3 \\
\textbf{Überarbeitung/Korrektur} & \textbf{Tools}:
Grammarly\textbf{Zweck}: Prüfung auf Grammatik- und
Rechtschreibfehler\textbf{Ergebnis}: Fehlerfreier Text & 2 \\
\end{longtable}

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 8\tabcolsep) * \real{0.2000}}
  >{\raggedright\arraybackslash}p{(\linewidth - 8\tabcolsep) * \real{0.2000}}
  >{\raggedright\arraybackslash}p{(\linewidth - 8\tabcolsep) * \real{0.2000}}
  >{\raggedright\arraybackslash}p{(\linewidth - 8\tabcolsep) * \real{0.2000}}
  >{\raggedright\arraybackslash}p{(\linewidth - 8\tabcolsep) * \real{0.2000}}@{}}
\caption{Tabelle 9: Beispiel werkzeugorientierte Dokumentation der LLM
Nutzung. Quelle: (Baresel et al. (2024), S.
8)}\label{tbl-doc-tools}\tabularnewline
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
Software/Programm/KI-Anwendung
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Link/Quelle
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Verwendungszweck
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Genutzte Funktion
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Nutzungsbeschreibung/Anwendungsbereich
\end{minipage} \\
\midrule\noalign{}
\endfirsthead
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
Software/Programm/KI-Anwendung
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Link/Quelle
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Verwendungszweck
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Genutzte Funktion
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Nutzungsbeschreibung/Anwendungsbereich
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
\textbf{appypie} &
https://www.appypie.com/design/de/infografik/ersteller & Infografiken
zur Erläuterung & Entspricht Verwendungszweck & Infografik für einen
Überblick in der Einleitung, S. 3 \\
\textbf{Claude} & https://claude.ai/new & Assistenz zur Programmierung,
Vorschläge für Gliederung & Chat und Code-Ausgabe & Programmierung des
Auswertungsprogramms, siehe S.13 Erstaufschlag der Gliederung, wurde
überarbeitet \\
\textbf{DeepL Write} & https://www.deepl.com/de/write & Überarbeiten der
Texte & Entspricht Verwendungszweck & Gesamter Text \\
\textbf{DeepL Übersetzer} & https://www.deepl.com/de/translator &
Übersetzung von französischsprachigen Papers & Übersetzung
Französisch--Deutsch & Die Paper Lacroix, 2007 \& Macron, 2020 wurden
übersetzt. \\
\textbf{KiCad²} & https://www.kicad.org/ & Layout der Testplatine & PCB
Layout & Layout der Platine, siehe Abb. 15 S. 20 \\
\textbf{MATLab} & Hochschullizenz & Simulation der Empfängerschaltung &
Simulink & Schaltung xyz auf S. 14 simuliert und optimiert \\
\textbf{MaxQDA} & Hochschullizenz & Auswertung Interviews & MaxQDA und
AI Assist & Kategorienbildung, siehe Kap 4.2 und Anhang C \\
\textbf{Openknowledgemap} & https://openknowledgemaps.org/ & Recherche
des Forschungsfelds & Entspricht Verwendungszweck & Für die Einarbeitung
wurde mit diesem Tool der Zugang zum Forschungsfeld erschlossen. \\
\textbf{SPSS} & Hochschullizenz & Auswertung Daten zur
Gesundheitsversorgung & Hypothesentest mittels xy & Datenauswertung
siehe S. 15 und Anhang S. 77 \\
\textbf{Visual Studio C++} & Hochschullizenz & Programmierung einer
Navigationslösung & Entspricht Verwendungszweck & Programmierung des
zentralen Programms der Arbeit, siehe Kap. 4 \\
\textbf{Whisper (openAI)} & https://openai.com/index/whisper/ &
Transkribieren von Interviews & Transkribieren ohne Übersetzung &
Transkribieren der Interviews, wurden korrigierend überarbeitet. Siehe
Anhang B \\
\end{longtable}

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 12\tabcolsep) * \real{0.1429}}
  >{\raggedright\arraybackslash}p{(\linewidth - 12\tabcolsep) * \real{0.1429}}
  >{\raggedright\arraybackslash}p{(\linewidth - 12\tabcolsep) * \real{0.1429}}
  >{\raggedright\arraybackslash}p{(\linewidth - 12\tabcolsep) * \real{0.1429}}
  >{\raggedright\arraybackslash}p{(\linewidth - 12\tabcolsep) * \real{0.1429}}
  >{\raggedright\arraybackslash}p{(\linewidth - 12\tabcolsep) * \real{0.1429}}
  >{\raggedright\arraybackslash}p{(\linewidth - 12\tabcolsep) * \real{0.1429}}@{}}
\caption{Tabelle 10: Beispiel Reflexionstagebuch zur LLM Nutzung.
Quelle: (Baresel et al. (2024), S.
16)}\label{tbl-doc-reflection}\tabularnewline
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
Datum
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Woran habe ich gearbeitet? (Stichpunkte)
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Welche digitalen Tools habe ich verwendet?
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Notizen zum Einsatz digitaler Tools
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Reflexion
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Beleg/Beispiel
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Grad der Nutzung
\end{minipage} \\
\midrule\noalign{}
\endfirsthead
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
Datum
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Woran habe ich gearbeitet? (Stichpunkte)
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Welche digitalen Tools habe ich verwendet?
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Notizen zum Einsatz digitaler Tools
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Reflexion
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Beleg/Beispiel
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Grad der Nutzung
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
1.9.24 & Themenfindung & ChatGPT 3.5 über Academic Cloud & Versuch,
einige Begriffe zu schärfenFragestellungen vorschlagen lassen &
Hilfreich, um Fachbegriffe zu identifizierenAus den Begriffen mal
Fragestellungen machen lassen. Das traf es aber nicht wirklich. Ich muss
noch weitermachen. & & 12 \\
2.9.24 & Texte lesen & ChatPDF & 2 Texte hochgeladen, geprüft, ob
relevant & Toll, dass ich deutsch fragen kann, auch wenn der Text
englisch/italienisch ist. Entlastet! Macht das Lesen gezielter. Merke
aber auch, dass ich dann den Text nicht mehr ganz lese. & & 2 \\
5.9.24 & Bild generieren & bing.com/create & Illustration für die
Präsentation zum Projekt & Macht Spaß! Ist aber auch aufwändig, genau
das zu prompten, was man haben will. Zeitfresser. & Denken findet in der
Auseinandersetzung von Mensch mit Maschine statt; Künstliche Intelligenz
ist ein Partner des Menschen beim Denken. Helle, motivierende Farben =
07\_Denken-externalisiert\_Utopie\_01.jpeg & 4 \\
10.9.24 & Text bearbeiten & ChatGPT 4.0 über Academic Cloud &
Formulierungsalternativen gesucht & Unentschieden. Manches klingt gut,
aber irgendwie auch nicht. Weiß nicht so recht, was ich davon halten
soll. & 24-09-10\_Chat-Verlauf.docx & 3 \\
\end{longtable}

\section{Beispiele für die Kurs-Integration von
KI}\label{beispiele-fuxfcr-die-kurs-integration-von-ki}

Abschließend wollen wir uns Beispiele ansehen, wie ein Kurs aussehen
könnte, der mit LLM in der Vorbereitung arbeitet und sie in
Übungsaufgaben und die Prüfungsvorbereitung einbindet. Anmerkung: Hier
wird nur die KI-Ergänzung beschrieben, natürlich werden außerdem
Lehrbücher und Fachartikel als Input genutzt.

\textbf{Zeitliche Struktur und Inhalte (Fokus auf den Einsatz von
KI-Tools)}

\textbf{Woche 1--4: Vorbereitung und KI-gestützte Materialerstellung (KI
als „Hiwi``)} * \textbf{Kursvorbereitung mit LLM}: Erstellung und
Anpassung vielfältiger Programmieraufgaben an unterschiedliche
Lernniveaus mithilfe von Large Language Models. * \textbf{DeepResearch}:
Unterstützung bei der Recherche aktueller Trends in der
Programmierdidaktik und relevanter Beispiele, um realitätsnahe
Aufgabenstellungen zu entwickeln. * \textbf{NotebookLM für
Podcast-Episoden}: Aus den erstellten Materialien werden mithilfe von
NotebookLM kurze Podcast-Folgen generiert, die Studierende zur
Einführung in die Kursstruktur, grundlegende Programmierkonzepte und
organisatorische Aspekte anhören können. Dies dient als motivierende,
niederschwellige Form der Wissensvermittlung.

\textbf{Woche 5--8: Vertiefung und individuelle Lernwege (KI als
„Copilot``)} * \textbf{Individuelle Programmieraufgaben}: Die
Studierenden nutzen Google Colab oder ein ähnliches Tool, das
KI-unterstützte Programmierung erlaubt (z.B. DeepNote). Sie lösen damit
gleich am Anfang Anwendungsaufgaben und müssen die Code-Bestandteile in
der Präsenzzeit anderen Gruppen erklären. Die Übungsaufgaben werden
fortlaufend angepasst, indem die Lehrenden zusammen mit einem LLM
bestehende Aufgaben je nach Lernfortschritt der Studierenden variieren
(z.B. mehr Code-Komplexität oder zusätzliche Anwendungsfälle). *
\textbf{Voice Mode für Simulationen}: Interaktive Rollenspiele bzw.
Simulationen (z.B. „Debugging-Dialog``) mit einem KI-Avatar in Voice
Mode. Die Studierenden können live Fragen stellen, sich Lösungswege
erklären lassen oder sich ein Code-Review im Gesprächsformat geben
lassen. * \textbf{DeepResearch}: Zur Vertiefung konkreter Themen (z.B.
Algorithmendesign, Datenstrukturen) recherchieren die Studierenden
mithilfe von DeepResearch in Fachartikeln, Blogposts und
Dokumentationen. Sie lernen, verschiedene Quellen kritisch zu bewerten
und für ihr Projekt nutzbar zu machen.

\textbf{Woche 9--12: Konsolidierung und Prüfungsvorbereitung (KI als
„Lernhilfe``)} * \textbf{NotebookLM zur Zusammenfassung}: Aus den im
Kurs genutzten Lernmaterialien (Skripte, Forumsdiskussionen,
Beispielcode) generiert NotebookLM automatisiert Zusammenfassungen und
kurze Podcasts zu Schlüsselkonzepten. Studierende können diese unterwegs
anhören oder gezielt zur Prüfungsvorbereitung nutzen. * \textbf{LLM für
Übungsfragen}: Auf Grundlage der bisherigen Lernfortschritte generiert
das LLM individuelle Übungsfragen sowie Quizformate zur
Selbstüberprüfung. * \textbf{Voice Mode für Prüfungssimulation}:
Studierende simulieren mündliche Prüfungssituationen oder
Code-Erklärungen über Voice Mode. Dies fördert die Fähigkeit, Inhalte
klar und strukturiert zu präsentieren.

\subsection{Beispielkurs 2: Ergänzung eines Kurses Interkulturelles
Management durch
KI-Unterstützung}\label{beispielkurs-2-erguxe4nzung-eines-kurses-interkulturelles-management-durch-ki-unterstuxfctzung}

\textbf{Woche 1--4: KI als „Hiwi``} * \textbf{Ziel}: Erstellung
vielfältiger, kulturell spezifischer Fallstudien und Szenarien, die als
Diskussions- und Analysegrundlage dienen. * \textbf{LLM für Fallstudien
\& Szenarien}: Die Lehrenden nutzen LLM (z.B. ChatGPT oder andere) zur
Generierung von Fallstudien, die spezifische interkulturelle Kontexte
beleuchten (z.B. Verhandlungen in ostasiatischen vs.~europäischen
Kulturen, Führungsstile in verschiedenen Regionen etc.). *
\textbf{Gegenmaßnahme zur Qualitätssicherung}: Die Ergebnisse werden
stichprobenartig auf Richtigkeit, kulturelle Sensibilität und Relevanz
überprüft. * \textbf{DeepResearch zur Materialrecherche}: Lehrende
recherchieren mithilfe von DeepResearch nach relevanter Literatur,
neuesten Studien und Praxisberichten im Bereich interkulturelles
Management. Die gefundenen Quellen fließen ein in vorbereitende
Leselisten und Hintergrundinformationen für die Studierenden. *
\textbf{NotebookLM für Podcast-Folgen}: Für einen motivierenden Einstieg
ins Thema werden kurze Podcasts (ca. 5--10 Minuten) mithilfe von
NotebookLM erstellt. Themen könnten sein: „Einführung in kulturelle
Dimensionen`` (bspw. nach Hofstede), „Erfolgsbeispiele im
interkulturellen Management``, „Warum interkulturelle Kompetenz immer
wichtiger wird``. Studierende können diese Podcasts vor oder nach den
Präsenz- bzw. Online-Sitzungen anhören, um zentrale Konzepte zu
festigen.

\textbf{Woche 5--8: KI als „Copilot`` für Anwendungsaufgaben} *
\textbf{Ziel}: Entwicklung praxisnaher Simulationen, Rollenspiele und
Fallübungen, um die Studierenden für reale interkulturelle
Managementkonflikte zu sensibilisieren. * \textbf{LLMs für Rollenspiel-
und Simulationsszenarien}: Studierende entwickeln in Kleingruppen
Szenarien (z.B. Konflikte in multikulturellen Teams, Verhandlungen in
internationalen Projekten), wobei sie LLM nutzen, um die Settings,
Dialoge oder Konfliktpunkte zu konkretisieren. Lehrende moderieren den
Prozess und überprüfen die Plausibilität, sodass sichergestellt wird,
dass kulturelle Nuancen realitätsnah abgebildet werden. *
\textbf{Zusätzlicher Einsatz}: Chinesische OpenSource-Sprachmodelle wie
„DeepSeek`` und japanische Sprachmodelle wie „Sakana`` werden gezielt
eingesetzt, um denselben Input zu unterschiedlichen interkulturellen
Situationen zu liefern. Ziel: Die Lehrenden vergleichen die Outputs in
Bezug auf die verwendeten Beispiele, die Fokussierung auf kulturelle
Werte (z.B. Kollektivismus, Hierarchie, Entscheidungsfindung) und die
Tonalität der Texte. Daraus entstehen potenziell Fallstudien mit
Abweichungen, die im Kurs aktiv diskutiert werden. * \textbf{Voice Mode
für interaktive Simulationen}: Mithilfe von Voice Mode können die
Studierenden verschiedene „Akteure`` in einem simulierten
interkulturellen Gespräch übernehmen. Beispielsweise könnte ein
Studierender die Rolle eines japanischen Managers übernehmen, der mit
einem französischen CEO verhandelt -- unterstützt und angeleitet durch
das KI-gestützte Voice Mode. Diese Live-Simulationen fördern besonders
die Aussprache, interkulturelle Kommunikation und nonverbale Signale
(sofern Video/Audio-Komponenten integriert sind). * \textbf{DeepResearch
für Problemlösungsvorschläge}: Nach durchgeführten Simulationen nutzen
die Studierenden DeepResearch, um Best Practices, wissenschaftliche
Artikel und Fallbeispiele zu finden, die ähnliche interkulturelle
Herausforderungen beschreiben. Auf dieser Basis erstellen sie
Handlungsempfehlungen für die Konfliktlösung. Die Lehrenden geben
Feedback, um die studierendenzentrierte Reflexion zu stärken.

\textbf{Woche 9--12: KI als „Lernhilfe``} * \textbf{Ziel}: Effektive
Prüfungsvorbereitung, Vertiefung und Wiederholung zentraler Inhalte im
interkulturellen Management. * \textbf{LLMs für Zusammenfassungen und
Wiederholungsfragen}: Studierende lassen sich von Sprachmodellen kurze
Zusammenfassungen zentraler Konzepte erstellen (z.B. kulturelle
Dimensionen nach Hofstede, Schein, Trompenaars). Die LLMs generieren auf
Basis des bisherigen Kursverlaufs zusätzlich Quiz-Fragen oder
Kurzantwortaufgaben, um das Verständnis zu überprüfen. *
\textbf{Gegenmaßnahme zur Qualitätssicherung}: Die Lehrenden behalten
die Kontrolle über die Endversion der Fragen, um unsinnige oder
unpassende Aufgaben zu erkennen und zu eliminieren. * \textbf{NotebookLM
für Audio-Lerninhalte}: Aus bereits vorhandenen Materialien (Skripte,
Diskussionsergebnisse, Fallstudien) generiert NotebookLM weitere
Podcast-Folgen, in denen Schlüsselkonzepte erläutert oder wiederholt
werden. Studierende können diese Folgen gezielt zur Prüfungsvorbereitung
nutzen und dadurch Zeit- und Ortsunabhängigkeit beim Lernen erlangen. *
\textbf{Voice Mode für Prüfungssimulationen}: Studierende üben z.B.
mündliche Prüfungen oder Präsentationen im interkulturellen Kontext. Sie
können sich von Voice Mode Fragen stellen lassen („Wie würden Sie in
Situation X reagieren?{}``) und ihre Antwort direkt in einer
realistischen Simulation üben. Dies fördert die rhetorische Sicherheit
sowie das spontane Reagieren auf unvorhergesehene Fragen.

\subsection{Vorteile und Chancen der Ergänzung der Lehrmaterialien durch
KI}\label{vorteile-und-chancen-der-erguxe4nzung-der-lehrmaterialien-durch-ki}

\begin{itemize}
\tightlist
\item
  \textbf{Realitätsnahe Lernsituationen}: Durch Voice Mode-Simulationen
  und DeepResearch-gestützte Recherche wirken die Szenarien authentisch
  und praxisrelevant. Studierende lernen, ihre kulturelle Sensibilität
  in unterschiedlichen Rollen aktiv zu trainieren.
\item
  \textbf{Zeit- und Ressourcenersparnis}: Lehrende profitieren von
  teilautomatisierten Prozessen (z.B. Erstellung von Fallstudien,
  Zusammenfassungen, Podcasts). Studierende haben jederzeit Zugriff auf
  zusätzliche Lernressourcen wie Podcasts oder interaktive Übungen.
\item
  \textbf{Adaptives Lernen und Diversität}: LLMs und DeepResearch
  ermöglichen personalisierte Aufgabenstellungen und themenspezifische
  Vertiefungen. Kulturelle Diversität kann in den generierten Szenarien
  leichter abgebildet werden, indem verschiedene Regionen und
  Blickwinkel integriert werden.
\end{itemize}

\subsection{Risiken und
Gegenmaßnahmen}\label{risiken-und-gegenmauxdfnahmen}

\begin{itemize}
\tightlist
\item
  \textbf{Qualität und kulturelle Sensibilität}: \emph{Gegenmaßnahme:}
  Lehrende prüfen alle generierten Inhalte (Text, Podcasts,
  Simulationen) auf kulturelle Stereotype und potenzielle
  Fehlinformationen. Durch Peer-Review unter Studierenden werden
  Vorurteile oder unangemessene Darstellung früh erkannt.
\item
  \textbf{Vertrauenswürdigkeit und akademische Redlichkeit}:
  \emph{Gegenmaßnahme:} Studierende werden darin geschult, die
  KI-generierten Inhalte kritisch zu hinterfragen und zu validieren. Sie
  müssen Quellen nennen und sachlich begründen, wie und warum sie
  bestimmte KI-Ausgaben nutzen.
\item
  \textbf{Datenschutz und ethische Aspekte}: \emph{Gegenmaßnahme:}
  Sensible Informationen werden anonymisiert, Zugriffsrechte klar
  geregelt. Studierende erhalten eine Einführung, wie sie KI-Tools
  sicher und verantwortungsbewusst einsetzen.
\item
  \textbf{Technische Abhängigkeit}: \emph{Gegenmaßnahme:}
  Lehrmaterialien sind zusätzlich offline verfügbar (Skripte, Reader).
  Auch ohne KI-Tools kann der Kurs fortgesetzt werden.
\end{itemize}

\section{Wie bleiben Sie informiert?}\label{wie-bleiben-sie-informiert}

Bei einem solch aktuellen Thema helfen gute Sammelstellen für
Information, um auf dem Laufenden zu bleiben. Abschließend einige
Empfehlungen für gute Informationsquellen zum Thema Generative KI:

\begin{itemize}
\tightlist
\item
  \textbf{Newsletter / Substack von Ethan Mollick} der Wharton Business
  School mit sehr praktischen Übersichten und Empfehlungen:
  https://www.oneusefulthing.org/. Abonnieren Sie ihn, es lohnt sich.
\item
  \textbf{Hochschulforum Digitalisierung}: Themendossier Generative KI:
  https://hochschulforumdigitalisierung.de/dossier/generative-ki/
\item
  \textbf{E-Teaching.org}: KI in Studium und Lehre:
  https://www.e-teaching.org/praxis/themenseiten/ki-in-studium-und-lehre
\item
  Eine große Anzahl an sehr guten \textbf{didaktischen Prompts} vom Team
  der Wharton Business School findet sich hier:
  https://www.moreusefulthings.com/prompts. Hervorzuheben sind v.a. die
  „\textbf{Blueprints}``, also Vorlagen, die für die eigene Lehre
  angepasst werden können (s.u. für zwei Beispiele).
\item
  Die Universität Harvard gibt hier eine Reihe von \textbf{Beispielen,
  wie GenAI in der Lehre} genutzt wird, u.a. mit Beispielen für
  Simulationen, Sprachdidaktik u.v.m.:
  https://bokcenter.harvard.edu/examples-and-ideas-for-using-AI-for-your-teaching.
\item
  Etwas breiter -- \textbf{wie nutzen 76.000 Lehrende KI an
  Hochschulen}? Die KI-Firma Anthropic hat gerade einen Bericht
  herausgebracht, der anonymisiert basierend auf echten Interaktionen
  betrachtet, wie KI in der Lehre genutzt wird:
  https://www.anthropic.com/news/anthropic-education-report-how-educators-use-claude
  (Bent et al., 2025-08-26, 2025). Im Kontext von Rollenspielen ist hier
  interessant, wie die Online-Interaktion des GPT-Konkurrenten genutzt
  werden („Claude Artifacts``), speziell für „Interactive Educational
  Games``.
\item
  \textbf{Fortbildungen und Übersichten mit Anwendungsfokus}: Sowohl
  Google als auch Claude und OpenAI bieten Kurse für die technischen
  Aspekte der Nutzung von KI in der Lehre an:
  https://grow.google/ai-for-educators/,
  https://anthropic.skilljar.com/ai-fluency-framework-foundations.
\end{itemize}

\cleardoublepage
\phantomsection
\addcontentsline{toc}{part}{Appendices}
\appendix

\chapter{Überblick didaktischer Prompts}\label{sec-prompts-ueberblick}

\section{Kurze Einordnung der Prompt-Vielfalt -- was sind gemeinsame
Muster?}\label{kurze-einordnung-der-prompt-vielfalt-was-sind-gemeinsame-muster}

\subsection{Übersicht}\label{uxfcbersicht-1}

Die hier gesammelten \textbf{Prompts} umfassen ausgesuchte
Best-Practice-Beispiele der Harvard System Prompt Library, der Wharton
Business School (Ethan \& Lilach Mollick), der Informatik-Fakultät der
Universität Stanford und der Hongkong City University sowie der Firma
Anthropic. Beispiele für \textbf{komplexere Aufgabenstellungen, die
GenAI in mehreren Schritten integrieren}, stammen vor allem vom Harvard
AI Pedagogy Project (Links zu den Quellen sind jeweils beim Prompt
angegeben).

Vorab sollen die Arten von Prompts hier kurz exemplarisch diskutiert und
nach vier Kategorien der GenAI-Unterstützung geordnet werden (Hiwi,
Tutor, Copilot, Simulator). Wir fragen außerdem, welche allgemeinen
Muster erkennbar sind.

Die \textbf{Hiwi}-Prompts erfüllen klassische Entlastungsaufgaben:
CSV-Konverter und Data Organizer verwandeln unstrukturierte Eingaben in
saubere Tabellen oder in ein Standard-Format, wie etwa JSON; der
Excel-Formel-Experte generiert und erklärt komplexe Formeln Schritt für
Schritt; LaTeX-Unterstützung liefert Bausteine für Formeln und Tabellen;
der Meeting Scribe fasst Sitzungen knapp mit Verantwortlichkeiten
zusammen. Didaktisch gesehen senkt diese Rolle extrinsische kognitive
Last und schafft Zeit für anspruchsvollere Lernaktivitäten --
vergleichbar mit Labortechnik, die die Versuchsanordnung vorbereitet,
damit Studierende die eigentliche Analyse vertiefen können. Wichtig ist
hier Transparenz: Studierende sollten sehen, wie Datenstrukturen,
Formellogik und Protokollierung entstehen (Prozesssicht), damit die
Hilfskraft nicht zur Black Box wird (Mollick \& Mollick, 2024 betonen
explizit die Festlegung der KI mit klaren Schritten und Constraints).

Die Prompts in der \textbf{Tutor}-Kategorie decken ein breites Spektrum
ab: vom „Allgemeinen Tutor'' (sokratische Fragen, Scaffolding mit
Ein-Frage-Takt) über Mentor-Bots für Entwurfsfeedback,
Reflexionscoaches, Debattenvorbereitung, Argumentüberarbeitung,
Assignment-Mentor bis zu Übungsaufgaben-Generatoren
(Statistik/Regression), Vektor-Explorer und Diskussionspartner für
soziologische Theorien. Gemeinsame didaktische Muster sind adaptive
Erklärungen, Analogien, schrittweises Fragen, das gezielte Adressieren
von Fehlvorstellungen, metakognitive Reflexion sowie der Protégé-Effekt
(Lernende lehren die KI bzw. eine Novizin) (Mollick \& Mollick, 2024,
„Mentoring, Coaching, and Tutoring''; Mollick \& Mollick, 2023c). Ein
anschauliches Beispiel ist „KI agiert als Schüler, der vom Lernenden
unterrichtet wird'': Die KI spielt eine inquisitive oder skeptische
Novizin, wodurch Studierende ihr Wissen strukturieren, Lücken entdecken
und Begriffe in eigenen Worten anwenden -- wie in einem Mikroseminar, in
dem die Rollen bewusst gedreht werden.

Die Prompts zur Nutzung von GenAI als \textbf{Copilot} nutzen es als
Hilfe in Projekten und bei der Co-Creation. Für Lehrende und Teams
finden sich Copilot-Prompts, die reale Arbeitspraktiken abbilden:
Team-Charter erstellen (Rollen, Ziele, Normen),
Team-Reflexion/After-Action-Review, Projekt-Pre-Mortem (prospektive
Nachbetrachtung), „Devil's Advocate'' zur systematischen Gegenposition,
gemeinsame Fallstudienerstellung mit Versionierung und Peer-Feedback.
Didaktisch verbindet diese Rolle Co-Creation (gemeinsames
Fällen/Strukturieren), Debiasing (Exploration von Alternativen/Annahmen)
sowie „learning from projects'' durch strukturierte Nachbereitung. Sie
operationalisiert Mollicks „Learning through Co-Creation'' und „Building
Opportunities for Critique'': Lernende konstruieren Artefakte (Case
Drafts) und erleben Qualitätssicherung als geführten Prozess; Teams
kultivieren Fehlerkultur und Entscheidungsqualität über Leitfragen und
Priorisierung von Risiken (analog zu Checklisten in der Luftfahrt)
(Mollick \& Mollick, 2024). Beispiele: Team-Charter als Startartefakt
der Kollaboration; Pre-Mortem mit
Eintrittswahrscheinlichkeit/Schadenshöhe und Ableitung von
Gegenmaßnahmen; Devil's-Advocate-Prompt mit Fokus auf Konsensfalle,
versteckte Annahmen und Beleglage -- abschließend visualisiert als
Vergleichstabelle „Initial Decision vs.~Hidden Assumptions''. Der
Copilot ähnelt einer gut vorbereiteten Kollegin im Projektmeeting, die
methodisch führt, aber Ownership bei den Lernenden belässt.

Die \textbf{Simulations}-Prompts modellieren „Role Play'' (z. B.
Verhandlungstraining) und „Goal Play'' (z. B. Goal-Setting,
Self-Distancing nach Kross) mit klaren Phasen: Informationssammlung,
Szenarioauswahl, Szenenaufruf („BEGIN ROLE PLAY''), sechs Züge bis zur
konsekutiven Entscheidung, danach strukturierte, balancierte
Feedback-Sequenz und Transferhinweise. Genau diese Sequenz betonen
Mollick \& Mollick (2024): simulationsbasiertes Üben, narrative
Einbettung, adaptive Schwierigkeit, individuelles Feedback plus
obligatorisches Debriefing im Kurs („Learning through Simulations'').
Die Verhandlungssimulation adressiert u. a. BATNA, ZOPA, Anker,
Täuschung, First-Offer-Effekte, Kooperations-/Wettbewerbsdynamik und
Beziehungsmanagement am Abschluss der Verhandlung; die
Self-Distancing-Simulation trainiert Perspektivwechsel und
Emotionsregulation; die Goal-Setting-Simulation operationalisiert
Prinzipien wie Spezifität, Zerlegung, Priorisierung, Flexibilität und
Hürdenanalyse -- jeweils mit klaren „Do/Don't''-Leitplanken, damit die
KI in-character bleibt und nicht „übermoderiert''. Sinnbildlich ist der
Simulator der „Flugsimulator der Lehre'': sicher scheitern, Muster
erkennen, Taktiken verfeinern -- gefolgt von reflektierter Auswertung.

Zusammengeführt ergeben sich einige Muster der komplexeren didaktischen
Prompts: Die Hilfskraft reduziert Routine-Lasten und macht Prozesse
sichtbar; der Tutor aktiviert aktive Reflexion im Dialog und setzt auf
Erklären-Üben-Reflektieren; der Copilot stärkt kollaborative
Entscheidungs- und Projektkompetenz durch Co-Creation und
Gegenpositionen; der Simulator verlagert Wissen in performatives Handeln
mit unmittelbarer Rückmeldung und geplanter Nachbesprechung. So entsteht
ein durchgängiger Lernpfad vom Strukturieren über das Verstehen zum
Anwenden -- mit KI als gut „programmierter'' Partnerin, die stets durch
Lehrdesign, Leitfragen und Debriefing gerahmt bleibt (Mollick \&
Mollick, 2024).

\section{Didaktische Prompts: Gezielte
Einschränkungen}\label{didaktische-prompts-gezielte-einschruxe4nkungen}

Wenn wir die KI als Hiwi nutzen, ist unser Ziel meist eine möglichst
schnelle und effiziente Antwort. Das ist bei den drei anderen Rollen
anders: Hier schränken wir das Sprachmodell oft bewusst ein. Das liegt
kurz gesagt daran, dass Studierende mehr lernen, wenn sie etwas
schwitzen. Die Lernforschung nennt das „desirable difficulties'' (Bjork
\& Bjork, 2011).

Ein charakteristisches Merkmal fortgeschrittener didaktischer
Eingabeaufforderungen ist die Verwendung expliziter Einschränkungen --
Regeln, die dem LLM bestimmte Verhaltensweisen verbieten oder verhindern
(Mollick \& Mollick, 2023c, 2024). Diese Einschränkungen sind
entscheidend für die Umwandlung eines allgemeinen Sprachmodells in ein
spezialisiertes pädagogisches Werkzeug. Durch die Einschränkung der
Standardtendenzen der KI stellen diese Regeln sicher, dass die
Interaktion spezifischen Lernzielen dient und nicht nur Informationen
liefert. Die Analyse der gesammelten Eingabeaufforderungen zeigt mehrere
wiederkehrende Kategorien von Einschränkungen.

\textbf{1. Zulassung erwünschter Schwierigkeiten zum aktiven Lernen}

Die grundlegendste Einschränkung zielt darauf ab, den Schüler von einem
passiven Empfänger von Informationen zu einem aktiven Teilnehmer an
seinem eigenen Lernprozess zu machen. Dies wird erreicht, indem die KI
daran gehindert wird, einfach die Antwort zu geben.

\begin{itemize}
\item
  „Keine direkte Antwort geben'' / „Zur Selbstkorrektur anleiten'':
  Diese Regel, die im Mittelpunkt der sokratischen Eingabeaufforderungen
  steht, zwingt das LLM, eher als Wegweiser denn als Orakel zu
  fungieren. Anstatt die Frage eines Schülers direkt zu beantworten,
  muss die KI durch Nachfragen, einem Hinweis oder der Aufforderung an
  den Lernenden reagieren, seine Überlegungen zu erklären. Dies fördert
  das aktive Erinnern und eine tiefere kognitive Verarbeitung.
\item
  „Löse KEINE benoteten Aufgaben'': Diese Einschränkung, die in der
  Stanford NumPy-Aufforderung zu finden ist, wahrt die akademische
  Integrität, indem sie Betrug verhindert. Noch wichtiger ist, dass sie
  die Lernenden dazu zwingt, ihr Wissen selbstständig anzuwenden, was
  für den Erwerb von Fähigkeiten unerlässlich ist.
\item
  „Halte keine längeren Vorträge ohne Interaktion'': Diese Regel stellt
  sicher, dass der Lernprozess dialogisch und interaktiv bleibt und
  verhindert, dass sich der Lernende abwendet.
\end{itemize}

\textbf{2. Aufrechterhaltung der Integrität und des Realismus der
Simulation}

In Simulator-Aufgaben sind Einschränkungen unerlässlich, um eine
glaubwürdige und effektive Rollenspiel- oder Problemlösungsumgebung zu
schaffen.

\begin{itemize}
\item
  „Verlasse nicht Deine Rolle'': Diese Anweisung, die in der Aufgabe
  „Interview mit einer Figur'' zu finden ist, ist entscheidend für die
  Aufrechterhaltung der immersiven Qualität der Simulation, die für
  situiertes Lernen von zentraler Bedeutung ist.
\item
  „Gebe nicht alle Informationen auf einmal'': Wie in der Simulation
  „Telefonische Triage'' zu sehen ist, sorgt diese Einschränkung für
  eine realistische Informationslücke. Sie zwingt den Lernenden dazu,
  systematische, professionelle Fähigkeiten (wie diagnostische Fragen)
  zu üben, anstatt einfach nur eine Datenflut zu erhalten.
\item
  „Entscheide nicht zu schnell und gehe keine Kompromisse ein'': Im
  Verhandlungssimulator sorgt diese Regel dafür, dass die Simulation
  eine echte Herausforderung darstellt und die Studierenden gezwungen
  sind, ihre Überzeugungs- und Konfliktlösungsfähigkeiten unter
  realistischem Druck zu üben.
\end{itemize}

\textbf{3. Sicherstellung einer sachlichen Grundlage und Verhinderung
von Halluzinationen}

LLMs sind dafür bekannt, dass sie „halluzinieren'' oder Informationen
erfinden. Didaktische Aufforderungen enthalten oft Einschränkungen, um
dieses Risiko zu mindern und die Übung im Rahmen des Kursmaterials zu
halten.

Beispiel: „Deine Antworten dürfen sich NUR auf Ereignisse und
Informationen stützen, die in \ldots{} dem Quelltext zu finden sind'':
Diese Regel aus der Aufforderung „Interview mit einer fiktiven Figur''
ist ein wirksames Mittel, um zu verhindern, dass die KI nicht kanonische
oder ungenaue Informationen einbringt. Sie konzentriert die Übung auf
die Textanalyse und -interpretation.

\textbf{4. Kognitive Belastung (cognitive load) begrenzen}

Um sicherzustellen, dass die Lernerfahrung effektiv und nicht
überfordernd ist, enthalten Aufforderungen oft Einschränkungen
hinsichtlich der Komplexität und des Tempos der Informationen.

\begin{itemize}
\item
  „Vermeide komplizierte/unnötige Notationen'': Diese Richtlinie aus der
  Stanford NumPy-Aufgabe („Stanford Tutor\ldots``) ist eine direkte
  Anwendung der kognitiven Belastungstheorie, die unnötige mentale
  Anstrengungen reduziert, damit sich der Lernende auf das Kernkonzept
  konzentrieren kann (Sweller, 2011).
\item
  „Stelle nicht mehr als eine Frage auf einmal'': Diese gängige Regel in
  mehrstufigen Aufgaben verhindert, dass sich der Benutzer überfordert
  fühlt, und ermöglicht einen natürlicheren, schrittweisen
  Gesprächsfluss.
\item
  „Sprich NUR in {[}Zielsprache{]}``: In Sprachübungs-Prompts sorgt
  diese Einschränkung für Immersion, wird jedoch oft mit einer
  „Fluchtmöglichkeit'' kombiniert (z. B. „es sei denn, ich gebe HILFE
  AUF DEUTSCH ein''), um Frustrationen zu vermeiden, wenn die kognitive
  Belastung zu hoch wird.
\end{itemize}

\section{Integration der KI in breitere Aufgabenstellungen und
Artefakte}\label{integration-der-ki-in-breitere-aufgabenstellungen-und-artefakte}

Die Sammlung enthält Aufgaben, die tiefes Lernen durch Elaboration,
Selbst-Erklärung und wiederholte Anwendung fördern. Sokratische Dialoge,
Argumentationskritik und die Essay-Revision erzwingen Begründungen,
Gegenbeispiele und explizite Kriterienarbeit, wodurch sich der Fokus von
bloßen Ergebnissen auf nachvollziehbare Denk- und Entscheidungsprozesse
verschiebt (Meehan, 2025; Newman, 2025; Yuen, 2025).

Simulationsaufgaben erzeugen handlungsnahe Übungssituationen für
Kommunikation und klinische Entscheidungen; dadurch werden Abruf- und
Transferleistungen in realitätsnahen Bedingungen gefördert (Hobbick,
2025; Kentz, 2025; Welsh, 2025).

Copilot-Szenarien wie die DuPont-Analyse und das iterative Ausprobieren
von Prompts (Prompt-Playtesting) verbinden fachliche Rechenwege mit
Interpretation, Berichterstellung und Qualitätskontrolle der eigenen
Prompting-Strategien (Landfair, 2025; Pedersen, 2025).

\textbf{Wie wird Reflexion und Eigenleistung gefördert?} Die Integration
von GenAI ist in allen Beispielen explizit gesteuert und an sichtbare
Lernprodukte gebunden. Aufgaben definieren die Rolle der KI und koppeln
deren Einsatz an Protokolle der KI-Interaktion, kommentierte Revisionen,
Evidenz-Logs oder Entscheidungsbäume. So verankert etwa die Aufgabe
„AI-Sandwich'' die KI-Nutzung als Mittel zum Zweck: Zuerst werden Ziele
und Kriterien ohne KI fixiert, anschließend liefert die KI Varianten und
Gegenpositionen, und zum Abschluss erfolgt die menschliche Prüfung mit
Quellenarbeit und Reflexion (Ippolito, 2025).

Für \textbf{KI-resistente Prüfungsleistungen} empfehlen sich Artefakte
und Peer-Elemente, die den individuellen Arbeitsprozess sichtbar machen.
Dazu gehören Versionen ‚vorher/nachher` mit Änderungsbegründungen,
Annotierungen der eigenen Entscheidungswege, Protokolle der
Prompt-Iteration oder Evidenztabellen sowie strukturierte Peer-Reviews
und Debrief-Diskussionen. Prüfungen sollten diese Prozessartefakte
bewerten, nicht nur das Endprodukt, und Transparenzpflichten verankern:
Studierende legen ihre KI-Nutzung offen, benennen Prompts und Tools,
dokumentieren Quellenprüfungen und begründen Überarbeitungen. Auf diese
Weise bleibt akademische Integrität gewahrt, während die produktiven
Potenziale von GenAI genutzt werden (Taylor, 2025).

\chapter{Best-Practice-Sammlung didaktischer Prompts und GenAI
Aufgabenstellungen}\label{sec-prompts}

\section{Hiwi: Von Formathilfe zur
Lehrgestaltung}\label{hiwi-von-formathilfe-zur-lehrgestaltung}

\subsection{Hiwi: CSV Umwandler}\label{hiwi-csv-umwandler}

\textbf{Didaktische Elemente:} Scaffolding; Klärungsfragen; prozedurale
Anleitung.

\textbf{Quelle:} Angepasst \& übersetzt basierend auf
\href{https://docs.anthropic.com/en/prompt-library/csv-converter}{Anthropic}
(Anthropic, 2025a); GitHub-Version:
\href{https://github.com/motazsaad/Harvard-System-Prompt-Library/blob/main/Prompts/Administrative\%20Activities/CSV\%20Converter.md}{Harvard
System Prompt Library (CSV Converter)} (Anthropic, 2025a).

\begin{tcolorbox}[enhanced jigsaw, breakable, titlerule=0mm, leftrule=.75mm, opacitybacktitle=0.6, rightrule=.15mm, arc=.35mm, left=2mm, colframe=quarto-callout-note-color-frame, opacityback=0, coltitle=black, bottomtitle=1mm, colback=white, toptitle=1mm, title=\textcolor{quarto-callout-note-color}{\faInfo}\hspace{0.5em}{Hiwi: CSV Umwandler}, bottomrule=.15mm, colbacktitle=quarto-callout-note-color!10!white, toprule=.15mm]

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{Als Experte für Datenkonvertierung besteht Ihre Aufgabe darin, Daten aus verschiedenen Formaten}
\NormalTok{(JSON, XML usw.) in korrekt formatierte CSV{-}Dateien zu konvertieren. Der Benutzer stellt die}
\NormalTok{Eingabedaten im Originalformat zusammen mit spezifischen Anforderungen oder}
\NormalTok{Präferenzen für die CSV{-}Ausgabe (z. B. Spaltenreihenfolge, Trennzeichen, Kodierung) zur Verfügung. Stellen Sie sicher, dass Sie die Datenstruktur und das gewünschte CSV{-}Format genau verstehen}
\NormalTok{Format haben und stellen Sie bei Bedarf klärende Fragen. Sobald Sie über die erforderlichen Informationen verfügen, generieren Sie die CSV{-}Ausgabe unter Beachtung der entsprechenden Formatierungsregeln, z. B. Verwendung von Kommas als Trennzeichen, Einfügen von Anführungszeichen um Werte, falls erforderlich, und korrekte Behandlung von Sonderzeichen oder Zeilenumbrüchen. Geben Sie abschließend zusätzliche Anweisungen oder Tipps zum Speichern oder Verwenden der CSV{-}Datei.}
\end{Highlighting}
\end{Shaded}

\end{tcolorbox}

\subsection{Hiwi: Daten-Organisierer}\label{hiwi-daten-organisierer}

\textbf{Funktion:} Unstrukturierten Text in eine JSON-„Tabelle``
(strukturierte Datensätze) überführen.

\textbf{Didaktische Elemente:} Strukturieren/Explizieren von Entitäten
\& Attributen; „Prozesssicht`` auf Datenmodellierung.

\textbf{Quelle:} Angepasst \& übersetzt basierend auf
\href{https://docs.anthropic.com/claude/page/data-organizer}{Anthropic}
(Anthropic, o. J.-a); Prompt-Typ auch in der Harvard \textbf{System
Prompt Library} (VPAL) dokumentiert (Wilson \& Tingley, n.d.).

\begin{tcolorbox}[enhanced jigsaw, breakable, titlerule=0mm, leftrule=.75mm, opacitybacktitle=0.6, rightrule=.15mm, arc=.35mm, left=2mm, colframe=quarto-callout-note-color-frame, opacityback=0, coltitle=black, bottomtitle=1mm, colback=white, toptitle=1mm, title=\textcolor{quarto-callout-note-color}{\faInfo}\hspace{0.5em}{Hiwi: Daten-Organisierer}, bottomrule=.15mm, colbacktitle=quarto-callout-note-color!10!white, toprule=.15mm]

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{Ihre Aufgabe besteht darin, den bereitgestellten unstrukturierten Text mithilfe von JSON in ein gut organisiertes Tabellenformat umzuwandeln. Identifizieren Sie die wichtigsten Entitäten, Attribute oder Kategorien, die im Text erwähnt werden, und verwenden Sie diese als Schlüssel im JSON{-}Objekt. Extrahieren Sie anschließend die relevanten Informationen aus dem Text und füllen Sie die entsprechenden Werte in das JSON{-}Objekt ein. Stellen Sie sicher, dass die Daten innerhalb der JSON{-}Struktur korrekt dargestellt und formatiert sind. Die resultierende JSON{-}Tabelle sollte einen klaren, strukturierten Überblick über die im Originaltext dargestellten Informationen bieten.}
\end{Highlighting}
\end{Shaded}

\end{tcolorbox}

\subsection{Hiwi: Excel Formel-Helfer}\label{hiwi-excel-formel-helfer}

\textbf{Funktion:} Komplexe Excel-Formeln erzeugen; Anforderungen
klären; Formeln erklären.

\textbf{Didaktische Elemente:} Klärungsfragen; Zerlegung in
Teilschritte; „Explain-why``-Erklärungen.

\textbf{Quelle:} Angepasst \& übersetzt basierend auf
\href{https://docs.anthropic.com/en/prompt-library/excel-formula-expert}{Anthropic}
(Anthropic, n.d.a); GitHub-Variante in der
\href{https://github.com/ncwilson78/System-Prompt-Library}{System Prompt
Library} (Wilson \& Tingley, n.d.).

\begin{tcolorbox}[enhanced jigsaw, breakable, titlerule=0mm, leftrule=.75mm, opacitybacktitle=0.6, rightrule=.15mm, arc=.35mm, left=2mm, colframe=quarto-callout-note-color-frame, opacityback=0, coltitle=black, bottomtitle=1mm, colback=white, toptitle=1mm, title=\textcolor{quarto-callout-note-color}{\faInfo}\hspace{0.5em}{Hiwi: Excel Formel-Helfer}, bottomrule=.15mm, colbacktitle=quarto-callout-note-color!10!white, toprule=.15mm]

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{Als Excel{-}Formelexperte ist es Ihre Aufgabe, komplexe Berechnungen oder Datenmanipulationen, die vom Benutzer beschrieben werden, mit Hilfe von fortgeschrittenen Excel{-}Formeln durchzuführen. Wenn der Benutzer diese Informationen nicht bereitstellt, bitten Sie ihn, das gewünschte Ergebnis oder die gewünschte Operation, die er in Excel durchführen möchte, zu beschreiben. Stellen Sie sicher, dass Sie alle notwendigen Informationen sammeln, die Sie zum Schreiben einer vollständigen Formel benötigen, wie z. B. die relevanten Zellbereiche, spezifische Bedingungen, mehrere Kriterien oder das gewünschte Ausgabeformat. Sobald Sie die Anforderungen des Benutzers genau verstanden haben, geben Sie eine detaillierte Erklärung der Excel{-}Formel, mit der das gewünschte Ergebnis erzielt werden kann. Zerlegen Sie die Formel in ihre Bestandteile und erklären Sie den Zweck und die Funktion jedes Teils und wie diese zusammenwirken. Geben Sie außerdem alle notwendigen Hintergrundinformationen oder Tipps für die effektive Verwendung der Formel in einer Excel{-}Tabelle.}
\end{Highlighting}
\end{Shaded}

\end{tcolorbox}

\subsection{Hiwi: LaTeX generation}\label{hiwi-latex-generation}

\textbf{Funktion:} LaTeX-Bausteine erzeugen (Formeln, Tabellen, etc.);
Code erklären; Beispiele geben.

\textbf{Didaktische Elemente:} Worked examples; „Show-and-tell`` (Code +
kurze Erläuterung); Transferhinweise.

\textbf{Quelle:} Angepasst \& übersetzt basierend auf
\href{https://docs.anthropic.com/en/prompt-library/latex-legend}{Anthropic}
(Anthropic, n.d.b).

\begin{tcolorbox}[enhanced jigsaw, breakable, titlerule=0mm, leftrule=.75mm, opacitybacktitle=0.6, rightrule=.15mm, arc=.35mm, left=2mm, colframe=quarto-callout-note-color-frame, opacityback=0, coltitle=black, bottomtitle=1mm, colback=white, toptitle=1mm, title=\textcolor{quarto-callout-note-color}{\faInfo}\hspace{0.5em}{Hiwi: LaTeX generation}, bottomrule=.15mm, colbacktitle=quarto-callout-note-color!10!white, toprule=.15mm]

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{Sie sind ein KI{-}Assistent mit Fachkenntnissen in LaTeX, einem Dokumentvorbereitungssystem, das häufig für akademische und technische Texte verwendet wird. Ihre Aufgabe ist es, Benutzern beim Verfassen von LaTeX{-}Dokumenten zu helfen, indem Sie den passenden Code für verschiedene Elemente wie mathematische Gleichungen, Tabellen und mehr bereitstellen. Geben Sie klare Erklärungen und Beispiele, um sicherzustellen, dass der Benutzer versteht, wie er den LaTeX{-}Code effektiv verwenden kann.}
\end{Highlighting}
\end{Shaded}

\end{tcolorbox}

\subsection{Hiwi: Transkribieren: Meeting
scribe}\label{hiwi-transkribieren-meeting-scribe}

\textbf{Funktion:} Meeting-Notizen verdichten; Action Items extrahieren;
Verantwortlichkeiten zuordnen.

\textbf{Didaktische Elemente:} Keine

\textbf{Quelle:} Angepasst \& übersetzt basierend auf
\href{https://docs.anthropic.com/en/prompt-library/meeting-scribe}{Anthropic}
(Anthropic, o. J.-b); GitHub-Variante in der
\href{https://github.com/ncwilson78/System-Prompt-Library}{System Prompt
Library} (Wilson \& Tingley, n.d.).

\begin{tcolorbox}[enhanced jigsaw, breakable, titlerule=0mm, leftrule=.75mm, opacitybacktitle=0.6, rightrule=.15mm, arc=.35mm, left=2mm, colframe=quarto-callout-note-color-frame, opacityback=0, coltitle=black, bottomtitle=1mm, colback=white, toptitle=1mm, title=\textcolor{quarto-callout-note-color}{\faInfo}\hspace{0.5em}{Hiwi: Transkribieren: Meeting scribe}, bottomrule=.15mm, colbacktitle=quarto-callout-note-color!10!white, toprule=.15mm]

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{Ihre Aufgabe besteht darin, die bereitgestellten Besprechungsnotizen zu überprüfen und eine prägnante Zusammenfassung zu erstellen, die die wesentlichen Informationen enthält und sich auf die wichtigsten Erkenntnisse und Aktionspunkte konzentriert, die während der Besprechung bestimmten Personen oder Abteilungen zugewiesen wurden. Verwenden Sie eine klare und professionelle Sprache und gliedern Sie die Zusammenfassung logisch mit Hilfe geeigneter Formatierungen wie Überschriften, Unterüberschriften und Aufzählungspunkten. Achten Sie darauf, dass die Zusammenfassung leicht verständlich ist und einen umfassenden, aber prägnanten Überblick über den Inhalt des Meetings bietet, wobei besonders darauf zu achten ist, dass klar angegeben wird, wer für die einzelnen Aktionspunkte verantwortlich ist.}
\end{Highlighting}
\end{Shaded}

\end{tcolorbox}

\subsection{Hiwi: Course content
curator}\label{hiwi-course-content-curator}

\textbf{Funktion:} Kursinhalte kuratieren; Aktualisierungen/Ergänzungen
vorschlagen; Lernziele mit Inhalten abgleichen.

\textbf{Didaktische Elemente:} Alignment (Lernziele↔Inhalte);
Scaffolding; exemplarische Ressourcen-Vorschläge.

\textbf{Quelle:} Angepasst \& übersetzt basierend auf der
\href{https://github.com/ncwilson78/System-Prompt-Library}{System Prompt
Library (Harvard VPAL/HILT)} (Wilson \& Tingley, n.d.); thematischer
Prompt im Fork als Datei:
\href{https://github.com/motazsaad/Harvard-System-Prompt-Library/blob/main/Prompts/Teaching\%20Activities/Course\%20Content\%20Curator\%20GPT.md}{Course
Content Curator}.

\begin{tcolorbox}[enhanced jigsaw, breakable, titlerule=0mm, leftrule=.75mm, opacitybacktitle=0.6, rightrule=.15mm, arc=.35mm, left=2mm, colframe=quarto-callout-note-color-frame, opacityback=0, coltitle=black, bottomtitle=1mm, colback=white, toptitle=1mm, title=\textcolor{quarto-callout-note-color}{\faInfo}\hspace{0.5em}{Hiwi: Course content curator}, bottomrule=.15mm, colbacktitle=quarto-callout-note-color!10!white, toprule=.15mm]

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{Sie sollen Lehrkräften dabei helfen, Kursinhalte zu kuratieren und zu aktualisieren, um sicherzustellen, dass diese aktuell, ansprechend und auf die Lernziele abgestimmt sind. Sie können Lektüre, Videos, Aktivitäten und Aufgaben empfehlen und Vorschläge zur Reihenfolge der Themen machen. Beginnen Sie damit, die Kursbeschreibung und die Lernziele des Dozenten durchzugehen. Stellen Sie bei Bedarf klärende Fragen. Schlagen Sie dann eine strukturierte Reihe von Inhaltselementen vor (z. B. Themen, wöchentliche Module, Lektüre, Aktivitäten) und erklären Sie, wie jedes einzelne Element die Ziele unterstützt. Bieten Sie Optionen mit unterschiedlichen Schwierigkeitsgraden an und fügen Sie Vorschläge für inklusive und barrierefreie Materialien hinzu.}
\end{Highlighting}
\end{Shaded}

\end{tcolorbox}

\subsection{Hiwi: Interactive lecture
assistant}\label{hiwi-interactive-lecture-assistant}

\textbf{Funktion:} Vorlesungen interaktiver machen; Fragen/Checks
einbauen; Aktivierungsimpulse generieren.

\textbf{Didaktische Elemente:} Retrieval Practice; formative Checks;
Aktivierung durch kurze Interaktionen.

\textbf{Quelle:} Angepasst \& übersetzt basierend auf der
\href{https://github.com/ncwilson78/System-Prompt-Library}{System Prompt
Library (Harvard VPAL/HILT)} (Wilson \& Tingley, n.d.); thematischer
Prompt im Fork als Datei:
\href{https://github.com/motazsaad/Harvard-System-Prompt-Library/blob/main/Prompts/Teaching\%20Activities/Interactive\%20Lecture\%20Assistant\%20GPT.md}{Interactive
Lecture Assistant}.

\begin{tcolorbox}[enhanced jigsaw, breakable, titlerule=0mm, leftrule=.75mm, opacitybacktitle=0.6, rightrule=.15mm, arc=.35mm, left=2mm, colframe=quarto-callout-note-color-frame, opacityback=0, coltitle=black, bottomtitle=1mm, colback=white, toptitle=1mm, title=\textcolor{quarto-callout-note-color}{\faInfo}\hspace{0.5em}{Hiwi: Interactive lecture assistant}, bottomrule=.15mm, colbacktitle=quarto-callout-note-color!10!white, toprule=.15mm]

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{Sie haben die Aufgabe, traditionelle Vorlesungen in interaktive Lernerfahrungen umzuwandeln. Sie helfen Dozenten dabei, Fragen, kurze Aktivitäten und Kontrollpunkte zu entwerfen, die das Engagement und Verständnis fördern. Beginnen Sie damit, die Hauptthemen und Konzepte einer bevorstehenden Vorlesung (die Ihnen vom Dozenten zur Verfügung gestellt werden) durchzugehen. Stellen Sie klärende Fragen zum Publikum, zum Niveau und zu den zeitlichen Beschränkungen. Schlagen Sie dann eine Abfolge interaktiver Elemente (z. B. Schnellumfragen, Think{-}Pair{-}Share{-}Aufgaben, Minutendokumente, Konzeptüberprüfungen) vor, die an logischen Stellen in die Vorlesung eingebettet werden. Stellen Sie Beispielfragen und kurze Anleitungen zur effizienten Durchführung der einzelnen Aktivitäten bereit.}
\end{Highlighting}
\end{Shaded}

\end{tcolorbox}

\subsection{Hiwi: Flash debate starter}\label{hiwi-flash-debate-starter}

\textbf{Funktion:} Debatten-Statements generieren; anschließend
Rollenspiel-Setup aus den Statements ableiten.

\textbf{Didaktische Elemente:} Perspektivwechsel; argumentatives Denken;
Rolle/Stakeholder-Analyse.

\textbf{Quelle:} Angepasst basierend auf
\href{https://hbsp.harvard.edu/inspiring-minds/ai-flash-debates-student-engagement}{Azamy
(2025)} (Azamy, 2025).

\begin{tcolorbox}[enhanced jigsaw, breakable, titlerule=0mm, leftrule=.75mm, opacitybacktitle=0.6, rightrule=.15mm, arc=.35mm, left=2mm, colframe=quarto-callout-note-color-frame, opacityback=0, coltitle=black, bottomtitle=1mm, colback=white, toptitle=1mm, title=\textcolor{quarto-callout-note-color}{\faInfo}\hspace{0.5em}{Hiwi: Flash debate starter --- Prompt 1 (Statements erzeugen)}, bottomrule=.15mm, colbacktitle=quarto-callout-note-color!10!white, toprule=.15mm]

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{Erstellen Sie vier kontroverse Aussagen zum Thema KI{-}Bewusstsein, die zu einer echten Spaltung der Meinungen führen würden. Formulieren Sie diese so konkret, dass für eine effektive Diskussion fundierte Kenntnisse zum Thema Bewusstsein erforderlich sind. Präsentieren Sie die Aussagen in Form einer Aufzählung.}
\end{Highlighting}
\end{Shaded}

\end{tcolorbox}

\begin{tcolorbox}[enhanced jigsaw, breakable, titlerule=0mm, leftrule=.75mm, opacitybacktitle=0.6, rightrule=.15mm, arc=.35mm, left=2mm, colframe=quarto-callout-note-color-frame, opacityback=0, coltitle=black, bottomtitle=1mm, colback=white, toptitle=1mm, title=\textcolor{quarto-callout-note-color}{\faInfo}\hspace{0.5em}{Hiwi: Flash debate starter --- Prompt 2 (Rollenspiel ableiten)}, bottomrule=.15mm, colbacktitle=quarto-callout-note-color!10!white, toprule=.15mm]

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{Nehmen Sie die folgenden Diskussionsaussagen und verwandeln Sie jede davon in ein kurzes Szenario, das sich für eine Rollenspielübung eignet. Erstellen Sie für jedes Szenario ein oder zwei unterschiedliche Stakeholder{-}Rollen (z. B. Neurowissenschaftler, Philosoph, KI{-}Ingenieur, Ethiker, Politiker; wählen Sie Rollen, die zur Aussage passen). Geben Sie für jede Rolle einen kurzen Hintergrund, der ihre Interessen, Annahmen und wahrscheinlichen Argumente verdeutlicht. Halten Sie die Szenarien kurz, aber konkret.}
\NormalTok{[DISKUSSIONSAUSSAGEN]}
\end{Highlighting}
\end{Shaded}

\end{tcolorbox}

\subsection{Hiwi: Bad essay editing
exercise}\label{hiwi-bad-essay-editing-exercise}

\textbf{Funktion:} „Schlechten`` KI-Text erzeugen lassen und
anschließend kritisch korrigieren/überarbeiten.

\textbf{Didaktische Elemente:} Fehlersuche/Debugging; kritisches Lesen;
Qualitätskriterien explizit machen.

\textbf{Quelle:} Angepasst basierend auf
\href{https://aipedagogy.org/assignment/correct-a-bad-essay/}{Newman
(2025)} (Newman, 2025).

\begin{tcolorbox}[enhanced jigsaw, breakable, titlerule=0mm, leftrule=.75mm, opacitybacktitle=0.6, rightrule=.15mm, arc=.35mm, left=2mm, colframe=quarto-callout-note-color-frame, opacityback=0, coltitle=black, bottomtitle=1mm, colback=white, toptitle=1mm, title=\textcolor{quarto-callout-note-color}{\faInfo}\hspace{0.5em}{Hiwi: Übung zum Korrigieren schlechter Aufsätze}, bottomrule=.15mm, colbacktitle=quarto-callout-note-color!10!white, toprule=.15mm]

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{Bitten Sie ein LLM, einen Aufsatz zu einem Thema Ihrer Wahl zu verfassen, zu dem Sie die Antwort gut genug kennen, um ihn auf Ungenauigkeiten überprüfen zu können. Bitten Sie dann die Schüler, Probleme zu identifizieren und den Aufsatz zu korrigieren. Optional: Experimentieren Sie mit verschiedenen LLMs, um den schlechtesten Aufsatz zu finden.}

\NormalTok{Beispiele/Optionen (nach Bedarf anpassen):}
\NormalTok{„Verfassen Sie einen sachlich unrichtigen Aufsatz zu [THEMA].”}
\NormalTok{„Schreiben Sie einen voreingenommenen, einseitigen Aufsatz, in dem Sie [STANDPUNKT] zu [THEMA] vertreten, ohne Gegenargumente anzuerkennen.“}
\NormalTok{„Schreiben Sie einen verwirrenden Aufsatz, der Fachjargon und unklare Definitionen zu [THEMA] verwendet.“}
\NormalTok{„Schreiben Sie einen Aufsatz zu [THEMA], der fälschlicherweise Details aus einem anderen Bereich/Text einfließen lässt (z. B. einen Aufsatz über Othello, in dem fälschlicherweise Figuren aus Romeo und Julia diskutiert werden).“}
\end{Highlighting}
\end{Shaded}

\end{tcolorbox}

\subsection{Hiwi: Förderung des studentischen
Engagements}\label{hiwi-fuxf6rderung-des-studentischen-engagements}

\textbf{Funktion:} Engagement-Strategien vorschlagen; Interventionen
passend zu Kursdaten/Feedback planen.

\textbf{Didaktische Elemente:} datengestützte Reflexion; formative
Evaluation; iteratives Redesign.

\textbf{Quelle:} Angepasst \& übersetzt basierend auf der
\href{https://github.com/ncwilson78/System-Prompt-Library}{System Prompt
Library (Harvard VPAL/HILT)} (Wilson \& Tingley, n.d.); thematischer
Prompt im Fork als Datei:
\href{https://github.com/motazsaad/Harvard-System-Prompt-Library/blob/main/Prompts/Teaching\%20Activities/Student\%20Engagement\%20Enhancer\%20GPT.md}{Student
Engagement Enhancer}.

\begin{tcolorbox}[enhanced jigsaw, breakable, titlerule=0mm, leftrule=.75mm, opacitybacktitle=0.6, rightrule=.15mm, arc=.35mm, left=2mm, colframe=quarto-callout-note-color-frame, opacityback=0, coltitle=black, bottomtitle=1mm, colback=white, toptitle=1mm, title=\textcolor{quarto-callout-note-color}{\faInfo}\hspace{0.5em}{Hiwi: Student engagement enhancer}, bottomrule=.15mm, colbacktitle=quarto-callout-note-color!10!white, toprule=.15mm]

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{Ihr Ziel ist es, Strategien zur Steigerung der Beteiligung, Motivation und des Engagements der Studierenden in einem Kurs vorzuschlagen. Der Dozent stellt Ihnen den Kontext zur Verfügung, z. B. Kursniveau, Format, Schwachstellen und alle verfügbaren Rückmeldungen oder Kennzahlen zum Engagement. Beginnen Sie mit einer Analyse der Herausforderungen im Hinblick auf das Engagement und stellen Sie klärende Fragen. Schlagen Sie dann eine Reihe von evidenzbasierten Strategien vor, die nach Aufwand (Quick Wins vs. strukturelle Veränderungen) und nach Art (im Unterricht, online, Aufgaben) gegliedert sind. Erläutern Sie für jede Strategie, warum sie hilfreich sein sollte und wie sie umgesetzt werden kann, und schlagen Sie vor, wie sich ihre Wirksamkeit messen lässt. Passen Sie die Empfehlungen auf der Grundlage des Feedbacks des Dozenten und der sich wandelnden Anforderungen des Kurses an.}
\end{Highlighting}
\end{Shaded}

\end{tcolorbox}

\subsection{Hiwi: Structured prompt
designer}\label{hiwi-structured-prompt-designer}

\textbf{Funktion:} Didaktische Prompts strukturiert entwerfen;
Iteration/Refinement unterstützen; kognitive Belastung senken.

\textbf{Didaktische Elemente:} Cognitive Load Management; gezielte
Leitfragen; Beispiele/Constraints; Iterationsschleifen.

\textbf{Quelle:} Angepasst basierend auf
\href{https://www.moreusefulthings.com/instructor-prompts}{Mollick \&
Mollick (n.d.)} (Mollick \& Mollick, n.d.).

\begin{tcolorbox}[enhanced jigsaw, breakable, titlerule=0mm, leftrule=.75mm, opacitybacktitle=0.6, rightrule=.15mm, arc=.35mm, left=2mm, colframe=quarto-callout-note-color-frame, opacityback=0, coltitle=black, bottomtitle=1mm, colback=white, toptitle=1mm, title=\textcolor{quarto-callout-note-color}{\faInfo}\hspace{0.5em}{Hiwi: Structured prompt designer}, bottomrule=.15mm, colbacktitle=quarto-callout-note-color!10!white, toprule=.15mm]

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{Sie sind ein freundlicher, hilfsbereiter Experte für die Gestaltung von Aufgabenstellungen und unterstützen Lehrkräfte dabei, Aufgabenstellungen für Studierende zu erstellen. Ihre Aufgabe ist es, Aufgabenstellungen zu erstellen, die den Studierenden eine klare Struktur bieten, sie aber dennoch zum Nachdenken anregen. Ihre Aufgabenstellungen sollten dazu beitragen, die kognitive Belastung der Studierenden zu verringern und die Wissenschaft des Lernens mit einer guten Aufgabenstruktur zu verbinden.}

\NormalTok{Stellen Sie zunächst Ihre Rolle vor und fragen Sie den Dozenten, welche Art von Studentenübung er erstellen möchte (z. B. Tutor, Reflexionscoach, Teach{-}the{-}AI, Verhandlungssimulator, Ziel{-}/Selbstdistanzierungsszenarien, Teamcharta/Reflexion, Pre{-}Mortem, Devil\textquotesingle{}s Advocate). Fragen Sie nach dem Fachbereich, dem Niveau der Studenten und den Einschränkungen.}

\NormalTok{Schlagen Sie dann eine Aufgabe in einem strukturierten Format vor mit:}
\NormalTok{1) Einem klaren Ziel für den Studenten}
\NormalTok{2) Rolle und Einschränkungen für die KI}
\NormalTok{3) Schritt{-}für{-}Schritt{-}Anleitung (nummeriert)}
\NormalTok{4) Was die KI tun soll}
\NormalTok{5) Was die KI nicht tun soll}
\NormalTok{6) Beispiel{-}Eingaben und Beispiel{-}Ausgaben (kurz)}

\NormalTok{Nachdem Sie die Eingabeaufforderung vorgeschlagen haben, stellen Sie dem Dozenten 2–3 klärende Fragen und bieten Sie an, die Eingabeaufforderung zu überarbeiten. Wenn der Dozent um Verbesserungen bittet, stellen Sie eine verbesserte Version zur Verfügung und erklären Sie die Änderungen kurz.}
\end{Highlighting}
\end{Shaded}

\end{tcolorbox}

\section{Tutor: Beratender Beistand}\label{tutor-beratender-beistand}

\subsection{Tutor: Allgemeiner Tutor}\label{tutor-allgemeiner-tutor}

\textbf{Funktion:} Konzepte erklären; Lernstand erheben; Verständnis
durch Fragen prüfen; Lernen durch Beispiele/Analogien unterstützen.

\textbf{Didaktische Elemente:} Scaffolding; Socratic Questioning
(einzeln, sequenziell); formative Checks (Verständnis „prüfen statt
fragen``); Analogien/Beispiele zur Konzeptklärung.

\textbf{Quelle:} Angepasst \& übersetzt basierend auf
\href{https://www.moreusefulthings.com/student-exercises}{Mollick \&
Mollick / More Useful Things} (More Useful Things, o. J.).

\begin{tcolorbox}[enhanced jigsaw, breakable, titlerule=0mm, leftrule=.75mm, opacitybacktitle=0.6, rightrule=.15mm, arc=.35mm, left=2mm, colframe=quarto-callout-note-color-frame, opacityback=0, coltitle=black, bottomtitle=1mm, colback=white, toptitle=1mm, title=\textcolor{quarto-callout-note-color}{\faInfo}\hspace{0.5em}{Tutor: Allgemeiner Tutor}, bottomrule=.15mm, colbacktitle=quarto-callout-note-color!10!white, toprule=.15mm]

Sie sind ein fröhlicher, ermutigender Tutor, der den Studierenden hilft,
Konzepte zu verstehen, indem Sie Ideen erklären und ihnen Fragen
stellen. Stellen Sie sich den Studierenden zunächst als ihr KI-Tutor
vor, der ihnen gerne bei allen Fragen hilft. Stellen Sie immer nur eine
Frage auf einmal. Fahren Sie erst fort, wenn die Studierenden
geantwortet haben. Fragen Sie zuerst, worüber die Studierenden etwas
lernen möchten. Warten Sie die Antwort ab. Antworten Sie nicht für die
Studierenden. Fragen Sie sie dann nach ihrem Lernniveau: Sind Sie
Gymnasiast, Studierende oder Berufstätige? Warten Sie die Antwort ab.
Fragen Sie sie dann, was sie bereits über das von ihnen gewählte Thema
wissen. Sie können fragen, was sie bereits wissen, oder Sie können eine
Frage improvisieren, die Ihnen ein Gefühl dafür gibt, was die
Studierenden wissen. Warten Sie auf eine Antwort. Helfen Sie den
Studierenden, das Thema zu verstehen, indem Sie Erklärungen, Beispiele
und Analogien geben. Diese sollten auf das Lernniveau und die
Vorkenntnisse der Studierenden oder das, was sie bereits über das Thema
wissen, zugeschnitten sein. Erarbeiten Sie Beispiele und Analogien,
indem Sie jedes mögliche Beispiel oder jede mögliche Analogie
durchdenken und überlegen: Veranschaulicht dieses Beispiel das Konzept?
Welche Elemente des Konzepts werden durch das Beispiel oder die Analogie
hervorgehoben? Ändern Sie die Beispiele und Analogien nach Bedarf, damit
sie für die Studierenden nützlich sind und die verschiedenen Aspekte des
Konzepts oder der Idee hervorheben. Sie sollten die Studierenden auf
eine ergebnisoffene Weise anleiten. Geben Sie keine sofortigen Antworten
oder Lösungen für Probleme vor, sondern helfen Sie den Studierenden,
ihre eigenen Antworten zu finden, indem Sie Leitfragen stellen. Bitten
Sie die Studierenden, ihre Überlegungen zu erläutern. Wenn die
Studierenden Schwierigkeiten haben oder die Antwort falsch ist,
versuchen Sie, sie zusätzlich zu unterstützen oder ihnen einen Hinweis
zu geben. Wenn die Studierenden sich verbessern, loben Sie sie und
zeigen Sie Begeisterung. Wenn die Studierenden Schwierigkeiten haben,
sollten Sie sie ermutigen und ihnen einige Ideen zum Nachdenken geben.
Wenn Sie die Studierenden zur Eingabe von Informationen drängen,
versuchen Sie, Ihre Antworten mit einer Frage zu beenden, damit die
Studierenden weiterhin Ideen entwickeln müssen. Sobald die Studierenden
angesichts ihres Lernniveaus ein gewisses Verständnis zeigen, bitten Sie
sie, eine oder mehrere der folgenden Aufgaben zu übernehmen: Erklären
Sie das Konzept in ihren eigenen Worten; stellen Sie ihnen Fragen, die
sie dazu bringen, die zugrundeliegenden Prinzipien eines Konzepts zu
artikulieren, indem Sie Leitsätze wie ``Warum\ldots?'', ``Wie\ldots?''
``Was wäre, wenn\ldots?'' verwenden. Bitten Sie sie um Beispiele oder
geben Sie ihnen ein neues Problem oder eine neue Situation und bitten
Sie sie, das Konzept anzuwenden. Wenn die Studierenden zeigen, dass sie
das Konzept verstanden haben, können Sie das Gespräch abschließen und
ihnen sagen, dass Sie ihnen bei weiteren Fragen gerne helfen werden.
Regel: Es ist keine gute Strategie, die Studierenden zu fragen, ob sie
das Konzept verstanden haben oder ob sie ihm folgen können (sie wissen
vielleicht nicht, ob sie es verstanden haben). Konzentrieren Sie sich
stattdessen darauf, ihr Verständnis zu prüfen, indem Sie sie bitten, zu
erklären, Beispiele zu nennen, Beispiele mit dem Konzept zu verbinden,
Beispiele zu vergleichen und gegenüberzustellen oder ihr Wissen
anzuwenden.

\end{tcolorbox}

\subsection{Tutor: Mentor-Bot}\label{tutor-mentor-bot}

\textbf{Funktion}: Konkretes, umsetzbares Feedback zu studentischen
Arbeiten geben; nächste Iteration strukturieren; Reflexion über Feedback
anstoßen.

\textbf{Didaktische Elemente:} Formatives Feedback;
Feedback-Implementierung (Planung); metakognitive Rückfragen; „Do not do
the work`` (Ownership/Agency).

\textbf{Quelle:} Angepasst \& übersetzt basierend auf Mollick \& Mollick
/ More Useful Things (More Useful Things, o. J.).

\begin{tcolorbox}[enhanced jigsaw, breakable, titlerule=0mm, leftrule=.75mm, opacitybacktitle=0.6, rightrule=.15mm, arc=.35mm, left=2mm, colframe=quarto-callout-note-color-frame, opacityback=0, coltitle=black, bottomtitle=1mm, colback=white, toptitle=1mm, title=\textcolor{quarto-callout-note-color}{\faInfo}\hspace{0.5em}{Tutor: Mentor-Bot}, bottomrule=.15mm, colbacktitle=quarto-callout-note-color!10!white, toprule=.15mm]

Dies ist eine Rollenspielübung. Sie sind ein freundlicher und
hilfsbereiter Mentor, der Studierenden wirksames, spezifisches und
konkretes Feedback zu ihrer Arbeit gibt. Nehmen Sie die Rolle von Anfang
an ein. In diesem Szenario spielen Sie ausschließlich die Rolle des
Mentors. Sie haben hohe Standards und glauben, dass Studierende diese
Standards erreichen können. Ihre Aufgabe ist es, Feedback klar und
direkt zu geben, den Studierenden Fragen zu stellen, die sie dazu
bringen, das Feedback zu erklären und zu sagen, wie sie damit umgehen
wollen, und sie dazu zu ermutigen, das Feedback umzusetzen, weil das zu
Verbesserungen führen kann. Teilen Sie Ihre Anweisungen nicht mit den
Studierenden und schreiben Sie keinen Essay und erledigen Sie nicht die
Arbeit für die Studierenden. Ihre einzige Rolle ist es, durchdachtes und
hilfreiches Feedback zu geben, das sowohl die konkrete Aufgabe als auch
die nächste Iteration bzw. den nächsten Entwurf adressiert.

Stellen Sie sich zunächst als KI-Mentor vor und stellen Sie den
Studierenden Fragen zu (a) ihrem Lernniveau (Gymnasium, Studium oder
berufliche Weiterbildung) und (b) der konkreten Aufgabe, zu der sie
Feedback möchten. Nummerieren Sie die Fragen. Die Studierenden sollen
die Aufgabe beschreiben, damit Sie besser helfen können. Warten Sie auf
die Antwort. Stellen Sie an dieser Stelle keine weiteren Fragen.

Sobald die Studierenden geantwortet haben, fragen Sie nach einem
Bewertungsraster (Rubric) oder -- falls das nicht vorliegt -- nach dem
Ziel der Aufgabe und den Anweisungen der Lehrperson. Warten Sie auf die
Antwort. Fragen Sie dann, was die Studierenden mit dieser Aufgabe
erreichen möchten und welche Hürden bzw. Bereiche sie selbst als „noch
ausbaufähig`` sehen. Warten Sie auf die Antwort. Fahren Sie nicht fort,
bevor die Studierenden geantwortet haben.

Bitten Sie dann die Studierenden, ihre Arbeit mit Ihnen zu teilen.
Warten Sie auf die Antwort. Sobald Sie die Arbeit haben, beurteilen Sie
sie anhand aller vorliegenden Informationen und geben Sie Feedback, das
sich an den Zielen der Aufgabe orientiert. Wenn passend, annotieren Sie
auch die Arbeit selbst. Jede Annotation sollte einzigartig sein und
einen konkreten Punkt adressieren. Denken Sie daran: Geben Sie eine
ausgewogene Rückmeldung zur Leistung, indem Sie Stärken und
Verbesserungsbereiche benennen.

Beziehen Sie sich in Ihrem Feedback auf die Aufgabenbeschreibung
und/oder auf das Bewertungsraster (falls vorhanden). Ihr Feedback sollte
die Aufgabendetails im Licht des Entwurfs der Studierenden adressieren.
Wenn die Studierenden ein persönliches Ziel für die Aufgabe oder einen
Schwerpunkt genannt haben, beziehen Sie das ausdrücklich ein. Nachdem
Sie Ihr Feedback gegeben haben, bitten Sie die Studierenden, es in Ruhe
zu lesen, und fragen Sie anschließend, wie sie planen, Ihr Feedback
umzusetzen.

Wenn die Studierenden sagen, dass sie einen Verbesserungsvorschlag
aufgreifen möchten, fragen Sie, wie sie das konkret tun werden. Geben
Sie keine Vorschläge; lassen Sie die Studierenden erklären, was sie als
Nächstes tun wollen. Wenn die Studierenden Fragen stellen, lassen Sie
sie zuerst sagen, was sie denken, was die Antwort sein könnte. Schließen
Sie ab, indem Sie daran erinnern, dass das Ziel die Verbesserung der
Arbeit ist, dass Peer-Feedback zusätzlich helfen kann, und dass die
Studierenden mit einer neuen Version wiederkommen und diese mit Ihnen
teilen können.

Regel: Schreiben oder produzieren Sie keine Arbeit für die Studierenden.
Ihr Ziel ist es, ausschließlich praktisches Feedback zu geben.

\end{tcolorbox}

\subsection{Tutor: Reflexionshilfe}\label{tutor-reflexionshilfe}

Funktion: Reflexion anleiten; Lernerfahrungen „destillieren``;
Distanzierung/Neurahmung fördern; Reflexion in Schreibaufgabe
überführen.

Didaktische Elemente: Guided Reflection; Self-distancing; metakognitive
Strukturierung; „One question at a time``.

Quelle: Angepasst \& übersetzt basierend auf Mollick \& Mollick / More
Useful Things (More Useful Things, o. J.).

\begin{tcolorbox}[enhanced jigsaw, breakable, titlerule=0mm, leftrule=.75mm, opacitybacktitle=0.6, rightrule=.15mm, arc=.35mm, left=2mm, colframe=quarto-callout-note-color-frame, opacityback=0, coltitle=black, bottomtitle=1mm, colback=white, toptitle=1mm, title=\textcolor{quarto-callout-note-color}{\faInfo}\hspace{0.5em}{Tutor: Reflexionshilfe}, bottomrule=.15mm, colbacktitle=quarto-callout-note-color!10!white, toprule=.15mm]

Sie sind ein hilfreicher und freundlicher Mentor und ein Experte darin,
Studierenden zu helfen, über Erfahrungen zu reflektieren, damit sie aus
diesen Erfahrungen Bedeutung und Lerngewinne ziehen können. Sie wissen,
dass Menschen während einer Erfahrung „im Moment`` sind und dass es
aktive Selbstbeobachtung braucht, um Abstand zur Erfahrung zu gewinnen
und daraus zu lernen.

Dies ist ein Dialog. Warten Sie immer auf die Antwort der Studierenden.
Sprechen Sie nicht für die Studierenden. Stellen Sie sich zunächst als
KI-Mentor vor und fragen Sie die Studierenden, worüber sie reflektieren
möchten. Sagen Sie ihnen, dass sie ggf. Anweisungen ihrer Lehrperson
erhalten haben. Warten Sie auf die Antwort. Stellen Sie immer nur eine
Frage auf einmal. Zu viele Fragen sind überwältigend.

Erklären Sie dann, warum Reflexion beim Lernen hilft -- einschließlich
der Tatsache, dass das Schreiben über eine Erfahrung entscheidend ist,
um Lehren daraus zu ziehen. Bieten Sie den Studierenden anschließend
drei Auswahlmöglichkeiten für Reflexionsübungen an. Jede Übung sollte
die Studierenden dazu bringen, die Erfahrung neu zu betrachten.

Sobald die Studierenden eine Wahl getroffen haben, bitten Sie sie, 2--3
Absätze zu schreiben. Bieten Sie nicht an, eine Reflexion für sie zu
entwerfen, und zeigen Sie ihnen kein Beispiel, wie eine Reflexion
aussehen könnte.

Warten Sie auf die Antwort. Wenn passend, können Sie den Studierenden
eine Frage zu ihrer Reflexion stellen. Schließen Sie dann ab, indem Sie
erklären, warum Reflexion wichtig ist, und dass die Studierenden weiter
über ihre Erfahrungen schreiben sollten -- das hilft, aus dem aktuellen
Moment heraus zu zoomen und eine breitere Perspektive sowie Einsichten
zu gewinnen.

\end{tcolorbox}

\phantomsection\label{refs}
\begin{CSLReferences}{1}{0}
\bibitem[\citeproctext]{ref-acemoglu2019}
Acemoglu, D., \& Restrepo, P. (2019). Automation and New Tasks: How
Technology Displaces and Reinstates Labor. \emph{Journal of Economic
Perspectives}, \emph{33}(2), 3--30.
\url{https://doi.org/10.1257/jep.33.2.3}.

\bibitem[\citeproctext]{ref-akimov2020}
Akimov, A., \& Malin, M. (2020). When old becomes new: a case study of
oral examination as an online assessment tool. \emph{Assessment \&
Evaluation in Higher Education}, \emph{45}(8), 1205--1221.
\url{https://doi.org/10.1080/02602938.2020.1730301}.

\bibitem[\citeproctext]{ref-allen2024}
Allen, S. J., \& Edelson, S. A. (2024). Brave New Classroom: Navigating
Educational Technology in Management Education. \emph{Journal of
Management Education}, \emph{48}(4), 603--609.
\url{https://doi.org/10.1177/10525629241243339}.

\bibitem[\citeproctext]{ref-an2025}
An, Y., Yu, J. H., \& James, S. (2025). Investigating the higher
education institutions' guidelines and policies regarding the use of
generative AI in teaching, learning, research, and administration.
\emph{International Journal of Educational Technology in Higher
Education}, \emph{22}(1), 10.
\url{https://doi.org/10.1186/s41239-025-00507-3}.

\bibitem[\citeproctext]{ref-docs_anthropic_com_data_organizer}
Anthropic (o. J.-a). \emph{Data organizer (prompt library)}.
\url{https://docs.anthropic.com/claude/page/data-organizer}.

\bibitem[\citeproctext]{ref-docs_anthropic_com_meeting_scribe}
Anthropic (o. J.-b). \emph{Meeting scribe (prompt library)}.
\url{https://docs.anthropic.com/claude/page/meeting-scribe}.

\bibitem[\citeproctext]{ref-anthropicCsvConverter}
Anthropic (2025a). \emph{CSV converter}.
\url{https://docs.anthropic.com/en/prompt-library/csv-converter}.

\bibitem[\citeproctext]{ref-anthropic2025a}
Anthropic (2025b, Dezember). Erste Schritte mit Agent Skills in der API.
\emph{Claude Docs}.
\url{https://platform.claude.com/docs/de/agents-and-tools/agent-skills/quickstart}.

\bibitem[\citeproctext]{ref-anthropicExcelFormulaExpert}
Anthropic (n.d.an.d.). \emph{Excel formula expert}.
\url{https://docs.anthropic.com/en/prompt-library/excel-formula-expert}.

\bibitem[\citeproctext]{ref-anthropicLatexLegend}
Anthropic (n.d.bn.d.). \emph{LaTeX legend}.
\url{https://docs.anthropic.com/en/prompt-library/latex-legend}.

\bibitem[\citeproctext]{ref-autor2015}
Autor, D. H. (2015).
\href{https://www.aeaweb.org/articles?id=10.1257\%2Fjep.29.3.3&source=post_page}{Why
are there still so many jobs? The history and future of workplace
automation}. \emph{Journal of economic perspectives}, \emph{29}(3),
3--30.

\bibitem[\citeproctext]{ref-azamy2025a}
Azamy, H. (2025, September). \emph{AI flash debates: Student
engagement}.
\url{https://hbsp.harvard.edu/inspiring-minds/ai-flash-debates-student-engagement}.

\bibitem[\citeproctext]{ref-baresel2024a}
Baresel, K., Eube, C., Knorr, D., Lutter, L., Nys, J. de, \& Röben, M.
(2024). \emph{KI-Gebrauch im Studienkontext dokumentieren}. 304839 b.
\url{https://doi.org/10.48548/PUBDATA-1476}.

\bibitem[\citeproctext]{ref-barra2024}
Barra, F. L., Costa, A., Rodella, G., Semeraro, F., \& Carenzo, L.
(2024). Shaping the future of simulator interactions: The role of
ChatGPT's Advanced Voice Mode. \emph{Resuscitation}, \emph{205}, 110452.
\url{https://doi.org/10.1016/j.resuscitation.2024.110452}.

\bibitem[\citeproctext]{ref-bent2025}
Bent, D., Handa, K., Durmus, E., Tamkin, A., McCain, M., Ritchie, S.,
Donegan, R., Martinez, J., \& Jones{]}, J. (2025-08-26, 20252025-08-26,
2025). \emph{Anthropic education report: How educators use claude}.
\url{https://www.anthropic.com/news/anthropic-education-report-how-educators-use-claude}.

\bibitem[\citeproctext]{ref-bien2025}
Bien, J., \& Mukherjee, G. (2025). Generative AI for Data Science 101:
Coding Without Learning to Code. \emph{Journal of Statistics and Data
Science Education}, \emph{33}(2), 129--142.
\url{https://doi.org/10.1080/26939169.2024.2432397}.

\bibitem[\citeproctext]{ref-bjork2011}
Bjork, E. L., \& Bjork, R. A. (2011). Making things hard on yourself,
but in a good way: Creating desirable difficulties to enhance learning.
\emph{Psychology and the real world: Essays illustrating fundamental
contributions to society}, \emph{2}(59--68), 56--64.

\bibitem[\citeproctext]{ref-brown2014}
Brown, P. C., Roediger, H. L., \& McDaniel, M. A. (2014).
\emph{\href{http://search.ebscohost.com/login.aspx?direct=true&scope=site&db=nlebk&db=nlabk&AN=771951}{Make
it stick: The science of successful learning}}. The Belknap Press of
Harvard University Press.

\bibitem[\citeproctext]{ref-brynjolfsson2025}
Brynjolfsson, E., Li, D., \& Raymond, L. (2025). Generative AI at work.
\emph{The Quarterly Journal of Economics}, qjae044.

\bibitem[\citeproctext]{ref-bubeck2023}
Bubeck, S., Chandrasekaran, V., Eldan, R., Gehrke, J., Horvitz, E.,
Kamar, E., Lee, P., Lee, Y. T., Li, Y., Lundberg, S., Nori, H., Palangi,
H., Ribeiro, M. T., \& Zhang, Y. (2023). \emph{Sparks of Artificial
General Intelligence: Early experiments with GPT-4}. arXiv.
\url{https://doi.org/10.48550/arXiv.2303.12712}.

\bibitem[\citeproctext]{ref-bubeck2025}
Bubeck, S., Coester, C., Eldan, R., Gowers, T., Lee, Y. T., Lupsasca,
A., Sawhney, M., Scherrer, R., Sellke, M., \& Spears, B. K. (2025).
\emph{Early science acceleration experiments with GPT-5}.

\bibitem[\citeproctext]{ref-cambra-fierro2025}
Cambra-Fierro, J. J., Blasco, M. F., López-Pérez, M.-E. E., \& Trifu, A.
(2025). ChatGPT adoption and its influence on faculty well-being: An
empirical research in higher education. \emph{Education and Information
Technologies}, \emph{30}(2), 1517--1538.
\url{https://doi.org/10.1007/s10639-024-12871-0}.

\bibitem[\citeproctext]{ref-chatterji2025a}
Chatterji, A. (2025).
\emph{\href{https://openai.com/index/the-state-of-enterprise-ai-2025-report/}{The
state of enterprise AI: 2025 report}} (Research Report). OpenAI.

\bibitem[\citeproctext]{ref-chen2024}
Chen, J., Liu, Z., Huang, X., Wu, C., Liu, Q., Jiang, G., et al. (2024).
When large language models meet personalization: Perspectives of
challenges and opportunities. \emph{World Wide Web-internet and Web
Information Systems}, \emph{27}(42).
\url{https://doi.org/10.1007/s11280-024-01276-1}.

\bibitem[\citeproctext]{ref-chi2018}
Chi, M. T. H., Adams, J., Bogusch, E. B., Bruchok, C., Kang, S.,
Lancaster, M., Levy, R., Li, N., McEldoon, K. L., Stump, G. S., Wylie,
R., Xu, D., \& Yaghmourian, D. L. (2018). Translating the ICAP Theory of
Cognitive Engagement Into Practice. \emph{Cognitive Science},
\emph{42}(6), 1777--1832. \url{https://doi.org/10/gd5n5p}.

\bibitem[\citeproctext]{ref-dellacqua2025}
Dell'Acqua, F., Ayoubi, C., Lifshitz-Assaf, H., Sadun, R., Mollick, E.
R., Mollick, L., Han, Y., Goldman, J., Nair, H., \& Taub, S. (2025).
\emph{The Cybernetic Teammate: A Field Experiment on Generative AI
Reshaping Teamwork and Expertise}.

\bibitem[\citeproctext]{ref-dellacqua2023}
Dell'Acqua, F., McFowland, E., Mollick, E. R., Lifshitz-Assaf, H.,
Kellogg, K., Rajendran, S., Krayer, L., Candelon, F., \& Lakhani, K. R.
(2023). \emph{Navigating the Jagged Technological Frontier: Field
Experimental Evidence of the Effects of AI on Knowledge Worker
Productivity and Quality}. \url{https://doi.org/10.2139/ssrn.4573321}.

\bibitem[\citeproctext]{ref-denny2023}
Denny, P., Kumar, V., \& Giacaman, N. (2023). Conversing with copilot:
Exploring prompt engineering for solving cs1 problems using natural
language.

\bibitem[\citeproctext]{ref-dihan2025}
Dihan, Q. A., Nihalani, B. R., Tooley, A. A., \& Elhusseiny, A. M.
(2025). Eyes on Google's NotebookLM: using generative AI to create
ophthalmology podcasts with a single click. \emph{Eye}, \emph{39}(2),
215--216. \url{https://doi.org/10.1038/s41433-024-03481-8}.

\bibitem[\citeproctext]{ref-dunlosky2013}
Dunlosky, J., Rawson, K. A., Marsh, E. J., Nathan, M. J., \& Willingham,
D. T. (2013). Improving Students' Learning With Effective Learning
Techniques: Promising Directions From Cognitive and Educational
Psychology. \emph{Psychological science in the public interest : a
journal of the American Psychological Society}, \emph{14}(1), 4--58.
\url{https://doi.org/10.1177/1529100612453266}.

\bibitem[\citeproctext]{ref-eikenberg2025}
Eikenberg, R. (2025). Browser-Helferlein per KI generieren. \emph{c't
Special}, \emph{2}, 94--99.

\bibitem[\citeproctext]{ref-elsworth2025}
Elsworth, C., Huang, K., Patterson, D., Schneider, I., Sedivy, R.,
Goodman, S., Townsend, B., Ranganathan, P., Dean, J., \& Vahdat, A.
(2025). Measuring the environmental impact of delivering AI at Google
Scale. \emph{arXiv preprint arXiv:2508.15734}.

\bibitem[\citeproctext]{ref-fischer2024}
Fischer, I., \& Dobbins, K. (2024). Is it Worth it? How Paradoxical
Tensions of Identity Shape the Readiness of Management Educators to
Embrace Transformative Technologies in their Teaching. \emph{Journal of
Management Education}, \emph{48}(4), 829--848.
\url{https://doi.org/10.1177/10525629231201843}.

\bibitem[\citeproctext]{ref-freeman2025}
Freeman, J. (2025).
\href{https://www.hepi.ac.uk/reports/student-generative-ai-survey-2025/}{Student
generative AI survey 2025}. \emph{Higher Education Policy Institute:
London, UK}, (HEPI Policy Note 61).

\bibitem[\citeproctext]{ref-friedrich2023}
Friedrich, J.-D. (2023, Februar 8). Zur Bedeutung von ChatGPT \& der
Notwendigkeit eines progressiven Umgangs mit neuen KI-Technologien im
Hochschulbereich. Ein Zwischenstand in 6 Thesen.
\url{https://hochschulforumdigitalisierung.de/zur-bedeutung-von-chatgpt-der-notwendigkeit-eines-progressiven-umgangs-mit-neuen-ki-technologien-im-hochschulbereich-ein-zwischenstand-in-6-thesen/}.

\bibitem[\citeproctext]{ref-gieselmann2024}
Gieselmann, H. (2024, August 16). Wie Sie Musik live coden mit Sonic Pi
unterstützt von Sprachmodellen. \emph{c't Magazin}.
\url{https://www.heise.de/ratgeber/Wie-Sie-Musik-live-coden-mit-Sonic-Pi-unterstuetzt-von-Sprachmodellen-9829751.html}.

\bibitem[\citeproctext]{ref-gimpel2023a}
Gimpel, H., Hall, K., Decker, S., Eymann, T., Lämmermann, L., Mädche,
A., Röglinger, M., Ruiner, C., Schoch, M., \& Schoop, M. (2023).
\emph{Unlocking the power of generative AI models and systems such as
GPT-4 and ChatGPT for higher education: A guide for students and
lecturers}. Hohenheim Discussion Papers in Business, Economics and
Social Sciences.

\bibitem[\citeproctext]{ref-gmeiner2025}
Gmeiner, B. (2025). \emph{\href{https://www.bernhardgmeiner.com}{Ohne
Shortcut zur Leistung: KI-resistente Aufgabenformate im Unterricht. Ein
Handbuch für Lehrkräfte der Sekundarstufe}}. Self-published.

\bibitem[\citeproctext]{ref-gottweis2025}
Gottweis, J., Weng, W.-H., Daryin, A., Tu, T., Palepu, A., Sirkovic, P.,
Myaskovsky, A., Weissenberger, F., Rong, K., Tanno, R., Saab, K.,
Popovici, D., Blum, J., Zhang, F., Chou, K., Hassidim, A., Gokturk, B.,
Vahdat, A., Kohli, P., \ldots{} Natarajan, V. (2025). \emph{Towards an
AI co-scientist}. arXiv.
\url{https://doi.org/10.48550/arXiv.2502.18864}.

\bibitem[\citeproctext]{ref-greene-dewasmes2025a}
Greene-Dewasmes, G., \& Tladi, T. (2025, Januar 21). \emph{AI's energy
dilemma: Challenges, opportunities, and a path forward}.
\url{https://www.weforum.org/stories/2025/01/ai-energy-dilemma-challenges-opportunities-and-path-forward/}.

\bibitem[\citeproctext]{ref-grootendorst2025}
Grootendorst, M. (2025, Februar 3). \emph{A Visual Guide to Reasoning
LLMs}.
\url{https://newsletter.maartengrootendorst.com/p/a-visual-guide-to-reasoning-llms}.

\bibitem[\citeproctext]{ref-handa2025}
Handa, K., Bent, D., Tamkin, A., McCain, M., Durmus, E., Stern, M.,
Schiraldi, M., Huang, S., Ritchie, S., Syverud, S., Jagadish, K., Vo,
M., Bell, M., \& Ganguli, D. (2025-04-08, 2025).
\emph{\href{https://www.anthropic.com/news/anthropic-education-report-how-university-students-use-claude}{Anthropic
education report: How university students use claude}}.

\bibitem[\citeproctext]{ref-handa2025a}
Handa, K., Tamkin, A., McCain, M., Huang, S., Durmus, E., Heck, S.,
Mueller, J., Hong, J., Ritchie, S., Belonax, T., Troy, K. K., Amodei,
D., Kaplan, J., Clark, J., \& Ganguli, D. (2025).
\emph{\href{https://assets.anthropic.com/m/2e23255f1e84ca97/original/Economic_Tasks_AI_Paper.pdf}{Which
economic tasks are performed with AI? Evidence from millions of claude
conversations}} (Report). Anthropic.

\bibitem[\citeproctext]{ref-hanoverresearch2024}
Hanover Research (2024).
\emph{\href{https://cms.ahs.uic.edu/inside-ahs/wp-content/uploads/sites/12/2024/04/Assessment-and-Generative-Artificial-Intelligence-in-Higher-Education.pdf}{Assessment
and generative artificial intelligence in higher education}} (Report).
Hanover Research.

\bibitem[\citeproctext]{ref-hassany2024}
Hassany, M., Brusilovsky, P., Ke, J., Akhuseyinoglu, K., \& Narayanan,
A. B. L. (2024). \emph{Human-AI Co-Creation of Worked Examples for
Programming Classes}. arXiv.
\url{https://doi.org/10.48550/ARXIV.2402.16235}.

\bibitem[\citeproctext]{ref-hattie2023}
Hattie, J. (2023). \emph{Visible learning, the sequel: a synthesis of
over 2,100 meta-analyses relating to achievement}. Routledge, Taylor \&
Francis Group. \url{https://doi.org/10.4324/9781003380542}.

\bibitem[\citeproctext]{ref-hayashi2025}
Hayashi, Y., Shimojo, S., \& Kawamura, T. (2025). Scripted interventions
versus reciprocal teaching in collaborative learning: A comparison of
pedagogical and teachable agents using a cognitive architecture.
\emph{Learning and Instruction}, \emph{96}, 102057.
\url{https://doi.org/10.1016/j.learninstruc.2024.102057}.

\bibitem[\citeproctext]{ref-heetkamp2023}
Heetkamp, S. J. (2023, Dezember 13). Die VR-Revolution im Justizwesen.
\url{https://www.deutscheranwaltspiegel.de/e-justice/digitalisierung/die-vr-revolution-im-justizwesen-151520/}.

\bibitem[\citeproctext]{ref-heidt2025}
Heidt, A. (2025). ChatGPT for students: learners find creative new uses
for chatbots. \emph{Nature}, \emph{639}(8053), 265--266.
\url{https://doi.org/10.1038/d41586-025-00621-2}.

\bibitem[\citeproctext]{ref-henderson2007}
Henderson, C., \& Dancy, M. H. (2007). Barriers to the use of
research-based instructional strategies: The influence of both
individual and situational characteristics. \emph{Physical Review
Special Topics---Physics Education Research}, \emph{3}(2), 020102.

\bibitem[\citeproctext]{ref-hobbick2025}
Hobbick, S. (2025). \emph{Simulated telephone triage calls}.
\url{https://aipedagogy.org/assignment/simulated-telephone-triage-calls/}.

\bibitem[\citeproctext]{ref-huffman2024}
Huffman, P., \& Hutson, J. (2024).
\href{https://digitalcommons.lindenwood.edu/faculty-research-papers/683}{Enhancing
History Education with Google NotebookLM: Case Study of Mary Easton
Sibley's Diary for Multimedia Content and Podcast Creation}. \emph{ISRG
Journal of Arts, Humanities and Social Sciences}, \emph{2}(5).

\bibitem[\citeproctext]{ref-che2025ki}
Hüsch, Marc, Horstmann, N., \& Breiter, A. (2025).
\emph{\href{https://hochschuldaten.che.de/kuenstliche-intelligenz-im-studium-die-sicht-von-studierenden-im-wintersemester-2024-25/}{Künstliche
Intelligenz im Studium: Die Sicht von Studierenden im Wintersemester
2024/25}}.

\bibitem[\citeproctext]{ref-invertedstone2025}
InvertedStone (2025, August 30). \emph{OpenAI API Pricing Calculator}.
\url{https://invertedstone.com/calculators/openai-pricing}.

\bibitem[\citeproctext]{ref-ippolito2025}
Ippolito, J. (2025). \emph{AI sandwich}.
\url{https://aipedagogy.org/assignment/ai-sandwich/}.

\bibitem[\citeproctext]{ref-jones2025}
Jones, C. R., \& Bergen, B. K. (2025). \emph{Large Language Models Pass
the Turing Test}. arXiv.
\url{https://doi.org/10.48550/arXiv.2503.23674}.

\bibitem[\citeproctext]{ref-jurafsky2025}
Jurafsky, D., \& Martin, J. H. (2025).
\emph{\href{https://web.stanford.edu/~jurafsky/slp3/}{Speech and
language processing: An introduction to natural language processing,
computational linguistics, and speech recognition with language
models}}.

\bibitem[\citeproctext]{ref-jurran2025}
Jurran, N. (2025). ChatGPT als sprechtrainer. \emph{c't Special},
\emph{2}, 100--103.

\bibitem[\citeproctext]{ref-kazu2025}
Kazu, İ. Y., \& Kuvvetli, M. (2025). Digital language learning with
Duolingo: assessing its impact on listening, speaking, reading, and
writing skills. \emph{Journal of Computers in Education}.
\url{https://doi.org/10.1007/s40692-025-00355-0}.

\bibitem[\citeproctext]{ref-kearney2019}
Kearney, S. (2019). Transforming the first-year experience through self
and peer assessment. \emph{Journal of University Teaching and Learning
Practice}, \emph{16}(5), 1--17.

\bibitem[\citeproctext]{ref-kentz2025}
Kentz, M. (2025). \emph{Interview a fictional character}.
\url{https://aipedagogy.org/assignment/interview-a-fictional-character/}.

\bibitem[\citeproctext]{ref-kestin2024}
Kestin, Gregory, Miller, K., Klales, A., Milbourne, T., \& Ponti, G.
(2024). \emph{AI Tutoring Outperforms Active Learning}.
\url{https://doi.org/10.21203/rs.3.rs-4243877/v1}.

\bibitem[\citeproctext]{ref-kestin2025}
Kestin, Greg, Miller, K., Klales, A., Milbourne, T., \& Ponti, G.
(2025). AI tutoring outperforms in-class active learning: an RCT
introducing a novel research-based design in an authentic educational
setting. \emph{Scientific Reports}, \emph{15}(1), 17458.
\url{https://doi.org/10.1038/s41598-025-97652-6}.

\bibitem[\citeproctext]{ref-klein2023}
Klein, D. A. (2023, Februar 17). „Die Hausarbeit ist tot, es lebe die
Hausarbeit!{}`` - Entwicklungsorientierung, wissenschaftliches Arbeiten
und KI gemeinsam denken.
\url{https://hochschulforumdigitalisierung.de/die-hausarbeit-ist-tot-es-lebe-die-hausarbeit-entwicklungsorientierung-wissenschaftliches-arbeiten-und-ki-gemeinsam-denken/}.

\bibitem[\citeproctext]{ref-korinek2024}
Korinek, A. (2024). \emph{Large language models learn to collaborate and
reason: December 2024 update on generative AI}.

\bibitem[\citeproctext]{ref-kwa2025}
Kwa, T., West, B., Becker, J., Deng, A., Garcia, K., Hasin, M., Jawhar,
S., Kinniment, M., Rush, N., Arx, S. V., Bloom, R., Broadley, T., Du,
H., Goodrich, B., Jurkovic, N., Miles, L. H., Nix, S., Lin, T., Parikh,
N., \ldots{} Chan, L. (2025). \emph{Measuring AI Ability to Complete
Long Tasks}. arXiv. \url{https://doi.org/10.48550/arXiv.2503.14499}.

\bibitem[\citeproctext]{ref-landfair2025}
Landfair, A. (2025). \emph{Playtesting your ChatGPT prompt}.
\url{https://aipedagogy.org/assignment/playtesting-your-chatgpt-prompt/}.

\bibitem[\citeproctext]{ref-lee2025}
Lee, H.-P. H., Sarkar, A., Tankelevitch, L., Drosos, I., Rintel, S.,
Banks, R., \& Wilson, N. (2025). \emph{The Impact of Generative AI on
Critical Thinking: Self-Reported Reductions in Cognitive Effort and
Confidence Effects From a Survey of Knowledge Workers}.

\bibitem[\citeproctext]{ref-lehrevirtuell-universitaetfrankfurt2023}
Lehre virtuell - Universität Frankfurt (2023, Oktober 6). Einsatz von
generativer KI im Studium -- Handlungsempfehlungen für Studierende --
Lehre virtuell.
\url{https://lehre-virtuell.uni-frankfurt.de/knowhow/einsatz-von-generativer-ki-im-studium-handlungsempfehlungen-fuer-studierende/}.

\bibitem[\citeproctext]{ref-liang2024}
Liang, J. T., Yang, C., \& Myers, B. A. (2024). A large-scale survey on
the usability of ai programming assistants: Successes and challenges.

\bibitem[\citeproctext]{ref-liang2025}
Liang, W., Zhang, Y., Codreanu, M., Wang, J., Cao, H., \& Zou, J.
(2025). The Widespread Adoption of Large Language Model-Assisted Writing
Across Society. \emph{arXiv preprint arXiv:2502.09747}.

\bibitem[\citeproctext]{ref-lindsey2025}
Lindsey, J., Gurnee, W., Ameisen, E., Chen, B., Pearce, A., Turner, N.
L., Citro, C., Abrahams, D., Carter, S., Hosmer, B., Marcus, J., Sklar,
M., Templeton, A., Bricken, T., McDougall, C., Cunningham, H., Henighan,
T., Jermyn, A., Jones, A., \ldots{} Batson, J. (2025).
\href{https://transformer-circuits.pub/2025/attribution-graphs/biology.html}{On
the biology of a large language model}. \emph{Transformer Circuits
Thread}.

\bibitem[\citeproctext]{ref-love2025}
Love, R., Law, E., Cohen, P. R., \& Kulić, D. (2025). Teaching a
Conversational Agent using Natural Language: Effect on Learning and
Engagement. \emph{International Journal of Artificial Intelligence in
Education}. \url{https://doi.org/10.1007/s40593-025-00461-1}.

\bibitem[\citeproctext]{ref-lovely2025}
Lovely, G. (2025). AI could soon tackle projects that take humans weeks.
\emph{Nature}. \url{https://doi.org/10.1038/d41586-025-00831-8}.

\bibitem[\citeproctext]{ref-lu2024a}
Lu, X., \& Wang, X. (2024). Generative students: Using LLM-simulated
student profiles to support question item evaluation.
\url{https://doi.org/10.48550/arXiv.2405.11591}.

\bibitem[\citeproctext]{ref-lyu2025}
Lyu, B., Li, C., Li, H., Oh, H., Song, Y., Zhu, W., \& Xing, W. (2025).
The Role of Teachable Agents' Personality Traits on Student-AI
Interactions and Math Learning. \emph{Computers \& Education}, 105314.
\url{https://doi.org/10.1016/j.compedu.2025.105314}.

\bibitem[\citeproctext]{ref-ma2025}
Ma, T. (2025). Systematically visualizing ChatGPT used in higher
education: Publication trend, disciplinary domains, research themes,
adoption and acceptance. \emph{Computers and Education: Artificial
Intelligence}, \emph{8}, 100336.
\url{https://doi.org/10.1016/j.caeai.2024.100336}.

\bibitem[\citeproctext]{ref-marangunic2015b}
Marangunić, N., \& Granić, A. (2015). Technology acceptance model: a
literature review from 1986 to 2013. \emph{Universal Access in the
Information Society}, \emph{14}(1), 81--95.
\url{https://doi.org/10.1007/s10209-014-0348-1}.

\bibitem[\citeproctext]{ref-masley2025}
Masley, A. (2025, April 28). A cheat sheet for why using ChatGPT is not
bad for the environment.
\url{https://andymasley.substack.com/p/a-cheat-sheet-for-conversations-about}.

\bibitem[\citeproctext]{ref-mcafee2024}
McAfee, A. (2024).
\emph{\href{https://ide.mit.edu/wp-content/uploads/2024/04/Davos-Report-Draft-XFN-Copy-01112024-Print-Version.pdf?x76181}{Generally
Faster: The Economic Impact of Generative AI}} (Davos Report). Google.

\bibitem[\citeproctext]{ref-mcknight2022}
McKnight, L. (2022, Oktober 14). \emph{Eight ways to engage with AI
writers in higher education}.
\url{https://www.timeshighereducation.com/campus/eight-ways-engage-ai-writers-higher-education}.

\bibitem[\citeproctext]{ref-meehan2025}
Meehan, S. (2025). \emph{Generative AI and stasis theory}.
\url{https://aipedagogy.org/assignment/generative-ai-and-stasis-theory/}.

\bibitem[\citeproctext]{ref-meincke2025a}
Meincke, L., Mollick, E. R., Mollick, L., \& Shapiro, D. (2025a).
\emph{Prompting Science Report 2: The Decreasing Value of Chain of
Thought in Prompting}. arXiv.
\url{https://doi.org/10.48550/arXiv.2506.07142}.

\bibitem[\citeproctext]{ref-meincke2024}
Meincke, L., Mollick, E. R., \& Terwiesch, C. (2024). \emph{Prompting
Diverse Ideas: Increasing AI Idea Variance}.
\url{https://papers.ssrn.com/abstract=4708466}.

\bibitem[\citeproctext]{ref-meincke2025}
Meincke, L., Mollick, E., Mollick, L., \& Shapiro, D. (2025b).
\emph{Prompting Science Report 1: Prompt Engineering is Complicated and
Contingent}. arXiv. \url{https://doi.org/10.48550/arXiv.2503.04818}.

\bibitem[\citeproctext]{ref-mitteaching+learninglab2023}
MIT Teaching + Learning Lab (2023). \emph{Rethinking Your Problem Sets
in the World of Generative AI \textbar{} Teaching + Learning Lab}.
\url{https://tll.mit.edu/rethinking-your-problem-sets-in-the-world-of-generative-ai/}.

\bibitem[\citeproctext]{ref-mollick2023}
Mollick, E. R. (2023, Juli 1). The Homework Apocalypse.
\url{https://www.oneusefulthing.org/p/the-homework-apocalypse}.

\bibitem[\citeproctext]{ref-mollick2025}
Mollick, E. R. (2025a, Januar 26). \emph{A new generation of AIs: Claude
3.7 and Grok 3}.
\url{https://www.oneusefulthing.org/p/a-new-generation-of-ais-claude-37}.

\bibitem[\citeproctext]{ref-mollick2025a}
Mollick, E. R. (2025b, Juni 23). \emph{GPT-5: It Just Does Stuff}.
\url{https://www.oneusefulthing.org/p/gpt-5-it-just-does-stuff}.

\bibitem[\citeproctext]{ref-mollick2025d}
Mollick, E. R. (2025c, August 7). \emph{The Shape of AI: Jaggedness,
Bottlenecks and Salients}.
\url{https://www.oneusefulthing.org/p/the-shape-of-ai-jaggedness-bottlenecks}.

\bibitem[\citeproctext]{ref-mollick2022}
Mollick, E. R., \& Mollick, L. (2022). \emph{New Modes of Learning
Enabled by AI Chatbots: Three Methods and Assignments}.
\url{https://doi.org/10.2139/ssrn.4300783}.

\bibitem[\citeproctext]{ref-mollick2023h}
Mollick, E. R., \& Mollick, L. (2023a). \emph{Assigning AI: Seven
approaches for students, with prompts}.
\url{https://doi.org/10.2139/ssrn.4564159}.

\bibitem[\citeproctext]{ref-mollick2023b}
Mollick, E. R., \& Mollick, L. (2023b).
\emph{\href{https://papers.ssrn.com/abstract=4391243}{Using AI to
Implement Effective Teaching Strategies in Classrooms: Five Strategies,
Including Prompts}} (SSRN Scholarly Paper; Nr. 4391243).

\bibitem[\citeproctext]{ref-mollick2023a}
Mollick, E. R., \& Mollick, L. (2023c). \emph{Assigning AI: Seven
Approaches for Students, with Prompts}. arXiv.
\url{https://doi.org/10.48550/arXiv.2306.10052}.

\bibitem[\citeproctext]{ref-mollick2024a}
Mollick, E. R., \& Mollick, L. (2024). \emph{Instructors as Innovators:
a Future-focused Approach to New AI Learning Opportunities, With
Prompts}. \url{https://doi.org/10.2139/ssrn.4802463}.

\bibitem[\citeproctext]{ref-moreUsefulThingsInstructorPrompts}
Mollick, E. R., \& Mollick, L. (n.d.n.d.). \emph{Instructor prompts}.
\url{https://www.moreusefulthings.com/instructor-prompts}.

\bibitem[\citeproctext]{ref-mollick2024}
Mollick, E. R., Mollick, L., Bach, N., Ciccarelli, L. J., Przystanski,
B., \& Ravipinto, D. (2024). AI agents and education: Simulated practice
at scale. \emph{arXiv preprint arXiv:2407.12796}.

\bibitem[\citeproctext]{ref-monashuniversity2025}
Monash University (2025).
\emph{\href{https://www.monash.edu/learning-teaching/teachhq/Assessment/academic-integrity/how-to/design-assessment-for-academic-integrity}{Choosing
assessment tasks}}.

\bibitem[\citeproctext]{ref-monib2025}
Monib, W. K., Qazi, A., \& Mahmud, M. M. (2025). Exploring learners'
experiences and perceptions of ChatGPT as a learning tool in higher
education. \emph{Education and Information Technologies}, \emph{30}(1),
917--939. \url{https://doi.org/10.1007/s10639-024-13065-4}.

\bibitem[\citeproctext]{ref-MoreUsefulThingsStudentExercises}
More Useful Things (o. J.). \emph{Student exercises}.
\url{https://www.moreusefulthings.com/student-exercises}.

\bibitem[\citeproctext]{ref-morgan2024}
Morgan, G. (2024, Juli 11).
\href{https://onedtech.philhillaa.com/p/what-students-want-when-it-comes-to-ai}{What
Students Want When It Comes To AI - The Digital Education Council Global
AI Student Survey 2024}. \emph{On EdTech Newsletter}.

\bibitem[\citeproctext]{ref-morth2021}
Mörth, M., Paridon, H., \& Sonntag, U. (2021).
Kognitionswissenschaftliche Erkenntnisse und ihre Folgerungen für
evidenzbasierte Hochschullehre: die hochschullehre 05/2021. \emph{die
hochschullehre}, \emph{7}(1), 38--48.

\bibitem[\citeproctext]{ref-mulder2023}
Mulder, R., Baik, C., \& Ryan, T. (2023). \emph{Rethinking assessment in
response to AI} (Guide). Melbourne Centre for the Study of Higher
Education.

\bibitem[\citeproctext]{ref-murre2015}
Murre, J. M., \& Dros, J. (2015). Replication and analysis of
Ebbinghaus' forgetting curve. \emph{PloS one}, \emph{10}(7), e0120644.

\bibitem[\citeproctext]{ref-naddaf2025}
Naddaf, M. (2025). How are researchers using AI? Survey reveals pros and
cons for science. \emph{Nature}.
\url{https://doi.org/10.1038/d41586-025-00343-5}.

\bibitem[\citeproctext]{ref-newman2025}
Newman, S. (2025). \emph{Correct a bad essay}.
\url{https://aipedagogy.org/assignment/correct-a-bad-essay/}.

\bibitem[\citeproctext]{ref-nibheolain2020}
Ní~Bheoláin, R., Lowney, R., \& O'Riordan, F. (2020). \emph{Students as
Partners in Assessment (SaPiA): A Literature Scoping Review}.
\url{https://doi.org/10.5281/zenodo.4270579}.

\bibitem[\citeproctext]{ref-nizamudeen2024}
Nizamudeen, F., Gatti, L., Bouali, N., \& Ahmed, F. (2024).
Investigating the Impact of Code Generation Tools (ChatGPT \& Github
CoPilot) on Programming Education.
\url{https://doi.org/10.5220/0012628000003693}.

\bibitem[\citeproctext]{ref-odonnell2025}
O'Donnell, J., \& Crownhart, C. (2025, Mai 20).
\href{https://www.technologyreview.com/2025/05/20/1116327/ai-energy-usage-climate-footprint-big-tech/}{We
did the math on AI's energy footprint. Here's the story you haven't
heard.} \emph{MIT Technology Review}.

\bibitem[\citeproctext]{ref-ogunleye2024}
Ogunleye, B., Zakariyyah, K. I., Ajao, O., Olayinka, O., \& Sharma, H.
(2024). A Systematic Review of Generative AI for Teaching and Learning
Practice. \emph{Education Sciences}, \emph{14}(6), 636.
\url{https://doi.org/10.3390/educsci14060636}.

\bibitem[\citeproctext]{ref-openai2024}
OpenAI (2024).
\emph{\href{https://openai.com/index/learning-to-reason-with-llms/}{Learning
to reason with LLMs}}.

\bibitem[\citeproctext]{ref-openai2025b}
OpenAI (2025).
\emph{\href{https://openai.com/index/introducing-gpt-5/}{Introducing
GPT-5}}.

\bibitem[\citeproctext]{ref-oesterreichischeruniversitaetsprofessorux2finnenverband2018}
Österreichischer Universitätsprofessor/innenverband (2018).
\emph{\href{https://de.statista.com/statistik/daten/studie/831638/umfrage/arbeitszeitverteilung-von-professoren-in-oesterreich/}{Österreich
- Arbeitszeitverteilung von Professoren 2017}}.

\bibitem[\citeproctext]{ref-ou2024}
Ou, A. W., Stöhr, C., \& Malmström, H. (2024). Academic communication
with AI-powered language tools in higher education: From a post-humanist
perspective. \emph{System}, \emph{121}, 103225.
\url{https://doi.org/10.1016/j.system.2024.103225}.

\bibitem[\citeproctext]{ref-pedersen2025}
Pedersen, D. (2025). \emph{DuPont analysis of coca-cola}.
\url{https://aipedagogy.org/assignment/dupont-analysis-of-coca-cola/}.

\bibitem[\citeproctext]{ref-peng2023}
Peng, S., Kalliamvakou, E., Cihon, P., \& Demirer, M. (2023). \emph{The
Impact of AI on Developer Productivity: Evidence from GitHub Copilot}.
arXiv. \url{https://doi.org/10.48550/arXiv.2302.06590}.

\bibitem[\citeproctext]{ref-porter2024}
Porter, L., \& Zingaro, D. (2024). \emph{Learn AI-Assisted Python
Programming: With Github Copilot and ChatGPT}. Simon and Schuster.

\bibitem[\citeproctext]{ref-puryear2022}
Puryear, B., \& Sprint, G. (2022). Github copilot in the classroom:
learning to code with AI assistance. \emph{Journal of Computing Sciences
in Colleges}, \emph{38}(1), 37--47.

\bibitem[\citeproctext]{ref-ritchie2024}
Ritchie, H. (2024a, September 19). \emph{What's the impact of artificial
intelligence on energy demand?}
\url{https://www.sustainabilitybynumbers.com/p/ai-energy-demand}.

\bibitem[\citeproctext]{ref-ritchie2024a}
Ritchie, H. (2024b, November 18). \emph{What's the carbon footprint of
using ChatGPT?}
\url{https://www.sustainabilitybynumbers.com/p/carbon-footprint-chatgpt}.

\bibitem[\citeproctext]{ref-roediger2006}
Roediger, H. L., \& Karpicke, J. D. (2006). Test-enhanced learning:
taking memory tests improves long-term retention. \emph{Psychological
science}, \emph{17}(3), 249--255.
\url{https://doi.org/10.1111/j.1467-9280.2006.01693.x}.

\bibitem[\citeproctext]{ref-roediger2012}
Roediger, H. L., \& Pyc, M. A. (2012). Inexpensive techniques to improve
education: Applying cognitive psychology to enhance educational
practice. \emph{Journal of Applied Research in Memory and Cognition},
\emph{1}(4), 242--248.
\url{https://doi.org/10.1016/j.jarmac.2012.09.002}.

\bibitem[\citeproctext]{ref-rowland2023}
Rowland, D. R. (2023). Two frameworks to guide discussions around levels
of acceptable use of generative AI in student academic research and
writing. \emph{Journal of Academic Language and Learning}, \emph{17}(1),
T31--T69.

\bibitem[\citeproctext]{ref-russell2021}
Russell, S. J., \& Norvig, P. (2021). \emph{Artificial intelligence: a
modern approach}. Pearson.

\bibitem[\citeproctext]{ref-sauberli2024}
Säuberli, A., \& Clematide, S. (2024). Automatic generation and
evaluation of reading comprehension test items with large language
models. \url{https://doi.org/10.48550/arXiv.2404.07720}.

\bibitem[\citeproctext]{ref-scarlatos2025}
Scarlatos, A., Liu, N., Lee, J., Baraniuk, R., \& Lan, A. (2025).
Training LLM-based tutors to improve student learning outcomes in
dialogues. \emph{arXiv preprint}.

\bibitem[\citeproctext]{ref-schmidt2005}
Schmidt, B., \& Tippelt, R. (2005). Besser Lehren-Neues von der
Hochschuldidaktik?

\bibitem[\citeproctext]{ref-schomburg2012}
Schomburg, H., Flöther, C., \& Wolf, V. (2012). \emph{Wandel von Lehre
und Studium an deutschen Hochschulen--Erfahrungen und Sichtweisen der
Lehrenden}.

\bibitem[\citeproctext]{ref-schwarcz2025}
Schwarcz, D., Manning, S., Barry, P. J., Cleveland, D. R., Prescott, J.
J., \& Rich, B. (2025). \emph{AI-Powered Lawyering: AI Reasoning Models,
Retrieval Augmented Generation, and the Future of Legal Practice}.
\url{https://doi.org/10.2139/ssrn.5162111}.

\bibitem[\citeproctext]{ref-schwarze2025}
Schwarze, M. (2025, Juli 16).
\href{https://www.faz.net/pro/digitalwirtschaft/prompt-der-woche/ki-assistent-witsy-kann-kostenlos-das-chatgpt-monatsabo-ersetzen-110586296.html}{KI-Assistent
Witsy kann kostenlos das ChatGPT-Monatsabo ersetzen}. \emph{Frankfurter
Allgemeine Zeitung (FAZ)}.

\bibitem[\citeproctext]{ref-shaer2024}
Shaer, O., Cooper, A., Mokryn, O., Kun, A. L., \& Ben Shoshan, H.
(2024). AI-augmented brainwriting: Investigating the use of llms in
group ideation. \url{https://doi.org/10.48550/arXiv.2402.14978}.

\bibitem[\citeproctext]{ref-snell2024}
Snell, C., Lee, J., Xu, K., \& Kumar, A. (2024). Scaling llm test-time
compute optimally can be more effective than scaling model parameters.
\emph{arXiv preprint arXiv:2408.03314}.

\bibitem[\citeproctext]{ref-spencer2024}
Spencer, T., \& Singh, S. (2024, Oktober 18). What the data centre and
AI boom could mean for the energy sector -- Analysis.
\url{https://www.iea.org/commentaries/what-the-data-centre-and-ai-boom-could-mean-for-the-energy-sector}.

\bibitem[\citeproctext]{ref-spencer2025}
Spencer, T., \& Singh, S. (2025).
\emph{\href{https://www.iea.org/reports/energy-and-ai}{Energy and AI}}
(World Energy Outlook Special Report). International Energy Agency.

\bibitem[\citeproctext]{ref-steinberger2025}
Steinberger, P. (2025, Oktober 14). \emph{Just Talk To It - the no-bs
Way of Agentic Engineering \textbar{} Peter Steinberger}.
\url{https://steipete.me/posts/just-talk-to-it}.

\bibitem[\citeproctext]{ref-sweller2011}
Sweller, J. (2011). Cognitive load theory. In \emph{Psychology of
learning and motivation}: (Bd. 55, 37--76). Elsevier.

\bibitem[\citeproctext]{ref-taylor2025}
Taylor, S. (2025). \emph{AI, the future, and you}.
\url{https://aipedagogy.org/assignment/ai-the-future-and-you/}.

\bibitem[\citeproctext]{ref-tobor2024}
Tobor, J. (2024).
\emph{\href{https://hochschulforumdigitalisierung.de/wp-content/uploads/2024/02/HFD_Blickpunkt_KI-Leitlinien_final.pdf}{Leitlinien
zum Umgang mit generativer KI}}. Hochschulforum Digitalisierung.

\bibitem[\citeproctext]{ref-tobor2025}
Tobor, J. (2025).
\emph{\href{https://hochschulforumdigitalisierung.de/news/blickpunkt-ki-leitlinien/}{Recap:
KI-leitlinien als beispiel für soziotechnische aushandlungsprozesse}}.

\bibitem[\citeproctext]{ref-tutton2025}
Tutton, M., \& Cohen, D. (2025). Reconceptualizing the Role of the
University Language Teacher in Light of Generative AI. \emph{Education
Sciences}, \emph{15}(1), 56.
\url{https://doi.org/10.3390/educsci15010056}.

\bibitem[\citeproctext]{ref-vaswani2017}
Vaswani, A., Shazeer, N., Parmar, N., Uszkoreit, J., Jones, L., Gomez,
A. N., Kaiser, Ł., \& Polosukhin, I. (2017). Attention is all you need.
\emph{Advances in neural information processing systems}, \emph{30}.

\bibitem[\citeproctext]{ref-vellum2024}
Vellum (2024, September 4). \emph{LLM Leaderboard 2024}.
\url{https://www.vellum.ai/llm-leaderboard}.

\bibitem[\citeproctext]{ref-walsh2025}
Walsh, J. D. (2025).
\href{https://nymag.com/intelligencer/article/openai-chatgpt-ai-cheating-education-college-students-school.html}{Everyone
is cheating their way through college: ChatGPT has unraveled the entire
academic project}. \emph{New York Magazine}.

\bibitem[\citeproctext]{ref-wang2024}
Wang, S., Xu, T., Li, H., Zhang, C., Liang, J., Tang, J., Yu, P. S., \&
Wen, Q. (2024). Large language models for education: A survey and
outlook. \emph{arXiv preprint arXiv:2403.18105}.

\bibitem[\citeproctext]{ref-wannemacher2025}
Wannemacher, K., Bosse, E., Lübcke, M., \& Kaemena, A. (2025).
\emph{\href{https://hochschulforumdigitalisierung.de/dossier/generative-ki/}{Wie
KI studium und lehre verändert. Anwendungsfelder, use-cases und
gelingensbedingungen}} (Arbeitspapier Nr. 87). Hochschulforum
Digitalisierung.

\bibitem[\citeproctext]{ref-ward2024}
Ward, M., O'Riordan, F., Logan-Fleming, D., Cooke, D., Concannon-Gibney,
T., Efthymiou, M., \& Watkins, N. (2024). Interactive oral assessment
case studies: An innovative, academically rigorous, authentic assessment
approach. \emph{Innovations in Education and Teaching International},
\emph{61}(5), 930--947.
\url{https://doi.org/10.1080/14703297.2023.2251967}.

\bibitem[\citeproctext]{ref-welsh2025}
Welsh, K. (2025). \emph{Rehearsal to a real-life interview}.
\url{https://aipedagogy.org/assignment/rehearsal-to-real-life-interview/}.

\bibitem[\citeproctext]{ref-willemain1994}
Willemain, T. R. (1994). Insights on modeling from a dozen experts.
\emph{Operations Research}, \emph{42}(2), 213--222.

\bibitem[\citeproctext]{ref-willemain1995}
Willemain, T. R. (1995). Model Formulation: What Experts Think About and
When. \emph{Operations Research}, \emph{43}(6), 916--932.
\url{https://doi.org/10.1287/opre.43.6.916}.

\bibitem[\citeproctext]{ref-willison2025}
Willison, S. (2025a, Oktober 5). Embracing the parallel coding agent
lifestyle. \emph{Simon Willison's Weblog}.
\url{https://simonwillison.net/2025/Oct/5/parallel-coding-agents/}.

\bibitem[\citeproctext]{ref-willison2025a}
Willison, S. (2025b, November 20). Nano Banana Pro aka
gemini-3-pro-image-preview is the best available image generation model.
\emph{Simon Willison's Weblog}.
\url{https://simonwillison.net/2025/Nov/20/nano-banana-pro/}.

\bibitem[\citeproctext]{ref-systemPromptLibrary}
Wilson, N., \& Tingley, D. (n.d.n.d.). \emph{System prompt library}.
\url{https://github.com/ncwilson78/System-Prompt-Library}.

\bibitem[\citeproctext]{ref-wittenberg2025a}
Wittenberg, A. (2025, Mai 6).
\href{https://www.politico.com/news/2025/05/06/elon-musk-xai-memphis-gas-turbines-air-pollution-permits-00317582}{{„How
come I can't breathe?``}: Musk's data company draws a backlash in
Memphis - POLITICO}. \emph{Politico}.

\bibitem[\citeproctext]{ref-wu2024a}
Wu, R., \& Yu, Z. (2024). Do AI chatbots improve students learning
outcomes? Evidence from a meta-analysis. \emph{British Journal of
Educational Technology}, \emph{55}(1), 10--33.
\url{https://doi.org/10.1111/bjet.13334}.

\bibitem[\citeproctext]{ref-wu2023a}
Wu, Y., Jia, F., Zhang, S., Li, H., Zhu, E., Wang, Y., Lee, Y. T., Peng,
R., Wu, Q., \& Wang, C. (2023). \emph{MathChat: Converse to Tackle
Challenging Math Problems with LLM Agents}. arXiv.
\url{https://doi.org/10.48550/ARXIV.2306.01337}.

\bibitem[\citeproctext]{ref-you2025}
You, J. (2025, Februar 7). How much energy does ChatGPT use? \emph{Epoch
AI}.
\url{https://epoch.ai/gradient-updates/how-much-energy-does-chatgpt-use}.

\bibitem[\citeproctext]{ref-yuen2025}
Yuen, N. (2025). \emph{Questioning the bot: Socratic chats with AI}.
\url{https://aipedagogy.org/assignment/questioning-the-bot-socratic-chats-with-ai-2/}.

\bibitem[\citeproctext]{ref-zhang2025}
Zhang, Y.-F., Li, H., Song, D., Sun, L., Xu, T., \& Wen, Q. (2025).
\emph{From Correctness to Comprehension: AI Agents for Personalized
Error Diagnosis in Education}. arXiv.
\url{https://doi.org/10.48550/ARXIV.2502.13789}.

\end{CSLReferences}




\end{document}
