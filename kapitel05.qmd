---
title: "Empfehlungen zur Umsetzung"
bibliography: references.json
csl: apa.csl
lang: de
reference-section-title: "Literaturverzeichnis"
format:
  html:
    toc: true
    toc-location: right
    number-sections: true
---

## Typische Aufgaben und Fragestellungen mit der KI durchspielen, Prompts anpassen, experimentieren

Lehrende sollten zunächst Informationen sammeln, um zu verstehen, was KI mit den Aufgaben in ihrem Kurs bewirken kann [@mitteaching+learninglab2023]. Melden Sie sich bei einem der professionellen KI-Dienste an wie ChatGPT oder Claude an und spielen Sie mit exemplarischen Konzepten, Fragen und Aufgabensets aus dem Kurs. Dabei ist es wichtig, nicht gleich bei der ersten schlechten Antwort aufzugeben, sondern Anpassungsmöglichkeiten durchzugehen: Lässt sich der **Input beschränken**? (Fragen auf einen Text-Input, eine gute Internetquelle oder eine hochgeladene PDF beschränken.) Lässt sich der **Prompt anpassen**? (Bearbeitung schrittweise durchführen lassen, Optionen und Szenarien durchgehen lassen usw., siehe den Abschnitt 2.5.2 zu Prompt Engineering.)

Wichtig ist, sich zu überlegen, welches Lernziel jede Aufgabe hat und wie die KI damit umgeht. Es sollte bewertet werden, bei welchen Arten von Fragen die KI gut abschneidet und wo ihre Grenzen liegen [@dellacqua2023a]. Diese Erkenntnisse können dann genutzt werden, um etwa Aufgabensets und andere Aufgabenstellungen besser zu strukturieren.

## Ausrichtung der Anpassungen nach Empfehlungen der Lernforschung

Um die Empfehlungen der Lernforschung in das Vorgehen mit Künstlicher Intelligenz (KI) und Aufgabensets zu integrieren, könnten folgende Schritte unternommen werden [@mitteaching+learninglab2023]:

* **Zeitliche Verteilung und inhaltliche Mischung von Lerninhalten (Spacing & interleaving)**: Die Aufgabensets sollten so gestaltet werden, dass sie über das Semester verteilt sind und eine Vielfalt an Themen abdecken. Dies fördert die Langzeiterinnerung und hilft den Studierenden, die Anwendung der Konzepte in verschiedenen Kontexten zu üben. KI kann genutzt werden, um personalisierte Lernpläne zu erstellen, die auf den individuellen Fortschritt der Studierenden abgestimmt sind und eine Mischung aus verschiedenen Aufgabentypen bieten.
* **Testgestütztes Lernen (Test-enhanced learning)**: Regelmäßige, durch KI unterstützte Quizze und Tests können in den Lehrplan integriert werden, um das Abrufen von Informationen zu fördern. Diese Tests könnten auch die kritische Bewertung von KI-generierten Antworten beinhalten, um die kritische Denkfähigkeit der Studierenden zu schärfen.
* **Fragebasierte Ausarbeitung (Explanatory questioning)**: KI-Tutor-Bots könnten entwickelt werden, um Studierende durch gezielte “Warum”-Fragen zu leiten, die ein tieferes Verständnis des Materials fördern. Diese Bots könnten in Simulationen und Rollenspielen eingesetzt werden, um die Studierenden dazu zu bringen, ihre Entscheidungen zu erklären und zu reflektieren, wodurch die Anwendung von Konzepten in realen oder simulierten Situationen vertieft wird.

## Einführung der Studierenden planen: Besser praktisch, häufig und niedrigschwellig

Den Einsatz von KI lernen die Studierenden, wenn sie häufig und über das Semester zeitversetzt damit experimentieren dürfen und müssen. Auch hier führen wieder die Empfehlungen des **Spacing & Interleaving** zu höherer Effektivität. Unterstützend können **externe Lernvideos** von seriösen Plattformen wie dem KI-Campus genutzt werden (z.B. https://ki-campus.org/videos/generativeki) oder selbst erstellte hochschulweite Angebote wie die Lehrpfade der TH Köln (https://lehrpfade.th-koeln.de/kategorie/ki/).

Um ein gemeinsames Verständnis über Grundlagen herzustellen, ist es hilfreich, **Zeit in einer der ersten Präsenzveranstaltungen einzuräumen**, um das gemeinsam zu üben. Der Sprung ins kalte Wasser ist dabei meist besser, als eine lange Theorieeinführung: **Gleich anfangen**, dann problembasiert erläutern. Aspekte von **testbasiertem Lernen** und **fragebasierte Ausarbeitung** lassen sich gut über Anwendungsaufgaben in der Präsenzveranstaltung einbauen.

### Beispiel: KI-Übung in Präsenzveranstaltung am Ende eines Theorieblock zu Nachhaltigkeit in Lieferketten

**Aufgabe:** Nicht lange schnacken, gleich anpacken! Mit der KI einen Projektplan für erste konkrete Schritte einer Nachhaltigkeitsstrategie erstellen (Edge Browser, Bing Copilot = GPT-4). Prompts zum Einstieg werden den Studierenden vorgegeben. Anfang mit:

* *Prompt #1*: „KI als Tutor“ oder ähnlich (siehe Appendix: Beispiel KI als Tutor #1/ Allgemeiner Tutor. Prompts im Folgenden immer *kursiv*.)
* *Prompt #2*: *Ich will eine Cradle-to-cradle Nachhaltigkeitsstrategie für ein Unternehmen entwerfen. Helfen Sie mir, konkrete erste Schritte nach der Cradle-to-cradle Zertifizierung zu planen.*

Studierende sollen ein Unternehmen auswählen, bei dem sie schon einmal gearbeitet haben, oder das sie gut kennen. Hier ein Beispiel.

* *Prompt #3*: *Ich denke über Voss Automotive nach, die folgende Produkte herstellen: innovative Leitungs-und Verbindungssysteme, die überall auf der Welt in Pkw und Nutzfahrzeugen sowie Land- und Baumaschinen eingesetzt werden. Unser Produktportfolio umfasst dabei einbaufertige Leitungsmodule mit Rohren, Schläuchen, Verbindungselementen, Ventilen und Sensoren. Zur Verbindungstechnik gehören Stecksysteme, Verschraubungen, Mehrfachkupplungen und Verteiler.*
* *Prompt #4*: *Erstelle einen Zeitplan als Tabelle mit Aufwandsschätzungen für 3 Personen in 4 Wochen.*
* *Prompt #5*: *Mehr Details bitte: Erstelle Unteraufgaben für die jeweiligen Aufgabenpakete, jeweils auch wieder mit Aufwandsschätzungen.*

Die Studierenden sollen den Projektplan dann weiter verbessern und diskutieren. Erweiternd können sie auch z.B. Projektrisiken, Indikatoren und Gegenmaßnahmen und Szenarien erheben und diskutieren.

## Wie prüfen wir jetzt? Jenseits der Homework Apocalypse

Jenseits der vielen produktiven Anwendungen besteht die Gefahr, dass Studierende wichtige Teile des Denkprozesses an Sprachmodelle delegieren [@lee2025a]. Klassische „Hausaufgaben“ wie **Seminararbeiten, Gruppenprojekte und Abschlussarbeiten drohen entwertet zu werden**. Ohne Anpassung der Aufgabenstellung werden die Aufgaben potenziell sinnlos, da Studierende etwa Aufsätze oder Reflexionsaufgaben einfach von Chat GPT schreiben und einreichen. Interviews mit Studierenden und Nutzungsstudien zeigen, dass diese Gefahr akut ist. Wie wir in der umfassenden empirische Nutzungsstudie von @handa2025c sehen, nutzen Studierende Sprachmodelle gerade zur Schreibunterstützung intensiv und häufig. Das New York Magazine betitelt eine aktuelle Recherche mit „**Everyone is cheating their way through college**”, auf der Grundlage einer Vielzahl von Interviews mit desillusionierten Studierenden und Lehrenden [@walsh2025a]. Der o.g. Artikel der Fachzeitschrift Nature (s. Tabelle 4) skizziert ebenfalls basierend auf Interviews ein breites Spektrum an aktiver Nutzung im höheren Bildungsbereich [@heidt2025a].

Schon 2023 kündigte der Wharton Professor Mollick die „Homework Apocalypse“ an [@mollick2023d]. Dabei geht es Mollick weniger um das Tricksen mit den neuen technischen Möglichkeiten („Cheating was already common in schools“), sondern mehr um die **empfundene Sinnlosigkeit von klassischen Hausaufgaben**. „Students will want to understand why they are doing assignments that seem obsolete thanks to AI.“. Wer gibt noch reine Rechenübungen auf, wenn alle Taschenrechner haben? Wie kann Eigen- und Fremdleistung unter diesen neuen technischen Bedingungen getrennt werden? Wie können auch jetzt noch Anreize für Studierende gesetzt werden, Texte noch selbst zu lesen und Sätze noch selbst zu formulieren?

![Abbildung 15: Etwa gleichverteilt: Vier Arten der Interaktion von Studierenden mit Sprachmodellen. Quelle: @handa2025b](images/script05-01.png){#fig-interaction-types}

Eine Unterscheidung der empirischen Anthropic-Studie von Studierenden Interaktionen mit Sprachmodellen ist dabei hilfreich, um das Problem einzuordnen [@handa2025b]: Hier werden vier Arten von LLM-Nutzung unterschieden, je nachdem, ob ein **Problem** gelöst, oder ein **Ergebnis generiert** werden soll und je nachdem, ob dies **direkt oder interaktiv** erfolgt. Kollaborative Nutzungsformen (Typ 3 und 4) sind dabei für den Lernerfolg eher hilfreich, während das direkte Bereitstellen von Problemlösungen oder Texten aufgrund mangelnder Beschäftigung der Studierenden mit den Problemen und Materialien für Hausarbeiten eher hinderlich sein könnte (anders als für die Vorbereitung von kontrollierten Tests wie Klausuren). Studierende werden so eher in eine passive Rolle gedrängt und es fehlen die erwünschten Schwierigkeiten (desirable difficulties, [@roediger2006b]), das fragebasierte Durchkauen und Hin- und Herüberlegen, das die Lernforschung als Wichtig für langfristiges Behalten ansieht [@roediger2012b].

Grob gesagt wollen wir also **kollaborative Interaktion und Hilfestellung fördern und einfaches Übernehmen bereitgestellter Lösungen verhindern**. Wie können wir dafür die Hausarbeiten anpassen? Im Folgenden werden einige Empfehlungen zusammengefasst. Der Vier-Säulen-Ansatz nach Gmeiner bietet Orientierung. Er unterscheidet vier Gegenmaßnahmen für das Prüfen unter KI-Bedingungen: Mündlichkeit, Prozessorientierung, Kontextualisierung sowie Kollaboration [@gmeiner2025a].

![Abbildung 16: KI-resistente Aufgabenstellungen – 4 Säulen nach Gmeiner (2025)](images/script05-02.png){#fig-gmeiner-pillars}

### Mündlichkeit

**Mündlichkeit** stärkt Verständnis, Transfer und Autorschaft. Disputation, Präsentationen mit strukturiertem Q&A und gezielte Kolloquien machen eigene Entscheidungen sichtbar. So verlieren generische KI-Texte an Wert. Leitfäden empfehlen diese Formate ausdrücklich als Ergänzung zu schriftlichen Arbeiten. Detektionsscores dienen nicht als Beweis, sondern höchstens als Anlass zur Klärung (QAA, n. d.; Jisc, n. d.). Die University of Melbourne verweist auf skalierbare, mündliche Validierungen. Die folgende Übersicht zeigt typische Formate der mündlichen Prüfung.

![Abbildung 17: Vergleich mündlicher Prüfungsformen (@ward2024a)](images/script05-03.png){#fig-oral-exams}

Hier sollen exemplarisch einzelne mündliche Prüfungsformate beschrieben werden, die Lehrende nutzen können.

Das erste Format ist das **Kurzkolloquium** („Viva Voce Exam“ in der Abbildung). Ziel ist der Nachweis von Verständnis und Autorschaft. Hier wird die schriftliche Arbeit vom Leistungsnachweis getrennt [@gmeiner2025a] und die Lernenden müssen ihre Entscheidungen in der schriftlichen Arbeit erläutern und verteidigen. Die Studierenden reichen ihre schriftliche Arbeit ein, die auch mit KI-Unterstützung erstellt werden darf und führen ein dann ein etwa zehnminütiges Gespräch über die Arbeit. Die Prüfenden wählen zum Beispiel zwei Kernentscheidungen zur weiteren Erläuterung aus: Datenaufbereitung und Argumentation. Die Studierenden erklären Vorgehen, Alternativen und Grenzen. Es folgt ein kurzes Transfer-Szenario: „Was würden Sie ändern, wenn…?“ Bewertet werden Klarheit, Begründung, Umgang mit Unsicherheit und Konsistenz zur Schriftfassung. KI-Regeln: KI-Nutzung wird offengelegt; Antworten sind persönlich und ohne Hilfsmittel. Skalierung gelingt mit standardisierten Leitfragen, Doppelprüfungen im Stichprobenprinzip und Aufzeichnung für Zweitbewertungen. Dieses Format eignet sich besonders für die Prüfung von Abschlussarbeiten und lässt sich leicht auch auf Seminararbeiten übertragen. Ähnlich wie auch für das folgende Format müssen hierfür initial Bewertungsmatrizen erstellt werden, potentielle **Herausforderungen** sind situativer **Stress** und Aspekte von **Validität** (Form vs. Inhalt, einfache vs. schwere Fragen, mündliche vs. schriftliche Ausdrucksfähigkeit), **Reliabilität** (Rating-Unterschiede bei verschiedenen Nachfragen und Bewertenden, verschiedenen Szenarien usw.) und **Fairness** (z.B. Sprachfähigkeiten, Vorwissen). Vorteile sind die Reaktivität und die Möglichkeit, durch vertiefende Nachfragen Hintergrundwissen und Begründungen abzufragen [@akimov2020, S. 31; @kearney2019a].

Ein ähnliches Format, aber mit anderem Fokus ist die **interaktive mündliche Prüfung** (interactive oral assessment, IO). Hier erhalten die Studierenden ein praxisnahes Szenario, das sie in Interaktion mit den Prüfenden analysieren und bearbeiten müssen [@ward2024a]. Gestaltet werden IOs als offene, nicht im Detailablauf vorgegebene Gespräche in realitätsnahen Szenarien, geführt zwischen Studierenden und Prüfenden (oder zwischen Studierenden). So wird etwa gefordert, eine Situation oder eine Fallstudie mit Bezug auf das erlesene Vorwissen zu analysieren. Bewertet wird die Interaktion durch unterlegt durch präzise Rubriken (die auch gemeinsam mit den Studierenden entwickelt werden können [@nibheolain2020a]), Beispielaufnahmen zur Vorbereitung und formative Einbettung über das Semester. Beispiele für die Einbettung umfassen etwa, dass Studierende die Rolle von Interviewten in einer Talkshow einnehmen, oder im Duo ihre Erkenntnisse von einer Konferenzteilnahme erläutern müssen. International wird diese Prüfungsform durchaus in sehr großen Kohorten eingesetzt, von Erstsemester-Kursen mit ca. 200 bis zu 800 Studierenden, mit 4 bis 10 Prüfenden (https://sway.cloud.microsoft/yQ2s0Bm3ILkWtGll). Es gibt eine Reihe detaillierter **Leitfäden zur Umsetzung solcher Szenario-Prüfungen** mit Aufnahmen von Beispielprüfungen und den Bewertungsrubriken (https://www.dcu.ie/sites/default/files/inline-files/interactive-oral-io-user-guide_0.pdf , siehe speziell die Übersicht der Ressourcen auf S.11).

![Abbildung 18: Mündlich prüfen geht auch in großen Kohorten – Beispiele von verschiedenen Universitäten](images/script05-04.png){#fig-large-cohorts}

![Abbildung 19: Drei Szenarien für eine mündliche Prüfung in Pädagogik](images/script05-05.png){#fig-pedagogy-scenarios}

Ein drittes Format ist die **Posterpräsentation** mit strukturiertem Q&A. Die Studierenden erstellen ein Forschungs- oder Praxisposter und präsentieren für fünf Minuten. Danach folgen gezielte Fragen zu Methode, Evidenz und Limitationen. Artefakte sind Poster, ein einseitiges Handout und ein Frageprotokoll. Bewertet wird die Evidenzführung, Passung von Methode und Frage sowie die Qualität der Antworten. KI darf für Layout und Sprachpolitur helfen, nicht für Inhalt. Offenlegung ist Pflicht. Große Gruppen lassen sich mit parallelen „Poster-Sessions“ und festen Zeitslots prüfen.

Für **Abschlussarbeiten** kann diese Ausweitung der mündlichen Prüfungskomponente so operationalisiert werden, dass die Gewichtung des Kolloquiums erhöht wird, bzw. ein zweites Kolloquium hinzugefügt wird (um die Belastung der mündlichen Prüfung zu verteilen), in dem die Studierenden ca. 1 Monat nach dem Beginn der Abschlussarbeit mündlich den Stand der Forschung zum Thema darstellen und die Forschungslücke begründen müssen. Ein aktueller Entwurf an der TH Köln hierfür sieht so aus:
* Kolloquium 1: Stand der Forschung und resultierende Forschungsfragen (3 ECTS)
* Schriftliche Arbeit (8 ECTS)
* Kolloquium 2: Ergebnis der Abschlussarbeit (4 ECTS)
(Früher: Schriftliche Arbeit = 12 ECTS, Kolloquium = 3 ECTS).

### Prozessorientierung

**Prozessorientierung** rückt den Weg zum Ergebnis in den Mittelpunkt und liefert über die stärkere Teilhabe der Prüfenden am Erstellungsprozess Evidenz für Autorschaft und verantwortliche KI-Nutzung. Insofern empfehlen die meisten Ratgeber, das Gewicht vom Produkt auf den Prozess zu verlagern. Ein Ratgeber der Melbourne University empfiehlt ausdrücklich, „vom Produkt zum Prozess“ zu wechseln, Prozess-Notizbücher und Reflexionen einzubauen und mit Umgebungen wie Cadmus digitale Prozess-Spuren zu erfassen [@mulder2023a]. Eine Studie von Hanover Research fordert gestaffelte Abgaben über die Zeit mit intensiver, iterativer Rückmeldung und betont, dass die Sichtbarmachung individueller und kollaborativer Arbeitsprozesse KI-Nutzung unattraktiv macht [@hanoverresearch2024a]. Empfehlungen der Monash University konkretisieren dies: Prozessbewertungen, verbundene Aufgaben und Einbindung der Prüfenden in den Entstehungsprozess [@monashuniversity2025]. Gmeiner operationalisiert Prozessfokus zudem durch transparente KI-Nutzungsdokumentation mit Prompt-/Output-Belegen und reflektierter Einbettung in die Eigenleistung [@gmeiner2025a].

![Abbildung 20: Abhilfe durch Interaktion oder engere Prozessbetreuung: Aufgabentypen nach der Schwierigkeit, durch KI repliziert zu werden (@hanoverresearch2024a)](images/script05-06.png){#fig-task-difficulty}

Ein zentrales Format ist das **Prozessjournal mit Audit-Trail**: Studierende dokumentieren Suche, Auswahl, Analyse, Entscheidungen und Revisionen fortlaufend; ein Versionsverlauf in Overleaf oder Git macht Änderungen nachvollziehbar. Abgegeben werden Journal, Query-Protokolle, Daten-/Code-Paket und Endprodukt. Bewertet werden Nachvollziehbarkeit, Qualität der Entscheidungen, Reproduzierbarkeit und eine reflektierte Darstellung der KI-Nutzung (Tool, Version, Prompts, Zweck, Umfang, Korrekturen). Detektoren entfallen; der dokumentierte Prozess bildet die Hauptgrundlage der Beurteilung.

Als zweites Format bietet sich die **gestaffelte Hausarbeit** an: Outline, Annotated Bibliography, Methoden-Memo, Rohanalyse, Draft und Final werden über das Semester verteilt, jeweils mit Feedback und klar getrennten Prozess- und Produktpunkten in der Rubrik. KI kann bei Ideenfindung und Sprachpolitur helfen, nicht bei Theoriebildung oder Ergebnissen; Nutzung und kritische Einordnung sind offenzulegen. In großen Kohorten tragen Peer-Reviews nach Rubrik und stichprobenhafte Dozierenden-Checks zur Skalierung bei.

### Kontextualisierung und empirischer Bezug

**Kontextualisierung und Empirie** binden Leistung an reale Daten, Orte und Rollen und entwerten generische KI-Outputs. Die Leitfäden empfehlen realweltliche, lokal verankerte, persönlich bezogene Aufgaben. Melbourne CSHE listet explizit „authentische, kontextspezifische oder persönliche“ Aufgaben – etwa Analysen weniger bekannter lokaler Objekte, Bezüge zu persönlicher Erfahrung oder Aufgaben, die genuine Berufsprodukte erzeugen [@mulder2023a]. Monash rät, Essayaufgaben so zu verändern, dass personalisierte Anwendung und Kontextualisierung zwingend sind; außerdem werden multimodale Artefakte als KI-resistenter eingestuft [@monashuniversity2025]. Gmeiner präzisiert diese Logik: biografisches Lernen, Aufgaben an außerschulischen Lernorten oder tagesaktuelle Kontexte machen die Aufgabe „un-promptbar“, weil sie persönliche, physische oder nicht-öffentliche Informationen, sinnliche Beobachtung und Gegenwartsbezug erfordern [@gmeiner2025a].

**Selbst erhobene Empirie zählt**, reine Literaturstudien oder theoretische Ausarbeitungen sind zu vermeiden. Interviews, Prozessanalysen, der Bau eines Prototypen oder sonstige Erhebungen von Primärdaten verlangen, dass Studierende einen passenden Fall auswählen, Daten erheben oder kuratieren, diese methodengerecht analysieren und eine Entscheidungsvorlage erstellen. Abzugeben sind Datensatz, Methodenprotokoll, Analyse-Notebook und eine kurze Empfehlung; bewertet werden Kontextpassung, Datenqualität, methodische Angemessenheit und die Tragfähigkeit der Handlungsempfehlung. KI darf strukturieren, nicht aber Evidenz ersetzen. Alternativ können Replikations- und Verifikationsaufgaben genutzt werden: Studierende replizieren eine veröffentlichte Analyse, dokumentieren Abweichungen und prüfen Robustheit mit alternativen Spezifikationen. Artefakte sind ein vollständiges Repro-Paket, ein Abweichungsprotokoll und ein Kurzbericht, der klar ausweist, was trägt und was nicht. KI kann Code-Snippets vorschlagen, doch jede Zeile wird verstanden, kommentiert und getestet. Offenlegung der Tool-Nutzung bleibt Pflicht. Automatisierte Checks und präzise Rubriken halten den Korrekturaufwand im Rahmen.

Für Abschlussarbeiten kann dies so operationalisiert werden, dass reine Literatur- oder Theoriearbeiten ohne empirischen Bezug vom Prüfungsausschuss zu genehmigen sind.

### Kollaboration und Kreation

**Kollaboration und Kreation** prüfen die soziale, evaluative und kreative Dimension des Lernens und machen Aushandlung und Revision sichtbar. Die Leitfäden schlagen in diesem Kontext etwa In-Class- und Gruppenaufgaben, Peer-/Selbstbeurteilung und gestufte Projekte vor. Melbourne CSHE zeigt in mehreren Fallbeispielen, wie verschachtelte Aufgaben mit Gruppen-Literaturarbeit, Projektplänen, Peer-Review und Präsentationen kombiniert werden. Diese Designs stärken Prozess-Transparenz, evaluative Urteilskraft und erschweren KI-Missbrauch [@mulder2023a]. Hanover Research betont ähnlich Gruppenarbeiten, In-Class-Aktivitäten und Aufgaben, die die Nutzung von KI explizit erlauben, aber kritisch auswerten lassen – also Kreation plus Metareflexion [@hanoverresearch2024a].

**Wie kann so etwas aussehen?** Ein peer-reviewtes Multimedia-Projekt etwa verlangt, dass kleine Teams ein konkretes Produkt – Podcast, Video oder Infografik – für ein definiertes Publikum erstellen. Der Prozess umfasst Briefing, Drehbuch, Quellenkurzprüfungen, Prototyp, Peer-Feedback und Finalisierung. Bewertet werden Evidenzbasis, Storyline, Zielgruppenpassung, Feedbackqualität und die Umsetzung der Rückmeldungen; neben dem Produkt liefern Teams Quellenlisten, Peer-Feedback-Protokolle und individuelle Reflexionen. Alternativ können Rollen- oder Planspiele erstellt oder bearbeitet und reflektiert werden [@gmeiner2025a]. KI kann als Ideengeber dienen, doch Entscheidungen und Quellenhoheit verbleiben beim Team; kurze Nachgespräche sichern Autorschaft ab.

Als Abschlussformat eignet sich ein Team-Capstone mit getrennter Team- und Individualnote: Das Team liefert ein belastbares Artefakt – etwa einen Prototyp, eine Konzeptstudie oder einen Policy-Brief mit Daten –, während jede Person einen individuellen Methoden-Anhang und eine Reflexion zum eigenen Beitrag und zur KI-Nutzung abgibt. Bewertet werden Teamprodukt, individueller methodischer Beitrag und die Qualität der Reflexion; klare KI-Regeln fordern Offenlegung, Bias-Prüfung und Quellenverifikation. Milestone-Boards, strukturierte Peer-Assessments und stichprobenhafte mündliche Abfrage pro Team sichern Skalierbarkeit und Integrität.

Kombiniert man die vier Säulen, entsteht eine Vielzahl von Optionen für ein konsistentes, skalierbares Prüfungsdesign, das auf Transparenz, Prozessnähe und reale Anwendung setzt. Mündliche Elemente sichern Autorschaft und Transfer, prozessorientierte Formate liefern nachvollziehbare Evidenz, kontextgebundene Aufgaben prüfen Verständnis unter realen Bedingungen, und kollaborative Produkte stärken Urteilskraft, Feedbackkultur und Kreativität. Klare Richtlinien, Offenlegung und belastbare Rubriken tragen das Konstrukt. KI-Detektoren werden überflüssig, weil die Beweise im Prozess liegen und Prüfende enger an diesem Prozess teilnehmen und in den vorgestellten Prüfungsformen interaktiv nachfragen können. Dies alles aufzusetzen bedeutet durchaus hohe Initialaufwände und die neuen Prüfungsformen müssen evaluiert werden, um bekannte Probleme etwa des Prüfens in direkter Interaktion (Validität, Reliabilität, Fairness, s.o.) einzudämmen [@akimov2020]. Positiv dabei: **Es gibt schon viele Vorlagen, auf die man aufbauen kann** und durch diese Anstrengungen bleiben Integrität und Qualität der Prüfungen gewahrt – die oben genannte **Furcht vor Betrug und Sinnlosigkeit der Prüfungen wird eingedämmt**, ohne dass auf reines Klausurlernen zurückgefallen werden muss, während Studierende lernen, KI verantwortlich, nachvollziehbar und wirksam einzusetzen.

## Richtlinien zur KI-Nutzung - welche Handreichungen geben Hochschulen und was wird empfohlen?

### Übersicht: Was regeln aktuelle Richtlinien?

Wie reagieren Hochschulen auf die Chancen und Herausforderungen von LLM? Eine Übersichtsstudie von @an2025a untersucht die **Richtlinien der Top 50 US Hochschulen zur Nutzung von LLM**. Mittels Topic Modeling identifizieren sie vier zentrale Themenfelder: die Integration von LLM in Lehre und Prüfungen, die Nutzung in visuellen und interaktiven Medien, Fragen der Sicherheit und Ethik sowie die Wahrung akademischer Integrität. Die Sentimentanalyse zeigt eine insgesamt positive Haltung gegenüber LLM, insbesondere in Richtlinien für Lehrende und Verwaltungspersonal. Studierendenrichtlinien sind hingegen zurückhaltender und stärker auf Einschränkungen fokussiert. Die Analyse differenziert die Inhalte nach Zielgruppen: Während Lehrende vor allem Unterstützung für Kursdesign und Prüfungsformate erhalten, stehen bei Studierenden Regelungen zur Integrität im Vordergrund. Forschende und Verwaltungspersonal werden bislang weniger berücksichtigt, obwohl sie ebenfalls spezifische Herausforderungen und Potenziale im Umgang mit LLM aufweisen. Die Autor:innen empfehlen daher eine stärkere Differenzierung und kontinuierliche Weiterentwicklung der Richtlinien, den Verzicht auf unzuverlässige Detektionstools sowie eine institutionenübergreifende Reflexion über ethische, rechtliche und didaktische Implikationen.

**Speziell deutsche Leitlinien an 27 Hochschulen** untersuchte das Hochschulforum Digitalisierung im Jahr 2024 [@tobor2024a], ein Update im Februar 2025 ergänzt neuere Entwicklungen [@tobor2025a]. Die Analyse umfasst hochschulweiten Leitlinien deutscher Universitäten zum Umgang mit generativer KI. Dabei hebt Tobor eine Reihe bewährter Praktiken hervor, die sich in mehreren Leitfäden wiederfinden (Für konkrete Beispiele siehe Appendix 2: Beispiele für KI-Richtlinien):

* Ein zentrales Element ist die **Anpassung der Eigenständigkeitserklärung** in schriftlichen Prüfungen ohne Aufsicht. Viele Hochschulen – exemplarisch die Vorlage der Hochschule RheinMain – fordern darin von Studierenden eine explizite Erklärung, ob und in welcher Weise KI-Tools verwendet wurden. Diese Erklärungen dienen der Transparenz und ermöglichen Lehrenden, KI-Nutzung regelkonform einzuordnen.
* Im Umgang mit **Verdachtsfällen unzulässiger KI-Nutzung** betonen viele Leitlinien die Grenzen technischer Erkennung. Tools wie GPTZero gelten als unzuverlässig. Stattdessen wird – wie im Leitfaden der Universität Vechta – ein **multifaktorielles Vorgehen** empfohlen, das Indikatoren wie nicht reale Quellen oder auffällige Formulierungen einbezieht. Bestätigt sich der Verdacht, erfolgt ein **Klärungsgespräch**, um das Verständnis der Studierenden für ihre Arbeit zu überprüfen.
* Im Bereich **Urheberrecht** wird festgehalten, dass KI-Systeme wie ChatGPT derzeit keine Urheber im juristischen Sinne sind. Ihre Inhalte stellen daher nicht automatisch ein Plagiat dar, können aber Rechte Dritter verletzen. Die Verantwortung für eine rechtskonforme Nutzung liegt bei den Studierenden – klare gesetzliche Regelungen stehen noch aus.
* Kritisch sehen viele Hochschulen die **Verwendung von KI zur automatisierten Bewertung** von Prüfungsleistungen. Diese widerspricht in der Regel Prüfungsordnungen, die eine begründete Bewertung durch eine prüfende Person verlangen. Zudem wird das Hochladen studentischer Arbeiten in KI-Systeme als urheberrechtlich bedenklich eingestuft.
* Schließlich fordern zahlreiche Leitlinien eine **didaktische Weiterentwicklung von Prüfungsformaten**. Empfehlungen reichen von stärker reflexionsorientierten Aufgaben über Zwischenfeedback und methodische Transparenz bis hin zu ergänzenden mündlichen Prüfungen. Ziel ist es, den Kompetenznachweis trotz verfügbarer KI-Tools aussagekräftig zu gestalten. Dabei sollte auch der Umgang mit KI selbst – inklusive Prompt-Gestaltung oder kritischer Reflexion – zum Prüfungsgegenstand werden. Lehrende werden ermutigt, den Einsatz von KI gemeinsam mit den Studierenden zu reflektieren und klare Regeln im Kurs zu kommunizieren.

Im Update von 2025 stellt Tobor auch kritisch die **thematische Zersplitterung** der verschiedenen Handreichungen fest: Die Richtlinien versuchen, eine Vielzahl von Einzelthemen für eine Vielzahl von Gruppen zu integrieren, speziell regulatorische und didaktische. Hinzu kommen Anforderungen zur Risikoaufklärung über Themen wie Halluzinationen, Vorurteile von LLM in den Ergebnissen und Ressourcenverbrauch. Die europäische KI-Verordnung (KI-VO) verschärft die Anforderungen an Hochschulen, insbesondere im Hinblick auf KI-Kompetenzen und Risikoeinstufungen bei Prüfungen. Positiv werden **integrierende Formate wie “Landing Pages“** genannt, etwa der KI-Hub der Universität Vechta (https://www.uni-vechta.de/ki-hub). Ein solcher zentraler Startpunkt kann allgemeine und spezielle Themen verbinden und – bei guter Kuratierung – helfen, Komplexität zu reduzieren.

### Allgemeine Empfehlungen zu Richtlinien

@an2025a plädieren für ausgewogenere, zielgruppenspezifische Leitlinien, die sowohl regulatorische Klarheit als auch didaktische Impulse bieten – insbesondere für Studierende, deren Perspektive bislang zu wenig berücksichtigt wird. Was für didaktische und regulatorische Aspekte für Lehrende und Studierende werden hier festgelegt?

Für **Lehrende** stehen didaktische Empfehlungen im Vordergrund, die auf eine bewusste Integration generativer KI in die Hochschullehre zielen. In 94 % der untersuchten Richtlinien werden konkrete Hinweise gegeben, wie LLM in **Kursdesign, Aufgabenstellungen und Prüfungsformate** eingebunden werden kann. Lehrende werden ermutigt, im Syllabus klar zu definieren, ob und wie der Einsatz von KI erlaubt ist – etwa durch gestufte Erlaubnisformen (verboten, erlaubt mit Dokumentation, ausdrücklich gewünscht). Zudem wird empfohlen, Prüfungsformate so umzugestalten, dass sie weniger anfällig für unreflektierte KI-Nutzung sind, z. B. durch individuelle Reflexionen, Gruppenarbeit oder mündliche Komponenten. Regulatorisch wird betont, dass die Verantwortung für die Formulierung und Durchsetzung dieser Regeln bei den Lehrenden liegt, jedoch unterstützt durch hochschulweite Orientierungshilfen. KI-Detektionstools wie Turnitin oder GPTZero werden hingegen kritisch gesehen: Viele Hochschulen raten von deren Einsatz ab, da ihre Ergebnisse unzuverlässig seien und leicht zu Fehlinterpretationen führen können.

Für **Studierende** betonen die Richtlinien vor allem regulatorische Aspekte im Sinne der **akademischen Integrität**. Häufig wird darauf hingewiesen, dass LLM nicht uneingeschränkt eingesetzt werden darf, und dass ein nicht genehmigter Einsatz als Täuschungsversuch gewertet werden kann. Die Verantwortung zur Klärung, ob LLM zulässig ist, wird den Studierenden zugeschrieben – sie sollen aktiv Rücksprache mit Lehrenden halten. Didaktisch werden Studierende allerdings meist weniger unterstützt: Nur wenige Richtlinien bieten Anleitungen zur kompetenten Nutzung von LLM oder reflektieren über sinnvolle Lernstrategien im Umgang mit KI. Eine Ausnahme bilden vereinzelte Hinweise zur Förderung von **AI Literacy**, etwa zur kritischen Bewertung von KI-generierten Texten oder zur Transparenzpflicht bei der Nutzung von LLM in Hausarbeiten. Insgesamt dominiert jedoch eine **restriktive und kontrollierende Perspektive**, die stärker auf Vermeidung von Fehlverhalten als auf befähigende Lernangebote setzt.

Die deutsche Untersuchung von @tobor2025a betont, dass die Wirksamkeit solcher Leitlinien maßgeblich davon abhängt, ob sie **bekannt gemacht, kontinuierlich diskutiert und weiterentwickelt** werden. Zentral ist es, die Leitlinien User-adäquat zu gestalten und bekannt zu machen. (Auch hier begegnen uns implizit wieder die zentralen Kategorien Nutzerfreundlichkeit und wahrgenommene Nützlichkeit des Technology Acceptance Models.) Tobor warnt davor, Leitlinien als bloße Beruhigungsmittel zu betrachten, und fordert stattdessen eine **dialogische, ko-kreative Weiterentwicklung** – etwa durch Beteiligung von Studierenden, verbundweite Zusammenarbeit und neue Formate wie Prompt-Battles. Leitlinien sollten als lebendige Rahmenwerke verstanden werden, die zur aktiven Gestaltung des KI-bedingten Wandels in Studium und Lehre beitragen.

**Wie sehen solche Richtlinien aus?** Konkrete Formulierungen und Links hierzu finden Sie im Appendix 2: Beispiele für KI-Richtlinien.

## Wie können Studierende die Nutzung von LLM dokumentieren? Stichworte, nach Arbeitsphase, nach Werkzeug oder als Reflexionstagebuch

**Frühe Handreichungen** zur Dokumentation von LLM in Studierendenarbeiten waren noch sehr allgemein formuliert und bestanden etwa darauf, dass **jegliche Nutzung im Schreibprozess** genau protokolliert würde. Bei täglicher und stark integrierter Nutzung ist das etwa so sinnvoll, wie die Forderung, jegliche Internetnutzung in einem Tagebuch zu erfassen. Sinnlose Forderungen führen schnell dazu, dass die dahinter stehende Forderung nach prinzipieller Nachvollziehbarkeit des Forschungsvorgehens entwertet und Umgehungshandlungen normalisiert werden.

**Neuere Empfehlungen** der Hochschulen sind hier deutlich realistischer: So bietet etwa eine Handreichung von niedersächsischen Hochschulen eine gute **Reihe von Optionen**, die von einer einfachen Stichpunktliste („elicit.com zur Literaturrecherche, perplexity.ai zur Internetrecherche, gamma.app zur Präsentationserstellung, stablediffusionweb.com zur Bildgeneration“) bis zu detaillierten Tagebüchern mit Reflexionshilfen reicht [@baresel2024a].

Im Folgenden zeigen wir drei weitere Beispiele für Dokumentationen nach Arbeitsphasen, nach Werkzeugen und in Form eines Reflexionstagebuches [@baresel2024a].

Die Dokumentation nach **Arbeitsphasen** (s. Tabelle 8) zielt auf eine strukturierte Erfassung des KI-Einsatzes entlang typischer wissenschaftlicher Arbeitsphasen (z. B. Themenfindung, Recherche, Schreiben). Studierende bewerten selbst den Grad der KI-Nutzung (von „inspirierend“ bis „inhaltsgestaltend“) und dokumentieren Tool, Einsatzkontext und Wirkung. Ziel ist Transparenz über den konkreten Einfluss auf das Ergebnis.

Bei der **werkzeugorientierten** Dokumentation (s. Tabelle 9) werden in tabellarischer Form die verwendeten Tools (z. B. ChatGPT, DeepL Write) samt Quelle, Zweck, Funktion und Einsatzbereich gelistet. Diese Variante erleichtert die Nachvollziehbarkeit, gibt aber wenig Einblick in den Kontext oder den Einfluss der Tools auf den Arbeitsprozess.

Beim **Reflexionstagebuch** (s. Tabelle 10) steht die kontinuierliche, persönliche Auseinandersetzung mit dem eigenen KI-Einsatz im Vordergrund. Studierende führen während des Arbeitsprozesses ein Tagebuch, das später in eine prüfungsrelevante Dokumentation überführt wird. Diese Methode fördert den Aufbau von **KI-Literacy** und metakognitiver Kompetenz, ist jedoch zeitaufwändig und betreuungsintensiv.

| Phase im Arbeitsprozess | Dokumentation: Eingesetzte Tools, Verwendungszweck, Funktionsweise, Ergebnis | Grad der KI-Nutzung |
| :--- | :--- | :--- |
| **Ideenfindung/Strukturierung** | **Tools**: ChatGPT, Perplexity<br>**Zweck**: Brainstorming zu Forschungsfragen, Gliederungsideen<br>**Ergebnis**: 5 Themenvorschläge, davon 1 weiterverfolgt | 1 |
| **Recherche** | **Tools**: Elicit, Semantic Scholar<br>**Zweck**: Suche nach passender Literatur<br>**Ergebnis**: Liste mit 15 Quellen, 8 davon verwendet | 2 |
| **Schreiben/Formulieren** | **Tools**: DeepL Write<br>**Zweck**: Verbesserung des sprachlichen Ausdrucks<br>**Ergebnis**: Überarbeitete Einleitung | 3 |
| **Überarbeitung/Korrektur** | **Tools**: Grammarly<br>**Zweck**: Prüfung auf Grammatik- und Rechtschreibfehler<br>**Ergebnis**: Fehlerfreier Text | 2 |

: Tabelle 8: Beispiel arbeitsphasenorientierte Dokumentation der LLM Nutzung. Quelle: (@baresel2024a, S. 11) {#tbl-doc-phases}

| Software/Programm/KI-Anwendung | Link/Quelle | Verwendungszweck | Genutzte Funktion | Nutzungsbeschreibung/Anwendungsbereich |
| :--- | :--- | :--- | :--- | :--- |
| **appypie** | https://www.appypie.com/design/de/infografik/ersteller | Infografiken zur Erläuterung | Entspricht Verwendungszweck | Infografik für einen Überblick in der Einleitung, S. 3 |
| **Claude** | https://claude.ai/new | Assistenz zur Programmierung, Vorschläge für Gliederung | Chat und Code-Ausgabe | Programmierung des Auswertungsprogramms, siehe S.13 Erstaufschlag der Gliederung, wurde überarbeitet |
| **DeepL Write** | https://www.deepl.com/de/write | Überarbeiten der Texte | Entspricht Verwendungszweck | Gesamter Text |
| **DeepL Übersetzer** | https://www.deepl.com/de/translator | Übersetzung von französischsprachigen Papers | Übersetzung Französisch–Deutsch | Die Paper Lacroix, 2007 & Macron, 2020 wurden übersetzt. |
| **KiCad²** | https://www.kicad.org/ | Layout der Testplatine | PCB Layout | Layout der Platine, siehe Abb. 15 S. 20 |
| **MATLab** | Hochschullizenz | Simulation der Empfängerschaltung | Simulink | Schaltung xyz auf S. 14 simuliert und optimiert |
| **MaxQDA** | Hochschullizenz | Auswertung Interviews | MaxQDA und AI Assist | Kategorienbildung, siehe Kap 4.2 und Anhang C |
| **Openknowledgemap** | https://openknowledgemaps.org/ | Recherche des Forschungsfelds | Entspricht Verwendungszweck | Für die Einarbeitung wurde mit diesem Tool der Zugang zum Forschungsfeld erschlossen. |
| **SPSS** | Hochschullizenz | Auswertung Daten zur Gesundheitsversorgung | Hypothesentest mittels xy | Datenauswertung siehe S. 15 und Anhang S. 77 |
| **Visual Studio C++** | Hochschullizenz | Programmierung einer Navigationslösung | Entspricht Verwendungszweck | Programmierung des zentralen Programms der Arbeit, siehe Kap. 4 |
| **Whisper (openAI)** | https://openai.com/index/whisper/ | Transkribieren von Interviews | Transkribieren ohne Übersetzung | Transkribieren der Interviews, wurden korrigierend überarbeitet. Siehe Anhang B |

: Tabelle 9: Beispiel werkzeugorientierte Dokumentation der LLM Nutzung. Quelle: (@baresel2024a, S. 8) {#tbl-doc-tools}

| Datum | Woran habe ich gearbeitet? (Stichpunkte) | Welche digitalen Tools habe ich verwendet? | Notizen zum Einsatz digitaler Tools | Reflexion | Beleg/Beispiel | Grad der Nutzung |
| :--- | :--- | :--- | :--- | :--- | :--- | :--- |
| 1.9.24 | Themenfindung | ChatGPT 3.5 über Academic Cloud | Versuch, einige Begriffe zu schärfen<br>Fragestellungen vorschlagen lassen | Hilfreich, um Fachbegriffe zu identifizieren<br>Aus den Begriffen mal Fragestellungen machen lassen. Das traf es aber nicht wirklich. Ich muss noch weitermachen. | | 1<br>2 |
| 2.9.24 | Texte lesen | ChatPDF | 2 Texte hochgeladen, geprüft, ob relevant | Toll, dass ich deutsch fragen kann, auch wenn der Text englisch/italienisch ist. Entlastet! Macht das Lesen gezielter. Merke aber auch, dass ich dann den Text nicht mehr ganz lese. | | 2 |
| 5.9.24 | Bild generieren | bing.com/create | Illustration für die Präsentation zum Projekt | Macht Spaß! Ist aber auch aufwändig, genau das zu prompten, was man haben will. Zeitfresser. | Denken findet in der Auseinandersetzung von Mensch mit Maschine statt; Künstliche Intelligenz ist ein Partner des Menschen beim Denken. Helle, motivierende Farben = 07_Denken-externalisiert_Utopie_01.jpeg | 4 |
| 10.9.24 | Text bearbeiten | ChatGPT 4.0 über Academic Cloud | Formulierungsalternativen gesucht | Unentschieden. Manches klingt gut, aber irgendwie auch nicht. Weiß nicht so recht, was ich davon halten soll. | 24-09-10_Chat-Verlauf.docx | 3 |

: Tabelle 10: Beispiel Reflexionstagebuch zur LLM Nutzung. Quelle: (@baresel2024a, S. 16) {#tbl-doc-reflection}

## Beispiele für die Kurs-Integration von KI

Abschließend wollen wir uns Beispiele ansehen, wie ein Kurs aussehen könnte, der mit LLM in der Vorbereitung arbeitet und sie in Übungsaufgaben und die Prüfungsvorbereitung einbindet. Anmerkung: Hier wird nur die KI-Ergänzung beschrieben, natürlich werden außerdem Lehrbücher und Fachartikel als Input genutzt.

**Zeitliche Struktur und Inhalte (Fokus auf den Einsatz von KI-Tools)**

**Woche 1–4: Vorbereitung und KI-gestützte Materialerstellung (KI als „Hiwi“)**
* **Kursvorbereitung mit LLM**: Erstellung und Anpassung vielfältiger Programmieraufgaben an unterschiedliche Lernniveaus mithilfe von Large Language Models.
* **DeepResearch**: Unterstützung bei der Recherche aktueller Trends in der Programmierdidaktik und relevanter Beispiele, um realitätsnahe Aufgabenstellungen zu entwickeln.
* **NotebookLM für Podcast-Episoden**: Aus den erstellten Materialien werden mithilfe von NotebookLM kurze Podcast-Folgen generiert, die Studierende zur Einführung in die Kursstruktur, grundlegende Programmierkonzepte und organisatorische Aspekte anhören können. Dies dient als motivierende, niederschwellige Form der Wissensvermittlung.

**Woche 5–8: Vertiefung und individuelle Lernwege (KI als „Copilot“)**
* **Individuelle Programmieraufgaben**: Die Studierenden nutzen Google Colab oder ein ähnliches Tool, das KI-unterstützte Programmierung erlaubt (z.B. DeepNote). Sie lösen damit gleich am Anfang Anwendungsaufgaben und müssen die Code-Bestandteile in der Präsenzzeit anderen Gruppen erklären. Die Übungsaufgaben werden fortlaufend angepasst, indem die Lehrenden zusammen mit einem LLM bestehende Aufgaben je nach Lernfortschritt der Studierenden variieren (z.B. mehr Code-Komplexität oder zusätzliche Anwendungsfälle).
* **Voice Mode für Simulationen**: Interaktive Rollenspiele bzw. Simulationen (z.B. „Debugging-Dialog“) mit einem KI-Avatar in Voice Mode. Die Studierenden können live Fragen stellen, sich Lösungswege erklären lassen oder sich ein Code-Review im Gesprächsformat geben lassen.
* **DeepResearch**: Zur Vertiefung konkreter Themen (z.B. Algorithmendesign, Datenstrukturen) recherchieren die Studierenden mithilfe von DeepResearch in Fachartikeln, Blogposts und Dokumentationen. Sie lernen, verschiedene Quellen kritisch zu bewerten und für ihr Projekt nutzbar zu machen.

**Woche 9–12: Konsolidierung und Prüfungsvorbereitung (KI als „Lernhilfe“)**
* **NotebookLM zur Zusammenfassung**: Aus den im Kurs genutzten Lernmaterialien (Skripte, Forumsdiskussionen, Beispielcode) generiert NotebookLM automatisiert Zusammenfassungen und kurze Podcasts zu Schlüsselkonzepten. Studierende können diese unterwegs anhören oder gezielt zur Prüfungsvorbereitung nutzen.
* **LLM für Übungsfragen**: Auf Grundlage der bisherigen Lernfortschritte generiert das LLM individuelle Übungsfragen sowie Quizformate zur Selbstüberprüfung.
* **Voice Mode für Prüfungssimulation**: Studierende simulieren mündliche Prüfungssituationen oder Code-Erklärungen über Voice Mode. Dies fördert die Fähigkeit, Inhalte klar und strukturiert zu präsentieren.

### Beispielkurs 2: Ergänzung eines Kurses Interkulturelles Management durch KI-Unterstützung

**Woche 1–4: KI als „Hiwi“**
* **Ziel**: Erstellung vielfältiger, kulturell spezifischer Fallstudien und Szenarien, die als Diskussions- und Analysegrundlage dienen.
* **LLM für Fallstudien & Szenarien**: Die Lehrenden nutzen LLM (z.B. ChatGPT oder andere) zur Generierung von Fallstudien, die spezifische interkulturelle Kontexte beleuchten (z.B. Verhandlungen in ostasiatischen vs. europäischen Kulturen, Führungsstile in verschiedenen Regionen etc.).
* **Gegenmaßnahme zur Qualitätssicherung**: Die Ergebnisse werden stichprobenartig auf Richtigkeit, kulturelle Sensibilität und Relevanz überprüft.
* **DeepResearch zur Materialrecherche**: Lehrende recherchieren mithilfe von DeepResearch nach relevanter Literatur, neuesten Studien und Praxisberichten im Bereich interkulturelles Management. Die gefundenen Quellen fließen ein in vorbereitende Leselisten und Hintergrundinformationen für die Studierenden.
* **NotebookLM für Podcast-Folgen**: Für einen motivierenden Einstieg ins Thema werden kurze Podcasts (ca. 5–10 Minuten) mithilfe von NotebookLM erstellt. Themen könnten sein: „Einführung in kulturelle Dimensionen“ (bspw. nach Hofstede), „Erfolgsbeispiele im interkulturellen Management“, „Warum interkulturelle Kompetenz immer wichtiger wird“. Studierende können diese Podcasts vor oder nach den Präsenz- bzw. Online-Sitzungen anhören, um zentrale Konzepte zu festigen.

**Woche 5–8: KI als „Copilot“ für Anwendungsaufgaben**
* **Ziel**: Entwicklung praxisnaher Simulationen, Rollenspiele und Fallübungen, um die Studierenden für reale interkulturelle Managementkonflikte zu sensibilisieren.
* **LLMs für Rollenspiel- und Simulationsszenarien**: Studierende entwickeln in Kleingruppen Szenarien (z.B. Konflikte in multikulturellen Teams, Verhandlungen in internationalen Projekten), wobei sie LLM nutzen, um die Settings, Dialoge oder Konfliktpunkte zu konkretisieren. Lehrende moderieren den Prozess und überprüfen die Plausibilität, sodass sichergestellt wird, dass kulturelle Nuancen realitätsnah abgebildet werden.
* **Zusätzlicher Einsatz**: Chinesische OpenSource-Sprachmodelle wie „DeepSeek“ und japanische Sprachmodelle wie „Sakana“ werden gezielt eingesetzt, um denselben Input zu unterschiedlichen interkulturellen Situationen zu liefern. Ziel: Die Lehrenden vergleichen die Outputs in Bezug auf die verwendeten Beispiele, die Fokussierung auf kulturelle Werte (z.B. Kollektivismus, Hierarchie, Entscheidungsfindung) und die Tonalität der Texte. Daraus entstehen potenziell Fallstudien mit Abweichungen, die im Kurs aktiv diskutiert werden.
* **Voice Mode für interaktive Simulationen**: Mithilfe von Voice Mode können die Studierenden verschiedene „Akteure“ in einem simulierten interkulturellen Gespräch übernehmen. Beispielsweise könnte ein Studierender die Rolle eines japanischen Managers übernehmen, der mit einem französischen CEO verhandelt – unterstützt und angeleitet durch das KI-gestützte Voice Mode. Diese Live-Simulationen fördern besonders die Aussprache, interkulturelle Kommunikation und nonverbale Signale (sofern Video/Audio-Komponenten integriert sind).
* **DeepResearch für Problemlösungsvorschläge**: Nach durchgeführten Simulationen nutzen die Studierenden DeepResearch, um Best Practices, wissenschaftliche Artikel und Fallbeispiele zu finden, die ähnliche interkulturelle Herausforderungen beschreiben. Auf dieser Basis erstellen sie Handlungsempfehlungen für die Konfliktlösung. Die Lehrenden geben Feedback, um die studierendenzentrierte Reflexion zu stärken.

**Woche 9–12: KI als „Lernhilfe“**
* **Ziel**: Effektive Prüfungsvorbereitung, Vertiefung und Wiederholung zentraler Inhalte im interkulturellen Management.
* **LLMs für Zusammenfassungen und Wiederholungsfragen**: Studierende lassen sich von Sprachmodellen kurze Zusammenfassungen zentraler Konzepte erstellen (z.B. kulturelle Dimensionen nach Hofstede, Schein, Trompenaars). Die LLMs generieren auf Basis des bisherigen Kursverlaufs zusätzlich Quiz-Fragen oder Kurzantwortaufgaben, um das Verständnis zu überprüfen.
* **Gegenmaßnahme zur Qualitätssicherung**: Die Lehrenden behalten die Kontrolle über die Endversion der Fragen, um unsinnige oder unpassende Aufgaben zu erkennen und zu eliminieren.
* **NotebookLM für Audio-Lerninhalte**: Aus bereits vorhandenen Materialien (Skripte, Diskussionsergebnisse, Fallstudien) generiert NotebookLM weitere Podcast-Folgen, in denen Schlüsselkonzepte erläutert oder wiederholt werden. Studierende können diese Folgen gezielt zur Prüfungsvorbereitung nutzen und dadurch Zeit- und Ortsunabhängigkeit beim Lernen erlangen.
* **Voice Mode für Prüfungssimulationen**: Studierende üben z.B. mündliche Prüfungen oder Präsentationen im interkulturellen Kontext. Sie können sich von Voice Mode Fragen stellen lassen („Wie würden Sie in Situation X reagieren?“) und ihre Antwort direkt in einer realistischen Simulation üben. Dies fördert die rhetorische Sicherheit sowie das spontane Reagieren auf unvorhergesehene Fragen.

### Vorteile und Chancen der Ergänzung der Lehrmaterialien durch KI

* **Realitätsnahe Lernsituationen**: Durch Voice Mode-Simulationen und DeepResearch-gestützte Recherche wirken die Szenarien authentisch und praxisrelevant. Studierende lernen, ihre kulturelle Sensibilität in unterschiedlichen Rollen aktiv zu trainieren.
* **Zeit- und Ressourcenersparnis**: Lehrende profitieren von teilautomatisierten Prozessen (z.B. Erstellung von Fallstudien, Zusammenfassungen, Podcasts). Studierende haben jederzeit Zugriff auf zusätzliche Lernressourcen wie Podcasts oder interaktive Übungen.
* **Adaptives Lernen und Diversität**: LLMs und DeepResearch ermöglichen personalisierte Aufgabenstellungen und themenspezifische Vertiefungen. Kulturelle Diversität kann in den generierten Szenarien leichter abgebildet werden, indem verschiedene Regionen und Blickwinkel integriert werden.

### Risiken und Gegenmaßnahmen

* **Qualität und kulturelle Sensibilität**: *Gegenmaßnahme:* Lehrende prüfen alle generierten Inhalte (Text, Podcasts, Simulationen) auf kulturelle Stereotype und potenzielle Fehlinformationen. Durch Peer-Review unter Studierenden werden Vorurteile oder unangemessene Darstellung früh erkannt.
* **Vertrauenswürdigkeit und akademische Redlichkeit**: *Gegenmaßnahme:* Studierende werden darin geschult, die KI-generierten Inhalte kritisch zu hinterfragen und zu validieren. Sie müssen Quellen nennen und sachlich begründen, wie und warum sie bestimmte KI-Ausgaben nutzen.
* **Datenschutz und ethische Aspekte**: *Gegenmaßnahme:* Sensible Informationen werden anonymisiert, Zugriffsrechte klar geregelt. Studierende erhalten eine Einführung, wie sie KI-Tools sicher und verantwortungsbewusst einsetzen.
* **Technische Abhängigkeit**: *Gegenmaßnahme:* Lehrmaterialien sind zusätzlich offline verfügbar (Skripte, Reader). Auch ohne KI-Tools kann der Kurs fortgesetzt werden.

## Wie bleiben Sie informiert?

Bei einem solch aktuellen Thema helfen gute Sammelstellen für Information, um auf dem Laufenden zu bleiben. Abschließend einige Empfehlungen für gute Informationsquellen zum Thema Generative KI:

* **Newsletter / Substack von Ethan Mollick** der Wharton Business School mit sehr praktischen Übersichten und Empfehlungen: https://www.oneusefulthing.org/. Abonnieren Sie ihn, es lohnt sich.
* **Hochschulforum Digitalisierung**: Themendossier Generative KI: https://hochschulforumdigitalisierung.de/dossier/generative-ki/
* **E-Teaching.org**: KI in Studium und Lehre: https://www.e-teaching.org/praxis/themenseiten/ki-in-studium-und-lehre
* Eine große Anzahl an sehr guten **didaktischen Prompts** vom Team der Wharton Business School findet sich hier: https://www.moreusefulthings.com/prompts. Hervorzuheben sind v.a. die „**Blueprints**“, also Vorlagen, die für die eigene Lehre angepasst werden können (s.u. für zwei Beispiele).
* Die Universität Harvard gibt hier eine Reihe von **Beispielen, wie GenAI in der Lehre** genutzt wird, u.a. mit Beispielen für Simulationen, Sprachdidaktik u.v.m.: https://bokcenter.harvard.edu/examples-and-ideas-for-using-AI-for-your-teaching.
* Etwas breiter – **wie nutzen 76.000 Lehrende KI an Hochschulen**? Die KI-Firma Anthropic hat gerade einen Bericht herausgebracht, der anonymisiert basierend auf echten Interaktionen betrachtet, wie KI in der Lehre genutzt wird: https://www.anthropic.com/news/anthropic-education-report-how-educators-use-claude [@bent2025]. Im Kontext von Rollenspielen ist hier interessant, wie die Online-Interaktion des GPT-Konkurrenten genutzt werden („Claude Artifacts“), speziell für „Interactive Educational Games“.
* **Fortbildungen und Übersichten mit Anwendungsfokus**: Sowohl Google als auch Claude und OpenAI bieten Kurse für die technischen Aspekte der Nutzung von KI in der Lehre an: https://grow.google/ai-for-educators/, https://anthropic.skilljar.com/ai-fluency-framework-foundations.